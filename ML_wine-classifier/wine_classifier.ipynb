{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__\n",
    "pd.options.display.max_rows=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 데이터 전처리\n",
    "데이터를 읽어들인 뒤, 읽어들인 데이터프레임을 display 함수를 통해 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25</td>\n",
       "      <td>67</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32</td>\n",
       "      <td>44</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39</td>\n",
       "      <td>51</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32</td>\n",
       "      <td>44</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                      11                    34  0.99780  3.51       0.56   \n",
       "1                      25                    67  0.99680  3.20       0.68   \n",
       "2                      15                    54  0.99700  3.26       0.65   \n",
       "3                      17                    60  0.99800  3.16       0.58   \n",
       "4                      11                    34  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                   32                    44  0.99490  3.45       0.58   \n",
       "1595                   39                    51  0.99512  3.52       0.76   \n",
       "1596                   29                    40  0.99574  3.42       0.75   \n",
       "1597                   32                    44  0.99547  3.57       0.71   \n",
       "1598                   18                    42  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "white_wine = pd.read_csv(\"winequality-white.csv\")\n",
    "red_wine = pd.read_csv(\"winequality-red.csv\")\n",
    "\n",
    "display(white_wine)\n",
    "display(red_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(df, t_r):\n",
    "\n",
    "    df = df.values\n",
    "    X_train,X_test = train_test_split(df, train_size = t_r, shuffle = False, random_state = 1004)\n",
    "    Y_train = X_train[:,11]\n",
    "    X_train = X_train[:,:11]\n",
    "    Y_test = X_test[:,11]\n",
    "    X_test = X_test[:,:11]\n",
    "    Y_train = np_utils.to_categorical(Y_train,11)\n",
    "    Y_test = np_utils.to_categorical(Y_test,11)\n",
    "\n",
    "\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = generate_data(white_wine, 0.7)\n",
    "X_train, Y_train, X_test, Y_test = generate_data(red_wine,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 케라스를 이용한 모델 생성, 학습, 테스트\n",
    "입력 데이터와 정답 셋이 만들어졌으니 케라스를 사용하여 각 데이터에 대한 분류기를 생성하고, 트레이닝 셋으로 학습시킨 뒤 테스트 정확도를 관찰합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제\n",
    "### 1. 화이트 와인 분류 모델과 레드 와인 분류 모델 설계 및 학습\n",
    "* 하나의 히든 레이어에 32개의 노드를 가진 인공신경망 모델 생성 및 모델 학습\n",
    "* 트레이닝 Epoch에 따라 Loss의 변화를 그래프로 시각화\n",
    "* 테스트 셋에 대한 정확도 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "54/54 [==============================] - 3s 47ms/step - loss: 8.4635 - accuracy: 0.3814 - val_loss: 2.2443 - val_accuracy: 0.4429\n",
      "Epoch 2/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 2.4012 - accuracy: 0.3973 - val_loss: 1.3891 - val_accuracy: 0.4673\n",
      "Epoch 3/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4149 - accuracy: 0.4229 - val_loss: 1.3068 - val_accuracy: 0.4980\n",
      "Epoch 4/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.3684 - accuracy: 0.4323 - val_loss: 1.2132 - val_accuracy: 0.4939\n",
      "Epoch 5/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.3255 - accuracy: 0.4342 - val_loss: 1.2664 - val_accuracy: 0.4224\n",
      "Epoch 6/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.3599 - accuracy: 0.4211 - val_loss: 1.1949 - val_accuracy: 0.4748\n",
      "Epoch 7/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2733 - accuracy: 0.4259 - val_loss: 1.1771 - val_accuracy: 0.4816\n",
      "Epoch 8/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2660 - accuracy: 0.4370 - val_loss: 1.1879 - val_accuracy: 0.4680\n",
      "Epoch 9/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2570 - accuracy: 0.4248 - val_loss: 1.1661 - val_accuracy: 0.4871\n",
      "Epoch 10/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2888 - accuracy: 0.4135 - val_loss: 1.1492 - val_accuracy: 0.4782\n",
      "Epoch 11/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2778 - accuracy: 0.4306 - val_loss: 1.1852 - val_accuracy: 0.4456\n",
      "Epoch 12/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2427 - accuracy: 0.4468 - val_loss: 1.2179 - val_accuracy: 0.4912\n",
      "Epoch 13/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2601 - accuracy: 0.4268 - val_loss: 1.1401 - val_accuracy: 0.4891\n",
      "Epoch 14/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2426 - accuracy: 0.4348 - val_loss: 1.1603 - val_accuracy: 0.4721\n",
      "Epoch 15/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2392 - accuracy: 0.4495 - val_loss: 1.1541 - val_accuracy: 0.4592\n",
      "Epoch 16/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2366 - accuracy: 0.4568 - val_loss: 1.1702 - val_accuracy: 0.4435\n",
      "Epoch 17/200\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.2341 - accuracy: 0.4587 - val_loss: 1.1322 - val_accuracy: 0.4864\n",
      "Epoch 18/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2408 - accuracy: 0.4571 - val_loss: 1.1473 - val_accuracy: 0.4748\n",
      "Epoch 19/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2373 - accuracy: 0.4369 - val_loss: 1.1341 - val_accuracy: 0.4755\n",
      "Epoch 20/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2190 - accuracy: 0.4572 - val_loss: 1.1565 - val_accuracy: 0.4966\n",
      "Epoch 21/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2519 - accuracy: 0.4346 - val_loss: 1.1192 - val_accuracy: 0.5020\n",
      "Epoch 22/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1994 - accuracy: 0.4510 - val_loss: 1.1389 - val_accuracy: 0.4878\n",
      "Epoch 23/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2438 - accuracy: 0.4477 - val_loss: 1.1711 - val_accuracy: 0.4694\n",
      "Epoch 24/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2260 - accuracy: 0.4570 - val_loss: 1.1409 - val_accuracy: 0.4871\n",
      "Epoch 25/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2279 - accuracy: 0.4598 - val_loss: 1.1361 - val_accuracy: 0.4735\n",
      "Epoch 26/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1959 - accuracy: 0.4529 - val_loss: 1.1546 - val_accuracy: 0.4993\n",
      "Epoch 27/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1922 - accuracy: 0.4861 - val_loss: 1.1529 - val_accuracy: 0.5224\n",
      "Epoch 28/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2128 - accuracy: 0.4720 - val_loss: 1.1665 - val_accuracy: 0.4878\n",
      "Epoch 29/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2055 - accuracy: 0.4630 - val_loss: 1.1137 - val_accuracy: 0.5048\n",
      "Epoch 30/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2054 - accuracy: 0.4684 - val_loss: 1.1304 - val_accuracy: 0.4884\n",
      "Epoch 31/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2334 - accuracy: 0.4475 - val_loss: 1.1071 - val_accuracy: 0.5299\n",
      "Epoch 32/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1810 - accuracy: 0.4815 - val_loss: 1.1329 - val_accuracy: 0.4857\n",
      "Epoch 33/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1744 - accuracy: 0.4848 - val_loss: 1.1784 - val_accuracy: 0.4925\n",
      "Epoch 34/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2081 - accuracy: 0.4614 - val_loss: 1.1644 - val_accuracy: 0.4769\n",
      "Epoch 35/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1810 - accuracy: 0.4770 - val_loss: 1.1349 - val_accuracy: 0.5041\n",
      "Epoch 36/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1754 - accuracy: 0.4710 - val_loss: 1.1311 - val_accuracy: 0.4728\n",
      "Epoch 37/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1778 - accuracy: 0.4826 - val_loss: 1.1729 - val_accuracy: 0.4476\n",
      "Epoch 38/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2054 - accuracy: 0.4552 - val_loss: 1.0810 - val_accuracy: 0.5088\n",
      "Epoch 39/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1810 - accuracy: 0.4639 - val_loss: 1.1305 - val_accuracy: 0.5177\n",
      "Epoch 40/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1884 - accuracy: 0.4727 - val_loss: 1.0990 - val_accuracy: 0.4939\n",
      "Epoch 41/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1644 - accuracy: 0.4726 - val_loss: 1.0901 - val_accuracy: 0.4898\n",
      "Epoch 42/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1844 - accuracy: 0.4704 - val_loss: 1.1450 - val_accuracy: 0.4673\n",
      "Epoch 43/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2011 - accuracy: 0.4712 - val_loss: 1.1140 - val_accuracy: 0.4864\n",
      "Epoch 44/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1885 - accuracy: 0.4704 - val_loss: 1.0952 - val_accuracy: 0.5116\n",
      "Epoch 45/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1740 - accuracy: 0.4889 - val_loss: 1.0765 - val_accuracy: 0.5156\n",
      "Epoch 46/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1673 - accuracy: 0.4925 - val_loss: 1.1083 - val_accuracy: 0.5048\n",
      "Epoch 47/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1826 - accuracy: 0.4768 - val_loss: 1.0943 - val_accuracy: 0.5068\n",
      "Epoch 48/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2040 - accuracy: 0.4640 - val_loss: 1.0972 - val_accuracy: 0.5272\n",
      "Epoch 49/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2111 - accuracy: 0.4709 - val_loss: 1.1764 - val_accuracy: 0.4143\n",
      "Epoch 50/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1804 - accuracy: 0.4642 - val_loss: 1.1745 - val_accuracy: 0.4068\n",
      "Epoch 51/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2148 - accuracy: 0.4642 - val_loss: 1.0964 - val_accuracy: 0.4864\n",
      "Epoch 52/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1969 - accuracy: 0.4808 - val_loss: 1.0853 - val_accuracy: 0.5075\n",
      "Epoch 53/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1564 - accuracy: 0.4888 - val_loss: 1.1339 - val_accuracy: 0.4816\n",
      "Epoch 54/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1891 - accuracy: 0.4669 - val_loss: 1.1701 - val_accuracy: 0.4531\n",
      "Epoch 55/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1725 - accuracy: 0.4831 - val_loss: 1.1475 - val_accuracy: 0.4633\n",
      "Epoch 56/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1601 - accuracy: 0.4692 - val_loss: 1.1215 - val_accuracy: 0.5136\n",
      "Epoch 57/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1694 - accuracy: 0.4815 - val_loss: 1.0911 - val_accuracy: 0.4980\n",
      "Epoch 58/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1838 - accuracy: 0.4730 - val_loss: 1.1189 - val_accuracy: 0.4694\n",
      "Epoch 59/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1736 - accuracy: 0.4736 - val_loss: 1.1922 - val_accuracy: 0.4524\n",
      "Epoch 60/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1651 - accuracy: 0.4852 - val_loss: 1.1019 - val_accuracy: 0.4952\n",
      "Epoch 61/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1471 - accuracy: 0.4993 - val_loss: 1.0838 - val_accuracy: 0.5177\n",
      "Epoch 62/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1438 - accuracy: 0.5006 - val_loss: 1.1011 - val_accuracy: 0.5163\n",
      "Epoch 63/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1817 - accuracy: 0.4778 - val_loss: 1.1010 - val_accuracy: 0.5170\n",
      "Epoch 64/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1661 - accuracy: 0.4893 - val_loss: 1.1372 - val_accuracy: 0.4381\n",
      "Epoch 65/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1591 - accuracy: 0.4774 - val_loss: 1.1815 - val_accuracy: 0.4238\n",
      "Epoch 66/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1712 - accuracy: 0.4867 - val_loss: 1.1828 - val_accuracy: 0.4503\n",
      "Epoch 67/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1774 - accuracy: 0.4842 - val_loss: 1.1065 - val_accuracy: 0.5156\n",
      "Epoch 68/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1577 - accuracy: 0.4833 - val_loss: 1.0791 - val_accuracy: 0.5095\n",
      "Epoch 69/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1544 - accuracy: 0.4915 - val_loss: 1.2052 - val_accuracy: 0.4020\n",
      "Epoch 70/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1768 - accuracy: 0.4873 - val_loss: 1.0798 - val_accuracy: 0.5299\n",
      "Epoch 71/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1835 - accuracy: 0.4758 - val_loss: 1.1338 - val_accuracy: 0.4857\n",
      "Epoch 72/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1576 - accuracy: 0.5023 - val_loss: 1.1151 - val_accuracy: 0.4850\n",
      "Epoch 73/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1664 - accuracy: 0.4788 - val_loss: 1.0915 - val_accuracy: 0.5680\n",
      "Epoch 74/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1823 - accuracy: 0.4779 - val_loss: 1.1002 - val_accuracy: 0.5367\n",
      "Epoch 75/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1779 - accuracy: 0.4989 - val_loss: 1.0927 - val_accuracy: 0.4912\n",
      "Epoch 76/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1581 - accuracy: 0.4806 - val_loss: 1.1505 - val_accuracy: 0.4265\n",
      "Epoch 77/200\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1379 - accuracy: 0.4973 - val_loss: 1.1518 - val_accuracy: 0.4646\n",
      "Epoch 78/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1480 - accuracy: 0.5002 - val_loss: 1.0881 - val_accuracy: 0.5163\n",
      "Epoch 79/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1395 - accuracy: 0.5023 - val_loss: 1.0874 - val_accuracy: 0.4959\n",
      "Epoch 80/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1457 - accuracy: 0.4954 - val_loss: 1.0687 - val_accuracy: 0.5293\n",
      "Epoch 81/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1499 - accuracy: 0.4982 - val_loss: 1.1126 - val_accuracy: 0.5027\n",
      "Epoch 82/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1505 - accuracy: 0.4923 - val_loss: 1.1604 - val_accuracy: 0.4483\n",
      "Epoch 83/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2086 - accuracy: 0.4469 - val_loss: 1.1764 - val_accuracy: 0.4048\n",
      "Epoch 84/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1586 - accuracy: 0.5029 - val_loss: 1.1535 - val_accuracy: 0.4517\n",
      "Epoch 85/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1894 - accuracy: 0.4757 - val_loss: 1.1165 - val_accuracy: 0.4925\n",
      "Epoch 86/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1624 - accuracy: 0.4946 - val_loss: 1.0732 - val_accuracy: 0.5388\n",
      "Epoch 87/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1224 - accuracy: 0.5051 - val_loss: 1.1224 - val_accuracy: 0.4762\n",
      "Epoch 88/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1486 - accuracy: 0.5078 - val_loss: 1.0810 - val_accuracy: 0.5401\n",
      "Epoch 89/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1358 - accuracy: 0.4957 - val_loss: 1.1248 - val_accuracy: 0.4612\n",
      "Epoch 90/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1793 - accuracy: 0.4728 - val_loss: 1.1366 - val_accuracy: 0.4599\n",
      "Epoch 91/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1406 - accuracy: 0.5074 - val_loss: 1.0935 - val_accuracy: 0.5286\n",
      "Epoch 92/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1485 - accuracy: 0.4950 - val_loss: 1.1070 - val_accuracy: 0.5122\n",
      "Epoch 93/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1390 - accuracy: 0.5102 - val_loss: 1.1041 - val_accuracy: 0.4959\n",
      "Epoch 94/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1426 - accuracy: 0.4890 - val_loss: 1.1450 - val_accuracy: 0.4259\n",
      "Epoch 95/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1745 - accuracy: 0.4874 - val_loss: 1.0774 - val_accuracy: 0.5143\n",
      "Epoch 96/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1762 - accuracy: 0.4759 - val_loss: 1.0674 - val_accuracy: 0.5279\n",
      "Epoch 97/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1467 - accuracy: 0.4957 - val_loss: 1.1429 - val_accuracy: 0.4340\n",
      "Epoch 98/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1555 - accuracy: 0.4983 - val_loss: 1.0588 - val_accuracy: 0.5327\n",
      "Epoch 99/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1443 - accuracy: 0.5073 - val_loss: 1.0815 - val_accuracy: 0.5177\n",
      "Epoch 100/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1709 - accuracy: 0.4903 - val_loss: 1.1825 - val_accuracy: 0.4082\n",
      "Epoch 101/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1562 - accuracy: 0.5093 - val_loss: 1.1020 - val_accuracy: 0.4952\n",
      "Epoch 102/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1424 - accuracy: 0.5022 - val_loss: 1.0669 - val_accuracy: 0.5034\n",
      "Epoch 103/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1329 - accuracy: 0.4970 - val_loss: 1.1748 - val_accuracy: 0.4571\n",
      "Epoch 104/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1389 - accuracy: 0.5133 - val_loss: 1.1125 - val_accuracy: 0.4891\n",
      "Epoch 105/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1367 - accuracy: 0.5071 - val_loss: 1.0720 - val_accuracy: 0.5449\n",
      "Epoch 106/200\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1581 - accuracy: 0.4999 - val_loss: 1.1033 - val_accuracy: 0.5122\n",
      "Epoch 107/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1235 - accuracy: 0.5012 - val_loss: 1.0924 - val_accuracy: 0.4980\n",
      "Epoch 108/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1409 - accuracy: 0.5044 - val_loss: 1.0668 - val_accuracy: 0.5245\n",
      "Epoch 109/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1404 - accuracy: 0.5132 - val_loss: 1.1169 - val_accuracy: 0.4912\n",
      "Epoch 110/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1623 - accuracy: 0.5054 - val_loss: 1.0852 - val_accuracy: 0.5265\n",
      "Epoch 111/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1390 - accuracy: 0.4964 - val_loss: 1.0739 - val_accuracy: 0.5524\n",
      "Epoch 112/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1485 - accuracy: 0.4798 - val_loss: 1.0992 - val_accuracy: 0.4925\n",
      "Epoch 113/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1329 - accuracy: 0.4944 - val_loss: 1.0767 - val_accuracy: 0.5231\n",
      "Epoch 114/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1325 - accuracy: 0.5163 - val_loss: 1.0989 - val_accuracy: 0.4803\n",
      "Epoch 115/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1469 - accuracy: 0.4843 - val_loss: 1.1005 - val_accuracy: 0.4932\n",
      "Epoch 116/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1442 - accuracy: 0.4994 - val_loss: 1.1420 - val_accuracy: 0.4571\n",
      "Epoch 117/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1455 - accuracy: 0.4955 - val_loss: 1.1030 - val_accuracy: 0.4857\n",
      "Epoch 118/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1599 - accuracy: 0.5028 - val_loss: 1.0650 - val_accuracy: 0.5354\n",
      "Epoch 119/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1633 - accuracy: 0.4997 - val_loss: 1.1285 - val_accuracy: 0.4585\n",
      "Epoch 120/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1282 - accuracy: 0.5134 - val_loss: 1.0970 - val_accuracy: 0.5259\n",
      "Epoch 121/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1496 - accuracy: 0.4901 - val_loss: 1.0831 - val_accuracy: 0.5224\n",
      "Epoch 122/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1475 - accuracy: 0.5009 - val_loss: 1.0630 - val_accuracy: 0.5259\n",
      "Epoch 123/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1205 - accuracy: 0.5148 - val_loss: 1.1543 - val_accuracy: 0.4551\n",
      "Epoch 124/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1309 - accuracy: 0.5119 - val_loss: 1.1657 - val_accuracy: 0.4333\n",
      "Epoch 125/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1545 - accuracy: 0.5042 - val_loss: 1.0723 - val_accuracy: 0.5041\n",
      "Epoch 126/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1163 - accuracy: 0.5129 - val_loss: 1.1083 - val_accuracy: 0.5075\n",
      "Epoch 127/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1503 - accuracy: 0.4859 - val_loss: 1.0927 - val_accuracy: 0.4769\n",
      "Epoch 128/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1334 - accuracy: 0.4972 - val_loss: 1.0858 - val_accuracy: 0.5170\n",
      "Epoch 129/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1474 - accuracy: 0.5002 - val_loss: 1.0812 - val_accuracy: 0.5109\n",
      "Epoch 130/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1424 - accuracy: 0.5045 - val_loss: 1.0920 - val_accuracy: 0.4850\n",
      "Epoch 131/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1419 - accuracy: 0.5008 - val_loss: 1.0700 - val_accuracy: 0.5034\n",
      "Epoch 132/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1441 - accuracy: 0.4943 - val_loss: 1.1163 - val_accuracy: 0.4823\n",
      "Epoch 133/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1101 - accuracy: 0.5066 - val_loss: 1.0831 - val_accuracy: 0.5177\n",
      "Epoch 134/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1205 - accuracy: 0.5164 - val_loss: 1.0868 - val_accuracy: 0.5034\n",
      "Epoch 135/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1540 - accuracy: 0.4920 - val_loss: 1.0701 - val_accuracy: 0.5014\n",
      "Epoch 136/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1474 - accuracy: 0.5126 - val_loss: 1.0886 - val_accuracy: 0.4891\n",
      "Epoch 137/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1282 - accuracy: 0.5122 - val_loss: 1.0700 - val_accuracy: 0.5469\n",
      "Epoch 138/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1213 - accuracy: 0.4937 - val_loss: 1.0921 - val_accuracy: 0.5177\n",
      "Epoch 139/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1518 - accuracy: 0.4941 - val_loss: 1.0907 - val_accuracy: 0.4830\n",
      "Epoch 140/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1354 - accuracy: 0.5080 - val_loss: 1.0783 - val_accuracy: 0.5014\n",
      "Epoch 141/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1145 - accuracy: 0.5072 - val_loss: 1.1134 - val_accuracy: 0.4694\n",
      "Epoch 142/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1469 - accuracy: 0.4803 - val_loss: 1.0771 - val_accuracy: 0.5211\n",
      "Epoch 143/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1334 - accuracy: 0.5178 - val_loss: 1.0566 - val_accuracy: 0.5177\n",
      "Epoch 144/200\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1256 - accuracy: 0.4975 - val_loss: 1.0502 - val_accuracy: 0.5299\n",
      "Epoch 145/200\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1455 - accuracy: 0.4857 - val_loss: 1.0901 - val_accuracy: 0.5122\n",
      "Epoch 146/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1309 - accuracy: 0.5126 - val_loss: 1.0668 - val_accuracy: 0.5184\n",
      "Epoch 147/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1077 - accuracy: 0.5180 - val_loss: 1.0945 - val_accuracy: 0.4905\n",
      "Epoch 148/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1200 - accuracy: 0.5105 - val_loss: 1.1589 - val_accuracy: 0.4748\n",
      "Epoch 149/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1546 - accuracy: 0.5005 - val_loss: 1.0535 - val_accuracy: 0.5381\n",
      "Epoch 150/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1236 - accuracy: 0.5023 - val_loss: 1.0694 - val_accuracy: 0.5190\n",
      "Epoch 151/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1360 - accuracy: 0.4884 - val_loss: 1.1016 - val_accuracy: 0.4986\n",
      "Epoch 152/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1174 - accuracy: 0.5089 - val_loss: 1.1691 - val_accuracy: 0.4347\n",
      "Epoch 153/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1455 - accuracy: 0.4985 - val_loss: 1.0984 - val_accuracy: 0.4939\n",
      "Epoch 154/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1670 - accuracy: 0.4930 - val_loss: 1.0640 - val_accuracy: 0.5102\n",
      "Epoch 155/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1435 - accuracy: 0.5016 - val_loss: 1.0488 - val_accuracy: 0.5347\n",
      "Epoch 156/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1098 - accuracy: 0.5141 - val_loss: 1.1835 - val_accuracy: 0.4224\n",
      "Epoch 157/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1492 - accuracy: 0.4966 - val_loss: 1.0896 - val_accuracy: 0.4925\n",
      "Epoch 158/200\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1362 - accuracy: 0.5089 - val_loss: 1.0822 - val_accuracy: 0.5007\n",
      "Epoch 159/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1186 - accuracy: 0.5093 - val_loss: 1.0691 - val_accuracy: 0.5054\n",
      "Epoch 160/200\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1201 - accuracy: 0.5101 - val_loss: 1.1910 - val_accuracy: 0.4136\n",
      "Epoch 161/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1502 - accuracy: 0.5112 - val_loss: 1.1098 - val_accuracy: 0.4755\n",
      "Epoch 162/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1339 - accuracy: 0.5069 - val_loss: 1.0270 - val_accuracy: 0.5612\n",
      "Epoch 163/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1576 - accuracy: 0.5005 - val_loss: 1.1323 - val_accuracy: 0.4313\n",
      "Epoch 164/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1554 - accuracy: 0.5143 - val_loss: 1.0772 - val_accuracy: 0.4980\n",
      "Epoch 165/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1165 - accuracy: 0.5139 - val_loss: 1.1763 - val_accuracy: 0.4871\n",
      "Epoch 166/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1366 - accuracy: 0.5045 - val_loss: 1.1166 - val_accuracy: 0.4585\n",
      "Epoch 167/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1229 - accuracy: 0.5169 - val_loss: 1.0768 - val_accuracy: 0.5061\n",
      "Epoch 168/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1127 - accuracy: 0.5052 - val_loss: 1.1717 - val_accuracy: 0.4925\n",
      "Epoch 169/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1330 - accuracy: 0.5042 - val_loss: 1.0574 - val_accuracy: 0.5204\n",
      "Epoch 170/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1306 - accuracy: 0.5114 - val_loss: 1.0656 - val_accuracy: 0.5231\n",
      "Epoch 171/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1210 - accuracy: 0.5135 - val_loss: 1.1466 - val_accuracy: 0.4456\n",
      "Epoch 172/200\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1269 - accuracy: 0.5028 - val_loss: 1.0632 - val_accuracy: 0.5408\n",
      "Epoch 173/200\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1433 - accuracy: 0.4952 - val_loss: 1.1078 - val_accuracy: 0.4755\n",
      "Epoch 174/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1318 - accuracy: 0.5014 - val_loss: 1.0856 - val_accuracy: 0.4878\n",
      "Epoch 175/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1123 - accuracy: 0.5281 - val_loss: 1.0497 - val_accuracy: 0.5265\n",
      "Epoch 176/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1230 - accuracy: 0.5116 - val_loss: 1.2134 - val_accuracy: 0.3830\n",
      "Epoch 177/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1188 - accuracy: 0.5203 - val_loss: 1.0646 - val_accuracy: 0.5027\n",
      "Epoch 178/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1229 - accuracy: 0.5192 - val_loss: 1.1398 - val_accuracy: 0.4721\n",
      "Epoch 179/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1582 - accuracy: 0.4979 - val_loss: 1.0636 - val_accuracy: 0.4952\n",
      "Epoch 180/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1439 - accuracy: 0.4934 - val_loss: 1.0430 - val_accuracy: 0.5735\n",
      "Epoch 181/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1395 - accuracy: 0.5081 - val_loss: 1.0540 - val_accuracy: 0.5320\n",
      "Epoch 182/200\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1405 - accuracy: 0.4867 - val_loss: 1.1237 - val_accuracy: 0.5020\n",
      "Epoch 183/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1445 - accuracy: 0.5026 - val_loss: 1.1114 - val_accuracy: 0.4735\n",
      "Epoch 184/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1552 - accuracy: 0.4879 - val_loss: 1.0781 - val_accuracy: 0.5170\n",
      "Epoch 185/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1227 - accuracy: 0.5069 - val_loss: 1.0800 - val_accuracy: 0.4918\n",
      "Epoch 186/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1152 - accuracy: 0.5104 - val_loss: 1.1203 - val_accuracy: 0.4728\n",
      "Epoch 187/200\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1347 - accuracy: 0.5046 - val_loss: 1.0663 - val_accuracy: 0.5197\n",
      "Epoch 188/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1153 - accuracy: 0.5149 - val_loss: 1.1153 - val_accuracy: 0.4823\n",
      "Epoch 189/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1181 - accuracy: 0.5035 - val_loss: 1.0746 - val_accuracy: 0.4966\n",
      "Epoch 190/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1260 - accuracy: 0.5192 - val_loss: 1.1044 - val_accuracy: 0.4483\n",
      "Epoch 191/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0857 - accuracy: 0.5349 - val_loss: 1.0670 - val_accuracy: 0.5007\n",
      "Epoch 192/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1223 - accuracy: 0.5115 - val_loss: 1.1314 - val_accuracy: 0.4476\n",
      "Epoch 193/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0959 - accuracy: 0.5256 - val_loss: 1.1296 - val_accuracy: 0.4741\n",
      "Epoch 194/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1022 - accuracy: 0.5363 - val_loss: 1.1267 - val_accuracy: 0.4776\n",
      "Epoch 195/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1421 - accuracy: 0.5165 - val_loss: 1.0406 - val_accuracy: 0.5544\n",
      "Epoch 196/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1288 - accuracy: 0.5121 - val_loss: 1.0809 - val_accuracy: 0.5034\n",
      "Epoch 197/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1184 - accuracy: 0.5306 - val_loss: 1.0653 - val_accuracy: 0.5286\n",
      "Epoch 198/200\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1477 - accuracy: 0.4879 - val_loss: 1.0452 - val_accuracy: 0.5231\n",
      "Epoch 199/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1138 - accuracy: 0.5063 - val_loss: 1.0876 - val_accuracy: 0.4932\n",
      "Epoch 200/200\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1309 - accuracy: 0.5240 - val_loss: 1.0526 - val_accuracy: 0.5075\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(units = 32,input_dim = 11,activation = 'relu'))\n",
    "model.add(keras.layers.Dense(units = 11,activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "              \n",
    "           \n",
    "\n",
    "hist = model.fit(x_train,y_train,epochs=200,batch_size=64,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 트레이닝 Epoch에 따라 Loss의 변화를 그래프로 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "acc_ax =ax1.twinx()\n",
    "\n",
    "ax1.plot(hist.history['loss'], 'y', label='train loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "\n",
    "\n",
    "ax2.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "ax2.set_ylabel('val_loss')\n",
    "\n",
    "\n",
    "ax3.plot(hist.history['accuracy'], 'b', label='accuracy')\n",
    "ax3.set_ylabel('accuray')\n",
    "\n",
    "ax4.plot(hist.history['val_accuracy'], 'g', label='val_accuracy')\n",
    "ax4.set_ylabel('val_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> comment\n",
    "epoch이 0에 가까이 떨어지지 않는 것을 확인할 수 있었다. 아직 train이 완벽하게 되지 않았다고 생각한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 - 0s - loss: 1.0526 - accuracy: 0.5075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0526217222213745, 0.5074830055236816]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test,verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 23ms/step - loss: 12.1766 - accuracy: 0.0203 - val_loss: 13.9985 - val_accuracy: 0.3605\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.8358 - accuracy: 0.2004 - val_loss: 7.6437 - val_accuracy: 0.1986\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 3.1394 - accuracy: 0.2763 - val_loss: 5.9134 - val_accuracy: 0.3122\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.0778 - accuracy: 0.4619 - val_loss: 3.7517 - val_accuracy: 0.3401\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6497 - accuracy: 0.4940 - val_loss: 3.8524 - val_accuracy: 0.2898\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4971 - accuracy: 0.4832 - val_loss: 3.6825 - val_accuracy: 0.2952\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.4230 - accuracy: 0.4954 - val_loss: 3.3274 - val_accuracy: 0.2878\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.3255 - accuracy: 0.5060 - val_loss: 3.1456 - val_accuracy: 0.2891\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.3538 - accuracy: 0.4993 - val_loss: 2.9413 - val_accuracy: 0.2435\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.3072 - accuracy: 0.5040 - val_loss: 3.0249 - val_accuracy: 0.2633\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2567 - accuracy: 0.4908 - val_loss: 2.6032 - val_accuracy: 0.2476\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.2326 - accuracy: 0.4998 - val_loss: 2.5550 - val_accuracy: 0.2680\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1756 - accuracy: 0.4843 - val_loss: 2.5482 - val_accuracy: 0.2694\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1831 - accuracy: 0.5000 - val_loss: 2.6875 - val_accuracy: 0.2673\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1948 - accuracy: 0.4869 - val_loss: 2.5314 - val_accuracy: 0.2687\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1952 - accuracy: 0.5066 - val_loss: 2.5320 - val_accuracy: 0.2673\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.2004 - accuracy: 0.5172 - val_loss: 2.3253 - val_accuracy: 0.2707\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1357 - accuracy: 0.5211 - val_loss: 2.4710 - val_accuracy: 0.2680\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1548 - accuracy: 0.5119 - val_loss: 2.0508 - val_accuracy: 0.2769\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1476 - accuracy: 0.4919 - val_loss: 2.1576 - val_accuracy: 0.2714\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1559 - accuracy: 0.5041 - val_loss: 2.3102 - val_accuracy: 0.2707\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.1150 - accuracy: 0.5294 - val_loss: 2.3273 - val_accuracy: 0.2701\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0888 - accuracy: 0.5217 - val_loss: 2.0821 - val_accuracy: 0.2721\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1223 - accuracy: 0.5229 - val_loss: 2.0311 - val_accuracy: 0.2714\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1290 - accuracy: 0.5261 - val_loss: 2.2697 - val_accuracy: 0.2707\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.1374 - accuracy: 0.5161 - val_loss: 2.4329 - val_accuracy: 0.2660\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0967 - accuracy: 0.4976 - val_loss: 2.3464 - val_accuracy: 0.2537\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0939 - accuracy: 0.5254 - val_loss: 2.4022 - val_accuracy: 0.2667\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1164 - accuracy: 0.5032 - val_loss: 2.4058 - val_accuracy: 0.2653\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0828 - accuracy: 0.5389 - val_loss: 2.1472 - val_accuracy: 0.2633\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1165 - accuracy: 0.5160 - val_loss: 2.2945 - val_accuracy: 0.2673\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0622 - accuracy: 0.5192 - val_loss: 2.1886 - val_accuracy: 0.2660\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0808 - accuracy: 0.5259 - val_loss: 2.0217 - val_accuracy: 0.2694\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1028 - accuracy: 0.5188 - val_loss: 2.0202 - val_accuracy: 0.2558\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.1075 - accuracy: 0.5334 - val_loss: 2.3069 - val_accuracy: 0.2680\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0970 - accuracy: 0.4999 - val_loss: 2.2445 - val_accuracy: 0.2673\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0805 - accuracy: 0.5457 - val_loss: 2.3559 - val_accuracy: 0.2571\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.1187 - accuracy: 0.5128 - val_loss: 2.2483 - val_accuracy: 0.2680\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0594 - accuracy: 0.5188 - val_loss: 2.1175 - val_accuracy: 0.2524\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0355 - accuracy: 0.5184 - val_loss: 1.9452 - val_accuracy: 0.2673\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0886 - accuracy: 0.5194 - val_loss: 1.9195 - val_accuracy: 0.2585\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0832 - accuracy: 0.5341 - val_loss: 2.0289 - val_accuracy: 0.2626\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0742 - accuracy: 0.5325 - val_loss: 2.0708 - val_accuracy: 0.2510\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0645 - accuracy: 0.5282 - val_loss: 2.2501 - val_accuracy: 0.2660\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0679 - accuracy: 0.5222 - val_loss: 2.1531 - val_accuracy: 0.2517\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0796 - accuracy: 0.5165 - val_loss: 1.9971 - val_accuracy: 0.2687\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0489 - accuracy: 0.5470 - val_loss: 2.0393 - val_accuracy: 0.2578\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0516 - accuracy: 0.5331 - val_loss: 1.8792 - val_accuracy: 0.2605\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0299 - accuracy: 0.5436 - val_loss: 1.7532 - val_accuracy: 0.2558\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0728 - accuracy: 0.5396 - val_loss: 2.0321 - val_accuracy: 0.2456\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0307 - accuracy: 0.5381 - val_loss: 1.8677 - val_accuracy: 0.2612\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0252 - accuracy: 0.5240 - val_loss: 2.0006 - val_accuracy: 0.2571\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0691 - accuracy: 0.5401 - val_loss: 2.2045 - val_accuracy: 0.2544\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.0332 - accuracy: 0.5655 - val_loss: 2.0364 - val_accuracy: 0.2585\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0332 - accuracy: 0.5473 - val_loss: 2.0787 - val_accuracy: 0.2612\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0699 - accuracy: 0.5130 - val_loss: 1.8243 - val_accuracy: 0.2653\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0065 - accuracy: 0.5508 - val_loss: 1.8350 - val_accuracy: 0.2551\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 1.0148 - accuracy: 0.5730 - val_loss: 2.0111 - val_accuracy: 0.2531\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0513 - accuracy: 0.5304 - val_loss: 1.8412 - val_accuracy: 0.2626\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0164 - accuracy: 0.5237 - val_loss: 1.9081 - val_accuracy: 0.2388\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0427 - accuracy: 0.5521 - val_loss: 1.9925 - val_accuracy: 0.2571\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0544 - accuracy: 0.5469 - val_loss: 1.9083 - val_accuracy: 0.2585\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0547 - accuracy: 0.5438 - val_loss: 1.8870 - val_accuracy: 0.2531\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0197 - accuracy: 0.5458 - val_loss: 2.1083 - val_accuracy: 0.2565\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0364 - accuracy: 0.5481 - val_loss: 2.2605 - val_accuracy: 0.2571\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0368 - accuracy: 0.5495 - val_loss: 2.2116 - val_accuracy: 0.2667\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 1.0283 - accuracy: 0.5478 - val_loss: 1.7777 - val_accuracy: 0.2578\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0169 - accuracy: 0.5371 - val_loss: 1.7844 - val_accuracy: 0.2497\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0141 - accuracy: 0.5209 - val_loss: 1.9108 - val_accuracy: 0.2490\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0416 - accuracy: 0.5315 - val_loss: 1.9293 - val_accuracy: 0.2544\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0060 - accuracy: 0.5632 - val_loss: 2.0126 - val_accuracy: 0.2497\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0651 - accuracy: 0.5410 - val_loss: 1.7918 - val_accuracy: 0.2653\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0280 - accuracy: 0.5248 - val_loss: 2.0421 - val_accuracy: 0.2578\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0269 - accuracy: 0.5348 - val_loss: 2.1554 - val_accuracy: 0.2544\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0157 - accuracy: 0.5509 - val_loss: 1.8743 - val_accuracy: 0.2578\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 1.0231 - accuracy: 0.5237 - val_loss: 2.0009 - val_accuracy: 0.2558\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0245 - accuracy: 0.5559 - val_loss: 1.8428 - val_accuracy: 0.2612\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0170 - accuracy: 0.5493 - val_loss: 2.0043 - val_accuracy: 0.2558\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0188 - accuracy: 0.5478 - val_loss: 1.7453 - val_accuracy: 0.2578\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 1.0174 - accuracy: 0.5427 - val_loss: 1.7816 - val_accuracy: 0.2639\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0058 - accuracy: 0.5463 - val_loss: 1.8994 - val_accuracy: 0.2571\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0077 - accuracy: 0.5540 - val_loss: 1.7817 - val_accuracy: 0.2327\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9913 - accuracy: 0.5451 - val_loss: 1.9392 - val_accuracy: 0.2605\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9984 - accuracy: 0.5473 - val_loss: 1.7359 - val_accuracy: 0.2673\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9717 - accuracy: 0.5537 - val_loss: 1.6717 - val_accuracy: 0.2714\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.9977 - accuracy: 0.5374 - val_loss: 1.8562 - val_accuracy: 0.2633\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 1.0121 - accuracy: 0.5538 - val_loss: 1.7165 - val_accuracy: 0.2687\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9609 - accuracy: 0.5680 - val_loss: 1.7308 - val_accuracy: 0.2633\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9917 - accuracy: 0.5408 - val_loss: 1.7714 - val_accuracy: 0.2687\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0233 - accuracy: 0.5492 - val_loss: 1.6354 - val_accuracy: 0.2510\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 1.0527 - accuracy: 0.5375 - val_loss: 1.9201 - val_accuracy: 0.2592\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9753 - accuracy: 0.5491 - val_loss: 1.8640 - val_accuracy: 0.2578\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9742 - accuracy: 0.5692 - val_loss: 1.7813 - val_accuracy: 0.2605\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9715 - accuracy: 0.5724 - val_loss: 1.7748 - val_accuracy: 0.2633\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9660 - accuracy: 0.5612 - val_loss: 1.5898 - val_accuracy: 0.2878\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9665 - accuracy: 0.5581 - val_loss: 2.1441 - val_accuracy: 0.2558\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9976 - accuracy: 0.5647 - val_loss: 2.1373 - val_accuracy: 0.2592\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9887 - accuracy: 0.5739 - val_loss: 1.8219 - val_accuracy: 0.2605\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9942 - accuracy: 0.5733 - val_loss: 1.7042 - val_accuracy: 0.2673\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9773 - accuracy: 0.5783 - val_loss: 1.6325 - val_accuracy: 0.2680\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9912 - accuracy: 0.5418 - val_loss: 1.6373 - val_accuracy: 0.2728\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9881 - accuracy: 0.5599 - val_loss: 1.6982 - val_accuracy: 0.2435\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0118 - accuracy: 0.5670 - val_loss: 1.6551 - val_accuracy: 0.2707\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9967 - accuracy: 0.5465 - val_loss: 1.8193 - val_accuracy: 0.2673\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9814 - accuracy: 0.5709 - val_loss: 1.7583 - val_accuracy: 0.2660\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9693 - accuracy: 0.5653 - val_loss: 1.7415 - val_accuracy: 0.2592\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9859 - accuracy: 0.5664 - val_loss: 1.6160 - val_accuracy: 0.2605\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9479 - accuracy: 0.5686 - val_loss: 1.5757 - val_accuracy: 0.2993\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9817 - accuracy: 0.5710 - val_loss: 1.6874 - val_accuracy: 0.2619\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9624 - accuracy: 0.6068 - val_loss: 1.7216 - val_accuracy: 0.2714\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.9805 - accuracy: 0.5551 - val_loss: 1.7264 - val_accuracy: 0.2571\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 1.0008 - accuracy: 0.5513 - val_loss: 1.5727 - val_accuracy: 0.2918\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9855 - accuracy: 0.5690 - val_loss: 1.9426 - val_accuracy: 0.2476\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.9522 - accuracy: 0.6024 - val_loss: 1.7704 - val_accuracy: 0.2660\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9667 - accuracy: 0.5824 - val_loss: 1.7222 - val_accuracy: 0.2660\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9883 - accuracy: 0.5335 - val_loss: 1.7241 - val_accuracy: 0.2605\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.9839 - accuracy: 0.5661 - val_loss: 1.9985 - val_accuracy: 0.2524\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9534 - accuracy: 0.5641 - val_loss: 1.9763 - val_accuracy: 0.2524\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 1.0111 - accuracy: 0.5520 - val_loss: 1.7827 - val_accuracy: 0.2646\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9384 - accuracy: 0.5787 - val_loss: 1.8398 - val_accuracy: 0.2401\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9405 - accuracy: 0.6018 - val_loss: 1.5291 - val_accuracy: 0.3163\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9655 - accuracy: 0.5712 - val_loss: 1.7264 - val_accuracy: 0.2619\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9510 - accuracy: 0.5746 - val_loss: 1.7047 - val_accuracy: 0.2721\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9970 - accuracy: 0.5737 - val_loss: 1.6595 - val_accuracy: 0.2803\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9791 - accuracy: 0.5729 - val_loss: 1.8197 - val_accuracy: 0.2612\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.9373 - accuracy: 0.6039 - val_loss: 1.6493 - val_accuracy: 0.2680\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9544 - accuracy: 0.5899 - val_loss: 1.4594 - val_accuracy: 0.3585\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9677 - accuracy: 0.5500 - val_loss: 1.6108 - val_accuracy: 0.2871\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9554 - accuracy: 0.5807 - val_loss: 1.5312 - val_accuracy: 0.3143\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9954 - accuracy: 0.5717 - val_loss: 1.5248 - val_accuracy: 0.3204\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9822 - accuracy: 0.5670 - val_loss: 1.7626 - val_accuracy: 0.2592\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9738 - accuracy: 0.5766 - val_loss: 1.7326 - val_accuracy: 0.2728\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9552 - accuracy: 0.5710 - val_loss: 1.7954 - val_accuracy: 0.2633\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9451 - accuracy: 0.5716 - val_loss: 1.7649 - val_accuracy: 0.2687\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9568 - accuracy: 0.5840 - val_loss: 1.8983 - val_accuracy: 0.2469\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9666 - accuracy: 0.5811 - val_loss: 1.8507 - val_accuracy: 0.2585\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9070 - accuracy: 0.6032 - val_loss: 1.9706 - val_accuracy: 0.2408\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9828 - accuracy: 0.5695 - val_loss: 2.0730 - val_accuracy: 0.2619\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9910 - accuracy: 0.5432 - val_loss: 1.9441 - val_accuracy: 0.2653\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9209 - accuracy: 0.6183 - val_loss: 1.7019 - val_accuracy: 0.2755\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9452 - accuracy: 0.5934 - val_loss: 1.5753 - val_accuracy: 0.3020\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9349 - accuracy: 0.5774 - val_loss: 1.6752 - val_accuracy: 0.2667\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9589 - accuracy: 0.5844 - val_loss: 1.6911 - val_accuracy: 0.2796\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9098 - accuracy: 0.5665 - val_loss: 1.6106 - val_accuracy: 0.2986\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9558 - accuracy: 0.5681 - val_loss: 1.7588 - val_accuracy: 0.2571\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9762 - accuracy: 0.5825 - val_loss: 1.8165 - val_accuracy: 0.2660\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9742 - accuracy: 0.5678 - val_loss: 2.0413 - val_accuracy: 0.2646\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.9400 - accuracy: 0.5938 - val_loss: 1.8432 - val_accuracy: 0.2388\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9157 - accuracy: 0.5846 - val_loss: 1.7134 - val_accuracy: 0.2810\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.9553 - accuracy: 0.5667 - val_loss: 1.5515 - val_accuracy: 0.3184\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8955 - accuracy: 0.5895 - val_loss: 1.6791 - val_accuracy: 0.2782\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9473 - accuracy: 0.5928 - val_loss: 1.6241 - val_accuracy: 0.2973\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9354 - accuracy: 0.5756 - val_loss: 1.6383 - val_accuracy: 0.2884\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9533 - accuracy: 0.5786 - val_loss: 1.6429 - val_accuracy: 0.2782\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9166 - accuracy: 0.6175 - val_loss: 1.4804 - val_accuracy: 0.3517\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9328 - accuracy: 0.5742 - val_loss: 1.5617 - val_accuracy: 0.3116\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9246 - accuracy: 0.5892 - val_loss: 1.5597 - val_accuracy: 0.3068\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9740 - accuracy: 0.5963 - val_loss: 1.5482 - val_accuracy: 0.3177\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9562 - accuracy: 0.5894 - val_loss: 1.6884 - val_accuracy: 0.2918\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9483 - accuracy: 0.5762 - val_loss: 1.5216 - val_accuracy: 0.3299\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9270 - accuracy: 0.5961 - val_loss: 1.7441 - val_accuracy: 0.2633\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9557 - accuracy: 0.5806 - val_loss: 1.7389 - val_accuracy: 0.2741\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.8891 - accuracy: 0.6038 - val_loss: 1.8238 - val_accuracy: 0.2510\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9078 - accuracy: 0.6043 - val_loss: 1.5622 - val_accuracy: 0.3116\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9280 - accuracy: 0.5934 - val_loss: 1.5339 - val_accuracy: 0.3156\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9349 - accuracy: 0.5968 - val_loss: 1.5281 - val_accuracy: 0.3422\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9552 - accuracy: 0.5852 - val_loss: 1.5139 - val_accuracy: 0.3340\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9269 - accuracy: 0.5767 - val_loss: 1.6496 - val_accuracy: 0.2741\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9141 - accuracy: 0.5876 - val_loss: 1.7819 - val_accuracy: 0.2653\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9439 - accuracy: 0.6002 - val_loss: 1.8906 - val_accuracy: 0.2714\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9506 - accuracy: 0.5914 - val_loss: 1.7571 - val_accuracy: 0.2510\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9559 - accuracy: 0.5739 - val_loss: 1.6536 - val_accuracy: 0.2694\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9186 - accuracy: 0.5785 - val_loss: 1.6456 - val_accuracy: 0.2925\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9296 - accuracy: 0.5996 - val_loss: 1.5314 - val_accuracy: 0.3211\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9222 - accuracy: 0.5766 - val_loss: 1.5470 - val_accuracy: 0.3306\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.9243 - accuracy: 0.6011 - val_loss: 1.4340 - val_accuracy: 0.3646\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9401 - accuracy: 0.5796 - val_loss: 1.6095 - val_accuracy: 0.3000\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9448 - accuracy: 0.5949 - val_loss: 1.5195 - val_accuracy: 0.3259\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.9205 - accuracy: 0.6226 - val_loss: 1.6504 - val_accuracy: 0.2918\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9177 - accuracy: 0.5999 - val_loss: 1.6920 - val_accuracy: 0.2810\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9441 - accuracy: 0.5793 - val_loss: 1.9848 - val_accuracy: 0.2667\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.9480 - accuracy: 0.5864 - val_loss: 1.6539 - val_accuracy: 0.2905\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.9257 - accuracy: 0.5834 - val_loss: 1.5303 - val_accuracy: 0.3395\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9569 - accuracy: 0.5891 - val_loss: 1.5806 - val_accuracy: 0.3354\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9544 - accuracy: 0.5861 - val_loss: 1.7305 - val_accuracy: 0.2626\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9433 - accuracy: 0.5868 - val_loss: 1.6866 - val_accuracy: 0.2871\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9116 - accuracy: 0.5832 - val_loss: 1.6390 - val_accuracy: 0.2884\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9056 - accuracy: 0.6058 - val_loss: 1.6783 - val_accuracy: 0.2789\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9447 - accuracy: 0.5745 - val_loss: 1.6370 - val_accuracy: 0.3150\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9452 - accuracy: 0.6110 - val_loss: 1.8815 - val_accuracy: 0.2687\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.9110 - accuracy: 0.6127 - val_loss: 1.6182 - val_accuracy: 0.2973\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.8801 - accuracy: 0.6003 - val_loss: 1.5778 - val_accuracy: 0.3061\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.9174 - accuracy: 0.5992 - val_loss: 1.7796 - val_accuracy: 0.2592\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9269 - accuracy: 0.5971 - val_loss: 1.7000 - val_accuracy: 0.2782\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9123 - accuracy: 0.5752 - val_loss: 1.5929 - val_accuracy: 0.3068\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9226 - accuracy: 0.5797 - val_loss: 1.6684 - val_accuracy: 0.2776\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9183 - accuracy: 0.5888 - val_loss: 1.5687 - val_accuracy: 0.3170\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.9011 - accuracy: 0.6012 - val_loss: 1.5118 - val_accuracy: 0.3463\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.9223 - accuracy: 0.6154 - val_loss: 1.5123 - val_accuracy: 0.3347\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.9133 - accuracy: 0.6154 - val_loss: 1.7760 - val_accuracy: 0.2653\n"
     ]
    }
   ],
   "source": [
    "model_white = keras.models.Sequential()\n",
    "model_white.add(keras.layers.Dense(units = 32,input_dim = 11,activation = 'relu'))\n",
    "model_white.add(keras.layers.Dense(units = 11,activation = 'softmax'))\n",
    "\n",
    "model_white.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "              \n",
    "           \n",
    "\n",
    "hist = model_white.fit(X_train,Y_train,epochs=200,batch_size=64,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "acc_ax = ax1.twinx()\n",
    "\n",
    "ax1.plot(hist.history['loss'], 'y', label='train loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "\n",
    "\n",
    "ax2.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "ax2.set_ylabel('val_loss')\n",
    "\n",
    "\n",
    "ax3.plot(hist.history['accuracy'], 'b', label='accuracy')\n",
    "ax3.set_ylabel('accuray')\n",
    "\n",
    "ax4.plot(hist.history['val_accuracy'], 'g', label='val_accuracy')\n",
    "ax4.set_ylabel('val_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 - 0s - loss: 1.8307 - accuracy: 0.2523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8307231664657593, 0.2523076832294464]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_white.evaluate(X_test,Y_test,verbose =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 각 모델의 성능을 향상시킬 수 있는 방법 적용\n",
    "* 하이퍼파라미터를 변경하여 테스트 셋에서의 정확도를 향상시킬 것\n",
    "    * 예) 레이어 수, 노드 수, Learning rate 등\n",
    "* 하이퍼파라미터를 변화시킨 각각의 모델에 대해, 트레이닝 Epoch 당 Loss의 변화를 기록하고 이를 시각화\n",
    "* 그 외 성능을 향상시킬 수 있는 모든 방법을 사용하여 가장 성능이 좋은 모델을 선택\n",
    "    * 예) Dropout, Normalization 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 11)                363       \n",
      "=================================================================\n",
      "Total params: 4,283\n",
      "Trainable params: 4,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 4.4222 - accuracy: 0.2213 - val_loss: 1.2704 - val_accuracy: 0.4986\n",
      "Epoch 2/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.3589 - accuracy: 0.4374 - val_loss: 1.2122 - val_accuracy: 0.4959\n",
      "Epoch 3/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2991 - accuracy: 0.4427 - val_loss: 1.1940 - val_accuracy: 0.5197\n",
      "Epoch 4/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2824 - accuracy: 0.4264 - val_loss: 1.2020 - val_accuracy: 0.4932\n",
      "Epoch 5/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2867 - accuracy: 0.4555 - val_loss: 1.1777 - val_accuracy: 0.5190\n",
      "Epoch 6/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.2521 - accuracy: 0.4375 - val_loss: 1.1677 - val_accuracy: 0.5361\n",
      "Epoch 7/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2426 - accuracy: 0.4332 - val_loss: 1.1682 - val_accuracy: 0.4571\n",
      "Epoch 8/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2421 - accuracy: 0.4327 - val_loss: 1.1270 - val_accuracy: 0.5041\n",
      "Epoch 9/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2417 - accuracy: 0.4384 - val_loss: 1.1294 - val_accuracy: 0.5054\n",
      "Epoch 10/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2116 - accuracy: 0.4579 - val_loss: 1.1381 - val_accuracy: 0.4932\n",
      "Epoch 11/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2130 - accuracy: 0.4380 - val_loss: 1.1448 - val_accuracy: 0.4660\n",
      "Epoch 12/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2345 - accuracy: 0.4521 - val_loss: 1.1410 - val_accuracy: 0.4653\n",
      "Epoch 13/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2343 - accuracy: 0.4418 - val_loss: 1.1223 - val_accuracy: 0.4789\n",
      "Epoch 14/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2022 - accuracy: 0.4558 - val_loss: 1.1076 - val_accuracy: 0.5041\n",
      "Epoch 15/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1918 - accuracy: 0.4576 - val_loss: 1.0960 - val_accuracy: 0.5224\n",
      "Epoch 16/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1845 - accuracy: 0.4661 - val_loss: 1.0902 - val_accuracy: 0.5061\n",
      "Epoch 17/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.4385 - val_loss: 1.1039 - val_accuracy: 0.5415\n",
      "Epoch 18/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1692 - accuracy: 0.4792 - val_loss: 1.1216 - val_accuracy: 0.4728\n",
      "Epoch 19/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1631 - accuracy: 0.4818 - val_loss: 1.1288 - val_accuracy: 0.4837\n",
      "Epoch 20/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1810 - accuracy: 0.4567 - val_loss: 1.0741 - val_accuracy: 0.5728\n",
      "Epoch 21/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1843 - accuracy: 0.4630 - val_loss: 1.0957 - val_accuracy: 0.5068\n",
      "Epoch 22/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2253 - accuracy: 0.4560 - val_loss: 1.0905 - val_accuracy: 0.5204\n",
      "Epoch 23/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1661 - accuracy: 0.4735 - val_loss: 1.1215 - val_accuracy: 0.4803\n",
      "Epoch 24/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1661 - accuracy: 0.4846 - val_loss: 1.0940 - val_accuracy: 0.5048\n",
      "Epoch 25/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1948 - accuracy: 0.4585 - val_loss: 1.1106 - val_accuracy: 0.5136\n",
      "Epoch 26/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1739 - accuracy: 0.4606 - val_loss: 1.1823 - val_accuracy: 0.4245\n",
      "Epoch 27/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1977 - accuracy: 0.4743 - val_loss: 1.0644 - val_accuracy: 0.5265\n",
      "Epoch 28/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1565 - accuracy: 0.4672 - val_loss: 1.0700 - val_accuracy: 0.5361\n",
      "Epoch 29/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1630 - accuracy: 0.4711 - val_loss: 1.1273 - val_accuracy: 0.4728\n",
      "Epoch 30/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1487 - accuracy: 0.4810 - val_loss: 1.0841 - val_accuracy: 0.5102\n",
      "Epoch 31/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1495 - accuracy: 0.4770 - val_loss: 1.0838 - val_accuracy: 0.5313\n",
      "Epoch 32/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1307 - accuracy: 0.4827 - val_loss: 1.1438 - val_accuracy: 0.4490\n",
      "Epoch 33/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1593 - accuracy: 0.4651 - val_loss: 1.0476 - val_accuracy: 0.5265\n",
      "Epoch 34/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1690 - accuracy: 0.4779 - val_loss: 1.0720 - val_accuracy: 0.5245\n",
      "Epoch 35/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1324 - accuracy: 0.4930 - val_loss: 1.1751 - val_accuracy: 0.4252\n",
      "Epoch 36/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1579 - accuracy: 0.4827 - val_loss: 1.1800 - val_accuracy: 0.4286\n",
      "Epoch 37/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1822 - accuracy: 0.4642 - val_loss: 1.0956 - val_accuracy: 0.4776\n",
      "Epoch 38/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1771 - accuracy: 0.4579 - val_loss: 1.1409 - val_accuracy: 0.4565\n",
      "Epoch 39/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1576 - accuracy: 0.4613 - val_loss: 1.0871 - val_accuracy: 0.4932\n",
      "Epoch 40/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1333 - accuracy: 0.4810 - val_loss: 1.0453 - val_accuracy: 0.5728\n",
      "Epoch 41/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1654 - accuracy: 0.4671 - val_loss: 1.0661 - val_accuracy: 0.5483\n",
      "Epoch 42/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1562 - accuracy: 0.4663 - val_loss: 1.1439 - val_accuracy: 0.4558\n",
      "Epoch 43/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1336 - accuracy: 0.4807 - val_loss: 1.0995 - val_accuracy: 0.4755\n",
      "Epoch 44/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1639 - accuracy: 0.4677 - val_loss: 1.1120 - val_accuracy: 0.5170\n",
      "Epoch 45/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1538 - accuracy: 0.4751 - val_loss: 1.1107 - val_accuracy: 0.4639\n",
      "Epoch 46/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1605 - accuracy: 0.4615 - val_loss: 1.0546 - val_accuracy: 0.5660\n",
      "Epoch 47/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1382 - accuracy: 0.4904 - val_loss: 1.0525 - val_accuracy: 0.5449\n",
      "Epoch 48/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1415 - accuracy: 0.4690 - val_loss: 1.0662 - val_accuracy: 0.5116\n",
      "Epoch 49/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1468 - accuracy: 0.4918 - val_loss: 1.0787 - val_accuracy: 0.5190\n",
      "Epoch 50/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1552 - accuracy: 0.4711 - val_loss: 1.0676 - val_accuracy: 0.5020\n",
      "Epoch 51/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1798 - accuracy: 0.4565 - val_loss: 1.1177 - val_accuracy: 0.4619\n",
      "Epoch 52/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1695 - accuracy: 0.4851 - val_loss: 1.1512 - val_accuracy: 0.4333\n",
      "Epoch 53/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1413 - accuracy: 0.4955 - val_loss: 1.1113 - val_accuracy: 0.4687\n",
      "Epoch 54/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1364 - accuracy: 0.4973 - val_loss: 1.0643 - val_accuracy: 0.5177\n",
      "Epoch 55/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1165 - accuracy: 0.4858 - val_loss: 1.0812 - val_accuracy: 0.4993\n",
      "Epoch 56/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1455 - accuracy: 0.4797 - val_loss: 1.0461 - val_accuracy: 0.5605\n",
      "Epoch 57/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1569 - accuracy: 0.4622 - val_loss: 1.0607 - val_accuracy: 0.5150\n",
      "Epoch 58/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1515 - accuracy: 0.4814 - val_loss: 1.1521 - val_accuracy: 0.4707\n",
      "Epoch 59/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1258 - accuracy: 0.4872 - val_loss: 1.0980 - val_accuracy: 0.4810\n",
      "Epoch 60/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1310 - accuracy: 0.4956 - val_loss: 1.0371 - val_accuracy: 0.5667\n",
      "Epoch 61/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1279 - accuracy: 0.4892 - val_loss: 1.0605 - val_accuracy: 0.5109\n",
      "Epoch 62/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1366 - accuracy: 0.4803 - val_loss: 1.0586 - val_accuracy: 0.5361\n",
      "Epoch 63/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1342 - accuracy: 0.4834 - val_loss: 1.0895 - val_accuracy: 0.4905\n",
      "Epoch 64/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1315 - accuracy: 0.4911 - val_loss: 1.0513 - val_accuracy: 0.5327\n",
      "Epoch 65/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1342 - accuracy: 0.4789 - val_loss: 1.0869 - val_accuracy: 0.5163\n",
      "Epoch 66/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0972 - accuracy: 0.5054 - val_loss: 1.0725 - val_accuracy: 0.5374\n",
      "Epoch 67/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1153 - accuracy: 0.4958 - val_loss: 1.1550 - val_accuracy: 0.4361\n",
      "Epoch 68/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1720 - accuracy: 0.4770 - val_loss: 1.0477 - val_accuracy: 0.5313\n",
      "Epoch 69/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1193 - accuracy: 0.5065 - val_loss: 1.1193 - val_accuracy: 0.4748\n",
      "Epoch 70/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1126 - accuracy: 0.4966 - val_loss: 1.0411 - val_accuracy: 0.5204\n",
      "Epoch 71/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1277 - accuracy: 0.5211 - val_loss: 1.1547 - val_accuracy: 0.4524\n",
      "Epoch 72/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1107 - accuracy: 0.4916 - val_loss: 1.1394 - val_accuracy: 0.4483\n",
      "Epoch 73/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1314 - accuracy: 0.4863 - val_loss: 1.1648 - val_accuracy: 0.4483\n",
      "Epoch 74/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1326 - accuracy: 0.5012 - val_loss: 1.0701 - val_accuracy: 0.5136\n",
      "Epoch 75/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1145 - accuracy: 0.5156 - val_loss: 1.1303 - val_accuracy: 0.4551\n",
      "Epoch 76/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1324 - accuracy: 0.4971 - val_loss: 1.0983 - val_accuracy: 0.5061\n",
      "Epoch 77/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1117 - accuracy: 0.5039 - val_loss: 1.0861 - val_accuracy: 0.5293\n",
      "Epoch 78/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0958 - accuracy: 0.5062 - val_loss: 1.1207 - val_accuracy: 0.4680\n",
      "Epoch 79/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1239 - accuracy: 0.5035 - val_loss: 1.1343 - val_accuracy: 0.4782\n",
      "Epoch 80/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1143 - accuracy: 0.5221 - val_loss: 1.1362 - val_accuracy: 0.4612\n",
      "Epoch 81/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1033 - accuracy: 0.5011 - val_loss: 1.0696 - val_accuracy: 0.5687\n",
      "Epoch 82/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1700 - accuracy: 0.4653 - val_loss: 1.0521 - val_accuracy: 0.5483\n",
      "Epoch 83/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1064 - accuracy: 0.5074 - val_loss: 1.1429 - val_accuracy: 0.4755\n",
      "Epoch 84/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1083 - accuracy: 0.4953 - val_loss: 1.1238 - val_accuracy: 0.4537\n",
      "Epoch 85/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1054 - accuracy: 0.4836 - val_loss: 1.1210 - val_accuracy: 0.4735\n",
      "Epoch 86/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1184 - accuracy: 0.5184 - val_loss: 1.0374 - val_accuracy: 0.5340\n",
      "Epoch 87/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0848 - accuracy: 0.5185 - val_loss: 1.0668 - val_accuracy: 0.5374\n",
      "Epoch 88/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1132 - accuracy: 0.5058 - val_loss: 1.1111 - val_accuracy: 0.5014\n",
      "Epoch 89/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1213 - accuracy: 0.5038 - val_loss: 1.0416 - val_accuracy: 0.5381\n",
      "Epoch 90/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1141 - accuracy: 0.5056 - val_loss: 1.0502 - val_accuracy: 0.5320\n",
      "Epoch 91/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1131 - accuracy: 0.5149 - val_loss: 1.0599 - val_accuracy: 0.5116\n",
      "Epoch 92/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1195 - accuracy: 0.5103 - val_loss: 1.0562 - val_accuracy: 0.5306\n",
      "Epoch 93/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1041 - accuracy: 0.5028 - val_loss: 1.1257 - val_accuracy: 0.4925\n",
      "Epoch 94/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1300 - accuracy: 0.5038 - val_loss: 1.0324 - val_accuracy: 0.5707\n",
      "Epoch 95/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1068 - accuracy: 0.4888 - val_loss: 1.0585 - val_accuracy: 0.5136\n",
      "Epoch 96/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1065 - accuracy: 0.5083 - val_loss: 1.0777 - val_accuracy: 0.4912\n",
      "Epoch 97/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1121 - accuracy: 0.5047 - val_loss: 1.0515 - val_accuracy: 0.5245\n",
      "Epoch 98/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1043 - accuracy: 0.5063 - val_loss: 1.2106 - val_accuracy: 0.4007\n",
      "Epoch 99/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1233 - accuracy: 0.5087 - val_loss: 1.1535 - val_accuracy: 0.4646\n",
      "Epoch 100/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1113 - accuracy: 0.5157 - val_loss: 1.0558 - val_accuracy: 0.5497\n",
      "Epoch 101/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1023 - accuracy: 0.5034 - val_loss: 1.0826 - val_accuracy: 0.5156\n",
      "Epoch 102/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1012 - accuracy: 0.5112 - val_loss: 1.1076 - val_accuracy: 0.4769\n",
      "Epoch 103/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1186 - accuracy: 0.4946 - val_loss: 1.0476 - val_accuracy: 0.5653\n",
      "Epoch 104/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1100 - accuracy: 0.4960 - val_loss: 1.1167 - val_accuracy: 0.4796\n",
      "Epoch 105/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0768 - accuracy: 0.5174 - val_loss: 1.1910 - val_accuracy: 0.4204\n",
      "Epoch 106/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1246 - accuracy: 0.4991 - val_loss: 1.0483 - val_accuracy: 0.5340\n",
      "Epoch 107/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1227 - accuracy: 0.4948 - val_loss: 1.0606 - val_accuracy: 0.5272\n",
      "Epoch 108/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0808 - accuracy: 0.5065 - val_loss: 1.0682 - val_accuracy: 0.5238\n",
      "Epoch 109/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1182 - accuracy: 0.5091 - val_loss: 1.0919 - val_accuracy: 0.5190\n",
      "Epoch 110/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1111 - accuracy: 0.4929 - val_loss: 1.0234 - val_accuracy: 0.5667\n",
      "Epoch 111/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0920 - accuracy: 0.5120 - val_loss: 1.0798 - val_accuracy: 0.4952\n",
      "Epoch 112/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0966 - accuracy: 0.5246 - val_loss: 1.0688 - val_accuracy: 0.5088\n",
      "Epoch 113/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0924 - accuracy: 0.5231 - val_loss: 1.0193 - val_accuracy: 0.5456\n",
      "Epoch 114/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1104 - accuracy: 0.5008 - val_loss: 1.2332 - val_accuracy: 0.3864\n",
      "Epoch 115/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1056 - accuracy: 0.5167 - val_loss: 1.0735 - val_accuracy: 0.5109\n",
      "Epoch 116/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0846 - accuracy: 0.5078 - val_loss: 1.0776 - val_accuracy: 0.4946\n",
      "Epoch 117/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0883 - accuracy: 0.5233 - val_loss: 1.0454 - val_accuracy: 0.5537\n",
      "Epoch 118/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0891 - accuracy: 0.5187 - val_loss: 1.0585 - val_accuracy: 0.5088\n",
      "Epoch 119/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0858 - accuracy: 0.5108 - val_loss: 1.0367 - val_accuracy: 0.5456\n",
      "Epoch 120/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1114 - accuracy: 0.5041 - val_loss: 1.0384 - val_accuracy: 0.5592\n",
      "Epoch 121/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0971 - accuracy: 0.5112 - val_loss: 1.0616 - val_accuracy: 0.5333\n",
      "Epoch 122/1000\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 1.0951 - accuracy: 0.5036 - val_loss: 1.0320 - val_accuracy: 0.5231\n",
      "Epoch 123/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1305 - accuracy: 0.4854 - val_loss: 1.0678 - val_accuracy: 0.4905\n",
      "Epoch 124/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1003 - accuracy: 0.5091 - val_loss: 1.0725 - val_accuracy: 0.5122\n",
      "Epoch 125/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1113 - accuracy: 0.5084 - val_loss: 1.1150 - val_accuracy: 0.4823\n",
      "Epoch 126/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1098 - accuracy: 0.5149 - val_loss: 1.0400 - val_accuracy: 0.5299\n",
      "Epoch 127/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0822 - accuracy: 0.5153 - val_loss: 1.1611 - val_accuracy: 0.4442\n",
      "Epoch 128/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1084 - accuracy: 0.5083 - val_loss: 1.1172 - val_accuracy: 0.4619\n",
      "Epoch 129/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1174 - accuracy: 0.5079 - val_loss: 1.0524 - val_accuracy: 0.5129\n",
      "Epoch 130/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0950 - accuracy: 0.5181 - val_loss: 1.1106 - val_accuracy: 0.4864\n",
      "Epoch 131/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0769 - accuracy: 0.5189 - val_loss: 1.0472 - val_accuracy: 0.5585\n",
      "Epoch 132/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0895 - accuracy: 0.5018 - val_loss: 1.1720 - val_accuracy: 0.4633\n",
      "Epoch 133/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0737 - accuracy: 0.5140 - val_loss: 1.0537 - val_accuracy: 0.5578\n",
      "Epoch 134/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1109 - accuracy: 0.4931 - val_loss: 1.0266 - val_accuracy: 0.5422\n",
      "Epoch 135/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0917 - accuracy: 0.5108 - val_loss: 1.0340 - val_accuracy: 0.5503\n",
      "Epoch 136/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0866 - accuracy: 0.5216 - val_loss: 1.0336 - val_accuracy: 0.5605\n",
      "Epoch 137/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1106 - accuracy: 0.4886 - val_loss: 1.1293 - val_accuracy: 0.4667\n",
      "Epoch 138/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0810 - accuracy: 0.5196 - val_loss: 1.0429 - val_accuracy: 0.5517\n",
      "Epoch 139/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0987 - accuracy: 0.5088 - val_loss: 1.0508 - val_accuracy: 0.5531\n",
      "Epoch 140/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1077 - accuracy: 0.5016 - val_loss: 1.1140 - val_accuracy: 0.4823\n",
      "Epoch 141/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0910 - accuracy: 0.5161 - val_loss: 1.0541 - val_accuracy: 0.5531\n",
      "Epoch 142/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0869 - accuracy: 0.5084 - val_loss: 1.0549 - val_accuracy: 0.5571\n",
      "Epoch 143/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0960 - accuracy: 0.5075 - val_loss: 1.0833 - val_accuracy: 0.5109\n",
      "Epoch 144/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1031 - accuracy: 0.5022 - val_loss: 1.1090 - val_accuracy: 0.5007\n",
      "Epoch 145/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1043 - accuracy: 0.5045 - val_loss: 1.1415 - val_accuracy: 0.4510\n",
      "Epoch 146/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1273 - accuracy: 0.4915 - val_loss: 1.1344 - val_accuracy: 0.4571\n",
      "Epoch 147/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1028 - accuracy: 0.4954 - val_loss: 1.0937 - val_accuracy: 0.5027\n",
      "Epoch 148/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0891 - accuracy: 0.5154 - val_loss: 1.0554 - val_accuracy: 0.5483\n",
      "Epoch 149/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0690 - accuracy: 0.5260 - val_loss: 1.1001 - val_accuracy: 0.5048\n",
      "Epoch 150/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0930 - accuracy: 0.5132 - val_loss: 1.0249 - val_accuracy: 0.5388\n",
      "Epoch 151/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1066 - accuracy: 0.5136 - val_loss: 1.0705 - val_accuracy: 0.5224\n",
      "Epoch 152/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0806 - accuracy: 0.5147 - val_loss: 1.0660 - val_accuracy: 0.5408\n",
      "Epoch 153/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0887 - accuracy: 0.5157 - val_loss: 1.0827 - val_accuracy: 0.5054\n",
      "Epoch 154/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0994 - accuracy: 0.5158 - val_loss: 1.1017 - val_accuracy: 0.4918\n",
      "Epoch 155/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1232 - accuracy: 0.5118 - val_loss: 1.1513 - val_accuracy: 0.4531\n",
      "Epoch 156/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1038 - accuracy: 0.5082 - val_loss: 1.0259 - val_accuracy: 0.5449\n",
      "Epoch 157/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1097 - accuracy: 0.5048 - val_loss: 1.1168 - val_accuracy: 0.4857\n",
      "Epoch 158/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1083 - accuracy: 0.5203 - val_loss: 1.0341 - val_accuracy: 0.5476\n",
      "Epoch 159/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0850 - accuracy: 0.5104 - val_loss: 1.0752 - val_accuracy: 0.5088\n",
      "Epoch 160/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1027 - accuracy: 0.5067 - val_loss: 1.0548 - val_accuracy: 0.5524\n",
      "Epoch 161/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1077 - accuracy: 0.5016 - val_loss: 1.0478 - val_accuracy: 0.5449\n",
      "Epoch 162/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0894 - accuracy: 0.5090 - val_loss: 1.0898 - val_accuracy: 0.4918\n",
      "Epoch 163/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0799 - accuracy: 0.5171 - val_loss: 1.2049 - val_accuracy: 0.3993\n",
      "Epoch 164/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1045 - accuracy: 0.5176 - val_loss: 1.0335 - val_accuracy: 0.5735\n",
      "Epoch 165/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1021 - accuracy: 0.5293 - val_loss: 1.0687 - val_accuracy: 0.5156\n",
      "Epoch 166/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1101 - accuracy: 0.5065 - val_loss: 1.0411 - val_accuracy: 0.5558\n",
      "Epoch 167/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0712 - accuracy: 0.5277 - val_loss: 1.0567 - val_accuracy: 0.5340\n",
      "Epoch 168/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0881 - accuracy: 0.5053 - val_loss: 1.1328 - val_accuracy: 0.4660\n",
      "Epoch 169/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0848 - accuracy: 0.5039 - val_loss: 1.0412 - val_accuracy: 0.5320\n",
      "Epoch 170/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0958 - accuracy: 0.5125 - val_loss: 1.0696 - val_accuracy: 0.5395\n",
      "Epoch 171/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1001 - accuracy: 0.5034 - val_loss: 1.0731 - val_accuracy: 0.4939\n",
      "Epoch 172/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0853 - accuracy: 0.5275 - val_loss: 1.1163 - val_accuracy: 0.4639\n",
      "Epoch 173/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0684 - accuracy: 0.5365 - val_loss: 1.1242 - val_accuracy: 0.4680\n",
      "Epoch 174/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1165 - accuracy: 0.5064 - val_loss: 1.1111 - val_accuracy: 0.5048\n",
      "Epoch 175/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0870 - accuracy: 0.5252 - val_loss: 1.0567 - val_accuracy: 0.5497\n",
      "Epoch 176/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0635 - accuracy: 0.5413 - val_loss: 1.1151 - val_accuracy: 0.4680\n",
      "Epoch 177/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0721 - accuracy: 0.5152 - val_loss: 1.1027 - val_accuracy: 0.5116\n",
      "Epoch 178/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0641 - accuracy: 0.5279 - val_loss: 1.1115 - val_accuracy: 0.5116\n",
      "Epoch 179/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0782 - accuracy: 0.5126 - val_loss: 1.1151 - val_accuracy: 0.4857\n",
      "Epoch 180/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0714 - accuracy: 0.5164 - val_loss: 1.0906 - val_accuracy: 0.4721\n",
      "Epoch 181/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0973 - accuracy: 0.5104 - val_loss: 1.1447 - val_accuracy: 0.5122\n",
      "Epoch 182/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0832 - accuracy: 0.5141 - val_loss: 1.1144 - val_accuracy: 0.4878\n",
      "Epoch 183/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0654 - accuracy: 0.5348 - val_loss: 1.0787 - val_accuracy: 0.4966\n",
      "Epoch 184/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0806 - accuracy: 0.5063 - val_loss: 1.1494 - val_accuracy: 0.4694\n",
      "Epoch 185/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0706 - accuracy: 0.5212 - val_loss: 1.1365 - val_accuracy: 0.4544\n",
      "Epoch 186/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0686 - accuracy: 0.5360 - val_loss: 1.1004 - val_accuracy: 0.5027\n",
      "Epoch 187/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0707 - accuracy: 0.5215 - val_loss: 1.1127 - val_accuracy: 0.4946\n",
      "Epoch 188/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0819 - accuracy: 0.5241 - val_loss: 1.0951 - val_accuracy: 0.4803\n",
      "Epoch 189/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0883 - accuracy: 0.5241 - val_loss: 1.0535 - val_accuracy: 0.5224\n",
      "Epoch 190/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0601 - accuracy: 0.5204 - val_loss: 1.0746 - val_accuracy: 0.5313\n",
      "Epoch 191/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0905 - accuracy: 0.5225 - val_loss: 1.1157 - val_accuracy: 0.4830\n",
      "Epoch 192/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0669 - accuracy: 0.5345 - val_loss: 1.0805 - val_accuracy: 0.5252\n",
      "Epoch 193/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0605 - accuracy: 0.5320 - val_loss: 1.0737 - val_accuracy: 0.5381\n",
      "Epoch 194/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0785 - accuracy: 0.5180 - val_loss: 1.1386 - val_accuracy: 0.5014\n",
      "Epoch 195/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0747 - accuracy: 0.5189 - val_loss: 1.1602 - val_accuracy: 0.4503\n",
      "Epoch 196/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0869 - accuracy: 0.5074 - val_loss: 1.0864 - val_accuracy: 0.5048\n",
      "Epoch 197/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0738 - accuracy: 0.5432 - val_loss: 1.0832 - val_accuracy: 0.5054\n",
      "Epoch 198/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0906 - accuracy: 0.5222 - val_loss: 1.0800 - val_accuracy: 0.5054\n",
      "Epoch 199/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0690 - accuracy: 0.5074 - val_loss: 1.1392 - val_accuracy: 0.4884\n",
      "Epoch 200/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0659 - accuracy: 0.5377 - val_loss: 1.0805 - val_accuracy: 0.5095\n",
      "Epoch 201/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0728 - accuracy: 0.5246 - val_loss: 1.1059 - val_accuracy: 0.4986\n",
      "Epoch 202/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0422 - accuracy: 0.5354 - val_loss: 1.1142 - val_accuracy: 0.5122\n",
      "Epoch 203/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1040 - accuracy: 0.5081 - val_loss: 1.0520 - val_accuracy: 0.5490\n",
      "Epoch 204/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0601 - accuracy: 0.5344 - val_loss: 1.0788 - val_accuracy: 0.5061\n",
      "Epoch 205/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0667 - accuracy: 0.5222 - val_loss: 1.0770 - val_accuracy: 0.5483\n",
      "Epoch 206/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0923 - accuracy: 0.5202 - val_loss: 1.1325 - val_accuracy: 0.4673\n",
      "Epoch 207/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.5108 - val_loss: 1.0751 - val_accuracy: 0.5122\n",
      "Epoch 208/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0450 - accuracy: 0.5235 - val_loss: 1.0921 - val_accuracy: 0.5048\n",
      "Epoch 209/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0503 - accuracy: 0.5448 - val_loss: 1.0680 - val_accuracy: 0.5456\n",
      "Epoch 210/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0760 - accuracy: 0.5268 - val_loss: 1.0854 - val_accuracy: 0.5224\n",
      "Epoch 211/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0911 - accuracy: 0.5253 - val_loss: 1.0763 - val_accuracy: 0.4939\n",
      "Epoch 212/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0891 - accuracy: 0.5178 - val_loss: 1.0588 - val_accuracy: 0.5633\n",
      "Epoch 213/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0657 - accuracy: 0.5372 - val_loss: 1.1101 - val_accuracy: 0.5238\n",
      "Epoch 214/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0929 - accuracy: 0.5126 - val_loss: 1.0714 - val_accuracy: 0.5224\n",
      "Epoch 215/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0677 - accuracy: 0.5407 - val_loss: 1.1323 - val_accuracy: 0.4667\n",
      "Epoch 216/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0325 - accuracy: 0.5535 - val_loss: 1.1136 - val_accuracy: 0.4687\n",
      "Epoch 217/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0807 - accuracy: 0.5032 - val_loss: 1.0551 - val_accuracy: 0.5558\n",
      "Epoch 218/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0582 - accuracy: 0.5376 - val_loss: 1.0924 - val_accuracy: 0.5224\n",
      "Epoch 219/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0557 - accuracy: 0.5317 - val_loss: 1.0944 - val_accuracy: 0.5442\n",
      "Epoch 220/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0438 - accuracy: 0.5383 - val_loss: 1.1602 - val_accuracy: 0.4578\n",
      "Epoch 221/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0425 - accuracy: 0.5418 - val_loss: 1.1558 - val_accuracy: 0.4204\n",
      "Epoch 222/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0535 - accuracy: 0.5340 - val_loss: 1.1137 - val_accuracy: 0.5143\n",
      "Epoch 223/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1044 - accuracy: 0.5028 - val_loss: 1.0431 - val_accuracy: 0.5524\n",
      "Epoch 224/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0679 - accuracy: 0.5258 - val_loss: 1.1147 - val_accuracy: 0.5544\n",
      "Epoch 225/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0682 - accuracy: 0.5253 - val_loss: 1.0926 - val_accuracy: 0.4952\n",
      "Epoch 226/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0653 - accuracy: 0.5354 - val_loss: 1.0639 - val_accuracy: 0.5020\n",
      "Epoch 227/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0440 - accuracy: 0.5486 - val_loss: 1.1137 - val_accuracy: 0.4898\n",
      "Epoch 228/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0356 - accuracy: 0.5378 - val_loss: 1.0927 - val_accuracy: 0.5231\n",
      "Epoch 229/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0347 - accuracy: 0.5434 - val_loss: 1.1215 - val_accuracy: 0.4816\n",
      "Epoch 230/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0708 - accuracy: 0.5292 - val_loss: 1.0805 - val_accuracy: 0.5565\n",
      "Epoch 231/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0788 - accuracy: 0.5130 - val_loss: 1.0819 - val_accuracy: 0.5088\n",
      "Epoch 232/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0577 - accuracy: 0.5449 - val_loss: 1.0592 - val_accuracy: 0.5694\n",
      "Epoch 233/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0724 - accuracy: 0.5224 - val_loss: 1.1221 - val_accuracy: 0.4871\n",
      "Epoch 234/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0668 - accuracy: 0.5167 - val_loss: 1.1218 - val_accuracy: 0.4755\n",
      "Epoch 235/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0570 - accuracy: 0.5313 - val_loss: 1.1394 - val_accuracy: 0.4660\n",
      "Epoch 236/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0574 - accuracy: 0.5304 - val_loss: 1.1073 - val_accuracy: 0.5041\n",
      "Epoch 237/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0610 - accuracy: 0.5271 - val_loss: 1.1109 - val_accuracy: 0.4714\n",
      "Epoch 238/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0774 - accuracy: 0.5161 - val_loss: 1.1414 - val_accuracy: 0.4789\n",
      "Epoch 239/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0817 - accuracy: 0.5329 - val_loss: 1.0903 - val_accuracy: 0.5116\n",
      "Epoch 240/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0478 - accuracy: 0.5391 - val_loss: 1.1063 - val_accuracy: 0.5211\n",
      "Epoch 241/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0485 - accuracy: 0.5527 - val_loss: 1.0792 - val_accuracy: 0.5408\n",
      "Epoch 242/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0525 - accuracy: 0.5359 - val_loss: 1.0596 - val_accuracy: 0.5211\n",
      "Epoch 243/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0601 - accuracy: 0.5275 - val_loss: 1.2229 - val_accuracy: 0.4156\n",
      "Epoch 244/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0708 - accuracy: 0.5261 - val_loss: 1.1270 - val_accuracy: 0.4612\n",
      "Epoch 245/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0603 - accuracy: 0.5404 - val_loss: 1.1180 - val_accuracy: 0.5095\n",
      "Epoch 246/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0830 - accuracy: 0.5197 - val_loss: 1.0566 - val_accuracy: 0.5544\n",
      "Epoch 247/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0482 - accuracy: 0.5515 - val_loss: 1.1604 - val_accuracy: 0.4667\n",
      "Epoch 248/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.5468 - val_loss: 1.1001 - val_accuracy: 0.4878\n",
      "Epoch 249/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0495 - accuracy: 0.5360 - val_loss: 1.1224 - val_accuracy: 0.4830\n",
      "Epoch 250/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0606 - accuracy: 0.5249 - val_loss: 1.1012 - val_accuracy: 0.5109\n",
      "Epoch 251/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0245 - accuracy: 0.5441 - val_loss: 1.1223 - val_accuracy: 0.4721\n",
      "Epoch 252/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0520 - accuracy: 0.5439 - val_loss: 1.1195 - val_accuracy: 0.5177\n",
      "Epoch 253/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0483 - accuracy: 0.5515 - val_loss: 1.1336 - val_accuracy: 0.5075\n",
      "Epoch 254/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0520 - accuracy: 0.5369 - val_loss: 1.1166 - val_accuracy: 0.4844\n",
      "Epoch 255/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0389 - accuracy: 0.5410 - val_loss: 1.0763 - val_accuracy: 0.5150\n",
      "Epoch 256/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0546 - accuracy: 0.5354 - val_loss: 1.0869 - val_accuracy: 0.5156\n",
      "Epoch 257/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0270 - accuracy: 0.5504 - val_loss: 1.1614 - val_accuracy: 0.4735\n",
      "Epoch 258/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0832 - accuracy: 0.5309 - val_loss: 1.0781 - val_accuracy: 0.5408\n",
      "Epoch 259/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0500 - accuracy: 0.5481 - val_loss: 1.0936 - val_accuracy: 0.5293\n",
      "Epoch 260/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0456 - accuracy: 0.5367 - val_loss: 1.1798 - val_accuracy: 0.4605\n",
      "Epoch 261/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0404 - accuracy: 0.5437 - val_loss: 1.1159 - val_accuracy: 0.5218\n",
      "Epoch 262/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0365 - accuracy: 0.5392 - val_loss: 1.1440 - val_accuracy: 0.5054\n",
      "Epoch 263/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0216 - accuracy: 0.5487 - val_loss: 1.1306 - val_accuracy: 0.5020\n",
      "Epoch 264/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0437 - accuracy: 0.5459 - val_loss: 1.0993 - val_accuracy: 0.4884\n",
      "Epoch 265/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0444 - accuracy: 0.5472 - val_loss: 1.0680 - val_accuracy: 0.5435\n",
      "Epoch 266/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0843 - accuracy: 0.5207 - val_loss: 1.0775 - val_accuracy: 0.5238\n",
      "Epoch 267/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0437 - accuracy: 0.5443 - val_loss: 1.1188 - val_accuracy: 0.4823\n",
      "Epoch 268/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0357 - accuracy: 0.5391 - val_loss: 1.1421 - val_accuracy: 0.4748\n",
      "Epoch 269/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0521 - accuracy: 0.5444 - val_loss: 1.1766 - val_accuracy: 0.4333\n",
      "Epoch 270/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0456 - accuracy: 0.5338 - val_loss: 1.0808 - val_accuracy: 0.5340\n",
      "Epoch 271/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0304 - accuracy: 0.5581 - val_loss: 1.1033 - val_accuracy: 0.5354\n",
      "Epoch 272/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0517 - accuracy: 0.5323 - val_loss: 1.1401 - val_accuracy: 0.4864\n",
      "Epoch 273/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0270 - accuracy: 0.5455 - val_loss: 1.1048 - val_accuracy: 0.4993\n",
      "Epoch 274/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0457 - accuracy: 0.5361 - val_loss: 1.1603 - val_accuracy: 0.4796\n",
      "Epoch 275/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0721 - accuracy: 0.5346 - val_loss: 1.1587 - val_accuracy: 0.4374\n",
      "Epoch 276/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0345 - accuracy: 0.5421 - val_loss: 1.1579 - val_accuracy: 0.4626\n",
      "Epoch 277/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0424 - accuracy: 0.5525 - val_loss: 1.1542 - val_accuracy: 0.4633\n",
      "Epoch 278/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0467 - accuracy: 0.5415 - val_loss: 1.0686 - val_accuracy: 0.5578\n",
      "Epoch 279/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0559 - accuracy: 0.5374 - val_loss: 1.1516 - val_accuracy: 0.4694\n",
      "Epoch 280/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0559 - accuracy: 0.5337 - val_loss: 1.2424 - val_accuracy: 0.4871\n",
      "Epoch 281/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0677 - accuracy: 0.5294 - val_loss: 1.0737 - val_accuracy: 0.5544\n",
      "Epoch 282/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0364 - accuracy: 0.5495 - val_loss: 1.1073 - val_accuracy: 0.5422\n",
      "Epoch 283/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0249 - accuracy: 0.5528 - val_loss: 1.1353 - val_accuracy: 0.5095\n",
      "Epoch 284/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0361 - accuracy: 0.5460 - val_loss: 1.1201 - val_accuracy: 0.4905\n",
      "Epoch 285/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0581 - accuracy: 0.5441 - val_loss: 1.0948 - val_accuracy: 0.5483\n",
      "Epoch 286/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0584 - accuracy: 0.5330 - val_loss: 1.0972 - val_accuracy: 0.5388\n",
      "Epoch 287/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0667 - accuracy: 0.5361 - val_loss: 1.0727 - val_accuracy: 0.5245\n",
      "Epoch 288/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0479 - accuracy: 0.5389 - val_loss: 1.1443 - val_accuracy: 0.4728\n",
      "Epoch 289/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0531 - accuracy: 0.5467 - val_loss: 1.1888 - val_accuracy: 0.4531\n",
      "Epoch 290/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0574 - accuracy: 0.5405 - val_loss: 1.1746 - val_accuracy: 0.4646\n",
      "Epoch 291/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0615 - accuracy: 0.5342 - val_loss: 1.1251 - val_accuracy: 0.4952\n",
      "Epoch 292/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0438 - accuracy: 0.5381 - val_loss: 1.1015 - val_accuracy: 0.4966\n",
      "Epoch 293/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0350 - accuracy: 0.5585 - val_loss: 1.0868 - val_accuracy: 0.5116\n",
      "Epoch 294/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0280 - accuracy: 0.5515 - val_loss: 1.1438 - val_accuracy: 0.4796\n",
      "Epoch 295/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0436 - accuracy: 0.5510 - val_loss: 1.1783 - val_accuracy: 0.4503\n",
      "Epoch 296/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0545 - accuracy: 0.5424 - val_loss: 1.1122 - val_accuracy: 0.4986\n",
      "Epoch 297/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0346 - accuracy: 0.5429 - val_loss: 1.1132 - val_accuracy: 0.4844\n",
      "Epoch 298/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0545 - accuracy: 0.5364 - val_loss: 1.1316 - val_accuracy: 0.5476\n",
      "Epoch 299/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0278 - accuracy: 0.5658 - val_loss: 1.1080 - val_accuracy: 0.5286\n",
      "Epoch 300/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0519 - accuracy: 0.5464 - val_loss: 1.0979 - val_accuracy: 0.5252\n",
      "Epoch 301/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0451 - accuracy: 0.5316 - val_loss: 1.2099 - val_accuracy: 0.4558\n",
      "Epoch 302/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0571 - accuracy: 0.5452 - val_loss: 1.1114 - val_accuracy: 0.5265\n",
      "Epoch 303/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0634 - accuracy: 0.5354 - val_loss: 1.0826 - val_accuracy: 0.5510\n",
      "Epoch 304/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0404 - accuracy: 0.5430 - val_loss: 1.1481 - val_accuracy: 0.4837\n",
      "Epoch 305/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0406 - accuracy: 0.5450 - val_loss: 1.1126 - val_accuracy: 0.5245\n",
      "Epoch 306/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0326 - accuracy: 0.5519 - val_loss: 1.1258 - val_accuracy: 0.4891\n",
      "Epoch 307/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0052 - accuracy: 0.5595 - val_loss: 1.1211 - val_accuracy: 0.4789\n",
      "Epoch 308/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0486 - accuracy: 0.5507 - val_loss: 1.1523 - val_accuracy: 0.4612\n",
      "Epoch 309/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0453 - accuracy: 0.5431 - val_loss: 1.1395 - val_accuracy: 0.5306\n",
      "Epoch 310/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0124 - accuracy: 0.5600 - val_loss: 1.1292 - val_accuracy: 0.5020\n",
      "Epoch 311/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0405 - accuracy: 0.5513 - val_loss: 1.0900 - val_accuracy: 0.5449\n",
      "Epoch 312/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0563 - accuracy: 0.5469 - val_loss: 1.1358 - val_accuracy: 0.4952\n",
      "Epoch 313/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0236 - accuracy: 0.5581 - val_loss: 1.2206 - val_accuracy: 0.4347\n",
      "Epoch 314/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0318 - accuracy: 0.5450 - val_loss: 1.1563 - val_accuracy: 0.4776\n",
      "Epoch 315/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0528 - accuracy: 0.5412 - val_loss: 1.1242 - val_accuracy: 0.5510\n",
      "Epoch 316/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0407 - accuracy: 0.5509 - val_loss: 1.1582 - val_accuracy: 0.4653\n",
      "Epoch 317/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0326 - accuracy: 0.5587 - val_loss: 1.1389 - val_accuracy: 0.5054\n",
      "Epoch 318/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0250 - accuracy: 0.5449 - val_loss: 1.1296 - val_accuracy: 0.5299\n",
      "Epoch 319/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0191 - accuracy: 0.5550 - val_loss: 1.1713 - val_accuracy: 0.4816\n",
      "Epoch 320/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0427 - accuracy: 0.5347 - val_loss: 1.1516 - val_accuracy: 0.5129\n",
      "Epoch 321/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0319 - accuracy: 0.5504 - val_loss: 1.2636 - val_accuracy: 0.4095\n",
      "Epoch 322/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0404 - accuracy: 0.5537 - val_loss: 1.1431 - val_accuracy: 0.4803\n",
      "Epoch 323/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0367 - accuracy: 0.5535 - val_loss: 1.1567 - val_accuracy: 0.4905\n",
      "Epoch 324/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0167 - accuracy: 0.5491 - val_loss: 1.1834 - val_accuracy: 0.4823\n",
      "Epoch 325/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0163 - accuracy: 0.5524 - val_loss: 1.1108 - val_accuracy: 0.5000\n",
      "Epoch 326/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0481 - accuracy: 0.5476 - val_loss: 1.2717 - val_accuracy: 0.4163\n",
      "Epoch 327/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0821 - accuracy: 0.5214 - val_loss: 1.1201 - val_accuracy: 0.4912\n",
      "Epoch 328/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0090 - accuracy: 0.5553 - val_loss: 1.1572 - val_accuracy: 0.4680\n",
      "Epoch 329/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0496 - accuracy: 0.5398 - val_loss: 1.1499 - val_accuracy: 0.5027\n",
      "Epoch 330/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0562 - accuracy: 0.5326 - val_loss: 1.1663 - val_accuracy: 0.4912\n",
      "Epoch 331/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0437 - accuracy: 0.5547 - val_loss: 1.1960 - val_accuracy: 0.4605\n",
      "Epoch 332/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0596 - accuracy: 0.5336 - val_loss: 1.1926 - val_accuracy: 0.4701\n",
      "Epoch 333/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0433 - accuracy: 0.5431 - val_loss: 1.1530 - val_accuracy: 0.4823\n",
      "Epoch 334/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0467 - accuracy: 0.5436 - val_loss: 1.1719 - val_accuracy: 0.4830\n",
      "Epoch 335/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0212 - accuracy: 0.5564 - val_loss: 1.1427 - val_accuracy: 0.4905\n",
      "Epoch 336/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0298 - accuracy: 0.5495 - val_loss: 1.1857 - val_accuracy: 0.4469\n",
      "Epoch 337/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0113 - accuracy: 0.5587 - val_loss: 1.2802 - val_accuracy: 0.4401\n",
      "Epoch 338/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0355 - accuracy: 0.5425 - val_loss: 1.1809 - val_accuracy: 0.5075\n",
      "Epoch 339/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0221 - accuracy: 0.5477 - val_loss: 1.1735 - val_accuracy: 0.4755\n",
      "Epoch 340/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0107 - accuracy: 0.5563 - val_loss: 1.1871 - val_accuracy: 0.4898\n",
      "Epoch 341/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0310 - accuracy: 0.5672 - val_loss: 1.1757 - val_accuracy: 0.5524\n",
      "Epoch 342/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0608 - accuracy: 0.5182 - val_loss: 1.1343 - val_accuracy: 0.4830\n",
      "Epoch 343/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0422 - accuracy: 0.5541 - val_loss: 1.1907 - val_accuracy: 0.5082\n",
      "Epoch 344/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0534 - accuracy: 0.5467 - val_loss: 1.1403 - val_accuracy: 0.5252\n",
      "Epoch 345/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0420 - accuracy: 0.5487 - val_loss: 1.1486 - val_accuracy: 0.4619\n",
      "Epoch 346/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0659 - accuracy: 0.5390 - val_loss: 1.1544 - val_accuracy: 0.5313\n",
      "Epoch 347/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0449 - accuracy: 0.5491 - val_loss: 1.1405 - val_accuracy: 0.5027\n",
      "Epoch 348/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0390 - accuracy: 0.5434 - val_loss: 1.2169 - val_accuracy: 0.4327\n",
      "Epoch 349/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0177 - accuracy: 0.5590 - val_loss: 1.1510 - val_accuracy: 0.4816\n",
      "Epoch 350/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0415 - accuracy: 0.5547 - val_loss: 1.1727 - val_accuracy: 0.4639\n",
      "Epoch 351/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0191 - accuracy: 0.5591 - val_loss: 1.2083 - val_accuracy: 0.4286\n",
      "Epoch 352/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0167 - accuracy: 0.5617 - val_loss: 1.1679 - val_accuracy: 0.4782\n",
      "Epoch 353/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0351 - accuracy: 0.5559 - val_loss: 1.1895 - val_accuracy: 0.4810\n",
      "Epoch 354/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0531 - accuracy: 0.5329 - val_loss: 1.1366 - val_accuracy: 0.5497\n",
      "Epoch 355/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0495 - accuracy: 0.5432 - val_loss: 1.1536 - val_accuracy: 0.4925\n",
      "Epoch 356/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0560 - accuracy: 0.5417 - val_loss: 1.2241 - val_accuracy: 0.4456\n",
      "Epoch 357/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0405 - accuracy: 0.5531 - val_loss: 1.1761 - val_accuracy: 0.4973\n",
      "Epoch 358/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0437 - accuracy: 0.5345 - val_loss: 1.1215 - val_accuracy: 0.5306\n",
      "Epoch 359/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0446 - accuracy: 0.5368 - val_loss: 1.1183 - val_accuracy: 0.5367\n",
      "Epoch 360/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0524 - accuracy: 0.5415 - val_loss: 1.1394 - val_accuracy: 0.5320\n",
      "Epoch 361/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0197 - accuracy: 0.5679 - val_loss: 1.2129 - val_accuracy: 0.4687\n",
      "Epoch 362/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0279 - accuracy: 0.5473 - val_loss: 1.1401 - val_accuracy: 0.4830\n",
      "Epoch 363/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0109 - accuracy: 0.5428 - val_loss: 1.1450 - val_accuracy: 0.5075\n",
      "Epoch 364/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0357 - accuracy: 0.5531 - val_loss: 1.1642 - val_accuracy: 0.4694\n",
      "Epoch 365/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0329 - accuracy: 0.5608 - val_loss: 1.1610 - val_accuracy: 0.4905\n",
      "Epoch 366/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0216 - accuracy: 0.5560 - val_loss: 1.2008 - val_accuracy: 0.4476\n",
      "Epoch 367/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0285 - accuracy: 0.5485 - val_loss: 1.1679 - val_accuracy: 0.4850\n",
      "Epoch 368/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0477 - accuracy: 0.5436 - val_loss: 1.1584 - val_accuracy: 0.4755\n",
      "Epoch 369/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0311 - accuracy: 0.5593 - val_loss: 1.1929 - val_accuracy: 0.4694\n",
      "Epoch 370/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0306 - accuracy: 0.5608 - val_loss: 1.2236 - val_accuracy: 0.4687\n",
      "Epoch 371/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0034 - accuracy: 0.5602 - val_loss: 1.1731 - val_accuracy: 0.4946\n",
      "Epoch 372/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0235 - accuracy: 0.5593 - val_loss: 1.1658 - val_accuracy: 0.5442\n",
      "Epoch 373/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0316 - accuracy: 0.5443 - val_loss: 1.1685 - val_accuracy: 0.5313\n",
      "Epoch 374/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0299 - accuracy: 0.5489 - val_loss: 1.1501 - val_accuracy: 0.5197\n",
      "Epoch 375/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0139 - accuracy: 0.5679 - val_loss: 1.1686 - val_accuracy: 0.4796\n",
      "Epoch 376/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0209 - accuracy: 0.5556 - val_loss: 1.1018 - val_accuracy: 0.4918\n",
      "Epoch 377/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0754 - accuracy: 0.5219 - val_loss: 1.1815 - val_accuracy: 0.4810\n",
      "Epoch 378/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0438 - accuracy: 0.5535 - val_loss: 1.1240 - val_accuracy: 0.5415\n",
      "Epoch 379/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0477 - accuracy: 0.5442 - val_loss: 1.1949 - val_accuracy: 0.4714\n",
      "Epoch 380/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0323 - accuracy: 0.5505 - val_loss: 1.1488 - val_accuracy: 0.5156\n",
      "Epoch 381/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0260 - accuracy: 0.5413 - val_loss: 1.1396 - val_accuracy: 0.4925\n",
      "Epoch 382/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0047 - accuracy: 0.5600 - val_loss: 1.1263 - val_accuracy: 0.5544\n",
      "Epoch 383/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0497 - accuracy: 0.5467 - val_loss: 1.1805 - val_accuracy: 0.4918\n",
      "Epoch 384/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0266 - accuracy: 0.5613 - val_loss: 1.1308 - val_accuracy: 0.4878\n",
      "Epoch 385/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0131 - accuracy: 0.5556 - val_loss: 1.2147 - val_accuracy: 0.4524\n",
      "Epoch 386/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0321 - accuracy: 0.5338 - val_loss: 1.1326 - val_accuracy: 0.5122\n",
      "Epoch 387/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0307 - accuracy: 0.5486 - val_loss: 1.2235 - val_accuracy: 0.4456\n",
      "Epoch 388/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0304 - accuracy: 0.5602 - val_loss: 1.1592 - val_accuracy: 0.5252\n",
      "Epoch 389/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0189 - accuracy: 0.5643 - val_loss: 1.1971 - val_accuracy: 0.4830\n",
      "Epoch 390/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0109 - accuracy: 0.5633 - val_loss: 1.1652 - val_accuracy: 0.4755\n",
      "Epoch 391/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0387 - accuracy: 0.5471 - val_loss: 1.1293 - val_accuracy: 0.5313\n",
      "Epoch 392/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0204 - accuracy: 0.5590 - val_loss: 1.1499 - val_accuracy: 0.5211\n",
      "Epoch 393/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0342 - accuracy: 0.5454 - val_loss: 1.1406 - val_accuracy: 0.4925\n",
      "Epoch 394/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0225 - accuracy: 0.5537 - val_loss: 1.1863 - val_accuracy: 0.4741\n",
      "Epoch 395/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0296 - accuracy: 0.5572 - val_loss: 1.1423 - val_accuracy: 0.5204\n",
      "Epoch 396/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0486 - accuracy: 0.5482 - val_loss: 1.1127 - val_accuracy: 0.5395\n",
      "Epoch 397/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0147 - accuracy: 0.5508 - val_loss: 1.1540 - val_accuracy: 0.4673\n",
      "Epoch 398/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0182 - accuracy: 0.5517 - val_loss: 1.1540 - val_accuracy: 0.5068\n",
      "Epoch 399/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0359 - accuracy: 0.5564 - val_loss: 1.1838 - val_accuracy: 0.4639\n",
      "Epoch 400/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0331 - accuracy: 0.5703 - val_loss: 1.1904 - val_accuracy: 0.4741\n",
      "Epoch 401/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0222 - accuracy: 0.5496 - val_loss: 1.1703 - val_accuracy: 0.4932\n",
      "Epoch 402/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0386 - accuracy: 0.5519 - val_loss: 1.1436 - val_accuracy: 0.5075\n",
      "Epoch 403/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0265 - accuracy: 0.5418 - val_loss: 1.1134 - val_accuracy: 0.5163\n",
      "Epoch 404/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0209 - accuracy: 0.5543 - val_loss: 1.1406 - val_accuracy: 0.5442\n",
      "Epoch 405/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0317 - accuracy: 0.5554 - val_loss: 1.1932 - val_accuracy: 0.4701\n",
      "Epoch 406/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0220 - accuracy: 0.5591 - val_loss: 1.1623 - val_accuracy: 0.5000\n",
      "Epoch 407/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0214 - accuracy: 0.5489 - val_loss: 1.1597 - val_accuracy: 0.4959\n",
      "Epoch 408/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0201 - accuracy: 0.5590 - val_loss: 1.1566 - val_accuracy: 0.5020\n",
      "Epoch 409/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0452 - accuracy: 0.5593 - val_loss: 1.1628 - val_accuracy: 0.5449\n",
      "Epoch 410/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0464 - accuracy: 0.5348 - val_loss: 1.2637 - val_accuracy: 0.4095\n",
      "Epoch 411/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0474 - accuracy: 0.5405 - val_loss: 1.1896 - val_accuracy: 0.5252\n",
      "Epoch 412/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0265 - accuracy: 0.5493 - val_loss: 1.2102 - val_accuracy: 0.4585\n",
      "Epoch 413/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0117 - accuracy: 0.5481 - val_loss: 1.1502 - val_accuracy: 0.5259\n",
      "Epoch 414/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0135 - accuracy: 0.5626 - val_loss: 1.1823 - val_accuracy: 0.4667\n",
      "Epoch 415/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0039 - accuracy: 0.5572 - val_loss: 1.1692 - val_accuracy: 0.5245\n",
      "Epoch 416/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0294 - accuracy: 0.5586 - val_loss: 1.1623 - val_accuracy: 0.5048\n",
      "Epoch 417/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0083 - accuracy: 0.5694 - val_loss: 1.1710 - val_accuracy: 0.4776\n",
      "Epoch 418/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0462 - accuracy: 0.5536 - val_loss: 1.1744 - val_accuracy: 0.5211\n",
      "Epoch 419/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0371 - accuracy: 0.5476 - val_loss: 1.1720 - val_accuracy: 0.5102\n",
      "Epoch 420/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0250 - accuracy: 0.5601 - val_loss: 1.2039 - val_accuracy: 0.4823\n",
      "Epoch 421/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0234 - accuracy: 0.5483 - val_loss: 1.1706 - val_accuracy: 0.4973\n",
      "Epoch 422/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0150 - accuracy: 0.5591 - val_loss: 1.1273 - val_accuracy: 0.5184\n",
      "Epoch 423/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0399 - accuracy: 0.5653 - val_loss: 1.1697 - val_accuracy: 0.5014\n",
      "Epoch 424/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0288 - accuracy: 0.5554 - val_loss: 1.1719 - val_accuracy: 0.5007\n",
      "Epoch 425/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0363 - accuracy: 0.5496 - val_loss: 1.1946 - val_accuracy: 0.4878\n",
      "Epoch 426/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0114 - accuracy: 0.5517 - val_loss: 1.1785 - val_accuracy: 0.5014\n",
      "Epoch 427/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0171 - accuracy: 0.5569 - val_loss: 1.1995 - val_accuracy: 0.4503\n",
      "Epoch 428/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0268 - accuracy: 0.5579 - val_loss: 1.1949 - val_accuracy: 0.4803\n",
      "Epoch 429/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0270 - accuracy: 0.5528 - val_loss: 1.3056 - val_accuracy: 0.4177\n",
      "Epoch 430/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0248 - accuracy: 0.5426 - val_loss: 1.1917 - val_accuracy: 0.4932\n",
      "Epoch 431/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0193 - accuracy: 0.5646 - val_loss: 1.1682 - val_accuracy: 0.5054\n",
      "Epoch 432/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0339 - accuracy: 0.5461 - val_loss: 1.1623 - val_accuracy: 0.4932\n",
      "Epoch 433/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0529 - accuracy: 0.5474 - val_loss: 1.1905 - val_accuracy: 0.5041\n",
      "Epoch 434/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0290 - accuracy: 0.5448 - val_loss: 1.2961 - val_accuracy: 0.4354\n",
      "Epoch 435/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0445 - accuracy: 0.5342 - val_loss: 1.1851 - val_accuracy: 0.5231\n",
      "Epoch 436/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0397 - accuracy: 0.5452 - val_loss: 1.1747 - val_accuracy: 0.5156\n",
      "Epoch 437/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0155 - accuracy: 0.5508 - val_loss: 1.2777 - val_accuracy: 0.4204\n",
      "Epoch 438/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0099 - accuracy: 0.5747 - val_loss: 1.2120 - val_accuracy: 0.5218\n",
      "Epoch 439/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0022 - accuracy: 0.5618 - val_loss: 1.2032 - val_accuracy: 0.4837\n",
      "Epoch 440/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.5590 - val_loss: 1.1851 - val_accuracy: 0.5116\n",
      "Epoch 441/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0041 - accuracy: 0.5655 - val_loss: 1.2120 - val_accuracy: 0.5068\n",
      "Epoch 442/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0093 - accuracy: 0.5508 - val_loss: 1.1841 - val_accuracy: 0.4932\n",
      "Epoch 443/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0198 - accuracy: 0.5580 - val_loss: 1.2538 - val_accuracy: 0.4599\n",
      "Epoch 444/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0068 - accuracy: 0.5734 - val_loss: 1.1890 - val_accuracy: 0.4796\n",
      "Epoch 445/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0173 - accuracy: 0.5487 - val_loss: 1.2224 - val_accuracy: 0.4803\n",
      "Epoch 446/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0279 - accuracy: 0.5517 - val_loss: 1.1810 - val_accuracy: 0.5129\n",
      "Epoch 447/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0254 - accuracy: 0.5631 - val_loss: 1.1617 - val_accuracy: 0.4816\n",
      "Epoch 448/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0186 - accuracy: 0.5673 - val_loss: 1.1749 - val_accuracy: 0.5156\n",
      "Epoch 449/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0186 - accuracy: 0.5670 - val_loss: 1.1971 - val_accuracy: 0.5279\n",
      "Epoch 450/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0068 - accuracy: 0.5631 - val_loss: 1.2406 - val_accuracy: 0.4721\n",
      "Epoch 451/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0177 - accuracy: 0.5538 - val_loss: 1.1951 - val_accuracy: 0.5170\n",
      "Epoch 452/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0135 - accuracy: 0.5672 - val_loss: 1.1558 - val_accuracy: 0.5381\n",
      "Epoch 453/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0211 - accuracy: 0.5519 - val_loss: 1.1411 - val_accuracy: 0.5347\n",
      "Epoch 454/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0329 - accuracy: 0.5390 - val_loss: 1.2217 - val_accuracy: 0.4333\n",
      "Epoch 455/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0343 - accuracy: 0.5568 - val_loss: 1.2325 - val_accuracy: 0.4551\n",
      "Epoch 456/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0134 - accuracy: 0.5636 - val_loss: 1.2706 - val_accuracy: 0.4592\n",
      "Epoch 457/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0139 - accuracy: 0.5560 - val_loss: 1.1579 - val_accuracy: 0.5306\n",
      "Epoch 458/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0085 - accuracy: 0.5523 - val_loss: 1.2125 - val_accuracy: 0.4701\n",
      "Epoch 459/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0165 - accuracy: 0.5556 - val_loss: 1.2550 - val_accuracy: 0.4442\n",
      "Epoch 460/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0104 - accuracy: 0.5652 - val_loss: 1.2605 - val_accuracy: 0.4592\n",
      "Epoch 461/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0294 - accuracy: 0.5466 - val_loss: 1.2319 - val_accuracy: 0.4707\n",
      "Epoch 462/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0469 - accuracy: 0.5344 - val_loss: 1.2099 - val_accuracy: 0.4986\n",
      "Epoch 463/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0186 - accuracy: 0.5578 - val_loss: 1.2055 - val_accuracy: 0.4864\n",
      "Epoch 464/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0114 - accuracy: 0.5710 - val_loss: 1.2320 - val_accuracy: 0.4823\n",
      "Epoch 465/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0028 - accuracy: 0.5739 - val_loss: 1.2762 - val_accuracy: 0.4252\n",
      "Epoch 466/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9864 - accuracy: 0.5762 - val_loss: 1.1810 - val_accuracy: 0.5116\n",
      "Epoch 467/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0226 - accuracy: 0.5432 - val_loss: 1.2307 - val_accuracy: 0.4551\n",
      "Epoch 468/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0037 - accuracy: 0.5755 - val_loss: 1.2084 - val_accuracy: 0.5088\n",
      "Epoch 469/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0366 - accuracy: 0.5548 - val_loss: 1.1624 - val_accuracy: 0.5204\n",
      "Epoch 470/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9891 - accuracy: 0.5723 - val_loss: 1.2317 - val_accuracy: 0.4905\n",
      "Epoch 471/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0245 - accuracy: 0.5389 - val_loss: 1.2307 - val_accuracy: 0.4605\n",
      "Epoch 472/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9904 - accuracy: 0.5768 - val_loss: 1.3099 - val_accuracy: 0.4503\n",
      "Epoch 473/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.5535 - val_loss: 1.2518 - val_accuracy: 0.4626\n",
      "Epoch 474/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0095 - accuracy: 0.5669 - val_loss: 1.2187 - val_accuracy: 0.5000\n",
      "Epoch 475/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0155 - accuracy: 0.5612 - val_loss: 1.2134 - val_accuracy: 0.5082\n",
      "Epoch 476/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0097 - accuracy: 0.5528 - val_loss: 1.1887 - val_accuracy: 0.4939\n",
      "Epoch 477/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0182 - accuracy: 0.5504 - val_loss: 1.2141 - val_accuracy: 0.5190\n",
      "Epoch 478/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0228 - accuracy: 0.5509 - val_loss: 1.1917 - val_accuracy: 0.5279\n",
      "Epoch 479/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0123 - accuracy: 0.5530 - val_loss: 1.3303 - val_accuracy: 0.3946\n",
      "Epoch 480/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0183 - accuracy: 0.5550 - val_loss: 1.2513 - val_accuracy: 0.4401\n",
      "Epoch 481/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0282 - accuracy: 0.5574 - val_loss: 1.2192 - val_accuracy: 0.4810\n",
      "Epoch 482/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0146 - accuracy: 0.5543 - val_loss: 1.1860 - val_accuracy: 0.4959\n",
      "Epoch 483/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0032 - accuracy: 0.5690 - val_loss: 1.2082 - val_accuracy: 0.5136\n",
      "Epoch 484/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0035 - accuracy: 0.5635 - val_loss: 1.1869 - val_accuracy: 0.5327\n",
      "Epoch 485/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0033 - accuracy: 0.5634 - val_loss: 1.2564 - val_accuracy: 0.4592\n",
      "Epoch 486/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0223 - accuracy: 0.5560 - val_loss: 1.2203 - val_accuracy: 0.4850\n",
      "Epoch 487/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0255 - accuracy: 0.5502 - val_loss: 1.2211 - val_accuracy: 0.5150\n",
      "Epoch 488/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9960 - accuracy: 0.5608 - val_loss: 1.2502 - val_accuracy: 0.4435\n",
      "Epoch 489/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9975 - accuracy: 0.5606 - val_loss: 1.1676 - val_accuracy: 0.4946\n",
      "Epoch 490/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9801 - accuracy: 0.5743 - val_loss: 1.2034 - val_accuracy: 0.5197\n",
      "Epoch 491/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0228 - accuracy: 0.5652 - val_loss: 1.2578 - val_accuracy: 0.4483\n",
      "Epoch 492/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0278 - accuracy: 0.5546 - val_loss: 1.1778 - val_accuracy: 0.5122\n",
      "Epoch 493/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0272 - accuracy: 0.5511 - val_loss: 1.1761 - val_accuracy: 0.4932\n",
      "Epoch 494/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9952 - accuracy: 0.5749 - val_loss: 1.1828 - val_accuracy: 0.4707\n",
      "Epoch 495/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0217 - accuracy: 0.5658 - val_loss: 1.2468 - val_accuracy: 0.4993\n",
      "Epoch 496/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9936 - accuracy: 0.5730 - val_loss: 1.2283 - val_accuracy: 0.5000\n",
      "Epoch 497/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0219 - accuracy: 0.5518 - val_loss: 1.1942 - val_accuracy: 0.5265\n",
      "Epoch 498/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9912 - accuracy: 0.5632 - val_loss: 1.2218 - val_accuracy: 0.4551\n",
      "Epoch 499/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0057 - accuracy: 0.5561 - val_loss: 1.2601 - val_accuracy: 0.4469\n",
      "Epoch 500/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9791 - accuracy: 0.5877 - val_loss: 1.2711 - val_accuracy: 0.4476\n",
      "Epoch 501/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9980 - accuracy: 0.5777 - val_loss: 1.2809 - val_accuracy: 0.4571\n",
      "Epoch 502/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0086 - accuracy: 0.5682 - val_loss: 1.2098 - val_accuracy: 0.5068\n",
      "Epoch 503/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9947 - accuracy: 0.5757 - val_loss: 1.3006 - val_accuracy: 0.4823\n",
      "Epoch 504/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0227 - accuracy: 0.5557 - val_loss: 1.2974 - val_accuracy: 0.5041\n",
      "Epoch 505/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0057 - accuracy: 0.5497 - val_loss: 1.2452 - val_accuracy: 0.5211\n",
      "Epoch 506/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0073 - accuracy: 0.5575 - val_loss: 1.2124 - val_accuracy: 0.5231\n",
      "Epoch 507/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0225 - accuracy: 0.5704 - val_loss: 1.2437 - val_accuracy: 0.4585\n",
      "Epoch 508/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0182 - accuracy: 0.5648 - val_loss: 1.2682 - val_accuracy: 0.5102\n",
      "Epoch 509/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0078 - accuracy: 0.5636 - val_loss: 1.2744 - val_accuracy: 0.4408\n",
      "Epoch 510/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0045 - accuracy: 0.5755 - val_loss: 1.1662 - val_accuracy: 0.5116\n",
      "Epoch 511/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0009 - accuracy: 0.5768 - val_loss: 1.1990 - val_accuracy: 0.5286\n",
      "Epoch 512/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0058 - accuracy: 0.5666 - val_loss: 1.1923 - val_accuracy: 0.5333\n",
      "Epoch 513/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9919 - accuracy: 0.5676 - val_loss: 1.2739 - val_accuracy: 0.4442\n",
      "Epoch 514/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0201 - accuracy: 0.5517 - val_loss: 1.1793 - val_accuracy: 0.5218\n",
      "Epoch 515/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0342 - accuracy: 0.5545 - val_loss: 1.2270 - val_accuracy: 0.4959\n",
      "Epoch 516/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0162 - accuracy: 0.5519 - val_loss: 1.2133 - val_accuracy: 0.5272\n",
      "Epoch 517/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0141 - accuracy: 0.5727 - val_loss: 1.3153 - val_accuracy: 0.4741\n",
      "Epoch 518/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0313 - accuracy: 0.5485 - val_loss: 1.2051 - val_accuracy: 0.5224\n",
      "Epoch 519/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9951 - accuracy: 0.5737 - val_loss: 1.2065 - val_accuracy: 0.4646\n",
      "Epoch 520/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0165 - accuracy: 0.5528 - val_loss: 1.2587 - val_accuracy: 0.5109\n",
      "Epoch 521/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9864 - accuracy: 0.5688 - val_loss: 1.2398 - val_accuracy: 0.4633\n",
      "Epoch 522/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9961 - accuracy: 0.5745 - val_loss: 1.2612 - val_accuracy: 0.5374\n",
      "Epoch 523/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0109 - accuracy: 0.5608 - val_loss: 1.2236 - val_accuracy: 0.5286\n",
      "Epoch 524/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9890 - accuracy: 0.5550 - val_loss: 1.2286 - val_accuracy: 0.4939\n",
      "Epoch 525/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0005 - accuracy: 0.5674 - val_loss: 1.2024 - val_accuracy: 0.4891\n",
      "Epoch 526/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9807 - accuracy: 0.5791 - val_loss: 1.2591 - val_accuracy: 0.4850\n",
      "Epoch 527/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9929 - accuracy: 0.5727 - val_loss: 1.2240 - val_accuracy: 0.4517\n",
      "Epoch 528/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0153 - accuracy: 0.5765 - val_loss: 1.3096 - val_accuracy: 0.4313\n",
      "Epoch 529/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0181 - accuracy: 0.5743 - val_loss: 1.3051 - val_accuracy: 0.4299\n",
      "Epoch 530/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0039 - accuracy: 0.5737 - val_loss: 1.2674 - val_accuracy: 0.4456\n",
      "Epoch 531/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0313 - accuracy: 0.5572 - val_loss: 1.2157 - val_accuracy: 0.5000\n",
      "Epoch 532/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9780 - accuracy: 0.5789 - val_loss: 1.2756 - val_accuracy: 0.4340\n",
      "Epoch 533/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0084 - accuracy: 0.5662 - val_loss: 1.2279 - val_accuracy: 0.4673\n",
      "Epoch 534/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9978 - accuracy: 0.5689 - val_loss: 1.2515 - val_accuracy: 0.5075\n",
      "Epoch 535/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0117 - accuracy: 0.5633 - val_loss: 1.2558 - val_accuracy: 0.5381\n",
      "Epoch 536/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0260 - accuracy: 0.5668 - val_loss: 1.2285 - val_accuracy: 0.5143\n",
      "Epoch 537/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9866 - accuracy: 0.5710 - val_loss: 1.2231 - val_accuracy: 0.4837\n",
      "Epoch 538/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0138 - accuracy: 0.5575 - val_loss: 1.2630 - val_accuracy: 0.4442\n",
      "Epoch 539/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9975 - accuracy: 0.5657 - val_loss: 1.2243 - val_accuracy: 0.4755\n",
      "Epoch 540/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9853 - accuracy: 0.5906 - val_loss: 1.2689 - val_accuracy: 0.4531\n",
      "Epoch 541/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9917 - accuracy: 0.5643 - val_loss: 1.2212 - val_accuracy: 0.4673\n",
      "Epoch 542/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0050 - accuracy: 0.5470 - val_loss: 1.2488 - val_accuracy: 0.4796\n",
      "Epoch 543/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9767 - accuracy: 0.5724 - val_loss: 1.2306 - val_accuracy: 0.5320\n",
      "Epoch 544/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0110 - accuracy: 0.5604 - val_loss: 1.2264 - val_accuracy: 0.5000\n",
      "Epoch 545/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0105 - accuracy: 0.5485 - val_loss: 1.2775 - val_accuracy: 0.4463\n",
      "Epoch 546/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9953 - accuracy: 0.5624 - val_loss: 1.2392 - val_accuracy: 0.4816\n",
      "Epoch 547/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0163 - accuracy: 0.5630 - val_loss: 1.2854 - val_accuracy: 0.4721\n",
      "Epoch 548/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0216 - accuracy: 0.5647 - val_loss: 1.2418 - val_accuracy: 0.5143\n",
      "Epoch 549/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0220 - accuracy: 0.5441 - val_loss: 1.2344 - val_accuracy: 0.5034\n",
      "Epoch 550/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0014 - accuracy: 0.5592 - val_loss: 1.2243 - val_accuracy: 0.5116\n",
      "Epoch 551/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9909 - accuracy: 0.5569 - val_loss: 1.2907 - val_accuracy: 0.4422\n",
      "Epoch 552/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9952 - accuracy: 0.5639 - val_loss: 1.1778 - val_accuracy: 0.5429\n",
      "Epoch 553/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0161 - accuracy: 0.5438 - val_loss: 1.2427 - val_accuracy: 0.5218\n",
      "Epoch 554/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9922 - accuracy: 0.5636 - val_loss: 1.2864 - val_accuracy: 0.5027\n",
      "Epoch 555/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0005 - accuracy: 0.5747 - val_loss: 1.2486 - val_accuracy: 0.4912\n",
      "Epoch 556/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9749 - accuracy: 0.5710 - val_loss: 1.2483 - val_accuracy: 0.4537\n",
      "Epoch 557/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0063 - accuracy: 0.5575 - val_loss: 1.2306 - val_accuracy: 0.4884\n",
      "Epoch 558/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9956 - accuracy: 0.5723 - val_loss: 1.2443 - val_accuracy: 0.5014\n",
      "Epoch 559/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9932 - accuracy: 0.5633 - val_loss: 1.2950 - val_accuracy: 0.4714\n",
      "Epoch 560/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0167 - accuracy: 0.5618 - val_loss: 1.3066 - val_accuracy: 0.4531\n",
      "Epoch 561/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0345 - accuracy: 0.5453 - val_loss: 1.2459 - val_accuracy: 0.5224\n",
      "Epoch 562/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0116 - accuracy: 0.5586 - val_loss: 1.3628 - val_accuracy: 0.3973\n",
      "Epoch 563/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0034 - accuracy: 0.5596 - val_loss: 1.2646 - val_accuracy: 0.4816\n",
      "Epoch 564/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9988 - accuracy: 0.5701 - val_loss: 1.2937 - val_accuracy: 0.4667\n",
      "Epoch 565/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9801 - accuracy: 0.5718 - val_loss: 1.2917 - val_accuracy: 0.4347\n",
      "Epoch 566/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9879 - accuracy: 0.5824 - val_loss: 1.3046 - val_accuracy: 0.4381\n",
      "Epoch 567/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0100 - accuracy: 0.5639 - val_loss: 1.3098 - val_accuracy: 0.4163\n",
      "Epoch 568/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0076 - accuracy: 0.5648 - val_loss: 1.2163 - val_accuracy: 0.5197\n",
      "Epoch 569/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0020 - accuracy: 0.5502 - val_loss: 1.2768 - val_accuracy: 0.5306\n",
      "Epoch 570/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0146 - accuracy: 0.5580 - val_loss: 1.2239 - val_accuracy: 0.5082\n",
      "Epoch 571/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9850 - accuracy: 0.5790 - val_loss: 1.2515 - val_accuracy: 0.4932\n",
      "Epoch 572/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9881 - accuracy: 0.5609 - val_loss: 1.2761 - val_accuracy: 0.4993\n",
      "Epoch 573/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0033 - accuracy: 0.5721 - val_loss: 1.2550 - val_accuracy: 0.5347\n",
      "Epoch 574/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9975 - accuracy: 0.5681 - val_loss: 1.2607 - val_accuracy: 0.4796\n",
      "Epoch 575/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9889 - accuracy: 0.5797 - val_loss: 1.3078 - val_accuracy: 0.5238\n",
      "Epoch 576/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0004 - accuracy: 0.5558 - val_loss: 1.3286 - val_accuracy: 0.4204\n",
      "Epoch 577/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0053 - accuracy: 0.5784 - val_loss: 1.2589 - val_accuracy: 0.4864\n",
      "Epoch 578/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9918 - accuracy: 0.5693 - val_loss: 1.2561 - val_accuracy: 0.5156\n",
      "Epoch 579/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0028 - accuracy: 0.5697 - val_loss: 1.3033 - val_accuracy: 0.4980\n",
      "Epoch 580/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9804 - accuracy: 0.5647 - val_loss: 1.2534 - val_accuracy: 0.4823\n",
      "Epoch 581/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9754 - accuracy: 0.5825 - val_loss: 1.2572 - val_accuracy: 0.5204\n",
      "Epoch 582/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9931 - accuracy: 0.5677 - val_loss: 1.2549 - val_accuracy: 0.5245\n",
      "Epoch 583/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9732 - accuracy: 0.5743 - val_loss: 1.3195 - val_accuracy: 0.4789\n",
      "Epoch 584/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0167 - accuracy: 0.5539 - val_loss: 1.1991 - val_accuracy: 0.5272\n",
      "Epoch 585/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0064 - accuracy: 0.5579 - val_loss: 1.2703 - val_accuracy: 0.5020\n",
      "Epoch 586/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9899 - accuracy: 0.5767 - val_loss: 1.2990 - val_accuracy: 0.4660\n",
      "Epoch 587/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9891 - accuracy: 0.5691 - val_loss: 1.2566 - val_accuracy: 0.5156\n",
      "Epoch 588/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9950 - accuracy: 0.5624 - val_loss: 1.3117 - val_accuracy: 0.4823\n",
      "Epoch 589/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0176 - accuracy: 0.5646 - val_loss: 1.2747 - val_accuracy: 0.5218\n",
      "Epoch 590/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0194 - accuracy: 0.5628 - val_loss: 1.2795 - val_accuracy: 0.4626\n",
      "Epoch 591/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9874 - accuracy: 0.5894 - val_loss: 1.2564 - val_accuracy: 0.4993\n",
      "Epoch 592/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0078 - accuracy: 0.5648 - val_loss: 1.2277 - val_accuracy: 0.5252\n",
      "Epoch 593/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9827 - accuracy: 0.5725 - val_loss: 1.2436 - val_accuracy: 0.5333\n",
      "Epoch 594/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9888 - accuracy: 0.5739 - val_loss: 1.2221 - val_accuracy: 0.5422\n",
      "Epoch 595/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0048 - accuracy: 0.5662 - val_loss: 1.2798 - val_accuracy: 0.5252\n",
      "Epoch 596/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9932 - accuracy: 0.5830 - val_loss: 1.2898 - val_accuracy: 0.4626\n",
      "Epoch 597/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0046 - accuracy: 0.5566 - val_loss: 1.2032 - val_accuracy: 0.4864\n",
      "Epoch 598/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0117 - accuracy: 0.5649 - val_loss: 1.2547 - val_accuracy: 0.5279\n",
      "Epoch 599/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0327 - accuracy: 0.5449 - val_loss: 1.3263 - val_accuracy: 0.4701\n",
      "Epoch 600/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9965 - accuracy: 0.5666 - val_loss: 1.2529 - val_accuracy: 0.5136\n",
      "Epoch 601/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9967 - accuracy: 0.5742 - val_loss: 1.2520 - val_accuracy: 0.5150\n",
      "Epoch 602/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9657 - accuracy: 0.5831 - val_loss: 1.3702 - val_accuracy: 0.3952\n",
      "Epoch 603/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9966 - accuracy: 0.5633 - val_loss: 1.2369 - val_accuracy: 0.5218\n",
      "Epoch 604/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9996 - accuracy: 0.5708 - val_loss: 1.2689 - val_accuracy: 0.5333\n",
      "Epoch 605/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0048 - accuracy: 0.5688 - val_loss: 1.2851 - val_accuracy: 0.4544\n",
      "Epoch 606/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9830 - accuracy: 0.5830 - val_loss: 1.3269 - val_accuracy: 0.5014\n",
      "Epoch 607/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0160 - accuracy: 0.5650 - val_loss: 1.2608 - val_accuracy: 0.5286\n",
      "Epoch 608/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9940 - accuracy: 0.5678 - val_loss: 1.2994 - val_accuracy: 0.4483\n",
      "Epoch 609/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0143 - accuracy: 0.5654 - val_loss: 1.2949 - val_accuracy: 0.5109\n",
      "Epoch 610/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0038 - accuracy: 0.5551 - val_loss: 1.2887 - val_accuracy: 0.4667\n",
      "Epoch 611/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9987 - accuracy: 0.5835 - val_loss: 1.2742 - val_accuracy: 0.4646\n",
      "Epoch 612/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9940 - accuracy: 0.5724 - val_loss: 1.2981 - val_accuracy: 0.5082\n",
      "Epoch 613/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0167 - accuracy: 0.5615 - val_loss: 1.2624 - val_accuracy: 0.5313\n",
      "Epoch 614/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9838 - accuracy: 0.5726 - val_loss: 1.3130 - val_accuracy: 0.5272\n",
      "Epoch 615/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9815 - accuracy: 0.5711 - val_loss: 1.2908 - val_accuracy: 0.4721\n",
      "Epoch 616/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9875 - accuracy: 0.5733 - val_loss: 1.3133 - val_accuracy: 0.4544\n",
      "Epoch 617/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9760 - accuracy: 0.5764 - val_loss: 1.2770 - val_accuracy: 0.4918\n",
      "Epoch 618/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9987 - accuracy: 0.5760 - val_loss: 1.2879 - val_accuracy: 0.4912\n",
      "Epoch 619/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9776 - accuracy: 0.5730 - val_loss: 1.2707 - val_accuracy: 0.5136\n",
      "Epoch 620/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9741 - accuracy: 0.5791 - val_loss: 1.2427 - val_accuracy: 0.5014\n",
      "Epoch 621/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9812 - accuracy: 0.5765 - val_loss: 1.2928 - val_accuracy: 0.4748\n",
      "Epoch 622/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0014 - accuracy: 0.5605 - val_loss: 1.3344 - val_accuracy: 0.4878\n",
      "Epoch 623/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9886 - accuracy: 0.5484 - val_loss: 1.2905 - val_accuracy: 0.4762\n",
      "Epoch 624/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9783 - accuracy: 0.5748 - val_loss: 1.2736 - val_accuracy: 0.5361\n",
      "Epoch 625/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9896 - accuracy: 0.5753 - val_loss: 1.3047 - val_accuracy: 0.4503\n",
      "Epoch 626/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0171 - accuracy: 0.5574 - val_loss: 1.2642 - val_accuracy: 0.4952\n",
      "Epoch 627/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0042 - accuracy: 0.5632 - val_loss: 1.2642 - val_accuracy: 0.5204\n",
      "Epoch 628/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9808 - accuracy: 0.5731 - val_loss: 1.2614 - val_accuracy: 0.4939\n",
      "Epoch 629/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9658 - accuracy: 0.5799 - val_loss: 1.3074 - val_accuracy: 0.4544\n",
      "Epoch 630/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0183 - accuracy: 0.5608 - val_loss: 1.3227 - val_accuracy: 0.4429\n",
      "Epoch 631/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9878 - accuracy: 0.5825 - val_loss: 1.4231 - val_accuracy: 0.4075\n",
      "Epoch 632/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9938 - accuracy: 0.5742 - val_loss: 1.2844 - val_accuracy: 0.4707\n",
      "Epoch 633/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0133 - accuracy: 0.5598 - val_loss: 1.3007 - val_accuracy: 0.4653\n",
      "Epoch 634/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9827 - accuracy: 0.5747 - val_loss: 1.3269 - val_accuracy: 0.4782\n",
      "Epoch 635/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0157 - accuracy: 0.5562 - val_loss: 1.3571 - val_accuracy: 0.4333\n",
      "Epoch 636/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0172 - accuracy: 0.5586 - val_loss: 1.3160 - val_accuracy: 0.4694\n",
      "Epoch 637/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9824 - accuracy: 0.5665 - val_loss: 1.2718 - val_accuracy: 0.5170\n",
      "Epoch 638/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9877 - accuracy: 0.5614 - val_loss: 1.2925 - val_accuracy: 0.5184\n",
      "Epoch 639/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9832 - accuracy: 0.5714 - val_loss: 1.2781 - val_accuracy: 0.5429\n",
      "Epoch 640/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9865 - accuracy: 0.5791 - val_loss: 1.2803 - val_accuracy: 0.4837\n",
      "Epoch 641/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9786 - accuracy: 0.5818 - val_loss: 1.3912 - val_accuracy: 0.4082\n",
      "Epoch 642/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0135 - accuracy: 0.5653 - val_loss: 1.3445 - val_accuracy: 0.4490\n",
      "Epoch 643/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9747 - accuracy: 0.5630 - val_loss: 1.3792 - val_accuracy: 0.4565\n",
      "Epoch 644/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9839 - accuracy: 0.5685 - val_loss: 1.2762 - val_accuracy: 0.5361\n",
      "Epoch 645/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9998 - accuracy: 0.5590 - val_loss: 1.3459 - val_accuracy: 0.4422\n",
      "Epoch 646/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9769 - accuracy: 0.5731 - val_loss: 1.2710 - val_accuracy: 0.5156\n",
      "Epoch 647/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0069 - accuracy: 0.5468 - val_loss: 1.2807 - val_accuracy: 0.5061\n",
      "Epoch 648/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0032 - accuracy: 0.5712 - val_loss: 1.2770 - val_accuracy: 0.5299\n",
      "Epoch 649/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0081 - accuracy: 0.5684 - val_loss: 1.2621 - val_accuracy: 0.5116\n",
      "Epoch 650/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9806 - accuracy: 0.5748 - val_loss: 1.3481 - val_accuracy: 0.4769\n",
      "Epoch 651/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9951 - accuracy: 0.5713 - val_loss: 1.3030 - val_accuracy: 0.4633\n",
      "Epoch 652/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9717 - accuracy: 0.5738 - val_loss: 1.2669 - val_accuracy: 0.5347\n",
      "Epoch 653/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9842 - accuracy: 0.5765 - val_loss: 1.3136 - val_accuracy: 0.4816\n",
      "Epoch 654/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9871 - accuracy: 0.5781 - val_loss: 1.3940 - val_accuracy: 0.4551\n",
      "Epoch 655/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0231 - accuracy: 0.5583 - val_loss: 1.3283 - val_accuracy: 0.4932\n",
      "Epoch 656/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9899 - accuracy: 0.5611 - val_loss: 1.3046 - val_accuracy: 0.5041\n",
      "Epoch 657/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9563 - accuracy: 0.5983 - val_loss: 1.3901 - val_accuracy: 0.4510\n",
      "Epoch 658/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9868 - accuracy: 0.5720 - val_loss: 1.3079 - val_accuracy: 0.4925\n",
      "Epoch 659/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0039 - accuracy: 0.5682 - val_loss: 1.3318 - val_accuracy: 0.4830\n",
      "Epoch 660/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9967 - accuracy: 0.5670 - val_loss: 1.2858 - val_accuracy: 0.5361\n",
      "Epoch 661/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0042 - accuracy: 0.5727 - val_loss: 1.3443 - val_accuracy: 0.4619\n",
      "Epoch 662/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0051 - accuracy: 0.5706 - val_loss: 1.2815 - val_accuracy: 0.5061\n",
      "Epoch 663/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9848 - accuracy: 0.5770 - val_loss: 1.2286 - val_accuracy: 0.5102\n",
      "Epoch 664/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9876 - accuracy: 0.5787 - val_loss: 1.3456 - val_accuracy: 0.4694\n",
      "Epoch 665/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0014 - accuracy: 0.5622 - val_loss: 1.3135 - val_accuracy: 0.5374\n",
      "Epoch 666/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0046 - accuracy: 0.5519 - val_loss: 1.2811 - val_accuracy: 0.5435\n",
      "Epoch 667/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9711 - accuracy: 0.5823 - val_loss: 1.4010 - val_accuracy: 0.5041\n",
      "Epoch 668/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9843 - accuracy: 0.5677 - val_loss: 1.3175 - val_accuracy: 0.5034\n",
      "Epoch 669/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9873 - accuracy: 0.5763 - val_loss: 1.3663 - val_accuracy: 0.4422\n",
      "Epoch 670/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0078 - accuracy: 0.5633 - val_loss: 1.2809 - val_accuracy: 0.4993\n",
      "Epoch 671/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9604 - accuracy: 0.5890 - val_loss: 1.2690 - val_accuracy: 0.5020\n",
      "Epoch 672/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9806 - accuracy: 0.5782 - val_loss: 1.3107 - val_accuracy: 0.5068\n",
      "Epoch 673/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9717 - accuracy: 0.5847 - val_loss: 1.3469 - val_accuracy: 0.4939\n",
      "Epoch 674/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9750 - accuracy: 0.5825 - val_loss: 1.2919 - val_accuracy: 0.4837\n",
      "Epoch 675/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9577 - accuracy: 0.5761 - val_loss: 1.3414 - val_accuracy: 0.4837\n",
      "Epoch 676/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9528 - accuracy: 0.5900 - val_loss: 1.3055 - val_accuracy: 0.5279\n",
      "Epoch 677/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9807 - accuracy: 0.5722 - val_loss: 1.2529 - val_accuracy: 0.5170\n",
      "Epoch 678/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0028 - accuracy: 0.5595 - val_loss: 1.2641 - val_accuracy: 0.5129\n",
      "Epoch 679/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0034 - accuracy: 0.5645 - val_loss: 1.2995 - val_accuracy: 0.4891\n",
      "Epoch 680/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0074 - accuracy: 0.5736 - val_loss: 1.3197 - val_accuracy: 0.4844\n",
      "Epoch 681/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9793 - accuracy: 0.5772 - val_loss: 1.3539 - val_accuracy: 0.4415\n",
      "Epoch 682/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9679 - accuracy: 0.5884 - val_loss: 1.2481 - val_accuracy: 0.5245\n",
      "Epoch 683/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9804 - accuracy: 0.5758 - val_loss: 1.3210 - val_accuracy: 0.5320\n",
      "Epoch 684/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0040 - accuracy: 0.5658 - val_loss: 1.3342 - val_accuracy: 0.4415\n",
      "Epoch 685/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9912 - accuracy: 0.5676 - val_loss: 1.3213 - val_accuracy: 0.4966\n",
      "Epoch 686/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.5768 - val_loss: 1.3427 - val_accuracy: 0.4483\n",
      "Epoch 687/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9637 - accuracy: 0.5878 - val_loss: 1.3378 - val_accuracy: 0.4646\n",
      "Epoch 688/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9959 - accuracy: 0.5650 - val_loss: 1.2883 - val_accuracy: 0.4946\n",
      "Epoch 689/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9891 - accuracy: 0.5778 - val_loss: 1.3756 - val_accuracy: 0.4483\n",
      "Epoch 690/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9760 - accuracy: 0.5766 - val_loss: 1.3414 - val_accuracy: 0.5020\n",
      "Epoch 691/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9906 - accuracy: 0.5647 - val_loss: 1.2763 - val_accuracy: 0.4810\n",
      "Epoch 692/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0061 - accuracy: 0.5589 - val_loss: 1.3620 - val_accuracy: 0.4510\n",
      "Epoch 693/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9999 - accuracy: 0.5722 - val_loss: 1.3111 - val_accuracy: 0.4735\n",
      "Epoch 694/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0072 - accuracy: 0.5659 - val_loss: 1.4070 - val_accuracy: 0.4585\n",
      "Epoch 695/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9827 - accuracy: 0.5699 - val_loss: 1.3592 - val_accuracy: 0.4884\n",
      "Epoch 696/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9729 - accuracy: 0.5793 - val_loss: 1.3418 - val_accuracy: 0.4224\n",
      "Epoch 697/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0128 - accuracy: 0.5570 - val_loss: 1.3163 - val_accuracy: 0.5095\n",
      "Epoch 698/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9765 - accuracy: 0.5896 - val_loss: 1.3122 - val_accuracy: 0.5313\n",
      "Epoch 699/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9882 - accuracy: 0.5700 - val_loss: 1.3156 - val_accuracy: 0.4721\n",
      "Epoch 700/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9901 - accuracy: 0.5754 - val_loss: 1.3211 - val_accuracy: 0.5095\n",
      "Epoch 701/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0077 - accuracy: 0.5661 - val_loss: 1.2841 - val_accuracy: 0.5313\n",
      "Epoch 702/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0019 - accuracy: 0.5552 - val_loss: 1.3153 - val_accuracy: 0.4769\n",
      "Epoch 703/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9633 - accuracy: 0.5847 - val_loss: 1.2938 - val_accuracy: 0.5218\n",
      "Epoch 704/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9700 - accuracy: 0.5787 - val_loss: 1.3492 - val_accuracy: 0.4980\n",
      "Epoch 705/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9733 - accuracy: 0.5789 - val_loss: 1.3342 - val_accuracy: 0.4497\n",
      "Epoch 706/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9914 - accuracy: 0.5632 - val_loss: 1.3424 - val_accuracy: 0.5218\n",
      "Epoch 707/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0456 - accuracy: 0.5468 - val_loss: 1.3155 - val_accuracy: 0.4612\n",
      "Epoch 708/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9840 - accuracy: 0.5852 - val_loss: 1.3417 - val_accuracy: 0.4966\n",
      "Epoch 709/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9975 - accuracy: 0.5646 - val_loss: 1.2874 - val_accuracy: 0.5306\n",
      "Epoch 710/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9942 - accuracy: 0.5727 - val_loss: 1.2997 - val_accuracy: 0.4803\n",
      "Epoch 711/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9629 - accuracy: 0.5966 - val_loss: 1.3383 - val_accuracy: 0.4796\n",
      "Epoch 712/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9610 - accuracy: 0.5854 - val_loss: 1.3437 - val_accuracy: 0.5231\n",
      "Epoch 713/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9963 - accuracy: 0.5553 - val_loss: 1.3142 - val_accuracy: 0.5075\n",
      "Epoch 714/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9891 - accuracy: 0.5669 - val_loss: 1.3386 - val_accuracy: 0.4639\n",
      "Epoch 715/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9845 - accuracy: 0.5874 - val_loss: 1.2891 - val_accuracy: 0.4925\n",
      "Epoch 716/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9915 - accuracy: 0.5721 - val_loss: 1.3067 - val_accuracy: 0.4959\n",
      "Epoch 717/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9891 - accuracy: 0.5661 - val_loss: 1.3650 - val_accuracy: 0.4415\n",
      "Epoch 718/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9696 - accuracy: 0.5882 - val_loss: 1.2921 - val_accuracy: 0.5129\n",
      "Epoch 719/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9805 - accuracy: 0.5693 - val_loss: 1.2925 - val_accuracy: 0.4565\n",
      "Epoch 720/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9641 - accuracy: 0.5887 - val_loss: 1.2841 - val_accuracy: 0.5068\n",
      "Epoch 721/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0110 - accuracy: 0.5534 - val_loss: 1.3372 - val_accuracy: 0.4456\n",
      "Epoch 722/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.5683 - val_loss: 1.2860 - val_accuracy: 0.5000\n",
      "Epoch 723/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9980 - accuracy: 0.5736 - val_loss: 1.3332 - val_accuracy: 0.4939\n",
      "Epoch 724/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9817 - accuracy: 0.5809 - val_loss: 1.3356 - val_accuracy: 0.4571\n",
      "Epoch 725/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0029 - accuracy: 0.5764 - val_loss: 1.3164 - val_accuracy: 0.4449\n",
      "Epoch 726/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9739 - accuracy: 0.5768 - val_loss: 1.3058 - val_accuracy: 0.5156\n",
      "Epoch 727/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9936 - accuracy: 0.5783 - val_loss: 1.3282 - val_accuracy: 0.4653\n",
      "Epoch 728/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9727 - accuracy: 0.5948 - val_loss: 1.3582 - val_accuracy: 0.4558\n",
      "Epoch 729/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9882 - accuracy: 0.5772 - val_loss: 1.3598 - val_accuracy: 0.4333\n",
      "Epoch 730/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9873 - accuracy: 0.5746 - val_loss: 1.3486 - val_accuracy: 0.4694\n",
      "Epoch 731/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9785 - accuracy: 0.5747 - val_loss: 1.4087 - val_accuracy: 0.4592\n",
      "Epoch 732/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0100 - accuracy: 0.5608 - val_loss: 1.2618 - val_accuracy: 0.5231\n",
      "Epoch 733/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9738 - accuracy: 0.5996 - val_loss: 1.3430 - val_accuracy: 0.4959\n",
      "Epoch 734/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9863 - accuracy: 0.5731 - val_loss: 1.3700 - val_accuracy: 0.4939\n",
      "Epoch 735/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9504 - accuracy: 0.5815 - val_loss: 1.3933 - val_accuracy: 0.4673\n",
      "Epoch 736/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9531 - accuracy: 0.5835 - val_loss: 1.3397 - val_accuracy: 0.4898\n",
      "Epoch 737/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9449 - accuracy: 0.5878 - val_loss: 1.3575 - val_accuracy: 0.4803\n",
      "Epoch 738/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9793 - accuracy: 0.5850 - val_loss: 1.2711 - val_accuracy: 0.5252\n",
      "Epoch 739/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0031 - accuracy: 0.5634 - val_loss: 1.3121 - val_accuracy: 0.5156\n",
      "Epoch 740/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9766 - accuracy: 0.5909 - val_loss: 1.2949 - val_accuracy: 0.5238\n",
      "Epoch 741/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9831 - accuracy: 0.5785 - val_loss: 1.3579 - val_accuracy: 0.4830\n",
      "Epoch 742/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0030 - accuracy: 0.5562 - val_loss: 1.3675 - val_accuracy: 0.4728\n",
      "Epoch 743/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9655 - accuracy: 0.5817 - val_loss: 1.3159 - val_accuracy: 0.5014\n",
      "Epoch 744/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9734 - accuracy: 0.5775 - val_loss: 1.3237 - val_accuracy: 0.5333\n",
      "Epoch 745/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9841 - accuracy: 0.5705 - val_loss: 1.3141 - val_accuracy: 0.5197\n",
      "Epoch 746/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9674 - accuracy: 0.5865 - val_loss: 1.3324 - val_accuracy: 0.4721\n",
      "Epoch 747/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9696 - accuracy: 0.5832 - val_loss: 1.3331 - val_accuracy: 0.5007\n",
      "Epoch 748/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9674 - accuracy: 0.5835 - val_loss: 1.3096 - val_accuracy: 0.4864\n",
      "Epoch 749/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0020 - accuracy: 0.5833 - val_loss: 1.4080 - val_accuracy: 0.4585\n",
      "Epoch 750/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9683 - accuracy: 0.5856 - val_loss: 1.3333 - val_accuracy: 0.4864\n",
      "Epoch 751/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9764 - accuracy: 0.5801 - val_loss: 1.3263 - val_accuracy: 0.4959\n",
      "Epoch 752/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9801 - accuracy: 0.5910 - val_loss: 1.3448 - val_accuracy: 0.4735\n",
      "Epoch 753/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9930 - accuracy: 0.5858 - val_loss: 1.3604 - val_accuracy: 0.5286\n",
      "Epoch 754/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9693 - accuracy: 0.5854 - val_loss: 1.3457 - val_accuracy: 0.5034\n",
      "Epoch 755/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9855 - accuracy: 0.5878 - val_loss: 1.3137 - val_accuracy: 0.4959\n",
      "Epoch 756/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9744 - accuracy: 0.5804 - val_loss: 1.2926 - val_accuracy: 0.5000\n",
      "Epoch 757/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9665 - accuracy: 0.5849 - val_loss: 1.3811 - val_accuracy: 0.4735\n",
      "Epoch 758/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0071 - accuracy: 0.5708 - val_loss: 1.2546 - val_accuracy: 0.5429\n",
      "Epoch 759/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9671 - accuracy: 0.5665 - val_loss: 1.3159 - val_accuracy: 0.4857\n",
      "Epoch 760/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0160 - accuracy: 0.5517 - val_loss: 1.2953 - val_accuracy: 0.4986\n",
      "Epoch 761/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9750 - accuracy: 0.5770 - val_loss: 1.3524 - val_accuracy: 0.4891\n",
      "Epoch 762/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9723 - accuracy: 0.5881 - val_loss: 1.3003 - val_accuracy: 0.5095\n",
      "Epoch 763/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9856 - accuracy: 0.5794 - val_loss: 1.3186 - val_accuracy: 0.4925\n",
      "Epoch 764/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9650 - accuracy: 0.5986 - val_loss: 1.3714 - val_accuracy: 0.4558\n",
      "Epoch 765/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9664 - accuracy: 0.5833 - val_loss: 1.3189 - val_accuracy: 0.5129\n",
      "Epoch 766/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9570 - accuracy: 0.5927 - val_loss: 1.3096 - val_accuracy: 0.5000\n",
      "Epoch 767/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9605 - accuracy: 0.5778 - val_loss: 1.3561 - val_accuracy: 0.5061\n",
      "Epoch 768/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9828 - accuracy: 0.5614 - val_loss: 1.2970 - val_accuracy: 0.4993\n",
      "Epoch 769/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9853 - accuracy: 0.5813 - val_loss: 1.2796 - val_accuracy: 0.5408\n",
      "Epoch 770/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9796 - accuracy: 0.5719 - val_loss: 1.3113 - val_accuracy: 0.5231\n",
      "Epoch 771/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9706 - accuracy: 0.5816 - val_loss: 1.3178 - val_accuracy: 0.5129\n",
      "Epoch 772/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9880 - accuracy: 0.5665 - val_loss: 1.3122 - val_accuracy: 0.5116\n",
      "Epoch 773/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9591 - accuracy: 0.5877 - val_loss: 1.3617 - val_accuracy: 0.5129\n",
      "Epoch 774/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9669 - accuracy: 0.5755 - val_loss: 1.3163 - val_accuracy: 0.5490\n",
      "Epoch 775/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9947 - accuracy: 0.5674 - val_loss: 1.3499 - val_accuracy: 0.5224\n",
      "Epoch 776/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9845 - accuracy: 0.5762 - val_loss: 1.2743 - val_accuracy: 0.5408\n",
      "Epoch 777/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9990 - accuracy: 0.5649 - val_loss: 1.4096 - val_accuracy: 0.5177\n",
      "Epoch 778/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0044 - accuracy: 0.5445 - val_loss: 1.4204 - val_accuracy: 0.5116\n",
      "Epoch 779/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9783 - accuracy: 0.5879 - val_loss: 1.3109 - val_accuracy: 0.4483\n",
      "Epoch 780/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9814 - accuracy: 0.5851 - val_loss: 1.3345 - val_accuracy: 0.5075\n",
      "Epoch 781/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9765 - accuracy: 0.5872 - val_loss: 1.3499 - val_accuracy: 0.4959\n",
      "Epoch 782/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9837 - accuracy: 0.5794 - val_loss: 1.3057 - val_accuracy: 0.5116\n",
      "Epoch 783/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9765 - accuracy: 0.5816 - val_loss: 1.3640 - val_accuracy: 0.4816\n",
      "Epoch 784/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9855 - accuracy: 0.5756 - val_loss: 1.3119 - val_accuracy: 0.5190\n",
      "Epoch 785/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9844 - accuracy: 0.5830 - val_loss: 1.4457 - val_accuracy: 0.4531\n",
      "Epoch 786/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9643 - accuracy: 0.5881 - val_loss: 1.3818 - val_accuracy: 0.4605\n",
      "Epoch 787/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9617 - accuracy: 0.5971 - val_loss: 1.3894 - val_accuracy: 0.4673\n",
      "Epoch 788/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9943 - accuracy: 0.5676 - val_loss: 1.3339 - val_accuracy: 0.4864\n",
      "Epoch 789/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9664 - accuracy: 0.5779 - val_loss: 1.3674 - val_accuracy: 0.4850\n",
      "Epoch 790/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9719 - accuracy: 0.5866 - val_loss: 1.4276 - val_accuracy: 0.4837\n",
      "Epoch 791/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0045 - accuracy: 0.5611 - val_loss: 1.3500 - val_accuracy: 0.4741\n",
      "Epoch 792/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9839 - accuracy: 0.5771 - val_loss: 1.3758 - val_accuracy: 0.4735\n",
      "Epoch 793/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9850 - accuracy: 0.5790 - val_loss: 1.3293 - val_accuracy: 0.4986\n",
      "Epoch 794/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9652 - accuracy: 0.5830 - val_loss: 1.3449 - val_accuracy: 0.4762\n",
      "Epoch 795/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9571 - accuracy: 0.5898 - val_loss: 1.3885 - val_accuracy: 0.4973\n",
      "Epoch 796/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9541 - accuracy: 0.5897 - val_loss: 1.3781 - val_accuracy: 0.4980\n",
      "Epoch 797/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9930 - accuracy: 0.5700 - val_loss: 1.3244 - val_accuracy: 0.5190\n",
      "Epoch 798/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9887 - accuracy: 0.5806 - val_loss: 1.4582 - val_accuracy: 0.4259\n",
      "Epoch 799/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9885 - accuracy: 0.5780 - val_loss: 1.3725 - val_accuracy: 0.4905\n",
      "Epoch 800/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9624 - accuracy: 0.6039 - val_loss: 1.4489 - val_accuracy: 0.5054\n",
      "Epoch 801/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9797 - accuracy: 0.5931 - val_loss: 1.3613 - val_accuracy: 0.5102\n",
      "Epoch 802/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9448 - accuracy: 0.5953 - val_loss: 1.3534 - val_accuracy: 0.5000\n",
      "Epoch 803/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9600 - accuracy: 0.5908 - val_loss: 1.4122 - val_accuracy: 0.4177\n",
      "Epoch 804/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0060 - accuracy: 0.5637 - val_loss: 1.3806 - val_accuracy: 0.4993\n",
      "Epoch 805/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9621 - accuracy: 0.5992 - val_loss: 1.3980 - val_accuracy: 0.4946\n",
      "Epoch 806/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9678 - accuracy: 0.5745 - val_loss: 1.2963 - val_accuracy: 0.4844\n",
      "Epoch 807/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9751 - accuracy: 0.5926 - val_loss: 1.3548 - val_accuracy: 0.4850\n",
      "Epoch 808/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0090 - accuracy: 0.5638 - val_loss: 1.3025 - val_accuracy: 0.4966\n",
      "Epoch 809/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9674 - accuracy: 0.5886 - val_loss: 1.3806 - val_accuracy: 0.4748\n",
      "Epoch 810/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9779 - accuracy: 0.5881 - val_loss: 1.3130 - val_accuracy: 0.4946\n",
      "Epoch 811/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9562 - accuracy: 0.5841 - val_loss: 1.3402 - val_accuracy: 0.5259\n",
      "Epoch 812/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9600 - accuracy: 0.5790 - val_loss: 1.3280 - val_accuracy: 0.5245\n",
      "Epoch 813/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9635 - accuracy: 0.5973 - val_loss: 1.3683 - val_accuracy: 0.4605\n",
      "Epoch 814/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9810 - accuracy: 0.5872 - val_loss: 1.2519 - val_accuracy: 0.5041\n",
      "Epoch 815/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9780 - accuracy: 0.5776 - val_loss: 1.3350 - val_accuracy: 0.4946\n",
      "Epoch 816/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9722 - accuracy: 0.5825 - val_loss: 1.3320 - val_accuracy: 0.4782\n",
      "Epoch 817/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9582 - accuracy: 0.5897 - val_loss: 1.3545 - val_accuracy: 0.5136\n",
      "Epoch 818/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9779 - accuracy: 0.5719 - val_loss: 1.3660 - val_accuracy: 0.5082\n",
      "Epoch 819/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9604 - accuracy: 0.5876 - val_loss: 1.4102 - val_accuracy: 0.4503\n",
      "Epoch 820/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9622 - accuracy: 0.5848 - val_loss: 1.3482 - val_accuracy: 0.4612\n",
      "Epoch 821/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9407 - accuracy: 0.6075 - val_loss: 1.3257 - val_accuracy: 0.5034\n",
      "Epoch 822/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9680 - accuracy: 0.5825 - val_loss: 1.4040 - val_accuracy: 0.4367\n",
      "Epoch 823/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9746 - accuracy: 0.5873 - val_loss: 1.3711 - val_accuracy: 0.5014\n",
      "Epoch 824/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9851 - accuracy: 0.5788 - val_loss: 1.3107 - val_accuracy: 0.4939\n",
      "Epoch 825/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9755 - accuracy: 0.5984 - val_loss: 1.3784 - val_accuracy: 0.5122\n",
      "Epoch 826/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0123 - accuracy: 0.5650 - val_loss: 1.3721 - val_accuracy: 0.5007\n",
      "Epoch 827/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9931 - accuracy: 0.5797 - val_loss: 1.3548 - val_accuracy: 0.4905\n",
      "Epoch 828/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9752 - accuracy: 0.5865 - val_loss: 1.3299 - val_accuracy: 0.5129\n",
      "Epoch 829/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9777 - accuracy: 0.5750 - val_loss: 1.4169 - val_accuracy: 0.4864\n",
      "Epoch 830/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9570 - accuracy: 0.5886 - val_loss: 1.3474 - val_accuracy: 0.4966\n",
      "Epoch 831/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9656 - accuracy: 0.5823 - val_loss: 1.3697 - val_accuracy: 0.4925\n",
      "Epoch 832/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9821 - accuracy: 0.5840 - val_loss: 1.3434 - val_accuracy: 0.5265\n",
      "Epoch 833/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9610 - accuracy: 0.6022 - val_loss: 1.3446 - val_accuracy: 0.4687\n",
      "Epoch 834/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9545 - accuracy: 0.5937 - val_loss: 1.3923 - val_accuracy: 0.4578\n",
      "Epoch 835/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9996 - accuracy: 0.5615 - val_loss: 1.3524 - val_accuracy: 0.4939\n",
      "Epoch 836/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9886 - accuracy: 0.5884 - val_loss: 1.2819 - val_accuracy: 0.5347\n",
      "Epoch 837/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9711 - accuracy: 0.5744 - val_loss: 1.3387 - val_accuracy: 0.5082\n",
      "Epoch 838/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0059 - accuracy: 0.5691 - val_loss: 1.3634 - val_accuracy: 0.4850\n",
      "Epoch 839/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9684 - accuracy: 0.5848 - val_loss: 1.4088 - val_accuracy: 0.4871\n",
      "Epoch 840/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9771 - accuracy: 0.5861 - val_loss: 1.3215 - val_accuracy: 0.4762\n",
      "Epoch 841/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9613 - accuracy: 0.5868 - val_loss: 1.2831 - val_accuracy: 0.5381\n",
      "Epoch 842/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9924 - accuracy: 0.5874 - val_loss: 1.4576 - val_accuracy: 0.4347\n",
      "Epoch 843/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9473 - accuracy: 0.5878 - val_loss: 1.3695 - val_accuracy: 0.4769\n",
      "Epoch 844/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9682 - accuracy: 0.5835 - val_loss: 1.3773 - val_accuracy: 0.5306\n",
      "Epoch 845/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9748 - accuracy: 0.5913 - val_loss: 1.3414 - val_accuracy: 0.5354\n",
      "Epoch 846/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9408 - accuracy: 0.5905 - val_loss: 1.3503 - val_accuracy: 0.5279\n",
      "Epoch 847/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9738 - accuracy: 0.5859 - val_loss: 1.3498 - val_accuracy: 0.5245\n",
      "Epoch 848/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9673 - accuracy: 0.5819 - val_loss: 1.3129 - val_accuracy: 0.5293\n",
      "Epoch 849/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9474 - accuracy: 0.5942 - val_loss: 1.4158 - val_accuracy: 0.4905\n",
      "Epoch 850/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9588 - accuracy: 0.5988 - val_loss: 1.4018 - val_accuracy: 0.4544\n",
      "Epoch 851/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0041 - accuracy: 0.5693 - val_loss: 1.3618 - val_accuracy: 0.5211\n",
      "Epoch 852/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9698 - accuracy: 0.5812 - val_loss: 1.3682 - val_accuracy: 0.4680\n",
      "Epoch 853/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9640 - accuracy: 0.6014 - val_loss: 1.4098 - val_accuracy: 0.4878\n",
      "Epoch 854/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9629 - accuracy: 0.5892 - val_loss: 1.3452 - val_accuracy: 0.5095\n",
      "Epoch 855/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9687 - accuracy: 0.5909 - val_loss: 1.3178 - val_accuracy: 0.5211\n",
      "Epoch 856/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9771 - accuracy: 0.5897 - val_loss: 1.3828 - val_accuracy: 0.4735\n",
      "Epoch 857/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9826 - accuracy: 0.5761 - val_loss: 1.3557 - val_accuracy: 0.4959\n",
      "Epoch 858/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9783 - accuracy: 0.5889 - val_loss: 1.3515 - val_accuracy: 0.4986\n",
      "Epoch 859/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9569 - accuracy: 0.5836 - val_loss: 1.3468 - val_accuracy: 0.4762\n",
      "Epoch 860/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9494 - accuracy: 0.5887 - val_loss: 1.3170 - val_accuracy: 0.5061\n",
      "Epoch 861/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9561 - accuracy: 0.5910 - val_loss: 1.3755 - val_accuracy: 0.5102\n",
      "Epoch 862/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9930 - accuracy: 0.5710 - val_loss: 1.3988 - val_accuracy: 0.5286\n",
      "Epoch 863/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9507 - accuracy: 0.5887 - val_loss: 1.4197 - val_accuracy: 0.4735\n",
      "Epoch 864/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9394 - accuracy: 0.6048 - val_loss: 1.3402 - val_accuracy: 0.5027\n",
      "Epoch 865/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9461 - accuracy: 0.5946 - val_loss: 1.3222 - val_accuracy: 0.5204\n",
      "Epoch 866/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9577 - accuracy: 0.5938 - val_loss: 1.3081 - val_accuracy: 0.5367\n",
      "Epoch 867/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9820 - accuracy: 0.5746 - val_loss: 1.3136 - val_accuracy: 0.5068\n",
      "Epoch 868/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9857 - accuracy: 0.5698 - val_loss: 1.3813 - val_accuracy: 0.5061\n",
      "Epoch 869/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9863 - accuracy: 0.5742 - val_loss: 1.4322 - val_accuracy: 0.4673\n",
      "Epoch 870/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9886 - accuracy: 0.5657 - val_loss: 1.3475 - val_accuracy: 0.4680\n",
      "Epoch 871/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9722 - accuracy: 0.5883 - val_loss: 1.4077 - val_accuracy: 0.5136\n",
      "Epoch 872/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9940 - accuracy: 0.5764 - val_loss: 1.3302 - val_accuracy: 0.5095\n",
      "Epoch 873/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9248 - accuracy: 0.6114 - val_loss: 1.3088 - val_accuracy: 0.4707\n",
      "Epoch 874/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9670 - accuracy: 0.5832 - val_loss: 1.3604 - val_accuracy: 0.5095\n",
      "Epoch 875/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9893 - accuracy: 0.5775 - val_loss: 1.4216 - val_accuracy: 0.5054\n",
      "Epoch 876/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9689 - accuracy: 0.5955 - val_loss: 1.3653 - val_accuracy: 0.5095\n",
      "Epoch 877/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9558 - accuracy: 0.5872 - val_loss: 1.3720 - val_accuracy: 0.5075\n",
      "Epoch 878/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9575 - accuracy: 0.6019 - val_loss: 1.3585 - val_accuracy: 0.5204\n",
      "Epoch 879/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9580 - accuracy: 0.5856 - val_loss: 1.4070 - val_accuracy: 0.5014\n",
      "Epoch 880/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9905 - accuracy: 0.5761 - val_loss: 1.2970 - val_accuracy: 0.5129\n",
      "Epoch 881/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9604 - accuracy: 0.6053 - val_loss: 1.4059 - val_accuracy: 0.4517\n",
      "Epoch 882/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9830 - accuracy: 0.5703 - val_loss: 1.3066 - val_accuracy: 0.5374\n",
      "Epoch 883/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9827 - accuracy: 0.5645 - val_loss: 1.3568 - val_accuracy: 0.4803\n",
      "Epoch 884/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9727 - accuracy: 0.5934 - val_loss: 1.3689 - val_accuracy: 0.5279\n",
      "Epoch 885/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9808 - accuracy: 0.5779 - val_loss: 1.4181 - val_accuracy: 0.4973\n",
      "Epoch 886/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9591 - accuracy: 0.5876 - val_loss: 1.3777 - val_accuracy: 0.4857\n",
      "Epoch 887/1000\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.9576 - accuracy: 0.5913 - val_loss: 1.4066 - val_accuracy: 0.4667\n",
      "Epoch 888/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9523 - accuracy: 0.6026 - val_loss: 1.3489 - val_accuracy: 0.5143\n",
      "Epoch 889/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9585 - accuracy: 0.5927 - val_loss: 1.4005 - val_accuracy: 0.4878\n",
      "Epoch 890/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9812 - accuracy: 0.5816 - val_loss: 1.4243 - val_accuracy: 0.4946\n",
      "Epoch 891/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9776 - accuracy: 0.5786 - val_loss: 1.3685 - val_accuracy: 0.5061\n",
      "Epoch 892/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9575 - accuracy: 0.5911 - val_loss: 1.3831 - val_accuracy: 0.4864\n",
      "Epoch 893/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9368 - accuracy: 0.6055 - val_loss: 1.4825 - val_accuracy: 0.4796\n",
      "Epoch 894/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9694 - accuracy: 0.5809 - val_loss: 1.3333 - val_accuracy: 0.4918\n",
      "Epoch 895/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9580 - accuracy: 0.5900 - val_loss: 1.3689 - val_accuracy: 0.5156\n",
      "Epoch 896/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9337 - accuracy: 0.6060 - val_loss: 1.3672 - val_accuracy: 0.4986\n",
      "Epoch 897/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9687 - accuracy: 0.5870 - val_loss: 1.3901 - val_accuracy: 0.4891\n",
      "Epoch 898/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9391 - accuracy: 0.5937 - val_loss: 1.4159 - val_accuracy: 0.5245\n",
      "Epoch 899/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9507 - accuracy: 0.5948 - val_loss: 1.4100 - val_accuracy: 0.5088\n",
      "Epoch 900/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9610 - accuracy: 0.5868 - val_loss: 1.3850 - val_accuracy: 0.5320\n",
      "Epoch 901/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9677 - accuracy: 0.5800 - val_loss: 1.4352 - val_accuracy: 0.4898\n",
      "Epoch 902/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9565 - accuracy: 0.5995 - val_loss: 1.4849 - val_accuracy: 0.4592\n",
      "Epoch 903/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0184 - accuracy: 0.5757 - val_loss: 1.3826 - val_accuracy: 0.5197\n",
      "Epoch 904/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9698 - accuracy: 0.5816 - val_loss: 1.4734 - val_accuracy: 0.4272\n",
      "Epoch 905/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9777 - accuracy: 0.5846 - val_loss: 1.4292 - val_accuracy: 0.4279\n",
      "Epoch 906/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9590 - accuracy: 0.6030 - val_loss: 1.3906 - val_accuracy: 0.4605\n",
      "Epoch 907/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9821 - accuracy: 0.5774 - val_loss: 1.3916 - val_accuracy: 0.4878\n",
      "Epoch 908/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9619 - accuracy: 0.5869 - val_loss: 1.3739 - val_accuracy: 0.5299\n",
      "Epoch 909/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9727 - accuracy: 0.5752 - val_loss: 1.3532 - val_accuracy: 0.5422\n",
      "Epoch 910/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9753 - accuracy: 0.5853 - val_loss: 1.3568 - val_accuracy: 0.4891\n",
      "Epoch 911/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9543 - accuracy: 0.5879 - val_loss: 1.3436 - val_accuracy: 0.4782\n",
      "Epoch 912/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9626 - accuracy: 0.5909 - val_loss: 1.3797 - val_accuracy: 0.4973\n",
      "Epoch 913/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9144 - accuracy: 0.6123 - val_loss: 1.3499 - val_accuracy: 0.5442\n",
      "Epoch 914/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9601 - accuracy: 0.5954 - val_loss: 1.4236 - val_accuracy: 0.4803\n",
      "Epoch 915/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9596 - accuracy: 0.5921 - val_loss: 1.4532 - val_accuracy: 0.4531\n",
      "Epoch 916/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9675 - accuracy: 0.5863 - val_loss: 1.3740 - val_accuracy: 0.5061\n",
      "Epoch 917/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9345 - accuracy: 0.5996 - val_loss: 1.4739 - val_accuracy: 0.4714\n",
      "Epoch 918/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9738 - accuracy: 0.5872 - val_loss: 1.4204 - val_accuracy: 0.4932\n",
      "Epoch 919/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9305 - accuracy: 0.6079 - val_loss: 1.4810 - val_accuracy: 0.4939\n",
      "Epoch 920/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9696 - accuracy: 0.5859 - val_loss: 1.4099 - val_accuracy: 0.4612\n",
      "Epoch 921/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9707 - accuracy: 0.5907 - val_loss: 1.3751 - val_accuracy: 0.5279\n",
      "Epoch 922/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9555 - accuracy: 0.5855 - val_loss: 1.4391 - val_accuracy: 0.4755\n",
      "Epoch 923/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9509 - accuracy: 0.6110 - val_loss: 1.4575 - val_accuracy: 0.4769\n",
      "Epoch 924/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9780 - accuracy: 0.5872 - val_loss: 1.3475 - val_accuracy: 0.5224\n",
      "Epoch 925/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9573 - accuracy: 0.5963 - val_loss: 1.4410 - val_accuracy: 0.4796\n",
      "Epoch 926/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9803 - accuracy: 0.5777 - val_loss: 1.3905 - val_accuracy: 0.4986\n",
      "Epoch 927/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9407 - accuracy: 0.5950 - val_loss: 1.4050 - val_accuracy: 0.5313\n",
      "Epoch 928/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9601 - accuracy: 0.5920 - val_loss: 1.3791 - val_accuracy: 0.4918\n",
      "Epoch 929/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9559 - accuracy: 0.5945 - val_loss: 1.4035 - val_accuracy: 0.4735\n",
      "Epoch 930/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9667 - accuracy: 0.5984 - val_loss: 1.4204 - val_accuracy: 0.4558\n",
      "Epoch 931/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9885 - accuracy: 0.5801 - val_loss: 1.4171 - val_accuracy: 0.4905\n",
      "Epoch 932/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9723 - accuracy: 0.5926 - val_loss: 1.3966 - val_accuracy: 0.5374\n",
      "Epoch 933/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9606 - accuracy: 0.5861 - val_loss: 1.4243 - val_accuracy: 0.5109\n",
      "Epoch 934/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9433 - accuracy: 0.5981 - val_loss: 1.3846 - val_accuracy: 0.5007\n",
      "Epoch 935/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9896 - accuracy: 0.5752 - val_loss: 1.4340 - val_accuracy: 0.4483\n",
      "Epoch 936/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9677 - accuracy: 0.5862 - val_loss: 1.4286 - val_accuracy: 0.4660\n",
      "Epoch 937/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9483 - accuracy: 0.5945 - val_loss: 1.4439 - val_accuracy: 0.4993\n",
      "Epoch 938/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9579 - accuracy: 0.5765 - val_loss: 1.4771 - val_accuracy: 0.5122\n",
      "Epoch 939/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9741 - accuracy: 0.5862 - val_loss: 1.4056 - val_accuracy: 0.4986\n",
      "Epoch 940/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9753 - accuracy: 0.5848 - val_loss: 1.4349 - val_accuracy: 0.4830\n",
      "Epoch 941/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9314 - accuracy: 0.6076 - val_loss: 1.4226 - val_accuracy: 0.4891\n",
      "Epoch 942/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9566 - accuracy: 0.5885 - val_loss: 1.3878 - val_accuracy: 0.4823\n",
      "Epoch 943/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9681 - accuracy: 0.5889 - val_loss: 1.4393 - val_accuracy: 0.5020\n",
      "Epoch 944/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9809 - accuracy: 0.5888 - val_loss: 1.3995 - val_accuracy: 0.5197\n",
      "Epoch 945/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9906 - accuracy: 0.5696 - val_loss: 1.4152 - val_accuracy: 0.5082\n",
      "Epoch 946/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9745 - accuracy: 0.5776 - val_loss: 1.3496 - val_accuracy: 0.4925\n",
      "Epoch 947/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9694 - accuracy: 0.5991 - val_loss: 1.3950 - val_accuracy: 0.5007\n",
      "Epoch 948/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9574 - accuracy: 0.5916 - val_loss: 1.3860 - val_accuracy: 0.5129\n",
      "Epoch 949/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9603 - accuracy: 0.5805 - val_loss: 1.3957 - val_accuracy: 0.4898\n",
      "Epoch 950/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9643 - accuracy: 0.5880 - val_loss: 1.3832 - val_accuracy: 0.4701\n",
      "Epoch 951/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9431 - accuracy: 0.5869 - val_loss: 1.4259 - val_accuracy: 0.4973\n",
      "Epoch 952/1000\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.9611 - accuracy: 0.5905 - val_loss: 1.4719 - val_accuracy: 0.4986\n",
      "Epoch 953/1000\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.9882 - accuracy: 0.5839 - val_loss: 1.4437 - val_accuracy: 0.4497\n",
      "Epoch 954/1000\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.9490 - accuracy: 0.5938 - val_loss: 1.4044 - val_accuracy: 0.5007\n",
      "Epoch 955/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9373 - accuracy: 0.5953 - val_loss: 1.4812 - val_accuracy: 0.4442\n",
      "Epoch 956/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9545 - accuracy: 0.5961 - val_loss: 1.3682 - val_accuracy: 0.5041\n",
      "Epoch 957/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9843 - accuracy: 0.5807 - val_loss: 1.4310 - val_accuracy: 0.4884\n",
      "Epoch 958/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9352 - accuracy: 0.6062 - val_loss: 1.4278 - val_accuracy: 0.4973\n",
      "Epoch 959/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9614 - accuracy: 0.5735 - val_loss: 1.3564 - val_accuracy: 0.5116\n",
      "Epoch 960/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9480 - accuracy: 0.6052 - val_loss: 1.4192 - val_accuracy: 0.4490\n",
      "Epoch 961/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9658 - accuracy: 0.6010 - val_loss: 1.4185 - val_accuracy: 0.4925\n",
      "Epoch 962/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9640 - accuracy: 0.5866 - val_loss: 1.4655 - val_accuracy: 0.4871\n",
      "Epoch 963/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9666 - accuracy: 0.5805 - val_loss: 1.4475 - val_accuracy: 0.4918\n",
      "Epoch 964/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9737 - accuracy: 0.5880 - val_loss: 1.4170 - val_accuracy: 0.5122\n",
      "Epoch 965/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9747 - accuracy: 0.5776 - val_loss: 1.3308 - val_accuracy: 0.5361\n",
      "Epoch 966/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9542 - accuracy: 0.5997 - val_loss: 1.3586 - val_accuracy: 0.4918\n",
      "Epoch 967/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9560 - accuracy: 0.5919 - val_loss: 1.3344 - val_accuracy: 0.5401\n",
      "Epoch 968/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9902 - accuracy: 0.5841 - val_loss: 1.4161 - val_accuracy: 0.5054\n",
      "Epoch 969/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0019 - accuracy: 0.5696 - val_loss: 1.3726 - val_accuracy: 0.5054\n",
      "Epoch 970/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9838 - accuracy: 0.5966 - val_loss: 1.3829 - val_accuracy: 0.5095\n",
      "Epoch 971/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9283 - accuracy: 0.6048 - val_loss: 1.4386 - val_accuracy: 0.5034\n",
      "Epoch 972/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9314 - accuracy: 0.6015 - val_loss: 1.3853 - val_accuracy: 0.5143\n",
      "Epoch 973/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9461 - accuracy: 0.5970 - val_loss: 1.4138 - val_accuracy: 0.5048\n",
      "Epoch 974/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9461 - accuracy: 0.5975 - val_loss: 1.3964 - val_accuracy: 0.5095\n",
      "Epoch 975/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9452 - accuracy: 0.6070 - val_loss: 1.4575 - val_accuracy: 0.4844\n",
      "Epoch 976/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9626 - accuracy: 0.5915 - val_loss: 1.4024 - val_accuracy: 0.5299\n",
      "Epoch 977/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9572 - accuracy: 0.5844 - val_loss: 1.4098 - val_accuracy: 0.5211\n",
      "Epoch 978/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9684 - accuracy: 0.5686 - val_loss: 1.4074 - val_accuracy: 0.4544\n",
      "Epoch 979/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9658 - accuracy: 0.5895 - val_loss: 1.4369 - val_accuracy: 0.4796\n",
      "Epoch 980/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9361 - accuracy: 0.5928 - val_loss: 1.3770 - val_accuracy: 0.5170\n",
      "Epoch 981/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9419 - accuracy: 0.5908 - val_loss: 1.4000 - val_accuracy: 0.5020\n",
      "Epoch 982/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9703 - accuracy: 0.5911 - val_loss: 1.3074 - val_accuracy: 0.5306\n",
      "Epoch 983/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9687 - accuracy: 0.5771 - val_loss: 1.4176 - val_accuracy: 0.5007\n",
      "Epoch 984/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9392 - accuracy: 0.6022 - val_loss: 1.4252 - val_accuracy: 0.4769\n",
      "Epoch 985/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9341 - accuracy: 0.6006 - val_loss: 1.4675 - val_accuracy: 0.4633\n",
      "Epoch 986/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9266 - accuracy: 0.6051 - val_loss: 1.4994 - val_accuracy: 0.4864\n",
      "Epoch 987/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9514 - accuracy: 0.5851 - val_loss: 1.3925 - val_accuracy: 0.4905\n",
      "Epoch 988/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9366 - accuracy: 0.6088 - val_loss: 1.4852 - val_accuracy: 0.4912\n",
      "Epoch 989/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9708 - accuracy: 0.5779 - val_loss: 1.4635 - val_accuracy: 0.5184\n",
      "Epoch 990/1000\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.9371 - accuracy: 0.6003 - val_loss: 1.4103 - val_accuracy: 0.5000\n",
      "Epoch 991/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9475 - accuracy: 0.6108 - val_loss: 1.4339 - val_accuracy: 0.4673\n",
      "Epoch 992/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9704 - accuracy: 0.5867 - val_loss: 1.3857 - val_accuracy: 0.5163\n",
      "Epoch 993/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9431 - accuracy: 0.5932 - val_loss: 1.3550 - val_accuracy: 0.5177\n",
      "Epoch 994/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9841 - accuracy: 0.5760 - val_loss: 1.5083 - val_accuracy: 0.4510\n",
      "Epoch 995/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9438 - accuracy: 0.5976 - val_loss: 1.4934 - val_accuracy: 0.4741\n",
      "Epoch 996/1000\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 0.9372 - accuracy: 0.6079 - val_loss: 1.3865 - val_accuracy: 0.5293\n",
      "Epoch 997/1000\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 0.9615 - accuracy: 0.5954 - val_loss: 1.3959 - val_accuracy: 0.5068\n",
      "Epoch 998/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9536 - accuracy: 0.5827 - val_loss: 1.3814 - val_accuracy: 0.5014\n",
      "Epoch 999/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9431 - accuracy: 0.6073 - val_loss: 1.4173 - val_accuracy: 0.5048\n",
      "Epoch 1000/1000\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 0.9501 - accuracy: 0.5940 - val_loss: 1.3417 - val_accuracy: 0.5184\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model2 =keras. models.Sequential()\n",
    "\n",
    "model2.add(keras.layers.Dense(units = 64,input_dim = 11,activation = 'relu'))\n",
    "model2.add(keras.layers.Dense(units = 32,activation = 'relu'))\n",
    "model2.add(keras.layers.Dense(units = 16,activation = 'relu'))\n",
    "model2.add(keras.layers.Dense(units = 32,activation = 'relu'))\n",
    "\n",
    "model2.add(keras.layers.Dense(11,activation = 'softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "hist2 = model2.fit(x_train,y_train,epochs=1000,batch_size=64,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "acc_ax = ax1.twinx()\n",
    "\n",
    "ax1.plot(hist2.history['loss'], 'y', label='train loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "\n",
    "\n",
    "ax2.plot(hist2.history['val_loss'], 'r', label='val loss')\n",
    "ax2.set_ylabel('val_loss')\n",
    "\n",
    "\n",
    "ax3.plot(hist2.history['accuracy'], 'b', label='accuracy')\n",
    "ax3.set_ylabel('accuray')\n",
    "\n",
    "ax4.plot(hist2.history['val_accuracy'], 'g', label='val_accuracy')\n",
    "ax4.set_ylabel('val_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 - 0s - loss: 1.3417 - accuracy: 0.5184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3416523933410645, 0.518367350101471]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_test,y_test,verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 16)                192       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 11)                231       \n",
      "=================================================================\n",
      "Total params: 1,627\n",
      "Trainable params: 1,627\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/800\n",
      "54/54 [==============================] - 1s 9ms/step - loss: 24.0096 - accuracy: 0.0691 - val_loss: 1.5127 - val_accuracy: 0.4721\n",
      "Epoch 2/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 3.2954 - accuracy: 0.3039 - val_loss: 1.3890 - val_accuracy: 0.3667\n",
      "Epoch 3/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 2.0747 - accuracy: 0.3414 - val_loss: 1.2643 - val_accuracy: 0.4469\n",
      "Epoch 4/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.6885 - accuracy: 0.3761 - val_loss: 1.2586 - val_accuracy: 0.4469\n",
      "Epoch 5/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.5648 - accuracy: 0.3901 - val_loss: 1.2536 - val_accuracy: 0.4456\n",
      "Epoch 6/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.4649 - accuracy: 0.3760 - val_loss: 1.2401 - val_accuracy: 0.4850\n",
      "Epoch 7/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.4091 - accuracy: 0.4075 - val_loss: 1.2476 - val_accuracy: 0.4503\n",
      "Epoch 8/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.4355 - accuracy: 0.4046 - val_loss: 1.2320 - val_accuracy: 0.4673\n",
      "Epoch 9/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.3719 - accuracy: 0.4105 - val_loss: 1.2167 - val_accuracy: 0.4993\n",
      "Epoch 10/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.3806 - accuracy: 0.4173 - val_loss: 1.2090 - val_accuracy: 0.5041\n",
      "Epoch 11/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.3717 - accuracy: 0.4035 - val_loss: 1.2325 - val_accuracy: 0.4844\n",
      "Epoch 12/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.3243 - accuracy: 0.4368 - val_loss: 1.2324 - val_accuracy: 0.4973\n",
      "Epoch 13/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.3047 - accuracy: 0.4243 - val_loss: 1.2179 - val_accuracy: 0.5007\n",
      "Epoch 14/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.3064 - accuracy: 0.4365 - val_loss: 1.2231 - val_accuracy: 0.4912\n",
      "Epoch 15/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2924 - accuracy: 0.4412 - val_loss: 1.2250 - val_accuracy: 0.4626\n",
      "Epoch 16/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.3064 - accuracy: 0.4230 - val_loss: 1.2217 - val_accuracy: 0.4993\n",
      "Epoch 17/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.3019 - accuracy: 0.4402 - val_loss: 1.2011 - val_accuracy: 0.4925\n",
      "Epoch 18/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.3076 - accuracy: 0.4372 - val_loss: 1.2278 - val_accuracy: 0.4837\n",
      "Epoch 19/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.3156 - accuracy: 0.4164 - val_loss: 1.1983 - val_accuracy: 0.4932\n",
      "Epoch 20/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2902 - accuracy: 0.4087 - val_loss: 1.2060 - val_accuracy: 0.4769\n",
      "Epoch 21/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2977 - accuracy: 0.4316 - val_loss: 1.1909 - val_accuracy: 0.5048\n",
      "Epoch 22/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2846 - accuracy: 0.4009 - val_loss: 1.1867 - val_accuracy: 0.4939\n",
      "Epoch 23/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2867 - accuracy: 0.4378 - val_loss: 1.1991 - val_accuracy: 0.4918\n",
      "Epoch 24/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2879 - accuracy: 0.4193 - val_loss: 1.2051 - val_accuracy: 0.4531\n",
      "Epoch 25/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2927 - accuracy: 0.4286 - val_loss: 1.1759 - val_accuracy: 0.4823\n",
      "Epoch 26/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2907 - accuracy: 0.4363 - val_loss: 1.1866 - val_accuracy: 0.4599\n",
      "Epoch 27/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2791 - accuracy: 0.4272 - val_loss: 1.2154 - val_accuracy: 0.4408\n",
      "Epoch 28/800\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 1.2702 - accuracy: 0.4389 - val_loss: 1.1953 - val_accuracy: 0.4735\n",
      "Epoch 29/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2632 - accuracy: 0.4181 - val_loss: 1.1749 - val_accuracy: 0.5034\n",
      "Epoch 30/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2799 - accuracy: 0.4387 - val_loss: 1.1683 - val_accuracy: 0.4939\n",
      "Epoch 31/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2755 - accuracy: 0.4541 - val_loss: 1.1874 - val_accuracy: 0.4946\n",
      "Epoch 32/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2872 - accuracy: 0.4396 - val_loss: 1.1681 - val_accuracy: 0.4837\n",
      "Epoch 33/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2962 - accuracy: 0.4365 - val_loss: 1.1804 - val_accuracy: 0.4694\n",
      "Epoch 34/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2719 - accuracy: 0.4340 - val_loss: 1.1769 - val_accuracy: 0.4884\n",
      "Epoch 35/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2724 - accuracy: 0.4428 - val_loss: 1.1742 - val_accuracy: 0.4728\n",
      "Epoch 36/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2612 - accuracy: 0.4256 - val_loss: 1.1609 - val_accuracy: 0.4939\n",
      "Epoch 37/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2694 - accuracy: 0.4458 - val_loss: 1.1815 - val_accuracy: 0.4585\n",
      "Epoch 38/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2490 - accuracy: 0.4579 - val_loss: 1.1577 - val_accuracy: 0.5054\n",
      "Epoch 39/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2584 - accuracy: 0.4552 - val_loss: 1.1961 - val_accuracy: 0.4449\n",
      "Epoch 40/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2553 - accuracy: 0.4449 - val_loss: 1.1550 - val_accuracy: 0.4891\n",
      "Epoch 41/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2480 - accuracy: 0.4451 - val_loss: 1.1530 - val_accuracy: 0.4986\n",
      "Epoch 42/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2434 - accuracy: 0.4601 - val_loss: 1.1636 - val_accuracy: 0.4728\n",
      "Epoch 43/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2369 - accuracy: 0.4313 - val_loss: 1.1868 - val_accuracy: 0.4497\n",
      "Epoch 44/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2319 - accuracy: 0.4491 - val_loss: 1.1769 - val_accuracy: 0.4619\n",
      "Epoch 45/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2518 - accuracy: 0.4433 - val_loss: 1.1892 - val_accuracy: 0.4449\n",
      "Epoch 46/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2551 - accuracy: 0.4148 - val_loss: 1.1433 - val_accuracy: 0.4980\n",
      "Epoch 47/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2336 - accuracy: 0.4523 - val_loss: 1.1715 - val_accuracy: 0.4653\n",
      "Epoch 48/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2357 - accuracy: 0.4459 - val_loss: 1.1517 - val_accuracy: 0.4980\n",
      "Epoch 49/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2297 - accuracy: 0.4456 - val_loss: 1.1448 - val_accuracy: 0.4932\n",
      "Epoch 50/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2582 - accuracy: 0.4333 - val_loss: 1.1640 - val_accuracy: 0.4585\n",
      "Epoch 51/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2276 - accuracy: 0.4332 - val_loss: 1.1424 - val_accuracy: 0.5122\n",
      "Epoch 52/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2092 - accuracy: 0.4448 - val_loss: 1.1492 - val_accuracy: 0.4871\n",
      "Epoch 53/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2309 - accuracy: 0.4521 - val_loss: 1.1361 - val_accuracy: 0.4966\n",
      "Epoch 54/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2675 - accuracy: 0.4461 - val_loss: 1.1469 - val_accuracy: 0.4925\n",
      "Epoch 55/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2193 - accuracy: 0.4389 - val_loss: 1.1344 - val_accuracy: 0.4966\n",
      "Epoch 56/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2301 - accuracy: 0.4357 - val_loss: 1.1508 - val_accuracy: 0.4830\n",
      "Epoch 57/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2120 - accuracy: 0.4558 - val_loss: 1.1615 - val_accuracy: 0.4748\n",
      "Epoch 58/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2469 - accuracy: 0.4588 - val_loss: 1.1533 - val_accuracy: 0.4701\n",
      "Epoch 59/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2400 - accuracy: 0.4439 - val_loss: 1.1751 - val_accuracy: 0.4680\n",
      "Epoch 60/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2358 - accuracy: 0.4568 - val_loss: 1.1349 - val_accuracy: 0.4830\n",
      "Epoch 61/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.4528 - val_loss: 1.1319 - val_accuracy: 0.4959\n",
      "Epoch 62/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2215 - accuracy: 0.4512 - val_loss: 1.1447 - val_accuracy: 0.4864\n",
      "Epoch 63/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2267 - accuracy: 0.4582 - val_loss: 1.1903 - val_accuracy: 0.4224\n",
      "Epoch 64/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2204 - accuracy: 0.4594 - val_loss: 1.1391 - val_accuracy: 0.4823\n",
      "Epoch 65/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2031 - accuracy: 0.4744 - val_loss: 1.1165 - val_accuracy: 0.5048\n",
      "Epoch 66/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1948 - accuracy: 0.4748 - val_loss: 1.1226 - val_accuracy: 0.5143\n",
      "Epoch 67/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2223 - accuracy: 0.4669 - val_loss: 1.1467 - val_accuracy: 0.4626\n",
      "Epoch 68/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1879 - accuracy: 0.4542 - val_loss: 1.1350 - val_accuracy: 0.4755\n",
      "Epoch 69/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.2073 - accuracy: 0.4437 - val_loss: 1.1412 - val_accuracy: 0.4891\n",
      "Epoch 70/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2202 - accuracy: 0.4660 - val_loss: 1.1226 - val_accuracy: 0.4918\n",
      "Epoch 71/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2286 - accuracy: 0.4495 - val_loss: 1.1621 - val_accuracy: 0.4544\n",
      "Epoch 72/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1981 - accuracy: 0.4637 - val_loss: 1.1056 - val_accuracy: 0.5211\n",
      "Epoch 73/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2009 - accuracy: 0.4652 - val_loss: 1.1062 - val_accuracy: 0.5014\n",
      "Epoch 74/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.2054 - accuracy: 0.4474 - val_loss: 1.0978 - val_accuracy: 0.5007\n",
      "Epoch 75/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2069 - accuracy: 0.4565 - val_loss: 1.1496 - val_accuracy: 0.4435\n",
      "Epoch 76/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1987 - accuracy: 0.4474 - val_loss: 1.1454 - val_accuracy: 0.4571\n",
      "Epoch 77/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2017 - accuracy: 0.4734 - val_loss: 1.1138 - val_accuracy: 0.4884\n",
      "Epoch 78/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1884 - accuracy: 0.4727 - val_loss: 1.0958 - val_accuracy: 0.5020\n",
      "Epoch 79/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1966 - accuracy: 0.4605 - val_loss: 1.1324 - val_accuracy: 0.4551\n",
      "Epoch 80/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1976 - accuracy: 0.4519 - val_loss: 1.1392 - val_accuracy: 0.4558\n",
      "Epoch 81/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1950 - accuracy: 0.4519 - val_loss: 1.1222 - val_accuracy: 0.4871\n",
      "Epoch 82/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1906 - accuracy: 0.4440 - val_loss: 1.1402 - val_accuracy: 0.4952\n",
      "Epoch 83/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1941 - accuracy: 0.4652 - val_loss: 1.1016 - val_accuracy: 0.4789\n",
      "Epoch 84/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1956 - accuracy: 0.4731 - val_loss: 1.1313 - val_accuracy: 0.4653\n",
      "Epoch 85/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1918 - accuracy: 0.4714 - val_loss: 1.0914 - val_accuracy: 0.5156\n",
      "Epoch 86/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2210 - accuracy: 0.4483 - val_loss: 1.0854 - val_accuracy: 0.5476\n",
      "Epoch 87/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2221 - accuracy: 0.4605 - val_loss: 1.1086 - val_accuracy: 0.4905\n",
      "Epoch 88/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1820 - accuracy: 0.4748 - val_loss: 1.0979 - val_accuracy: 0.5020\n",
      "Epoch 89/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1535 - accuracy: 0.4592 - val_loss: 1.1212 - val_accuracy: 0.4864\n",
      "Epoch 90/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1851 - accuracy: 0.4711 - val_loss: 1.1213 - val_accuracy: 0.4735\n",
      "Epoch 91/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2059 - accuracy: 0.4397 - val_loss: 1.0817 - val_accuracy: 0.5014\n",
      "Epoch 92/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1826 - accuracy: 0.4666 - val_loss: 1.1245 - val_accuracy: 0.4789\n",
      "Epoch 93/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.2168 - accuracy: 0.4547 - val_loss: 1.0814 - val_accuracy: 0.5299\n",
      "Epoch 94/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1699 - accuracy: 0.4561 - val_loss: 1.0865 - val_accuracy: 0.5354\n",
      "Epoch 95/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1886 - accuracy: 0.4615 - val_loss: 1.0737 - val_accuracy: 0.5265\n",
      "Epoch 96/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1682 - accuracy: 0.4725 - val_loss: 1.1251 - val_accuracy: 0.4769\n",
      "Epoch 97/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1917 - accuracy: 0.4516 - val_loss: 1.1009 - val_accuracy: 0.4891\n",
      "Epoch 98/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.2028 - accuracy: 0.4708 - val_loss: 1.0669 - val_accuracy: 0.5469\n",
      "Epoch 99/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1917 - accuracy: 0.4552 - val_loss: 1.0856 - val_accuracy: 0.4918\n",
      "Epoch 100/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1841 - accuracy: 0.4544 - val_loss: 1.0755 - val_accuracy: 0.5347\n",
      "Epoch 101/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1824 - accuracy: 0.4599 - val_loss: 1.0889 - val_accuracy: 0.5218\n",
      "Epoch 102/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1746 - accuracy: 0.4547 - val_loss: 1.0790 - val_accuracy: 0.5313\n",
      "Epoch 103/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1704 - accuracy: 0.4744 - val_loss: 1.1074 - val_accuracy: 0.5048\n",
      "Epoch 104/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1708 - accuracy: 0.4713 - val_loss: 1.0847 - val_accuracy: 0.4925\n",
      "Epoch 105/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1691 - accuracy: 0.4556 - val_loss: 1.1078 - val_accuracy: 0.4925\n",
      "Epoch 106/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1785 - accuracy: 0.4679 - val_loss: 1.1270 - val_accuracy: 0.4810\n",
      "Epoch 107/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1787 - accuracy: 0.4648 - val_loss: 1.1345 - val_accuracy: 0.4741\n",
      "Epoch 108/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1866 - accuracy: 0.4551 - val_loss: 1.1270 - val_accuracy: 0.4912\n",
      "Epoch 109/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1511 - accuracy: 0.4802 - val_loss: 1.1156 - val_accuracy: 0.5000\n",
      "Epoch 110/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1610 - accuracy: 0.4836 - val_loss: 1.0692 - val_accuracy: 0.5524\n",
      "Epoch 111/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1816 - accuracy: 0.4630 - val_loss: 1.0744 - val_accuracy: 0.5177\n",
      "Epoch 112/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1717 - accuracy: 0.4718 - val_loss: 1.0818 - val_accuracy: 0.5088\n",
      "Epoch 113/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1990 - accuracy: 0.4676 - val_loss: 1.0629 - val_accuracy: 0.5401\n",
      "Epoch 114/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1916 - accuracy: 0.4461 - val_loss: 1.0740 - val_accuracy: 0.5177\n",
      "Epoch 115/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1784 - accuracy: 0.4632 - val_loss: 1.0996 - val_accuracy: 0.4864\n",
      "Epoch 116/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1575 - accuracy: 0.4696 - val_loss: 1.0866 - val_accuracy: 0.5163\n",
      "Epoch 117/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1700 - accuracy: 0.4739 - val_loss: 1.0898 - val_accuracy: 0.5286\n",
      "Epoch 118/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1764 - accuracy: 0.4747 - val_loss: 1.0830 - val_accuracy: 0.5129\n",
      "Epoch 119/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1528 - accuracy: 0.4846 - val_loss: 1.0537 - val_accuracy: 0.5279\n",
      "Epoch 120/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1676 - accuracy: 0.4633 - val_loss: 1.0922 - val_accuracy: 0.4980\n",
      "Epoch 121/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1537 - accuracy: 0.4842 - val_loss: 1.1233 - val_accuracy: 0.5061\n",
      "Epoch 122/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1651 - accuracy: 0.4771 - val_loss: 1.0716 - val_accuracy: 0.5374\n",
      "Epoch 123/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1655 - accuracy: 0.4877 - val_loss: 1.0855 - val_accuracy: 0.5381\n",
      "Epoch 124/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1714 - accuracy: 0.4728 - val_loss: 1.0741 - val_accuracy: 0.5116\n",
      "Epoch 125/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1712 - accuracy: 0.4731 - val_loss: 1.0817 - val_accuracy: 0.5197\n",
      "Epoch 126/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1588 - accuracy: 0.4766 - val_loss: 1.0922 - val_accuracy: 0.4939\n",
      "Epoch 127/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1578 - accuracy: 0.4830 - val_loss: 1.0604 - val_accuracy: 0.5537\n",
      "Epoch 128/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1509 - accuracy: 0.4897 - val_loss: 1.0868 - val_accuracy: 0.5082\n",
      "Epoch 129/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1613 - accuracy: 0.4661 - val_loss: 1.1207 - val_accuracy: 0.4891\n",
      "Epoch 130/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1617 - accuracy: 0.4659 - val_loss: 1.1035 - val_accuracy: 0.4986\n",
      "Epoch 131/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1650 - accuracy: 0.4675 - val_loss: 1.1105 - val_accuracy: 0.4816\n",
      "Epoch 132/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1675 - accuracy: 0.4834 - val_loss: 1.1056 - val_accuracy: 0.4932\n",
      "Epoch 133/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1528 - accuracy: 0.4795 - val_loss: 1.0998 - val_accuracy: 0.4741\n",
      "Epoch 134/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1565 - accuracy: 0.4699 - val_loss: 1.0716 - val_accuracy: 0.5408\n",
      "Epoch 135/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1434 - accuracy: 0.4799 - val_loss: 1.0841 - val_accuracy: 0.5102\n",
      "Epoch 136/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1645 - accuracy: 0.4949 - val_loss: 1.0800 - val_accuracy: 0.5048\n",
      "Epoch 137/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1738 - accuracy: 0.4734 - val_loss: 1.1780 - val_accuracy: 0.4381\n",
      "Epoch 138/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1545 - accuracy: 0.4744 - val_loss: 1.0731 - val_accuracy: 0.5483\n",
      "Epoch 139/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1755 - accuracy: 0.4769 - val_loss: 1.0739 - val_accuracy: 0.5252\n",
      "Epoch 140/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1373 - accuracy: 0.4810 - val_loss: 1.0834 - val_accuracy: 0.5354\n",
      "Epoch 141/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1673 - accuracy: 0.4547 - val_loss: 1.0885 - val_accuracy: 0.5156\n",
      "Epoch 142/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1410 - accuracy: 0.4931 - val_loss: 1.0785 - val_accuracy: 0.5435\n",
      "Epoch 143/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1587 - accuracy: 0.4667 - val_loss: 1.1129 - val_accuracy: 0.5088\n",
      "Epoch 144/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1601 - accuracy: 0.4874 - val_loss: 1.0802 - val_accuracy: 0.5313\n",
      "Epoch 145/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1515 - accuracy: 0.4833 - val_loss: 1.0672 - val_accuracy: 0.5333\n",
      "Epoch 146/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1471 - accuracy: 0.4946 - val_loss: 1.0625 - val_accuracy: 0.5218\n",
      "Epoch 147/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1432 - accuracy: 0.4818 - val_loss: 1.0715 - val_accuracy: 0.5333\n",
      "Epoch 148/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1551 - accuracy: 0.4902 - val_loss: 1.0582 - val_accuracy: 0.5265\n",
      "Epoch 149/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1553 - accuracy: 0.4665 - val_loss: 1.0613 - val_accuracy: 0.5429\n",
      "Epoch 150/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1434 - accuracy: 0.4861 - val_loss: 1.0898 - val_accuracy: 0.5361\n",
      "Epoch 151/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1381 - accuracy: 0.5004 - val_loss: 1.0760 - val_accuracy: 0.5259\n",
      "Epoch 152/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1654 - accuracy: 0.4599 - val_loss: 1.0503 - val_accuracy: 0.5442\n",
      "Epoch 153/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1749 - accuracy: 0.4630 - val_loss: 1.0872 - val_accuracy: 0.4986\n",
      "Epoch 154/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1597 - accuracy: 0.4800 - val_loss: 1.0464 - val_accuracy: 0.5279\n",
      "Epoch 155/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1381 - accuracy: 0.4861 - val_loss: 1.0840 - val_accuracy: 0.5136\n",
      "Epoch 156/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1706 - accuracy: 0.4760 - val_loss: 1.0992 - val_accuracy: 0.5000\n",
      "Epoch 157/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1642 - accuracy: 0.4793 - val_loss: 1.0858 - val_accuracy: 0.4912\n",
      "Epoch 158/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1901 - accuracy: 0.4532 - val_loss: 1.0631 - val_accuracy: 0.5320\n",
      "Epoch 159/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1431 - accuracy: 0.4810 - val_loss: 1.0879 - val_accuracy: 0.5279\n",
      "Epoch 160/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1481 - accuracy: 0.4832 - val_loss: 1.0623 - val_accuracy: 0.5156\n",
      "Epoch 161/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1713 - accuracy: 0.4730 - val_loss: 1.0489 - val_accuracy: 0.5204\n",
      "Epoch 162/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1464 - accuracy: 0.4770 - val_loss: 1.0837 - val_accuracy: 0.4980\n",
      "Epoch 163/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1675 - accuracy: 0.4685 - val_loss: 1.0769 - val_accuracy: 0.5272\n",
      "Epoch 164/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1563 - accuracy: 0.4911 - val_loss: 1.0671 - val_accuracy: 0.5456\n",
      "Epoch 165/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1374 - accuracy: 0.4775 - val_loss: 1.0821 - val_accuracy: 0.5068\n",
      "Epoch 166/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1248 - accuracy: 0.4958 - val_loss: 1.0774 - val_accuracy: 0.5143\n",
      "Epoch 167/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1385 - accuracy: 0.4975 - val_loss: 1.0852 - val_accuracy: 0.5136\n",
      "Epoch 168/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1512 - accuracy: 0.4748 - val_loss: 1.0593 - val_accuracy: 0.5517\n",
      "Epoch 169/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1546 - accuracy: 0.4571 - val_loss: 1.1027 - val_accuracy: 0.5020\n",
      "Epoch 170/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1290 - accuracy: 0.5008 - val_loss: 1.0749 - val_accuracy: 0.5150\n",
      "Epoch 171/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1533 - accuracy: 0.4820 - val_loss: 1.0558 - val_accuracy: 0.5408\n",
      "Epoch 172/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1723 - accuracy: 0.4746 - val_loss: 1.0746 - val_accuracy: 0.5020\n",
      "Epoch 173/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1262 - accuracy: 0.4751 - val_loss: 1.0894 - val_accuracy: 0.4980\n",
      "Epoch 174/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1522 - accuracy: 0.4787 - val_loss: 1.0551 - val_accuracy: 0.5388\n",
      "Epoch 175/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1356 - accuracy: 0.4987 - val_loss: 1.0525 - val_accuracy: 0.5095\n",
      "Epoch 176/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1551 - accuracy: 0.4765 - val_loss: 1.0700 - val_accuracy: 0.5531\n",
      "Epoch 177/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1267 - accuracy: 0.4973 - val_loss: 1.1004 - val_accuracy: 0.5129\n",
      "Epoch 178/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1521 - accuracy: 0.4745 - val_loss: 1.0680 - val_accuracy: 0.5048\n",
      "Epoch 179/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1495 - accuracy: 0.4811 - val_loss: 1.0384 - val_accuracy: 0.5095\n",
      "Epoch 180/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1360 - accuracy: 0.4774 - val_loss: 1.1014 - val_accuracy: 0.4633\n",
      "Epoch 181/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1328 - accuracy: 0.4829 - val_loss: 1.0653 - val_accuracy: 0.5197\n",
      "Epoch 182/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1365 - accuracy: 0.4897 - val_loss: 1.0729 - val_accuracy: 0.5218\n",
      "Epoch 183/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1546 - accuracy: 0.4797 - val_loss: 1.1085 - val_accuracy: 0.4966\n",
      "Epoch 184/800\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 1.1303 - accuracy: 0.4902 - val_loss: 1.0669 - val_accuracy: 0.5340\n",
      "Epoch 185/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1192 - accuracy: 0.4817 - val_loss: 1.0973 - val_accuracy: 0.4844\n",
      "Epoch 186/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1367 - accuracy: 0.4964 - val_loss: 1.0651 - val_accuracy: 0.5497\n",
      "Epoch 187/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1473 - accuracy: 0.4821 - val_loss: 1.0641 - val_accuracy: 0.5150\n",
      "Epoch 188/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1414 - accuracy: 0.4887 - val_loss: 1.0692 - val_accuracy: 0.5395\n",
      "Epoch 189/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1205 - accuracy: 0.4859 - val_loss: 1.0655 - val_accuracy: 0.5170\n",
      "Epoch 190/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1465 - accuracy: 0.4830 - val_loss: 1.0839 - val_accuracy: 0.5041\n",
      "Epoch 191/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1386 - accuracy: 0.4995 - val_loss: 1.0697 - val_accuracy: 0.5048\n",
      "Epoch 192/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1324 - accuracy: 0.4995 - val_loss: 1.0601 - val_accuracy: 0.5367\n",
      "Epoch 193/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1394 - accuracy: 0.4819 - val_loss: 1.0862 - val_accuracy: 0.5054\n",
      "Epoch 194/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1439 - accuracy: 0.5082 - val_loss: 1.0718 - val_accuracy: 0.5082\n",
      "Epoch 195/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1172 - accuracy: 0.4836 - val_loss: 1.0635 - val_accuracy: 0.5422\n",
      "Epoch 196/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1441 - accuracy: 0.4911 - val_loss: 1.0729 - val_accuracy: 0.5156\n",
      "Epoch 197/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1393 - accuracy: 0.4853 - val_loss: 1.0553 - val_accuracy: 0.5517\n",
      "Epoch 198/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1344 - accuracy: 0.4898 - val_loss: 1.0768 - val_accuracy: 0.5027\n",
      "Epoch 199/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1288 - accuracy: 0.5049 - val_loss: 1.0743 - val_accuracy: 0.5293\n",
      "Epoch 200/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1373 - accuracy: 0.4789 - val_loss: 1.0638 - val_accuracy: 0.5088\n",
      "Epoch 201/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1486 - accuracy: 0.4920 - val_loss: 1.0442 - val_accuracy: 0.5156\n",
      "Epoch 202/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1327 - accuracy: 0.4785 - val_loss: 1.0580 - val_accuracy: 0.5490\n",
      "Epoch 203/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1421 - accuracy: 0.4713 - val_loss: 1.0765 - val_accuracy: 0.5211\n",
      "Epoch 204/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1256 - accuracy: 0.4878 - val_loss: 1.0642 - val_accuracy: 0.5340\n",
      "Epoch 205/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1308 - accuracy: 0.4754 - val_loss: 1.0916 - val_accuracy: 0.5109\n",
      "Epoch 206/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1516 - accuracy: 0.4885 - val_loss: 1.0580 - val_accuracy: 0.5469\n",
      "Epoch 207/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1217 - accuracy: 0.4938 - val_loss: 1.0523 - val_accuracy: 0.5517\n",
      "Epoch 208/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1296 - accuracy: 0.4979 - val_loss: 1.0975 - val_accuracy: 0.4966\n",
      "Epoch 209/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1236 - accuracy: 0.4753 - val_loss: 1.0828 - val_accuracy: 0.4959\n",
      "Epoch 210/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1315 - accuracy: 0.4979 - val_loss: 1.0972 - val_accuracy: 0.4844\n",
      "Epoch 211/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1531 - accuracy: 0.4795 - val_loss: 1.0484 - val_accuracy: 0.5252\n",
      "Epoch 212/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1449 - accuracy: 0.4746 - val_loss: 1.0609 - val_accuracy: 0.5116\n",
      "Epoch 213/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1300 - accuracy: 0.5044 - val_loss: 1.0500 - val_accuracy: 0.5503\n",
      "Epoch 214/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1239 - accuracy: 0.4610 - val_loss: 1.0612 - val_accuracy: 0.5163\n",
      "Epoch 215/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1464 - accuracy: 0.4706 - val_loss: 1.0633 - val_accuracy: 0.5456\n",
      "Epoch 216/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1192 - accuracy: 0.5092 - val_loss: 1.0795 - val_accuracy: 0.5061\n",
      "Epoch 217/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1462 - accuracy: 0.4908 - val_loss: 1.0657 - val_accuracy: 0.5231\n",
      "Epoch 218/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1269 - accuracy: 0.5016 - val_loss: 1.0722 - val_accuracy: 0.4796\n",
      "Epoch 219/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1411 - accuracy: 0.4968 - val_loss: 1.0741 - val_accuracy: 0.5551\n",
      "Epoch 220/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1259 - accuracy: 0.5076 - val_loss: 1.0807 - val_accuracy: 0.5313\n",
      "Epoch 221/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1234 - accuracy: 0.4960 - val_loss: 1.0632 - val_accuracy: 0.5327\n",
      "Epoch 222/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1481 - accuracy: 0.4991 - val_loss: 1.0500 - val_accuracy: 0.5122\n",
      "Epoch 223/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1236 - accuracy: 0.4987 - val_loss: 1.0782 - val_accuracy: 0.4925\n",
      "Epoch 224/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1172 - accuracy: 0.4842 - val_loss: 1.0586 - val_accuracy: 0.5156\n",
      "Epoch 225/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1052 - accuracy: 0.5031 - val_loss: 1.0510 - val_accuracy: 0.5429\n",
      "Epoch 226/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1492 - accuracy: 0.4908 - val_loss: 1.0565 - val_accuracy: 0.5571\n",
      "Epoch 227/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1065 - accuracy: 0.4884 - val_loss: 1.0769 - val_accuracy: 0.5075\n",
      "Epoch 228/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1179 - accuracy: 0.5213 - val_loss: 1.0561 - val_accuracy: 0.5456\n",
      "Epoch 229/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1329 - accuracy: 0.4905 - val_loss: 1.0730 - val_accuracy: 0.5279\n",
      "Epoch 230/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1311 - accuracy: 0.4867 - val_loss: 1.0570 - val_accuracy: 0.5381\n",
      "Epoch 231/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1082 - accuracy: 0.4930 - val_loss: 1.0632 - val_accuracy: 0.5136\n",
      "Epoch 232/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1354 - accuracy: 0.4955 - val_loss: 1.0555 - val_accuracy: 0.5435\n",
      "Epoch 233/800\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 1.1300 - accuracy: 0.5019 - val_loss: 1.0773 - val_accuracy: 0.5014\n",
      "Epoch 234/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1029 - accuracy: 0.5089 - val_loss: 1.0571 - val_accuracy: 0.4966\n",
      "Epoch 235/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1431 - accuracy: 0.4923 - val_loss: 1.0522 - val_accuracy: 0.5306\n",
      "Epoch 236/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1330 - accuracy: 0.4875 - val_loss: 1.0766 - val_accuracy: 0.5054\n",
      "Epoch 237/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1233 - accuracy: 0.4997 - val_loss: 1.0673 - val_accuracy: 0.5143\n",
      "Epoch 238/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1284 - accuracy: 0.4971 - val_loss: 1.0810 - val_accuracy: 0.5034\n",
      "Epoch 239/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1455 - accuracy: 0.4950 - val_loss: 1.0516 - val_accuracy: 0.5592\n",
      "Epoch 240/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1175 - accuracy: 0.4981 - val_loss: 1.1147 - val_accuracy: 0.4741\n",
      "Epoch 241/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1269 - accuracy: 0.4853 - val_loss: 1.0529 - val_accuracy: 0.5068\n",
      "Epoch 242/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1098 - accuracy: 0.5074 - val_loss: 1.0674 - val_accuracy: 0.4980\n",
      "Epoch 243/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1047 - accuracy: 0.5057 - val_loss: 1.0673 - val_accuracy: 0.5177\n",
      "Epoch 244/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1324 - accuracy: 0.5043 - val_loss: 1.0640 - val_accuracy: 0.4973\n",
      "Epoch 245/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1285 - accuracy: 0.4803 - val_loss: 1.0564 - val_accuracy: 0.5293\n",
      "Epoch 246/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1069 - accuracy: 0.4934 - val_loss: 1.0612 - val_accuracy: 0.5082\n",
      "Epoch 247/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1073 - accuracy: 0.5136 - val_loss: 1.0544 - val_accuracy: 0.5252\n",
      "Epoch 248/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1365 - accuracy: 0.4863 - val_loss: 1.0733 - val_accuracy: 0.5102\n",
      "Epoch 249/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1180 - accuracy: 0.5155 - val_loss: 1.0722 - val_accuracy: 0.5293\n",
      "Epoch 250/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1329 - accuracy: 0.4759 - val_loss: 1.0653 - val_accuracy: 0.5245\n",
      "Epoch 251/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1498 - accuracy: 0.4972 - val_loss: 1.0751 - val_accuracy: 0.4952\n",
      "Epoch 252/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1317 - accuracy: 0.5036 - val_loss: 1.0501 - val_accuracy: 0.5218\n",
      "Epoch 253/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1163 - accuracy: 0.4957 - val_loss: 1.0495 - val_accuracy: 0.5578\n",
      "Epoch 254/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1219 - accuracy: 0.4892 - val_loss: 1.0666 - val_accuracy: 0.5129\n",
      "Epoch 255/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1177 - accuracy: 0.4958 - val_loss: 1.0540 - val_accuracy: 0.5599\n",
      "Epoch 256/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1238 - accuracy: 0.4850 - val_loss: 1.0525 - val_accuracy: 0.5170\n",
      "Epoch 257/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1138 - accuracy: 0.4702 - val_loss: 1.0545 - val_accuracy: 0.5381\n",
      "Epoch 258/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1189 - accuracy: 0.4965 - val_loss: 1.0517 - val_accuracy: 0.5286\n",
      "Epoch 259/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1096 - accuracy: 0.5020 - val_loss: 1.1173 - val_accuracy: 0.4796\n",
      "Epoch 260/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1259 - accuracy: 0.5012 - val_loss: 1.0629 - val_accuracy: 0.5279\n",
      "Epoch 261/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1186 - accuracy: 0.4902 - val_loss: 1.0380 - val_accuracy: 0.5388\n",
      "Epoch 262/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1539 - accuracy: 0.4908 - val_loss: 1.0502 - val_accuracy: 0.5422\n",
      "Epoch 263/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1178 - accuracy: 0.5045 - val_loss: 1.0404 - val_accuracy: 0.5320\n",
      "Epoch 264/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1296 - accuracy: 0.4835 - val_loss: 1.0609 - val_accuracy: 0.5211\n",
      "Epoch 265/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1236 - accuracy: 0.4905 - val_loss: 1.0543 - val_accuracy: 0.5333\n",
      "Epoch 266/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1070 - accuracy: 0.5097 - val_loss: 1.0562 - val_accuracy: 0.5449\n",
      "Epoch 267/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1095 - accuracy: 0.4897 - val_loss: 1.0713 - val_accuracy: 0.5068\n",
      "Epoch 268/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1342 - accuracy: 0.4844 - val_loss: 1.1030 - val_accuracy: 0.5313\n",
      "Epoch 269/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1242 - accuracy: 0.5001 - val_loss: 1.0418 - val_accuracy: 0.5395\n",
      "Epoch 270/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1308 - accuracy: 0.4750 - val_loss: 1.0458 - val_accuracy: 0.5340\n",
      "Epoch 271/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1048 - accuracy: 0.4980 - val_loss: 1.0673 - val_accuracy: 0.5068\n",
      "Epoch 272/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0955 - accuracy: 0.5062 - val_loss: 1.0837 - val_accuracy: 0.5279\n",
      "Epoch 273/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1250 - accuracy: 0.4901 - val_loss: 1.0531 - val_accuracy: 0.5605\n",
      "Epoch 274/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1176 - accuracy: 0.4949 - val_loss: 1.0635 - val_accuracy: 0.5367\n",
      "Epoch 275/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1094 - accuracy: 0.4888 - val_loss: 1.0569 - val_accuracy: 0.5184\n",
      "Epoch 276/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1211 - accuracy: 0.5180 - val_loss: 1.0508 - val_accuracy: 0.5374\n",
      "Epoch 277/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1210 - accuracy: 0.5066 - val_loss: 1.0524 - val_accuracy: 0.5245\n",
      "Epoch 278/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1375 - accuracy: 0.4904 - val_loss: 1.0682 - val_accuracy: 0.5116\n",
      "Epoch 279/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1259 - accuracy: 0.4800 - val_loss: 1.0703 - val_accuracy: 0.5143\n",
      "Epoch 280/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1003 - accuracy: 0.4963 - val_loss: 1.0861 - val_accuracy: 0.4918\n",
      "Epoch 281/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1441 - accuracy: 0.4834 - val_loss: 1.0895 - val_accuracy: 0.4707\n",
      "Epoch 282/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1275 - accuracy: 0.4859 - val_loss: 1.0433 - val_accuracy: 0.5367\n",
      "Epoch 283/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1020 - accuracy: 0.5143 - val_loss: 1.0993 - val_accuracy: 0.4680\n",
      "Epoch 284/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1106 - accuracy: 0.4934 - val_loss: 1.0814 - val_accuracy: 0.5048\n",
      "Epoch 285/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1138 - accuracy: 0.5059 - val_loss: 1.0643 - val_accuracy: 0.5075\n",
      "Epoch 286/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1111 - accuracy: 0.4976 - val_loss: 1.0497 - val_accuracy: 0.5517\n",
      "Epoch 287/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1135 - accuracy: 0.4963 - val_loss: 1.0614 - val_accuracy: 0.5170\n",
      "Epoch 288/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1120 - accuracy: 0.4836 - val_loss: 1.0555 - val_accuracy: 0.5259\n",
      "Epoch 289/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1407 - accuracy: 0.4726 - val_loss: 1.0744 - val_accuracy: 0.5034\n",
      "Epoch 290/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1170 - accuracy: 0.5044 - val_loss: 1.0536 - val_accuracy: 0.5639\n",
      "Epoch 291/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1270 - accuracy: 0.4985 - val_loss: 1.0413 - val_accuracy: 0.5497\n",
      "Epoch 292/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1506 - accuracy: 0.4808 - val_loss: 1.0797 - val_accuracy: 0.5592\n",
      "Epoch 293/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1313 - accuracy: 0.5032 - val_loss: 1.0424 - val_accuracy: 0.5388\n",
      "Epoch 294/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1026 - accuracy: 0.5141 - val_loss: 1.0560 - val_accuracy: 0.5095\n",
      "Epoch 295/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0940 - accuracy: 0.5033 - val_loss: 1.0851 - val_accuracy: 0.5007\n",
      "Epoch 296/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1217 - accuracy: 0.5056 - val_loss: 1.1324 - val_accuracy: 0.4612\n",
      "Epoch 297/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1334 - accuracy: 0.4883 - val_loss: 1.0610 - val_accuracy: 0.5020\n",
      "Epoch 298/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0933 - accuracy: 0.5100 - val_loss: 1.0500 - val_accuracy: 0.5156\n",
      "Epoch 299/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1201 - accuracy: 0.4927 - val_loss: 1.0620 - val_accuracy: 0.5224\n",
      "Epoch 300/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1072 - accuracy: 0.5022 - val_loss: 1.0803 - val_accuracy: 0.5122\n",
      "Epoch 301/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1113 - accuracy: 0.4985 - val_loss: 1.0649 - val_accuracy: 0.5211\n",
      "Epoch 302/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1193 - accuracy: 0.4875 - val_loss: 1.0596 - val_accuracy: 0.5265\n",
      "Epoch 303/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1372 - accuracy: 0.4961 - val_loss: 1.0557 - val_accuracy: 0.5415\n",
      "Epoch 304/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1241 - accuracy: 0.4995 - val_loss: 1.0513 - val_accuracy: 0.5204\n",
      "Epoch 305/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1160 - accuracy: 0.4873 - val_loss: 1.0683 - val_accuracy: 0.5197\n",
      "Epoch 306/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1369 - accuracy: 0.4797 - val_loss: 1.0815 - val_accuracy: 0.5048\n",
      "Epoch 307/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0992 - accuracy: 0.5028 - val_loss: 1.0576 - val_accuracy: 0.5435\n",
      "Epoch 308/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1243 - accuracy: 0.4941 - val_loss: 1.0461 - val_accuracy: 0.5776\n",
      "Epoch 309/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1020 - accuracy: 0.5082 - val_loss: 1.0861 - val_accuracy: 0.4823\n",
      "Epoch 310/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0909 - accuracy: 0.5150 - val_loss: 1.0813 - val_accuracy: 0.5054\n",
      "Epoch 311/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1158 - accuracy: 0.5028 - val_loss: 1.0626 - val_accuracy: 0.5633\n",
      "Epoch 312/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1121 - accuracy: 0.4947 - val_loss: 1.0715 - val_accuracy: 0.5245\n",
      "Epoch 313/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1120 - accuracy: 0.5029 - val_loss: 1.0494 - val_accuracy: 0.5422\n",
      "Epoch 314/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1119 - accuracy: 0.4905 - val_loss: 1.0672 - val_accuracy: 0.4946\n",
      "Epoch 315/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1145 - accuracy: 0.4982 - val_loss: 1.0659 - val_accuracy: 0.5122\n",
      "Epoch 316/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1300 - accuracy: 0.5098 - val_loss: 1.0468 - val_accuracy: 0.5490\n",
      "Epoch 317/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1226 - accuracy: 0.5039 - val_loss: 1.0323 - val_accuracy: 0.5490\n",
      "Epoch 318/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1402 - accuracy: 0.4771 - val_loss: 1.0849 - val_accuracy: 0.5293\n",
      "Epoch 319/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1258 - accuracy: 0.4924 - val_loss: 1.0840 - val_accuracy: 0.5082\n",
      "Epoch 320/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1144 - accuracy: 0.4899 - val_loss: 1.1074 - val_accuracy: 0.4728\n",
      "Epoch 321/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1178 - accuracy: 0.4895 - val_loss: 1.0529 - val_accuracy: 0.5299\n",
      "Epoch 322/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0916 - accuracy: 0.5108 - val_loss: 1.0669 - val_accuracy: 0.5061\n",
      "Epoch 323/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1264 - accuracy: 0.4954 - val_loss: 1.0870 - val_accuracy: 0.5469\n",
      "Epoch 324/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1055 - accuracy: 0.5021 - val_loss: 1.0585 - val_accuracy: 0.5054\n",
      "Epoch 325/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1179 - accuracy: 0.4972 - val_loss: 1.0600 - val_accuracy: 0.5184\n",
      "Epoch 326/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1031 - accuracy: 0.5018 - val_loss: 1.0471 - val_accuracy: 0.5490\n",
      "Epoch 327/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1030 - accuracy: 0.5011 - val_loss: 1.0674 - val_accuracy: 0.5177\n",
      "Epoch 328/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1006 - accuracy: 0.5078 - val_loss: 1.0985 - val_accuracy: 0.4789\n",
      "Epoch 329/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1193 - accuracy: 0.4897 - val_loss: 1.0614 - val_accuracy: 0.5177\n",
      "Epoch 330/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1031 - accuracy: 0.4919 - val_loss: 1.0393 - val_accuracy: 0.5293\n",
      "Epoch 331/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1021 - accuracy: 0.5015 - val_loss: 1.0643 - val_accuracy: 0.5163\n",
      "Epoch 332/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1261 - accuracy: 0.4759 - val_loss: 1.0687 - val_accuracy: 0.5320\n",
      "Epoch 333/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1118 - accuracy: 0.4902 - val_loss: 1.0871 - val_accuracy: 0.4939\n",
      "Epoch 334/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1035 - accuracy: 0.5020 - val_loss: 1.0879 - val_accuracy: 0.4905\n",
      "Epoch 335/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1212 - accuracy: 0.5119 - val_loss: 1.0577 - val_accuracy: 0.5585\n",
      "Epoch 336/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0995 - accuracy: 0.5095 - val_loss: 1.0514 - val_accuracy: 0.5469\n",
      "Epoch 337/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1212 - accuracy: 0.4982 - val_loss: 1.0728 - val_accuracy: 0.4986\n",
      "Epoch 338/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1154 - accuracy: 0.4975 - val_loss: 1.0402 - val_accuracy: 0.5605\n",
      "Epoch 339/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1008 - accuracy: 0.5051 - val_loss: 1.0891 - val_accuracy: 0.4946\n",
      "Epoch 340/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1110 - accuracy: 0.5053 - val_loss: 1.0535 - val_accuracy: 0.5088\n",
      "Epoch 341/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1042 - accuracy: 0.5012 - val_loss: 1.0704 - val_accuracy: 0.5238\n",
      "Epoch 342/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1040 - accuracy: 0.5143 - val_loss: 1.0583 - val_accuracy: 0.5190\n",
      "Epoch 343/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0967 - accuracy: 0.5110 - val_loss: 1.0757 - val_accuracy: 0.4803\n",
      "Epoch 344/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1156 - accuracy: 0.5054 - val_loss: 1.0745 - val_accuracy: 0.4810\n",
      "Epoch 345/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0989 - accuracy: 0.5034 - val_loss: 1.1094 - val_accuracy: 0.4776\n",
      "Epoch 346/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1186 - accuracy: 0.4923 - val_loss: 1.0767 - val_accuracy: 0.5204\n",
      "Epoch 347/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1206 - accuracy: 0.4829 - val_loss: 1.0456 - val_accuracy: 0.5469\n",
      "Epoch 348/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1318 - accuracy: 0.4978 - val_loss: 1.0585 - val_accuracy: 0.5517\n",
      "Epoch 349/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1135 - accuracy: 0.4932 - val_loss: 1.0644 - val_accuracy: 0.5422\n",
      "Epoch 350/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1006 - accuracy: 0.4832 - val_loss: 1.0614 - val_accuracy: 0.5095\n",
      "Epoch 351/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1137 - accuracy: 0.4953 - val_loss: 1.0502 - val_accuracy: 0.5170\n",
      "Epoch 352/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1229 - accuracy: 0.4925 - val_loss: 1.0808 - val_accuracy: 0.5388\n",
      "Epoch 353/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1096 - accuracy: 0.5103 - val_loss: 1.0637 - val_accuracy: 0.5293\n",
      "Epoch 354/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1262 - accuracy: 0.5037 - val_loss: 1.0548 - val_accuracy: 0.5673\n",
      "Epoch 355/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1119 - accuracy: 0.4893 - val_loss: 1.0618 - val_accuracy: 0.5306\n",
      "Epoch 356/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1237 - accuracy: 0.4898 - val_loss: 1.0536 - val_accuracy: 0.5354\n",
      "Epoch 357/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1103 - accuracy: 0.4782 - val_loss: 1.0563 - val_accuracy: 0.5143\n",
      "Epoch 358/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0834 - accuracy: 0.5061 - val_loss: 1.0639 - val_accuracy: 0.5735\n",
      "Epoch 359/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1253 - accuracy: 0.4794 - val_loss: 1.0471 - val_accuracy: 0.5565\n",
      "Epoch 360/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1063 - accuracy: 0.5094 - val_loss: 1.0405 - val_accuracy: 0.5347\n",
      "Epoch 361/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1131 - accuracy: 0.4996 - val_loss: 1.0601 - val_accuracy: 0.5544\n",
      "Epoch 362/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0837 - accuracy: 0.5137 - val_loss: 1.0694 - val_accuracy: 0.5320\n",
      "Epoch 363/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1315 - accuracy: 0.4908 - val_loss: 1.0617 - val_accuracy: 0.5272\n",
      "Epoch 364/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1236 - accuracy: 0.5054 - val_loss: 1.0436 - val_accuracy: 0.5680\n",
      "Epoch 365/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1147 - accuracy: 0.5052 - val_loss: 1.0751 - val_accuracy: 0.5687\n",
      "Epoch 366/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1168 - accuracy: 0.5022 - val_loss: 1.0397 - val_accuracy: 0.5680\n",
      "Epoch 367/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1295 - accuracy: 0.4922 - val_loss: 1.0452 - val_accuracy: 0.5279\n",
      "Epoch 368/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1010 - accuracy: 0.4949 - val_loss: 1.0562 - val_accuracy: 0.5578\n",
      "Epoch 369/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1281 - accuracy: 0.4962 - val_loss: 1.0855 - val_accuracy: 0.5048\n",
      "Epoch 370/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1342 - accuracy: 0.4949 - val_loss: 1.0618 - val_accuracy: 0.5286\n",
      "Epoch 371/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1199 - accuracy: 0.4926 - val_loss: 1.0747 - val_accuracy: 0.5150\n",
      "Epoch 372/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1143 - accuracy: 0.5077 - val_loss: 1.0955 - val_accuracy: 0.4850\n",
      "Epoch 373/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1398 - accuracy: 0.4844 - val_loss: 1.1165 - val_accuracy: 0.4946\n",
      "Epoch 374/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1424 - accuracy: 0.5000 - val_loss: 1.1081 - val_accuracy: 0.4925\n",
      "Epoch 375/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1175 - accuracy: 0.4996 - val_loss: 1.0820 - val_accuracy: 0.4966\n",
      "Epoch 376/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0914 - accuracy: 0.5203 - val_loss: 1.0554 - val_accuracy: 0.5163\n",
      "Epoch 377/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1158 - accuracy: 0.4922 - val_loss: 1.0630 - val_accuracy: 0.5259\n",
      "Epoch 378/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1035 - accuracy: 0.5049 - val_loss: 1.0967 - val_accuracy: 0.4884\n",
      "Epoch 379/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1047 - accuracy: 0.5060 - val_loss: 1.0767 - val_accuracy: 0.5245\n",
      "Epoch 380/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1185 - accuracy: 0.5004 - val_loss: 1.0439 - val_accuracy: 0.5177\n",
      "Epoch 381/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1010 - accuracy: 0.5010 - val_loss: 1.0517 - val_accuracy: 0.5320\n",
      "Epoch 382/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1005 - accuracy: 0.5010 - val_loss: 1.0464 - val_accuracy: 0.5245\n",
      "Epoch 383/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1006 - accuracy: 0.4976 - val_loss: 1.0511 - val_accuracy: 0.5381\n",
      "Epoch 384/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1245 - accuracy: 0.4905 - val_loss: 1.0540 - val_accuracy: 0.5347\n",
      "Epoch 385/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0911 - accuracy: 0.4945 - val_loss: 1.0948 - val_accuracy: 0.4878\n",
      "Epoch 386/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1229 - accuracy: 0.5047 - val_loss: 1.0647 - val_accuracy: 0.5293\n",
      "Epoch 387/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1268 - accuracy: 0.4889 - val_loss: 1.0483 - val_accuracy: 0.5442\n",
      "Epoch 388/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1064 - accuracy: 0.5029 - val_loss: 1.0686 - val_accuracy: 0.5565\n",
      "Epoch 389/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1039 - accuracy: 0.4972 - val_loss: 1.0355 - val_accuracy: 0.5667\n",
      "Epoch 390/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1309 - accuracy: 0.4782 - val_loss: 1.0624 - val_accuracy: 0.5109\n",
      "Epoch 391/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1009 - accuracy: 0.5204 - val_loss: 1.0595 - val_accuracy: 0.5313\n",
      "Epoch 392/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1315 - accuracy: 0.5060 - val_loss: 1.0508 - val_accuracy: 0.5442\n",
      "Epoch 393/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0992 - accuracy: 0.5181 - val_loss: 1.0688 - val_accuracy: 0.5129\n",
      "Epoch 394/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0944 - accuracy: 0.5079 - val_loss: 1.0456 - val_accuracy: 0.5347\n",
      "Epoch 395/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1095 - accuracy: 0.5073 - val_loss: 1.0737 - val_accuracy: 0.5129\n",
      "Epoch 396/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0903 - accuracy: 0.5072 - val_loss: 1.0802 - val_accuracy: 0.5129\n",
      "Epoch 397/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1070 - accuracy: 0.5043 - val_loss: 1.0475 - val_accuracy: 0.5483\n",
      "Epoch 398/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1138 - accuracy: 0.5006 - val_loss: 1.0442 - val_accuracy: 0.5639\n",
      "Epoch 399/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1159 - accuracy: 0.4848 - val_loss: 1.0650 - val_accuracy: 0.5327\n",
      "Epoch 400/800\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 1.1131 - accuracy: 0.5033 - val_loss: 1.0601 - val_accuracy: 0.5517\n",
      "Epoch 401/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1181 - accuracy: 0.5003 - val_loss: 1.0884 - val_accuracy: 0.5095\n",
      "Epoch 402/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1167 - accuracy: 0.4962 - val_loss: 1.0716 - val_accuracy: 0.5095\n",
      "Epoch 403/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1062 - accuracy: 0.5030 - val_loss: 1.0635 - val_accuracy: 0.5313\n",
      "Epoch 404/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1023 - accuracy: 0.5046 - val_loss: 1.0505 - val_accuracy: 0.5667\n",
      "Epoch 405/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0973 - accuracy: 0.5039 - val_loss: 1.1235 - val_accuracy: 0.4639\n",
      "Epoch 406/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1177 - accuracy: 0.5088 - val_loss: 1.1076 - val_accuracy: 0.4912\n",
      "Epoch 407/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0924 - accuracy: 0.4970 - val_loss: 1.0812 - val_accuracy: 0.4932\n",
      "Epoch 408/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1128 - accuracy: 0.4986 - val_loss: 1.0902 - val_accuracy: 0.4993\n",
      "Epoch 409/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1104 - accuracy: 0.5083 - val_loss: 1.0720 - val_accuracy: 0.5327\n",
      "Epoch 410/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1007 - accuracy: 0.5204 - val_loss: 1.0410 - val_accuracy: 0.5415\n",
      "Epoch 411/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1271 - accuracy: 0.4973 - val_loss: 1.0690 - val_accuracy: 0.5245\n",
      "Epoch 412/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0822 - accuracy: 0.5114 - val_loss: 1.0699 - val_accuracy: 0.5000\n",
      "Epoch 413/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0981 - accuracy: 0.5142 - val_loss: 1.1192 - val_accuracy: 0.4605\n",
      "Epoch 414/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1077 - accuracy: 0.4843 - val_loss: 1.0481 - val_accuracy: 0.5707\n",
      "Epoch 415/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1034 - accuracy: 0.5138 - val_loss: 1.0554 - val_accuracy: 0.5435\n",
      "Epoch 416/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0927 - accuracy: 0.5128 - val_loss: 1.0512 - val_accuracy: 0.5599\n",
      "Epoch 417/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1144 - accuracy: 0.4930 - val_loss: 1.0686 - val_accuracy: 0.4980\n",
      "Epoch 418/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0941 - accuracy: 0.4971 - val_loss: 1.1186 - val_accuracy: 0.4497\n",
      "Epoch 419/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1175 - accuracy: 0.5122 - val_loss: 1.0441 - val_accuracy: 0.5347\n",
      "Epoch 420/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0951 - accuracy: 0.5036 - val_loss: 1.0765 - val_accuracy: 0.4986\n",
      "Epoch 421/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0951 - accuracy: 0.5035 - val_loss: 1.0696 - val_accuracy: 0.5156\n",
      "Epoch 422/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1007 - accuracy: 0.5119 - val_loss: 1.1198 - val_accuracy: 0.4782\n",
      "Epoch 423/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1140 - accuracy: 0.4979 - val_loss: 1.0473 - val_accuracy: 0.5224\n",
      "Epoch 424/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0984 - accuracy: 0.5005 - val_loss: 1.0738 - val_accuracy: 0.5401\n",
      "Epoch 425/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0804 - accuracy: 0.5122 - val_loss: 1.0924 - val_accuracy: 0.4891\n",
      "Epoch 426/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1100 - accuracy: 0.5059 - val_loss: 1.0994 - val_accuracy: 0.4878\n",
      "Epoch 427/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1143 - accuracy: 0.4993 - val_loss: 1.0888 - val_accuracy: 0.5048\n",
      "Epoch 428/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1376 - accuracy: 0.5037 - val_loss: 1.0573 - val_accuracy: 0.5558\n",
      "Epoch 429/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1096 - accuracy: 0.5090 - val_loss: 1.0779 - val_accuracy: 0.5102\n",
      "Epoch 430/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1020 - accuracy: 0.5062 - val_loss: 1.0921 - val_accuracy: 0.5150\n",
      "Epoch 431/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1053 - accuracy: 0.5144 - val_loss: 1.0952 - val_accuracy: 0.5129\n",
      "Epoch 432/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0983 - accuracy: 0.5098 - val_loss: 1.0675 - val_accuracy: 0.4762\n",
      "Epoch 433/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1292 - accuracy: 0.4907 - val_loss: 1.0748 - val_accuracy: 0.5224\n",
      "Epoch 434/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1093 - accuracy: 0.5027 - val_loss: 1.0415 - val_accuracy: 0.5367\n",
      "Epoch 435/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0752 - accuracy: 0.5111 - val_loss: 1.1026 - val_accuracy: 0.4776\n",
      "Epoch 436/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1182 - accuracy: 0.4993 - val_loss: 1.0495 - val_accuracy: 0.5646\n",
      "Epoch 437/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1035 - accuracy: 0.5052 - val_loss: 1.0560 - val_accuracy: 0.5231\n",
      "Epoch 438/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0978 - accuracy: 0.5030 - val_loss: 1.0870 - val_accuracy: 0.5177\n",
      "Epoch 439/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0825 - accuracy: 0.5218 - val_loss: 1.0969 - val_accuracy: 0.5503\n",
      "Epoch 440/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0904 - accuracy: 0.5144 - val_loss: 1.1119 - val_accuracy: 0.4898\n",
      "Epoch 441/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1312 - accuracy: 0.4846 - val_loss: 1.0693 - val_accuracy: 0.4952\n",
      "Epoch 442/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0815 - accuracy: 0.5082 - val_loss: 1.0552 - val_accuracy: 0.5286\n",
      "Epoch 443/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1162 - accuracy: 0.4916 - val_loss: 1.0549 - val_accuracy: 0.5313\n",
      "Epoch 444/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0927 - accuracy: 0.5254 - val_loss: 1.1086 - val_accuracy: 0.4857\n",
      "Epoch 445/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1041 - accuracy: 0.4950 - val_loss: 1.0581 - val_accuracy: 0.5272\n",
      "Epoch 446/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0825 - accuracy: 0.5049 - val_loss: 1.0537 - val_accuracy: 0.5320\n",
      "Epoch 447/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0959 - accuracy: 0.5132 - val_loss: 1.0766 - val_accuracy: 0.5197\n",
      "Epoch 448/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1028 - accuracy: 0.5075 - val_loss: 1.0880 - val_accuracy: 0.4796\n",
      "Epoch 449/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0857 - accuracy: 0.5025 - val_loss: 1.0860 - val_accuracy: 0.5469\n",
      "Epoch 450/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0974 - accuracy: 0.4938 - val_loss: 1.0887 - val_accuracy: 0.4735\n",
      "Epoch 451/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0973 - accuracy: 0.5109 - val_loss: 1.1171 - val_accuracy: 0.4871\n",
      "Epoch 452/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1099 - accuracy: 0.4898 - val_loss: 1.0631 - val_accuracy: 0.5238\n",
      "Epoch 453/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1249 - accuracy: 0.4908 - val_loss: 1.0898 - val_accuracy: 0.5109\n",
      "Epoch 454/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1128 - accuracy: 0.5103 - val_loss: 1.0610 - val_accuracy: 0.5068\n",
      "Epoch 455/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0990 - accuracy: 0.5066 - val_loss: 1.0691 - val_accuracy: 0.5150\n",
      "Epoch 456/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0911 - accuracy: 0.5139 - val_loss: 1.0784 - val_accuracy: 0.5150\n",
      "Epoch 457/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1151 - accuracy: 0.5012 - val_loss: 1.0757 - val_accuracy: 0.5313\n",
      "Epoch 458/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1144 - accuracy: 0.4853 - val_loss: 1.1015 - val_accuracy: 0.4959\n",
      "Epoch 459/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1139 - accuracy: 0.5121 - val_loss: 1.0492 - val_accuracy: 0.5299\n",
      "Epoch 460/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0889 - accuracy: 0.5174 - val_loss: 1.0736 - val_accuracy: 0.4789\n",
      "Epoch 461/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1292 - accuracy: 0.4793 - val_loss: 1.1144 - val_accuracy: 0.4871\n",
      "Epoch 462/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0927 - accuracy: 0.5003 - val_loss: 1.0991 - val_accuracy: 0.5014\n",
      "Epoch 463/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1482 - accuracy: 0.4763 - val_loss: 1.0580 - val_accuracy: 0.5279\n",
      "Epoch 464/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0957 - accuracy: 0.5064 - val_loss: 1.0889 - val_accuracy: 0.5082\n",
      "Epoch 465/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1081 - accuracy: 0.4933 - val_loss: 1.0691 - val_accuracy: 0.5238\n",
      "Epoch 466/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1134 - accuracy: 0.4777 - val_loss: 1.0516 - val_accuracy: 0.5374\n",
      "Epoch 467/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1318 - accuracy: 0.4821 - val_loss: 1.0826 - val_accuracy: 0.5299\n",
      "Epoch 468/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1189 - accuracy: 0.4969 - val_loss: 1.0706 - val_accuracy: 0.5150\n",
      "Epoch 469/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1168 - accuracy: 0.4886 - val_loss: 1.0510 - val_accuracy: 0.5293\n",
      "Epoch 470/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0893 - accuracy: 0.5280 - val_loss: 1.0620 - val_accuracy: 0.5211\n",
      "Epoch 471/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1014 - accuracy: 0.4971 - val_loss: 1.0842 - val_accuracy: 0.5143\n",
      "Epoch 472/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1066 - accuracy: 0.5064 - val_loss: 1.0670 - val_accuracy: 0.5517\n",
      "Epoch 473/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1040 - accuracy: 0.5046 - val_loss: 1.0578 - val_accuracy: 0.5204\n",
      "Epoch 474/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0867 - accuracy: 0.5007 - val_loss: 1.0975 - val_accuracy: 0.5088\n",
      "Epoch 475/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1121 - accuracy: 0.4848 - val_loss: 1.0598 - val_accuracy: 0.5075\n",
      "Epoch 476/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0940 - accuracy: 0.5043 - val_loss: 1.0820 - val_accuracy: 0.4844\n",
      "Epoch 477/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1122 - accuracy: 0.4896 - val_loss: 1.1039 - val_accuracy: 0.4714\n",
      "Epoch 478/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1199 - accuracy: 0.4988 - val_loss: 1.0632 - val_accuracy: 0.5279\n",
      "Epoch 479/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0881 - accuracy: 0.5197 - val_loss: 1.0449 - val_accuracy: 0.5401\n",
      "Epoch 480/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0760 - accuracy: 0.5184 - val_loss: 1.1059 - val_accuracy: 0.5020\n",
      "Epoch 481/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1386 - accuracy: 0.4865 - val_loss: 1.0475 - val_accuracy: 0.5490\n",
      "Epoch 482/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1180 - accuracy: 0.4980 - val_loss: 1.0480 - val_accuracy: 0.5252\n",
      "Epoch 483/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0875 - accuracy: 0.5041 - val_loss: 1.0697 - val_accuracy: 0.5224\n",
      "Epoch 484/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1002 - accuracy: 0.5018 - val_loss: 1.0631 - val_accuracy: 0.5395\n",
      "Epoch 485/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1205 - accuracy: 0.5122 - val_loss: 1.0816 - val_accuracy: 0.5136\n",
      "Epoch 486/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1191 - accuracy: 0.5040 - val_loss: 1.0507 - val_accuracy: 0.5490\n",
      "Epoch 487/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1006 - accuracy: 0.5052 - val_loss: 1.0854 - val_accuracy: 0.5272\n",
      "Epoch 488/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1071 - accuracy: 0.5090 - val_loss: 1.0413 - val_accuracy: 0.5286\n",
      "Epoch 489/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1045 - accuracy: 0.5137 - val_loss: 1.0866 - val_accuracy: 0.4993\n",
      "Epoch 490/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0976 - accuracy: 0.5282 - val_loss: 1.0695 - val_accuracy: 0.5388\n",
      "Epoch 491/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1226 - accuracy: 0.5001 - val_loss: 1.0801 - val_accuracy: 0.4918\n",
      "Epoch 492/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0944 - accuracy: 0.5123 - val_loss: 1.0549 - val_accuracy: 0.5252\n",
      "Epoch 493/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1152 - accuracy: 0.5027 - val_loss: 1.0644 - val_accuracy: 0.5252\n",
      "Epoch 494/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0843 - accuracy: 0.5234 - val_loss: 1.0577 - val_accuracy: 0.5204\n",
      "Epoch 495/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0964 - accuracy: 0.5134 - val_loss: 1.0437 - val_accuracy: 0.5293\n",
      "Epoch 496/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0883 - accuracy: 0.5146 - val_loss: 1.0618 - val_accuracy: 0.4810\n",
      "Epoch 497/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1326 - accuracy: 0.4821 - val_loss: 1.0571 - val_accuracy: 0.5265\n",
      "Epoch 498/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1208 - accuracy: 0.5034 - val_loss: 1.0974 - val_accuracy: 0.5252\n",
      "Epoch 499/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1172 - accuracy: 0.4884 - val_loss: 1.0761 - val_accuracy: 0.5143\n",
      "Epoch 500/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0842 - accuracy: 0.5132 - val_loss: 1.0683 - val_accuracy: 0.5170\n",
      "Epoch 501/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0803 - accuracy: 0.5032 - val_loss: 1.0648 - val_accuracy: 0.5272\n",
      "Epoch 502/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0705 - accuracy: 0.5111 - val_loss: 1.0645 - val_accuracy: 0.5231\n",
      "Epoch 503/800\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 1.1155 - accuracy: 0.5167 - val_loss: 1.0607 - val_accuracy: 0.5293\n",
      "Epoch 504/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1066 - accuracy: 0.4995 - val_loss: 1.0727 - val_accuracy: 0.5361\n",
      "Epoch 505/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1025 - accuracy: 0.5054 - val_loss: 1.0770 - val_accuracy: 0.5007\n",
      "Epoch 506/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0920 - accuracy: 0.5098 - val_loss: 1.0391 - val_accuracy: 0.5449\n",
      "Epoch 507/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1038 - accuracy: 0.4960 - val_loss: 1.0531 - val_accuracy: 0.5429\n",
      "Epoch 508/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0852 - accuracy: 0.5242 - val_loss: 1.0850 - val_accuracy: 0.5354\n",
      "Epoch 509/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0889 - accuracy: 0.5197 - val_loss: 1.0798 - val_accuracy: 0.5435\n",
      "Epoch 510/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1187 - accuracy: 0.5061 - val_loss: 1.0729 - val_accuracy: 0.5116\n",
      "Epoch 511/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1092 - accuracy: 0.5004 - val_loss: 1.0759 - val_accuracy: 0.5150\n",
      "Epoch 512/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0994 - accuracy: 0.4988 - val_loss: 1.0635 - val_accuracy: 0.5238\n",
      "Epoch 513/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0886 - accuracy: 0.5280 - val_loss: 1.0979 - val_accuracy: 0.4986\n",
      "Epoch 514/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0921 - accuracy: 0.5054 - val_loss: 1.0621 - val_accuracy: 0.5177\n",
      "Epoch 515/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0985 - accuracy: 0.5083 - val_loss: 1.0408 - val_accuracy: 0.5578\n",
      "Epoch 516/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0862 - accuracy: 0.5101 - val_loss: 1.1033 - val_accuracy: 0.4912\n",
      "Epoch 517/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1082 - accuracy: 0.5069 - val_loss: 1.1117 - val_accuracy: 0.5374\n",
      "Epoch 518/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0819 - accuracy: 0.5218 - val_loss: 1.0941 - val_accuracy: 0.4769\n",
      "Epoch 519/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1159 - accuracy: 0.4892 - val_loss: 1.0730 - val_accuracy: 0.5143\n",
      "Epoch 520/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0966 - accuracy: 0.4996 - val_loss: 1.0890 - val_accuracy: 0.5517\n",
      "Epoch 521/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1191 - accuracy: 0.5036 - val_loss: 1.0470 - val_accuracy: 0.5524\n",
      "Epoch 522/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0957 - accuracy: 0.5074 - val_loss: 1.0991 - val_accuracy: 0.4721\n",
      "Epoch 523/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1031 - accuracy: 0.4990 - val_loss: 1.0380 - val_accuracy: 0.5558\n",
      "Epoch 524/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0931 - accuracy: 0.5247 - val_loss: 1.0535 - val_accuracy: 0.5231\n",
      "Epoch 525/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0828 - accuracy: 0.5144 - val_loss: 1.0661 - val_accuracy: 0.5272\n",
      "Epoch 526/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0912 - accuracy: 0.5121 - val_loss: 1.0353 - val_accuracy: 0.5463\n",
      "Epoch 527/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0819 - accuracy: 0.5180 - val_loss: 1.0711 - val_accuracy: 0.5503\n",
      "Epoch 528/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0806 - accuracy: 0.5078 - val_loss: 1.0804 - val_accuracy: 0.5374\n",
      "Epoch 529/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1085 - accuracy: 0.4908 - val_loss: 1.0898 - val_accuracy: 0.5163\n",
      "Epoch 530/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0873 - accuracy: 0.5060 - val_loss: 1.0693 - val_accuracy: 0.5286\n",
      "Epoch 531/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1077 - accuracy: 0.4940 - val_loss: 1.0629 - val_accuracy: 0.5068\n",
      "Epoch 532/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0831 - accuracy: 0.5126 - val_loss: 1.0664 - val_accuracy: 0.5218\n",
      "Epoch 533/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0843 - accuracy: 0.5102 - val_loss: 1.1058 - val_accuracy: 0.5231\n",
      "Epoch 534/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0954 - accuracy: 0.5257 - val_loss: 1.0581 - val_accuracy: 0.5544\n",
      "Epoch 535/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0776 - accuracy: 0.5127 - val_loss: 1.0466 - val_accuracy: 0.5354\n",
      "Epoch 536/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0842 - accuracy: 0.5034 - val_loss: 1.0613 - val_accuracy: 0.5041\n",
      "Epoch 537/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1198 - accuracy: 0.4958 - val_loss: 1.0534 - val_accuracy: 0.5102\n",
      "Epoch 538/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1126 - accuracy: 0.4925 - val_loss: 1.0690 - val_accuracy: 0.5551\n",
      "Epoch 539/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1019 - accuracy: 0.4936 - val_loss: 1.0776 - val_accuracy: 0.5068\n",
      "Epoch 540/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0768 - accuracy: 0.4980 - val_loss: 1.0579 - val_accuracy: 0.5463\n",
      "Epoch 541/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0764 - accuracy: 0.5321 - val_loss: 1.0556 - val_accuracy: 0.5395\n",
      "Epoch 542/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1184 - accuracy: 0.4912 - val_loss: 1.0788 - val_accuracy: 0.5143\n",
      "Epoch 543/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0892 - accuracy: 0.5077 - val_loss: 1.0736 - val_accuracy: 0.5020\n",
      "Epoch 544/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0823 - accuracy: 0.5120 - val_loss: 1.0818 - val_accuracy: 0.4939\n",
      "Epoch 545/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0753 - accuracy: 0.5216 - val_loss: 1.0460 - val_accuracy: 0.5605\n",
      "Epoch 546/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0819 - accuracy: 0.5152 - val_loss: 1.0592 - val_accuracy: 0.5252\n",
      "Epoch 547/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0890 - accuracy: 0.5066 - val_loss: 1.0743 - val_accuracy: 0.4864\n",
      "Epoch 548/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0971 - accuracy: 0.5048 - val_loss: 1.0542 - val_accuracy: 0.5327\n",
      "Epoch 549/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0855 - accuracy: 0.5158 - val_loss: 1.0416 - val_accuracy: 0.5245\n",
      "Epoch 550/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1039 - accuracy: 0.5023 - val_loss: 1.0595 - val_accuracy: 0.5327\n",
      "Epoch 551/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1128 - accuracy: 0.5071 - val_loss: 1.0367 - val_accuracy: 0.5619\n",
      "Epoch 552/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0697 - accuracy: 0.5416 - val_loss: 1.0647 - val_accuracy: 0.5184\n",
      "Epoch 553/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1251 - accuracy: 0.4970 - val_loss: 1.0675 - val_accuracy: 0.5218\n",
      "Epoch 554/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0850 - accuracy: 0.5195 - val_loss: 1.0433 - val_accuracy: 0.5558\n",
      "Epoch 555/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1030 - accuracy: 0.4968 - val_loss: 1.0745 - val_accuracy: 0.5306\n",
      "Epoch 556/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0947 - accuracy: 0.5270 - val_loss: 1.0526 - val_accuracy: 0.5327\n",
      "Epoch 557/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1215 - accuracy: 0.4896 - val_loss: 1.0832 - val_accuracy: 0.5184\n",
      "Epoch 558/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0767 - accuracy: 0.5124 - val_loss: 1.0542 - val_accuracy: 0.5136\n",
      "Epoch 559/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1016 - accuracy: 0.5057 - val_loss: 1.0910 - val_accuracy: 0.5585\n",
      "Epoch 560/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0925 - accuracy: 0.5146 - val_loss: 1.0751 - val_accuracy: 0.5463\n",
      "Epoch 561/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0890 - accuracy: 0.5115 - val_loss: 1.0663 - val_accuracy: 0.5252\n",
      "Epoch 562/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1043 - accuracy: 0.4999 - val_loss: 1.0424 - val_accuracy: 0.5510\n",
      "Epoch 563/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1079 - accuracy: 0.4878 - val_loss: 1.0559 - val_accuracy: 0.5204\n",
      "Epoch 564/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1018 - accuracy: 0.5043 - val_loss: 1.0574 - val_accuracy: 0.5333\n",
      "Epoch 565/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0949 - accuracy: 0.5021 - val_loss: 1.0586 - val_accuracy: 0.5619\n",
      "Epoch 566/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1151 - accuracy: 0.4974 - val_loss: 1.0757 - val_accuracy: 0.5442\n",
      "Epoch 567/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1036 - accuracy: 0.4978 - val_loss: 1.0815 - val_accuracy: 0.5265\n",
      "Epoch 568/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0877 - accuracy: 0.5168 - val_loss: 1.0726 - val_accuracy: 0.5218\n",
      "Epoch 569/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0966 - accuracy: 0.4918 - val_loss: 1.0525 - val_accuracy: 0.5646\n",
      "Epoch 570/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1000 - accuracy: 0.5106 - val_loss: 1.0865 - val_accuracy: 0.5429\n",
      "Epoch 571/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1145 - accuracy: 0.5110 - val_loss: 1.0875 - val_accuracy: 0.5340\n",
      "Epoch 572/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0703 - accuracy: 0.5244 - val_loss: 1.0601 - val_accuracy: 0.5374\n",
      "Epoch 573/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0908 - accuracy: 0.5041 - val_loss: 1.0810 - val_accuracy: 0.4993\n",
      "Epoch 574/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0906 - accuracy: 0.5171 - val_loss: 1.0327 - val_accuracy: 0.5578\n",
      "Epoch 575/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1007 - accuracy: 0.4990 - val_loss: 1.0409 - val_accuracy: 0.5415\n",
      "Epoch 576/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1065 - accuracy: 0.5124 - val_loss: 1.1129 - val_accuracy: 0.4796\n",
      "Epoch 577/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1149 - accuracy: 0.4994 - val_loss: 1.0923 - val_accuracy: 0.5136\n",
      "Epoch 578/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1167 - accuracy: 0.5054 - val_loss: 1.0446 - val_accuracy: 0.5782\n",
      "Epoch 579/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0990 - accuracy: 0.5090 - val_loss: 1.0570 - val_accuracy: 0.5095\n",
      "Epoch 580/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0972 - accuracy: 0.5109 - val_loss: 1.0674 - val_accuracy: 0.4959\n",
      "Epoch 581/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1003 - accuracy: 0.5189 - val_loss: 1.1091 - val_accuracy: 0.4782\n",
      "Epoch 582/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0970 - accuracy: 0.5060 - val_loss: 1.0812 - val_accuracy: 0.4905\n",
      "Epoch 583/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0850 - accuracy: 0.5058 - val_loss: 1.0813 - val_accuracy: 0.4966\n",
      "Epoch 584/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0890 - accuracy: 0.5181 - val_loss: 1.0520 - val_accuracy: 0.5395\n",
      "Epoch 585/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0667 - accuracy: 0.5208 - val_loss: 1.0746 - val_accuracy: 0.5116\n",
      "Epoch 586/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.5082 - val_loss: 1.0431 - val_accuracy: 0.5367\n",
      "Epoch 587/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0863 - accuracy: 0.5212 - val_loss: 1.0470 - val_accuracy: 0.5252\n",
      "Epoch 588/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0611 - accuracy: 0.5207 - val_loss: 1.0556 - val_accuracy: 0.5442\n",
      "Epoch 589/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0887 - accuracy: 0.5013 - val_loss: 1.0893 - val_accuracy: 0.4980\n",
      "Epoch 590/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1078 - accuracy: 0.4901 - val_loss: 1.0605 - val_accuracy: 0.5204\n",
      "Epoch 591/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0946 - accuracy: 0.5057 - val_loss: 1.0458 - val_accuracy: 0.5435\n",
      "Epoch 592/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0736 - accuracy: 0.5069 - val_loss: 1.0543 - val_accuracy: 0.5510\n",
      "Epoch 593/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1063 - accuracy: 0.5093 - val_loss: 1.0704 - val_accuracy: 0.5252\n",
      "Epoch 594/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0930 - accuracy: 0.5153 - val_loss: 1.0448 - val_accuracy: 0.5558\n",
      "Epoch 595/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0952 - accuracy: 0.5063 - val_loss: 1.0527 - val_accuracy: 0.5204\n",
      "Epoch 596/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0842 - accuracy: 0.5276 - val_loss: 1.0811 - val_accuracy: 0.4939\n",
      "Epoch 597/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1267 - accuracy: 0.4935 - val_loss: 1.0619 - val_accuracy: 0.5340\n",
      "Epoch 598/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0904 - accuracy: 0.5229 - val_loss: 1.0924 - val_accuracy: 0.4857\n",
      "Epoch 599/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1124 - accuracy: 0.4992 - val_loss: 1.0878 - val_accuracy: 0.4966\n",
      "Epoch 600/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0650 - accuracy: 0.5202 - val_loss: 1.0498 - val_accuracy: 0.5238\n",
      "Epoch 601/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1170 - accuracy: 0.4997 - val_loss: 1.0614 - val_accuracy: 0.5272\n",
      "Epoch 602/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1120 - accuracy: 0.5050 - val_loss: 1.0418 - val_accuracy: 0.5565\n",
      "Epoch 603/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0823 - accuracy: 0.5271 - val_loss: 1.0572 - val_accuracy: 0.4966\n",
      "Epoch 604/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1103 - accuracy: 0.4992 - val_loss: 1.0524 - val_accuracy: 0.5129\n",
      "Epoch 605/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0810 - accuracy: 0.4980 - val_loss: 1.0481 - val_accuracy: 0.5231\n",
      "Epoch 606/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0876 - accuracy: 0.5187 - val_loss: 1.0602 - val_accuracy: 0.5095\n",
      "Epoch 607/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0952 - accuracy: 0.5185 - val_loss: 1.0403 - val_accuracy: 0.5395\n",
      "Epoch 608/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0873 - accuracy: 0.5094 - val_loss: 1.0387 - val_accuracy: 0.5653\n",
      "Epoch 609/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1056 - accuracy: 0.5134 - val_loss: 1.0813 - val_accuracy: 0.4980\n",
      "Epoch 610/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1149 - accuracy: 0.5047 - val_loss: 1.0807 - val_accuracy: 0.5190\n",
      "Epoch 611/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0977 - accuracy: 0.5106 - val_loss: 1.0486 - val_accuracy: 0.5340\n",
      "Epoch 612/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0910 - accuracy: 0.5185 - val_loss: 1.0687 - val_accuracy: 0.5156\n",
      "Epoch 613/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1006 - accuracy: 0.5013 - val_loss: 1.0564 - val_accuracy: 0.5537\n",
      "Epoch 614/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0801 - accuracy: 0.5290 - val_loss: 1.0418 - val_accuracy: 0.5408\n",
      "Epoch 615/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0808 - accuracy: 0.5137 - val_loss: 1.0661 - val_accuracy: 0.5109\n",
      "Epoch 616/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0703 - accuracy: 0.5245 - val_loss: 1.0569 - val_accuracy: 0.5408\n",
      "Epoch 617/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0755 - accuracy: 0.5069 - val_loss: 1.0311 - val_accuracy: 0.5537\n",
      "Epoch 618/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0838 - accuracy: 0.5157 - val_loss: 1.0716 - val_accuracy: 0.5333\n",
      "Epoch 619/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0985 - accuracy: 0.5088 - val_loss: 1.0493 - val_accuracy: 0.5667\n",
      "Epoch 620/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0957 - accuracy: 0.5182 - val_loss: 1.0535 - val_accuracy: 0.5735\n",
      "Epoch 621/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1068 - accuracy: 0.5201 - val_loss: 1.0673 - val_accuracy: 0.5143\n",
      "Epoch 622/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0894 - accuracy: 0.5182 - val_loss: 1.0591 - val_accuracy: 0.5299\n",
      "Epoch 623/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0956 - accuracy: 0.5134 - val_loss: 1.0656 - val_accuracy: 0.5224\n",
      "Epoch 624/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0734 - accuracy: 0.5159 - val_loss: 1.0742 - val_accuracy: 0.5374\n",
      "Epoch 625/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0736 - accuracy: 0.5023 - val_loss: 1.0828 - val_accuracy: 0.5184\n",
      "Epoch 626/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0962 - accuracy: 0.5104 - val_loss: 1.0892 - val_accuracy: 0.4973\n",
      "Epoch 627/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0853 - accuracy: 0.5151 - val_loss: 1.0817 - val_accuracy: 0.4966\n",
      "Epoch 628/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0942 - accuracy: 0.5180 - val_loss: 1.0576 - val_accuracy: 0.5361\n",
      "Epoch 629/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0826 - accuracy: 0.5198 - val_loss: 1.0525 - val_accuracy: 0.5653\n",
      "Epoch 630/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0689 - accuracy: 0.5141 - val_loss: 1.0575 - val_accuracy: 0.5170\n",
      "Epoch 631/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1018 - accuracy: 0.5122 - val_loss: 1.0839 - val_accuracy: 0.4946\n",
      "Epoch 632/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1056 - accuracy: 0.5011 - val_loss: 1.0463 - val_accuracy: 0.5320\n",
      "Epoch 633/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0964 - accuracy: 0.5049 - val_loss: 1.0571 - val_accuracy: 0.5313\n",
      "Epoch 634/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0805 - accuracy: 0.5133 - val_loss: 1.0500 - val_accuracy: 0.5313\n",
      "Epoch 635/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0633 - accuracy: 0.5157 - val_loss: 1.0255 - val_accuracy: 0.5741\n",
      "Epoch 636/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0729 - accuracy: 0.5282 - val_loss: 1.0377 - val_accuracy: 0.5612\n",
      "Epoch 637/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0904 - accuracy: 0.5120 - val_loss: 1.0605 - val_accuracy: 0.5204\n",
      "Epoch 638/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0867 - accuracy: 0.5215 - val_loss: 1.0382 - val_accuracy: 0.5592\n",
      "Epoch 639/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1140 - accuracy: 0.5053 - val_loss: 1.0769 - val_accuracy: 0.5259\n",
      "Epoch 640/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1107 - accuracy: 0.4940 - val_loss: 1.0669 - val_accuracy: 0.5150\n",
      "Epoch 641/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1078 - accuracy: 0.5142 - val_loss: 1.0711 - val_accuracy: 0.5170\n",
      "Epoch 642/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0770 - accuracy: 0.5145 - val_loss: 1.0612 - val_accuracy: 0.5299\n",
      "Epoch 643/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0916 - accuracy: 0.5041 - val_loss: 1.0608 - val_accuracy: 0.5109\n",
      "Epoch 644/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0957 - accuracy: 0.5007 - val_loss: 1.0276 - val_accuracy: 0.5748\n",
      "Epoch 645/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1099 - accuracy: 0.5095 - val_loss: 1.0684 - val_accuracy: 0.5143\n",
      "Epoch 646/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0985 - accuracy: 0.5051 - val_loss: 1.0535 - val_accuracy: 0.5293\n",
      "Epoch 647/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0827 - accuracy: 0.5252 - val_loss: 1.0767 - val_accuracy: 0.5245\n",
      "Epoch 648/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0983 - accuracy: 0.5045 - val_loss: 1.0767 - val_accuracy: 0.4993\n",
      "Epoch 649/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0897 - accuracy: 0.5186 - val_loss: 1.0333 - val_accuracy: 0.5707\n",
      "Epoch 650/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0875 - accuracy: 0.5144 - val_loss: 1.0495 - val_accuracy: 0.5565\n",
      "Epoch 651/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0895 - accuracy: 0.5035 - val_loss: 1.0557 - val_accuracy: 0.5449\n",
      "Epoch 652/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1156 - accuracy: 0.4971 - val_loss: 1.0442 - val_accuracy: 0.5327\n",
      "Epoch 653/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1049 - accuracy: 0.5009 - val_loss: 1.0917 - val_accuracy: 0.4905\n",
      "Epoch 654/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0938 - accuracy: 0.5141 - val_loss: 1.0847 - val_accuracy: 0.4939\n",
      "Epoch 655/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0786 - accuracy: 0.5185 - val_loss: 1.0469 - val_accuracy: 0.5476\n",
      "Epoch 656/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0813 - accuracy: 0.5225 - val_loss: 1.0419 - val_accuracy: 0.5361\n",
      "Epoch 657/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0976 - accuracy: 0.5173 - val_loss: 1.0590 - val_accuracy: 0.5313\n",
      "Epoch 658/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0763 - accuracy: 0.5149 - val_loss: 1.0579 - val_accuracy: 0.5197\n",
      "Epoch 659/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0804 - accuracy: 0.5298 - val_loss: 1.0477 - val_accuracy: 0.5279\n",
      "Epoch 660/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0971 - accuracy: 0.5084 - val_loss: 1.0723 - val_accuracy: 0.5109\n",
      "Epoch 661/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0920 - accuracy: 0.5027 - val_loss: 1.0693 - val_accuracy: 0.5469\n",
      "Epoch 662/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1109 - accuracy: 0.4959 - val_loss: 1.1016 - val_accuracy: 0.4673\n",
      "Epoch 663/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1064 - accuracy: 0.5022 - val_loss: 1.0468 - val_accuracy: 0.5347\n",
      "Epoch 664/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0844 - accuracy: 0.5128 - val_loss: 1.0896 - val_accuracy: 0.4857\n",
      "Epoch 665/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1117 - accuracy: 0.5126 - val_loss: 1.0565 - val_accuracy: 0.5381\n",
      "Epoch 666/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0994 - accuracy: 0.4999 - val_loss: 1.1022 - val_accuracy: 0.4748\n",
      "Epoch 667/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1125 - accuracy: 0.5086 - val_loss: 1.0365 - val_accuracy: 0.5565\n",
      "Epoch 668/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0802 - accuracy: 0.5237 - val_loss: 1.0646 - val_accuracy: 0.5354\n",
      "Epoch 669/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0672 - accuracy: 0.5041 - val_loss: 1.0645 - val_accuracy: 0.5367\n",
      "Epoch 670/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0983 - accuracy: 0.4997 - val_loss: 1.1130 - val_accuracy: 0.4830\n",
      "Epoch 671/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0953 - accuracy: 0.5075 - val_loss: 1.0374 - val_accuracy: 0.5565\n",
      "Epoch 672/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0817 - accuracy: 0.5152 - val_loss: 1.0572 - val_accuracy: 0.5259\n",
      "Epoch 673/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0638 - accuracy: 0.5248 - val_loss: 1.0827 - val_accuracy: 0.5150\n",
      "Epoch 674/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0840 - accuracy: 0.5188 - val_loss: 1.0577 - val_accuracy: 0.5401\n",
      "Epoch 675/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0877 - accuracy: 0.5157 - val_loss: 1.0805 - val_accuracy: 0.4850\n",
      "Epoch 676/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1000 - accuracy: 0.4941 - val_loss: 1.0449 - val_accuracy: 0.5347\n",
      "Epoch 677/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0721 - accuracy: 0.5222 - val_loss: 1.0881 - val_accuracy: 0.5238\n",
      "Epoch 678/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0856 - accuracy: 0.5088 - val_loss: 1.1010 - val_accuracy: 0.4932\n",
      "Epoch 679/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0808 - accuracy: 0.5227 - val_loss: 1.0400 - val_accuracy: 0.5374\n",
      "Epoch 680/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0816 - accuracy: 0.5160 - val_loss: 1.0400 - val_accuracy: 0.5680\n",
      "Epoch 681/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0790 - accuracy: 0.5314 - val_loss: 1.0801 - val_accuracy: 0.5082\n",
      "Epoch 682/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0764 - accuracy: 0.5292 - val_loss: 1.0551 - val_accuracy: 0.5633\n",
      "Epoch 683/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0886 - accuracy: 0.5022 - val_loss: 1.0790 - val_accuracy: 0.5245\n",
      "Epoch 684/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0926 - accuracy: 0.5078 - val_loss: 1.0419 - val_accuracy: 0.5388\n",
      "Epoch 685/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0981 - accuracy: 0.5124 - val_loss: 1.0434 - val_accuracy: 0.5333\n",
      "Epoch 686/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0749 - accuracy: 0.5202 - val_loss: 1.0756 - val_accuracy: 0.5177\n",
      "Epoch 687/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0779 - accuracy: 0.5150 - val_loss: 1.0527 - val_accuracy: 0.5293\n",
      "Epoch 688/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0756 - accuracy: 0.5224 - val_loss: 1.0567 - val_accuracy: 0.5442\n",
      "Epoch 689/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0924 - accuracy: 0.5121 - val_loss: 1.0631 - val_accuracy: 0.5143\n",
      "Epoch 690/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1039 - accuracy: 0.5107 - val_loss: 1.0403 - val_accuracy: 0.5510\n",
      "Epoch 691/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0852 - accuracy: 0.5229 - val_loss: 1.0530 - val_accuracy: 0.5415\n",
      "Epoch 692/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0923 - accuracy: 0.5159 - val_loss: 1.0843 - val_accuracy: 0.5007\n",
      "Epoch 693/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1290 - accuracy: 0.4882 - val_loss: 1.0670 - val_accuracy: 0.5116\n",
      "Epoch 694/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0875 - accuracy: 0.5228 - val_loss: 1.0607 - val_accuracy: 0.5272\n",
      "Epoch 695/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0716 - accuracy: 0.5303 - val_loss: 1.0673 - val_accuracy: 0.5163\n",
      "Epoch 696/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1107 - accuracy: 0.5027 - val_loss: 1.0638 - val_accuracy: 0.5721\n",
      "Epoch 697/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1085 - accuracy: 0.5213 - val_loss: 1.0565 - val_accuracy: 0.5197\n",
      "Epoch 698/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0846 - accuracy: 0.5095 - val_loss: 1.0968 - val_accuracy: 0.5000\n",
      "Epoch 699/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1200 - accuracy: 0.4860 - val_loss: 1.0382 - val_accuracy: 0.5469\n",
      "Epoch 700/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1026 - accuracy: 0.5174 - val_loss: 1.0474 - val_accuracy: 0.5299\n",
      "Epoch 701/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0883 - accuracy: 0.5152 - val_loss: 1.0966 - val_accuracy: 0.4966\n",
      "Epoch 702/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1009 - accuracy: 0.5210 - val_loss: 1.0660 - val_accuracy: 0.5354\n",
      "Epoch 703/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0722 - accuracy: 0.5252 - val_loss: 1.0422 - val_accuracy: 0.5476\n",
      "Epoch 704/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0789 - accuracy: 0.5106 - val_loss: 1.0578 - val_accuracy: 0.5306\n",
      "Epoch 705/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0826 - accuracy: 0.5117 - val_loss: 1.0380 - val_accuracy: 0.5551\n",
      "Epoch 706/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0664 - accuracy: 0.5247 - val_loss: 1.0676 - val_accuracy: 0.5054\n",
      "Epoch 707/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0718 - accuracy: 0.5170 - val_loss: 1.0508 - val_accuracy: 0.5231\n",
      "Epoch 708/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0846 - accuracy: 0.5212 - val_loss: 1.0751 - val_accuracy: 0.5204\n",
      "Epoch 709/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0960 - accuracy: 0.5196 - val_loss: 1.0638 - val_accuracy: 0.5449\n",
      "Epoch 710/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0867 - accuracy: 0.5181 - val_loss: 1.0568 - val_accuracy: 0.5231\n",
      "Epoch 711/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0870 - accuracy: 0.5122 - val_loss: 1.1416 - val_accuracy: 0.4333\n",
      "Epoch 712/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0876 - accuracy: 0.5045 - val_loss: 1.0452 - val_accuracy: 0.5626\n",
      "Epoch 713/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0905 - accuracy: 0.4938 - val_loss: 1.0587 - val_accuracy: 0.5327\n",
      "Epoch 714/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0780 - accuracy: 0.5153 - val_loss: 1.0670 - val_accuracy: 0.5333\n",
      "Epoch 715/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0680 - accuracy: 0.5049 - val_loss: 1.0571 - val_accuracy: 0.5048\n",
      "Epoch 716/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0706 - accuracy: 0.5187 - val_loss: 1.0571 - val_accuracy: 0.5395\n",
      "Epoch 717/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0806 - accuracy: 0.5124 - val_loss: 1.0615 - val_accuracy: 0.5306\n",
      "Epoch 718/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0860 - accuracy: 0.5217 - val_loss: 1.0468 - val_accuracy: 0.5422\n",
      "Epoch 719/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0994 - accuracy: 0.5251 - val_loss: 1.0362 - val_accuracy: 0.5435\n",
      "Epoch 720/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0917 - accuracy: 0.5223 - val_loss: 1.0542 - val_accuracy: 0.5503\n",
      "Epoch 721/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0849 - accuracy: 0.5173 - val_loss: 1.0829 - val_accuracy: 0.5170\n",
      "Epoch 722/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0831 - accuracy: 0.5079 - val_loss: 1.0573 - val_accuracy: 0.5551\n",
      "Epoch 723/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1157 - accuracy: 0.5057 - val_loss: 1.0620 - val_accuracy: 0.5224\n",
      "Epoch 724/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0649 - accuracy: 0.5330 - val_loss: 1.0377 - val_accuracy: 0.5408\n",
      "Epoch 725/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0767 - accuracy: 0.5260 - val_loss: 1.0344 - val_accuracy: 0.5660\n",
      "Epoch 726/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1007 - accuracy: 0.5086 - val_loss: 1.0562 - val_accuracy: 0.5490\n",
      "Epoch 727/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0890 - accuracy: 0.5187 - val_loss: 1.0577 - val_accuracy: 0.5388\n",
      "Epoch 728/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0718 - accuracy: 0.5129 - val_loss: 1.0695 - val_accuracy: 0.5286\n",
      "Epoch 729/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0558 - accuracy: 0.5161 - val_loss: 1.0737 - val_accuracy: 0.5204\n",
      "Epoch 730/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0978 - accuracy: 0.5171 - val_loss: 1.0533 - val_accuracy: 0.5429\n",
      "Epoch 731/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0823 - accuracy: 0.5197 - val_loss: 1.0993 - val_accuracy: 0.5204\n",
      "Epoch 732/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1011 - accuracy: 0.5117 - val_loss: 1.0564 - val_accuracy: 0.5517\n",
      "Epoch 733/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1010 - accuracy: 0.5207 - val_loss: 1.1072 - val_accuracy: 0.4857\n",
      "Epoch 734/800\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 1.0736 - accuracy: 0.5261 - val_loss: 1.0872 - val_accuracy: 0.5075\n",
      "Epoch 735/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0897 - accuracy: 0.5211 - val_loss: 1.0561 - val_accuracy: 0.5184\n",
      "Epoch 736/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0596 - accuracy: 0.5289 - val_loss: 1.0657 - val_accuracy: 0.5061\n",
      "Epoch 737/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0749 - accuracy: 0.5089 - val_loss: 1.0538 - val_accuracy: 0.5429\n",
      "Epoch 738/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0873 - accuracy: 0.5129 - val_loss: 1.0677 - val_accuracy: 0.5415\n",
      "Epoch 739/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0838 - accuracy: 0.5148 - val_loss: 1.0583 - val_accuracy: 0.5429\n",
      "Epoch 740/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0718 - accuracy: 0.5254 - val_loss: 1.0378 - val_accuracy: 0.5497\n",
      "Epoch 741/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0673 - accuracy: 0.5225 - val_loss: 1.0695 - val_accuracy: 0.5143\n",
      "Epoch 742/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1261 - accuracy: 0.4964 - val_loss: 1.0403 - val_accuracy: 0.5544\n",
      "Epoch 743/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0776 - accuracy: 0.5154 - val_loss: 1.0886 - val_accuracy: 0.5068\n",
      "Epoch 744/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0761 - accuracy: 0.5345 - val_loss: 1.0710 - val_accuracy: 0.5041\n",
      "Epoch 745/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0712 - accuracy: 0.5211 - val_loss: 1.0615 - val_accuracy: 0.5265\n",
      "Epoch 746/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0969 - accuracy: 0.5028 - val_loss: 1.0854 - val_accuracy: 0.5163\n",
      "Epoch 747/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0953 - accuracy: 0.5062 - val_loss: 1.0542 - val_accuracy: 0.5605\n",
      "Epoch 748/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.0735 - accuracy: 0.5255 - val_loss: 1.0774 - val_accuracy: 0.5320\n",
      "Epoch 749/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0903 - accuracy: 0.5082 - val_loss: 1.0570 - val_accuracy: 0.5578\n",
      "Epoch 750/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0682 - accuracy: 0.5135 - val_loss: 1.0428 - val_accuracy: 0.5599\n",
      "Epoch 751/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0583 - accuracy: 0.5229 - val_loss: 1.0368 - val_accuracy: 0.5490\n",
      "Epoch 752/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0768 - accuracy: 0.5031 - val_loss: 1.0638 - val_accuracy: 0.5265\n",
      "Epoch 753/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0973 - accuracy: 0.5208 - val_loss: 1.0326 - val_accuracy: 0.5442\n",
      "Epoch 754/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0773 - accuracy: 0.5057 - val_loss: 1.0428 - val_accuracy: 0.5524\n",
      "Epoch 755/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0939 - accuracy: 0.5147 - val_loss: 1.0645 - val_accuracy: 0.5299\n",
      "Epoch 756/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0998 - accuracy: 0.5016 - val_loss: 1.0586 - val_accuracy: 0.5707\n",
      "Epoch 757/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0963 - accuracy: 0.4871 - val_loss: 1.0574 - val_accuracy: 0.5612\n",
      "Epoch 758/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0687 - accuracy: 0.5192 - val_loss: 1.0501 - val_accuracy: 0.5408\n",
      "Epoch 759/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0537 - accuracy: 0.5418 - val_loss: 1.0350 - val_accuracy: 0.5769\n",
      "Epoch 760/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0972 - accuracy: 0.5214 - val_loss: 1.0739 - val_accuracy: 0.5075\n",
      "Epoch 761/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.5053 - val_loss: 1.0486 - val_accuracy: 0.5272\n",
      "Epoch 762/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0903 - accuracy: 0.5327 - val_loss: 1.0529 - val_accuracy: 0.5184\n",
      "Epoch 763/800\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 1.1022 - accuracy: 0.5101 - val_loss: 1.0388 - val_accuracy: 0.5279\n",
      "Epoch 764/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0744 - accuracy: 0.5118 - val_loss: 1.0657 - val_accuracy: 0.5333\n",
      "Epoch 765/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0725 - accuracy: 0.5140 - val_loss: 1.0897 - val_accuracy: 0.4939\n",
      "Epoch 766/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0858 - accuracy: 0.5158 - val_loss: 1.0537 - val_accuracy: 0.5469\n",
      "Epoch 767/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0956 - accuracy: 0.5032 - val_loss: 1.0621 - val_accuracy: 0.5415\n",
      "Epoch 768/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0948 - accuracy: 0.5235 - val_loss: 1.0735 - val_accuracy: 0.5204\n",
      "Epoch 769/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0662 - accuracy: 0.5263 - val_loss: 1.0361 - val_accuracy: 0.5748\n",
      "Epoch 770/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.0824 - accuracy: 0.5039 - val_loss: 1.0753 - val_accuracy: 0.5265\n",
      "Epoch 771/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0887 - accuracy: 0.5073 - val_loss: 1.0707 - val_accuracy: 0.5320\n",
      "Epoch 772/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0763 - accuracy: 0.5177 - val_loss: 1.0606 - val_accuracy: 0.5238\n",
      "Epoch 773/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0806 - accuracy: 0.5375 - val_loss: 1.0400 - val_accuracy: 0.5721\n",
      "Epoch 774/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1076 - accuracy: 0.5135 - val_loss: 1.0686 - val_accuracy: 0.5395\n",
      "Epoch 775/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.1006 - accuracy: 0.5120 - val_loss: 1.0430 - val_accuracy: 0.5578\n",
      "Epoch 776/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0926 - accuracy: 0.5162 - val_loss: 1.0690 - val_accuracy: 0.5449\n",
      "Epoch 777/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0954 - accuracy: 0.5040 - val_loss: 1.0442 - val_accuracy: 0.5442\n",
      "Epoch 778/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.1006 - accuracy: 0.5112 - val_loss: 1.0837 - val_accuracy: 0.5231\n",
      "Epoch 779/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0983 - accuracy: 0.5043 - val_loss: 1.0472 - val_accuracy: 0.5401\n",
      "Epoch 780/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0962 - accuracy: 0.5221 - val_loss: 1.0628 - val_accuracy: 0.5272\n",
      "Epoch 781/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0797 - accuracy: 0.5384 - val_loss: 1.0739 - val_accuracy: 0.5415\n",
      "Epoch 782/800\n",
      "54/54 [==============================] - 0s 6ms/step - loss: 1.1017 - accuracy: 0.5108 - val_loss: 1.0945 - val_accuracy: 0.5136\n",
      "Epoch 783/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.1011 - accuracy: 0.5132 - val_loss: 1.0559 - val_accuracy: 0.5408\n",
      "Epoch 784/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0800 - accuracy: 0.5141 - val_loss: 1.0532 - val_accuracy: 0.5252\n",
      "Epoch 785/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0840 - accuracy: 0.5188 - val_loss: 1.0432 - val_accuracy: 0.5701\n",
      "Epoch 786/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0930 - accuracy: 0.5169 - val_loss: 1.0814 - val_accuracy: 0.5020\n",
      "Epoch 787/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0738 - accuracy: 0.5285 - val_loss: 1.0513 - val_accuracy: 0.5422\n",
      "Epoch 788/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0893 - accuracy: 0.5030 - val_loss: 1.0450 - val_accuracy: 0.5517\n",
      "Epoch 789/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0675 - accuracy: 0.5321 - val_loss: 1.0636 - val_accuracy: 0.5095\n",
      "Epoch 790/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0877 - accuracy: 0.5306 - val_loss: 1.0412 - val_accuracy: 0.5306\n",
      "Epoch 791/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0737 - accuracy: 0.5370 - val_loss: 1.0482 - val_accuracy: 0.5619\n",
      "Epoch 792/800\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 1.0777 - accuracy: 0.5223 - val_loss: 1.0607 - val_accuracy: 0.5231\n",
      "Epoch 793/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0868 - accuracy: 0.5284 - val_loss: 1.0545 - val_accuracy: 0.5408\n",
      "Epoch 794/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0847 - accuracy: 0.5164 - val_loss: 1.0624 - val_accuracy: 0.5163\n",
      "Epoch 795/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0784 - accuracy: 0.5284 - val_loss: 1.0365 - val_accuracy: 0.5673\n",
      "Epoch 796/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0712 - accuracy: 0.5219 - val_loss: 1.0431 - val_accuracy: 0.5544\n",
      "Epoch 797/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0829 - accuracy: 0.5181 - val_loss: 1.0533 - val_accuracy: 0.5286\n",
      "Epoch 798/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0772 - accuracy: 0.5050 - val_loss: 1.0546 - val_accuracy: 0.5177\n",
      "Epoch 799/800\n",
      "54/54 [==============================] - 0s 4ms/step - loss: 1.0782 - accuracy: 0.5175 - val_loss: 1.0575 - val_accuracy: 0.5245\n",
      "Epoch 800/800\n",
      "54/54 [==============================] - 0s 5ms/step - loss: 1.0675 - accuracy: 0.5234 - val_loss: 1.0638 - val_accuracy: 0.5245\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model3 =keras. models.Sequential()\n",
    "\n",
    "model3.add(keras.layers.Dense(units = 16,input_dim = 11,activation = 'relu'))\n",
    "model3.add(keras.layers.Dense(units = 32,activation = 'relu'))\n",
    "model3.add(keras.layers.Dropout(0.2))\n",
    "model3.add(keras.layers.Dense(units = 20,activation = 'relu'))\n",
    "model3.add(keras.layers.Dense(11,activation = 'softmax'))\n",
    "\n",
    "model3.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model3.summary()\n",
    "\n",
    "hist3 = model3.fit(x_train,y_train,epochs=800,batch_size=64,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "acc_ax = ax1.twinx()\n",
    "\n",
    "ax1.plot(hist3.history['loss'], 'y', label='train loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "\n",
    "\n",
    "ax2.plot(hist3.history['val_loss'], 'r', label='val loss')\n",
    "ax2.set_ylabel('val_loss')\n",
    "\n",
    "\n",
    "ax3.plot(hist3.history['accuracy'], 'b', label='accuracy')\n",
    "ax3.set_ylabel('accuray')\n",
    "\n",
    "ax4.plot(hist3.history['val_accuracy'], 'g', label='val_accuracy')\n",
    "ax4.set_ylabel('val_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 - 0s - loss: 1.0638 - accuracy: 0.5245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.063830852508545, 0.5244898200035095]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_test,y_test,verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 11)                363       \n",
      "=================================================================\n",
      "Total params: 4,283\n",
      "Trainable params: 4,283\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "72/72 [==============================] - 1s 4ms/step - loss: 3.0271 - accuracy: 0.1952 - val_loss: 1.3651 - val_accuracy: 0.3492\n",
      "Epoch 2/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3179 - accuracy: 0.4216 - val_loss: 1.2862 - val_accuracy: 0.3513\n",
      "Epoch 3/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2854 - accuracy: 0.4028 - val_loss: 1.2548 - val_accuracy: 0.4969\n",
      "Epoch 4/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2929 - accuracy: 0.4230 - val_loss: 1.2712 - val_accuracy: 0.4282\n",
      "Epoch 5/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2690 - accuracy: 0.4212 - val_loss: 1.2538 - val_accuracy: 0.4554\n",
      "Epoch 6/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2544 - accuracy: 0.4162 - val_loss: 1.2575 - val_accuracy: 0.4959\n",
      "Epoch 7/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2739 - accuracy: 0.4253 - val_loss: 1.2230 - val_accuracy: 0.4908\n",
      "Epoch 8/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2557 - accuracy: 0.4395 - val_loss: 1.2894 - val_accuracy: 0.3595\n",
      "Epoch 9/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2615 - accuracy: 0.4342 - val_loss: 1.2271 - val_accuracy: 0.4605\n",
      "Epoch 10/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2327 - accuracy: 0.4555 - val_loss: 1.1951 - val_accuracy: 0.4944\n",
      "Epoch 11/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2257 - accuracy: 0.4398 - val_loss: 1.2586 - val_accuracy: 0.4297\n",
      "Epoch 12/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2515 - accuracy: 0.4524 - val_loss: 1.1862 - val_accuracy: 0.4964\n",
      "Epoch 13/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2279 - accuracy: 0.4394 - val_loss: 1.1630 - val_accuracy: 0.5108\n",
      "Epoch 14/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1896 - accuracy: 0.4808 - val_loss: 1.1299 - val_accuracy: 0.5113\n",
      "Epoch 15/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1877 - accuracy: 0.4769 - val_loss: 1.1426 - val_accuracy: 0.5267\n",
      "Epoch 16/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1897 - accuracy: 0.4650 - val_loss: 1.1472 - val_accuracy: 0.5108\n",
      "Epoch 17/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1495 - accuracy: 0.5046 - val_loss: 1.1587 - val_accuracy: 0.4790\n",
      "Epoch 18/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1641 - accuracy: 0.4827 - val_loss: 1.3368 - val_accuracy: 0.3405\n",
      "Epoch 19/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2238 - accuracy: 0.4412 - val_loss: 1.1070 - val_accuracy: 0.5097\n",
      "Epoch 20/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1384 - accuracy: 0.5153 - val_loss: 1.1502 - val_accuracy: 0.4738\n",
      "Epoch 21/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1390 - accuracy: 0.4997 - val_loss: 1.2191 - val_accuracy: 0.4528\n",
      "Epoch 22/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1116 - accuracy: 0.5152 - val_loss: 1.1078 - val_accuracy: 0.5195\n",
      "Epoch 23/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1410 - accuracy: 0.4954 - val_loss: 1.7057 - val_accuracy: 0.2354\n",
      "Epoch 24/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1892 - accuracy: 0.4746 - val_loss: 1.0917 - val_accuracy: 0.5390\n",
      "Epoch 25/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1113 - accuracy: 0.5158 - val_loss: 1.1470 - val_accuracy: 0.4738\n",
      "Epoch 26/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1121 - accuracy: 0.5043 - val_loss: 1.0820 - val_accuracy: 0.5159\n",
      "Epoch 27/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1285 - accuracy: 0.5099 - val_loss: 1.0757 - val_accuracy: 0.5221\n",
      "Epoch 28/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1664 - accuracy: 0.4814 - val_loss: 1.0821 - val_accuracy: 0.5436\n",
      "Epoch 29/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1217 - accuracy: 0.5012 - val_loss: 1.3453 - val_accuracy: 0.3518\n",
      "Epoch 30/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1507 - accuracy: 0.4808 - val_loss: 1.0606 - val_accuracy: 0.5431\n",
      "Epoch 31/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1327 - accuracy: 0.4938 - val_loss: 1.3961 - val_accuracy: 0.3482\n",
      "Epoch 32/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2081 - accuracy: 0.4708 - val_loss: 1.1428 - val_accuracy: 0.4785\n",
      "Epoch 33/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0754 - accuracy: 0.5249 - val_loss: 1.1150 - val_accuracy: 0.4949\n",
      "Epoch 34/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1015 - accuracy: 0.5041 - val_loss: 1.1124 - val_accuracy: 0.5133\n",
      "Epoch 35/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0985 - accuracy: 0.5089 - val_loss: 1.0624 - val_accuracy: 0.5287\n",
      "Epoch 36/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1201 - accuracy: 0.5068 - val_loss: 1.3046 - val_accuracy: 0.3451\n",
      "Epoch 37/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1482 - accuracy: 0.4849 - val_loss: 1.0759 - val_accuracy: 0.5405\n",
      "Epoch 38/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1377 - accuracy: 0.5037 - val_loss: 1.0988 - val_accuracy: 0.5000\n",
      "Epoch 39/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1060 - accuracy: 0.5192 - val_loss: 1.0889 - val_accuracy: 0.5026\n",
      "Epoch 40/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0924 - accuracy: 0.5264 - val_loss: 1.1660 - val_accuracy: 0.4610\n",
      "Epoch 41/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1878 - accuracy: 0.4859 - val_loss: 1.1360 - val_accuracy: 0.4831\n",
      "Epoch 42/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0895 - accuracy: 0.5296 - val_loss: 1.1085 - val_accuracy: 0.4913\n",
      "Epoch 43/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0878 - accuracy: 0.5290 - val_loss: 1.1711 - val_accuracy: 0.4385\n",
      "Epoch 44/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0933 - accuracy: 0.5164 - val_loss: 1.1485 - val_accuracy: 0.4579\n",
      "Epoch 45/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1216 - accuracy: 0.5097 - val_loss: 1.1718 - val_accuracy: 0.4262\n",
      "Epoch 46/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0913 - accuracy: 0.5238 - val_loss: 1.0819 - val_accuracy: 0.5005\n",
      "Epoch 47/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0677 - accuracy: 0.5224 - val_loss: 1.0715 - val_accuracy: 0.5374\n",
      "Epoch 48/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1120 - accuracy: 0.5005 - val_loss: 1.0684 - val_accuracy: 0.5144\n",
      "Epoch 49/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0741 - accuracy: 0.5262 - val_loss: 1.0745 - val_accuracy: 0.5128\n",
      "Epoch 50/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0930 - accuracy: 0.5115 - val_loss: 1.0794 - val_accuracy: 0.5256\n",
      "Epoch 51/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1317 - accuracy: 0.4890 - val_loss: 1.0806 - val_accuracy: 0.5108\n",
      "Epoch 52/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0803 - accuracy: 0.5166 - val_loss: 1.1051 - val_accuracy: 0.4938\n",
      "Epoch 53/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0725 - accuracy: 0.5239 - val_loss: 1.0673 - val_accuracy: 0.5226\n",
      "Epoch 54/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0858 - accuracy: 0.5217 - val_loss: 1.0865 - val_accuracy: 0.5062\n",
      "Epoch 55/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0725 - accuracy: 0.5317 - val_loss: 1.0770 - val_accuracy: 0.5026\n",
      "Epoch 56/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0711 - accuracy: 0.5313 - val_loss: 1.0761 - val_accuracy: 0.5169\n",
      "Epoch 57/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.5194 - val_loss: 1.1102 - val_accuracy: 0.4738\n",
      "Epoch 58/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0851 - accuracy: 0.5304 - val_loss: 1.2037 - val_accuracy: 0.4451\n",
      "Epoch 59/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0637 - accuracy: 0.5316 - val_loss: 1.1834 - val_accuracy: 0.4338\n",
      "Epoch 60/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0750 - accuracy: 0.5195 - val_loss: 1.0654 - val_accuracy: 0.5200\n",
      "Epoch 61/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0738 - accuracy: 0.5378 - val_loss: 1.0681 - val_accuracy: 0.5441\n",
      "Epoch 62/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0950 - accuracy: 0.5288 - val_loss: 1.0723 - val_accuracy: 0.5328\n",
      "Epoch 63/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0462 - accuracy: 0.5412 - val_loss: 1.1245 - val_accuracy: 0.4826\n",
      "Epoch 64/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0741 - accuracy: 0.5316 - val_loss: 1.1914 - val_accuracy: 0.4410\n",
      "Epoch 65/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0888 - accuracy: 0.5304 - val_loss: 1.2146 - val_accuracy: 0.4446\n",
      "Epoch 66/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0586 - accuracy: 0.5411 - val_loss: 1.3010 - val_accuracy: 0.3703\n",
      "Epoch 67/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0859 - accuracy: 0.5343 - val_loss: 1.0431 - val_accuracy: 0.5390\n",
      "Epoch 68/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0506 - accuracy: 0.5436 - val_loss: 1.1444 - val_accuracy: 0.4615\n",
      "Epoch 69/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0497 - accuracy: 0.5491 - val_loss: 1.1038 - val_accuracy: 0.4918\n",
      "Epoch 70/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0661 - accuracy: 0.5473 - val_loss: 1.5019 - val_accuracy: 0.3108\n",
      "Epoch 71/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1120 - accuracy: 0.5123 - val_loss: 1.1235 - val_accuracy: 0.4656\n",
      "Epoch 72/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0610 - accuracy: 0.5301 - val_loss: 1.2383 - val_accuracy: 0.4159\n",
      "Epoch 73/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0706 - accuracy: 0.5296 - val_loss: 1.1522 - val_accuracy: 0.4759\n",
      "Epoch 74/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0747 - accuracy: 0.5332 - val_loss: 1.0545 - val_accuracy: 0.5344\n",
      "Epoch 75/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0818 - accuracy: 0.5125 - val_loss: 1.0683 - val_accuracy: 0.5133\n",
      "Epoch 76/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0716 - accuracy: 0.5319 - val_loss: 1.1293 - val_accuracy: 0.4831\n",
      "Epoch 77/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0728 - accuracy: 0.5249 - val_loss: 1.2887 - val_accuracy: 0.3995\n",
      "Epoch 78/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1428 - accuracy: 0.4949 - val_loss: 1.1371 - val_accuracy: 0.4672\n",
      "Epoch 79/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0573 - accuracy: 0.54 - 0s 2ms/step - loss: 1.0574 - accuracy: 0.5450 - val_loss: 1.0513 - val_accuracy: 0.5297\n",
      "Epoch 80/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0758 - accuracy: 0.5372 - val_loss: 1.0842 - val_accuracy: 0.5133\n",
      "Epoch 81/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0640 - accuracy: 0.5406 - val_loss: 1.0834 - val_accuracy: 0.4851\n",
      "Epoch 82/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0756 - accuracy: 0.5247 - val_loss: 1.1266 - val_accuracy: 0.4713\n",
      "Epoch 83/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0622 - accuracy: 0.5421 - val_loss: 1.1397 - val_accuracy: 0.4713\n",
      "Epoch 84/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0616 - accuracy: 0.5261 - val_loss: 1.1215 - val_accuracy: 0.4723\n",
      "Epoch 85/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0477 - accuracy: 0.5540 - val_loss: 1.1030 - val_accuracy: 0.4990\n",
      "Epoch 86/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0574 - accuracy: 0.5388 - val_loss: 1.0544 - val_accuracy: 0.5395\n",
      "Epoch 87/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0656 - accuracy: 0.5514 - val_loss: 1.0636 - val_accuracy: 0.5138\n",
      "Epoch 88/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0695 - accuracy: 0.5185 - val_loss: 1.0720 - val_accuracy: 0.5174\n",
      "Epoch 89/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0559 - accuracy: 0.5327 - val_loss: 1.2011 - val_accuracy: 0.4415\n",
      "Epoch 90/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0922 - accuracy: 0.5087 - val_loss: 1.1592 - val_accuracy: 0.4436\n",
      "Epoch 91/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0363 - accuracy: 0.5578 - val_loss: 1.1224 - val_accuracy: 0.4759\n",
      "Epoch 92/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0459 - accuracy: 0.5454 - val_loss: 1.0785 - val_accuracy: 0.5026\n",
      "Epoch 93/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0556 - accuracy: 0.5390 - val_loss: 1.0934 - val_accuracy: 0.4990\n",
      "Epoch 94/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0574 - accuracy: 0.5452 - val_loss: 1.0936 - val_accuracy: 0.4954\n",
      "Epoch 95/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0611 - accuracy: 0.5293 - val_loss: 1.0721 - val_accuracy: 0.5215\n",
      "Epoch 96/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0558 - accuracy: 0.5291 - val_loss: 1.1041 - val_accuracy: 0.4949\n",
      "Epoch 97/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0709 - accuracy: 0.5330 - val_loss: 1.0923 - val_accuracy: 0.5021\n",
      "Epoch 98/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0604 - accuracy: 0.5266 - val_loss: 1.0894 - val_accuracy: 0.5000\n",
      "Epoch 99/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0437 - accuracy: 0.5401 - val_loss: 1.0861 - val_accuracy: 0.5154\n",
      "Epoch 100/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0531 - accuracy: 0.5426 - val_loss: 1.1831 - val_accuracy: 0.4492\n",
      "Epoch 101/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0339 - accuracy: 0.5513 - val_loss: 1.1341 - val_accuracy: 0.4831\n",
      "Epoch 102/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0511 - accuracy: 0.5399 - val_loss: 1.0903 - val_accuracy: 0.4954\n",
      "Epoch 103/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0485 - accuracy: 0.5346 - val_loss: 1.2091 - val_accuracy: 0.4410\n",
      "Epoch 104/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.5324 - val_loss: 1.1043 - val_accuracy: 0.4938\n",
      "Epoch 105/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0539 - accuracy: 0.5325 - val_loss: 1.0861 - val_accuracy: 0.5026\n",
      "Epoch 106/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.5371 - val_loss: 1.0879 - val_accuracy: 0.4841\n",
      "Epoch 107/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0411 - accuracy: 0.5316 - val_loss: 1.0759 - val_accuracy: 0.5215\n",
      "Epoch 108/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0463 - accuracy: 0.5498 - val_loss: 1.2286 - val_accuracy: 0.3877\n",
      "Epoch 109/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0405 - accuracy: 0.5394 - val_loss: 1.3040 - val_accuracy: 0.3749\n",
      "Epoch 110/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0545 - accuracy: 0.5327 - val_loss: 1.1548 - val_accuracy: 0.4656\n",
      "Epoch 111/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0633 - accuracy: 0.5286 - val_loss: 1.0595 - val_accuracy: 0.5215\n",
      "Epoch 112/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0495 - accuracy: 0.5332 - val_loss: 1.1281 - val_accuracy: 0.4846\n",
      "Epoch 113/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0563 - accuracy: 0.5374 - val_loss: 1.0637 - val_accuracy: 0.5226\n",
      "Epoch 114/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0688 - accuracy: 0.5223 - val_loss: 1.0765 - val_accuracy: 0.5005\n",
      "Epoch 115/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0350 - accuracy: 0.5571 - val_loss: 1.1136 - val_accuracy: 0.4836\n",
      "Epoch 116/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0646 - accuracy: 0.5473 - val_loss: 1.1285 - val_accuracy: 0.4708\n",
      "Epoch 117/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0495 - accuracy: 0.5396 - val_loss: 1.1468 - val_accuracy: 0.4764\n",
      "Epoch 118/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0646 - accuracy: 0.5290 - val_loss: 1.0762 - val_accuracy: 0.5200\n",
      "Epoch 119/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0350 - accuracy: 0.5495 - val_loss: 1.0924 - val_accuracy: 0.4851\n",
      "Epoch 120/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0528 - accuracy: 0.5382 - val_loss: 1.1666 - val_accuracy: 0.4738\n",
      "Epoch 121/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0591 - accuracy: 0.5403 - val_loss: 1.0646 - val_accuracy: 0.5149\n",
      "Epoch 122/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0421 - accuracy: 0.5441 - val_loss: 1.1331 - val_accuracy: 0.4682\n",
      "Epoch 123/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0205 - accuracy: 0.5505 - val_loss: 1.0929 - val_accuracy: 0.5103\n",
      "Epoch 124/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0275 - accuracy: 0.5600 - val_loss: 1.2635 - val_accuracy: 0.3744\n",
      "Epoch 125/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0420 - accuracy: 0.5325 - val_loss: 1.0696 - val_accuracy: 0.5308\n",
      "Epoch 126/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0687 - accuracy: 0.5455 - val_loss: 1.0928 - val_accuracy: 0.4964\n",
      "Epoch 127/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0583 - accuracy: 0.5367 - val_loss: 1.0808 - val_accuracy: 0.5179\n",
      "Epoch 128/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0192 - accuracy: 0.5661 - val_loss: 1.1139 - val_accuracy: 0.4954\n",
      "Epoch 129/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0323 - accuracy: 0.5622 - val_loss: 1.0732 - val_accuracy: 0.5262\n",
      "Epoch 130/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0262 - accuracy: 0.5455 - val_loss: 1.1041 - val_accuracy: 0.4964\n",
      "Epoch 131/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0194 - accuracy: 0.5378 - val_loss: 1.0997 - val_accuracy: 0.5154\n",
      "Epoch 132/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0228 - accuracy: 0.5577 - val_loss: 1.1792 - val_accuracy: 0.4497\n",
      "Epoch 133/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0200 - accuracy: 0.5625 - val_loss: 1.1301 - val_accuracy: 0.4846\n",
      "Epoch 134/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0184 - accuracy: 0.5663 - val_loss: 1.0800 - val_accuracy: 0.5174\n",
      "Epoch 135/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0374 - accuracy: 0.5505 - val_loss: 1.1056 - val_accuracy: 0.4928\n",
      "Epoch 136/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0219 - accuracy: 0.5648 - val_loss: 1.1112 - val_accuracy: 0.5036\n",
      "Epoch 137/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0343 - accuracy: 0.5412 - val_loss: 1.1449 - val_accuracy: 0.4718\n",
      "Epoch 138/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0151 - accuracy: 0.5657 - val_loss: 1.0718 - val_accuracy: 0.5262\n",
      "Epoch 139/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0473 - accuracy: 0.5368 - val_loss: 1.1803 - val_accuracy: 0.4169\n",
      "Epoch 140/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0356 - accuracy: 0.5497 - val_loss: 1.0691 - val_accuracy: 0.5231\n",
      "Epoch 141/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0519 - accuracy: 0.5368 - val_loss: 1.0838 - val_accuracy: 0.4985\n",
      "Epoch 142/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0318 - accuracy: 0.5443 - val_loss: 1.1448 - val_accuracy: 0.4703\n",
      "Epoch 143/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0212 - accuracy: 0.5546 - val_loss: 1.1913 - val_accuracy: 0.4251\n",
      "Epoch 144/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0094 - accuracy: 0.5438 - val_loss: 1.1630 - val_accuracy: 0.4441\n",
      "Epoch 145/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0203 - accuracy: 0.5567 - val_loss: 1.0834 - val_accuracy: 0.5123\n",
      "Epoch 146/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0316 - accuracy: 0.5591 - val_loss: 1.1018 - val_accuracy: 0.4938\n",
      "Epoch 147/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0818 - accuracy: 0.5262 - val_loss: 1.0883 - val_accuracy: 0.4979\n",
      "Epoch 148/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1189 - accuracy: 0.5067 - val_loss: 1.0822 - val_accuracy: 0.5036\n",
      "Epoch 149/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0360 - accuracy: 0.5425 - val_loss: 1.1163 - val_accuracy: 0.5056\n",
      "Epoch 150/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0081 - accuracy: 0.5628 - val_loss: 1.1140 - val_accuracy: 0.4759\n",
      "Epoch 151/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0527 - accuracy: 0.5337 - val_loss: 1.1350 - val_accuracy: 0.4790\n",
      "Epoch 152/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0059 - accuracy: 0.5707 - val_loss: 1.1688 - val_accuracy: 0.4631\n",
      "Epoch 153/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0069 - accuracy: 0.5605 - val_loss: 1.2262 - val_accuracy: 0.3938\n",
      "Epoch 154/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0113 - accuracy: 0.5560 - val_loss: 1.2590 - val_accuracy: 0.4021\n",
      "Epoch 155/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0702 - accuracy: 0.5205 - val_loss: 1.1837 - val_accuracy: 0.4544\n",
      "Epoch 156/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0224 - accuracy: 0.5504 - val_loss: 1.1402 - val_accuracy: 0.4836\n",
      "Epoch 157/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9945 - accuracy: 0.5670 - val_loss: 1.1165 - val_accuracy: 0.5215\n",
      "Epoch 158/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0097 - accuracy: 0.5641 - val_loss: 1.1400 - val_accuracy: 0.4656\n",
      "Epoch 159/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0144 - accuracy: 0.5646 - val_loss: 1.0939 - val_accuracy: 0.4892\n",
      "Epoch 160/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0524 - accuracy: 0.5314 - val_loss: 1.1422 - val_accuracy: 0.4610\n",
      "Epoch 161/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9984 - accuracy: 0.5652 - val_loss: 1.0974 - val_accuracy: 0.5000\n",
      "Epoch 162/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0659 - accuracy: 0.5265 - val_loss: 1.1047 - val_accuracy: 0.5062\n",
      "Epoch 163/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0293 - accuracy: 0.5566 - val_loss: 1.2441 - val_accuracy: 0.4056\n",
      "Epoch 164/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0399 - accuracy: 0.5377 - val_loss: 1.1506 - val_accuracy: 0.4754\n",
      "Epoch 165/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0107 - accuracy: 0.5579 - val_loss: 1.0929 - val_accuracy: 0.5123\n",
      "Epoch 166/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0178 - accuracy: 0.5404 - val_loss: 1.1275 - val_accuracy: 0.4846\n",
      "Epoch 167/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0306 - accuracy: 0.5422 - val_loss: 1.1180 - val_accuracy: 0.4995\n",
      "Epoch 168/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0073 - accuracy: 0.5638 - val_loss: 1.1076 - val_accuracy: 0.5159\n",
      "Epoch 169/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0046 - accuracy: 0.5593 - val_loss: 1.0884 - val_accuracy: 0.5272\n",
      "Epoch 170/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0331 - accuracy: 0.5559 - val_loss: 1.1983 - val_accuracy: 0.4482\n",
      "Epoch 171/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0111 - accuracy: 0.5677 - val_loss: 1.1425 - val_accuracy: 0.4800\n",
      "Epoch 172/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0219 - accuracy: 0.5516 - val_loss: 1.2008 - val_accuracy: 0.4328\n",
      "Epoch 173/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0150 - accuracy: 0.5738 - val_loss: 1.0863 - val_accuracy: 0.5277\n",
      "Epoch 174/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9900 - accuracy: 0.5758 - val_loss: 1.1141 - val_accuracy: 0.5103\n",
      "Epoch 175/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0092 - accuracy: 0.5551 - val_loss: 1.1209 - val_accuracy: 0.5005\n",
      "Epoch 176/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0118 - accuracy: 0.5582 - val_loss: 1.0989 - val_accuracy: 0.5118\n",
      "Epoch 177/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0144 - accuracy: 0.5533 - val_loss: 1.1153 - val_accuracy: 0.5021\n",
      "Epoch 178/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0213 - accuracy: 0.5471 - val_loss: 1.1982 - val_accuracy: 0.4215\n",
      "Epoch 179/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0148 - accuracy: 0.5588 - val_loss: 1.2119 - val_accuracy: 0.4446\n",
      "Epoch 180/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0313 - accuracy: 0.5559 - val_loss: 1.2056 - val_accuracy: 0.4451\n",
      "Epoch 181/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9949 - accuracy: 0.5767 - val_loss: 1.2632 - val_accuracy: 0.4005\n",
      "Epoch 182/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0337 - accuracy: 0.5611 - val_loss: 1.1328 - val_accuracy: 0.5062\n",
      "Epoch 183/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0142 - accuracy: 0.5557 - val_loss: 1.1162 - val_accuracy: 0.5015\n",
      "Epoch 184/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0150 - accuracy: 0.5628 - val_loss: 1.2313 - val_accuracy: 0.4267\n",
      "Epoch 185/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9970 - accuracy: 0.5612 - val_loss: 1.0792 - val_accuracy: 0.5118\n",
      "Epoch 186/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9876 - accuracy: 0.5668 - val_loss: 1.1748 - val_accuracy: 0.4523\n",
      "Epoch 187/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0039 - accuracy: 0.5696 - val_loss: 1.1262 - val_accuracy: 0.4805\n",
      "Epoch 188/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0036 - accuracy: 0.5634 - val_loss: 1.1265 - val_accuracy: 0.4944\n",
      "Epoch 189/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9822 - accuracy: 0.5695 - val_loss: 1.1471 - val_accuracy: 0.4682\n",
      "Epoch 190/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0004 - accuracy: 0.5737 - val_loss: 1.2036 - val_accuracy: 0.4185\n",
      "Epoch 191/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0108 - accuracy: 0.5600 - val_loss: 1.1226 - val_accuracy: 0.4892\n",
      "Epoch 192/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9830 - accuracy: 0.5744 - val_loss: 1.1683 - val_accuracy: 0.4856\n",
      "Epoch 193/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9993 - accuracy: 0.5694 - val_loss: 1.1203 - val_accuracy: 0.5051\n",
      "Epoch 194/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0400 - accuracy: 0.54 - 0s 1ms/step - loss: 1.0390 - accuracy: 0.5483 - val_loss: 1.1426 - val_accuracy: 0.4821\n",
      "Epoch 195/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9950 - accuracy: 0.5715 - val_loss: 1.0896 - val_accuracy: 0.5205\n",
      "Epoch 196/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0050 - accuracy: 0.56 - 0s 2ms/step - loss: 1.0041 - accuracy: 0.5674 - val_loss: 1.1250 - val_accuracy: 0.5000\n",
      "Epoch 197/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0445 - accuracy: 0.5554 - val_loss: 1.1121 - val_accuracy: 0.5174\n",
      "Epoch 198/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0006 - accuracy: 0.5695 - val_loss: 1.1201 - val_accuracy: 0.4908\n",
      "Epoch 199/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0100 - accuracy: 0.5803 - val_loss: 1.1450 - val_accuracy: 0.4831\n",
      "Epoch 200/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.5758 - val_loss: 1.1885 - val_accuracy: 0.4682\n",
      "Epoch 201/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9849 - accuracy: 0.5808 - val_loss: 1.1674 - val_accuracy: 0.4733\n",
      "Epoch 202/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9770 - accuracy: 0.5790 - val_loss: 1.2546 - val_accuracy: 0.3754\n",
      "Epoch 203/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0206 - accuracy: 0.5464 - val_loss: 1.1711 - val_accuracy: 0.4554\n",
      "Epoch 204/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9852 - accuracy: 0.5677 - val_loss: 1.1120 - val_accuracy: 0.5015\n",
      "Epoch 205/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9882 - accuracy: 0.5756 - val_loss: 1.2268 - val_accuracy: 0.4236\n",
      "Epoch 206/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0119 - accuracy: 0.5498 - val_loss: 1.1372 - val_accuracy: 0.5108\n",
      "Epoch 207/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0348 - accuracy: 0.5541 - val_loss: 1.1701 - val_accuracy: 0.4441\n",
      "Epoch 208/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9768 - accuracy: 0.5805 - val_loss: 1.1533 - val_accuracy: 0.4908\n",
      "Epoch 209/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9990 - accuracy: 0.5727 - val_loss: 1.1398 - val_accuracy: 0.4713\n",
      "Epoch 210/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9883 - accuracy: 0.5756 - val_loss: 1.1691 - val_accuracy: 0.4872\n",
      "Epoch 211/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9973 - accuracy: 0.5758 - val_loss: 1.1120 - val_accuracy: 0.4974\n",
      "Epoch 212/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0233 - accuracy: 0.5470 - val_loss: 1.1194 - val_accuracy: 0.4964\n",
      "Epoch 213/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9983 - accuracy: 0.5684 - val_loss: 1.1259 - val_accuracy: 0.4908\n",
      "Epoch 214/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9911 - accuracy: 0.5698 - val_loss: 1.2245 - val_accuracy: 0.4441\n",
      "Epoch 215/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0051 - accuracy: 0.5572 - val_loss: 1.1891 - val_accuracy: 0.4374\n",
      "Epoch 216/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9990 - accuracy: 0.5674 - val_loss: 1.2954 - val_accuracy: 0.3903\n",
      "Epoch 217/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9977 - accuracy: 0.5746 - val_loss: 1.1643 - val_accuracy: 0.4769\n",
      "Epoch 218/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0040 - accuracy: 0.5670 - val_loss: 1.1739 - val_accuracy: 0.4738\n",
      "Epoch 219/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9634 - accuracy: 0.5827 - val_loss: 1.1925 - val_accuracy: 0.4354\n",
      "Epoch 220/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9739 - accuracy: 0.5856 - val_loss: 1.0937 - val_accuracy: 0.5179\n",
      "Epoch 221/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0242 - accuracy: 0.5432 - val_loss: 1.1205 - val_accuracy: 0.5036\n",
      "Epoch 222/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0206 - accuracy: 0.5533 - val_loss: 1.1312 - val_accuracy: 0.4964\n",
      "Epoch 223/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9912 - accuracy: 0.5797 - val_loss: 1.1428 - val_accuracy: 0.4846\n",
      "Epoch 224/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0021 - accuracy: 0.5682 - val_loss: 1.2112 - val_accuracy: 0.4159\n",
      "Epoch 225/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9742 - accuracy: 0.5788 - val_loss: 1.2262 - val_accuracy: 0.4523\n",
      "Epoch 226/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9865 - accuracy: 0.5731 - val_loss: 1.2711 - val_accuracy: 0.3846\n",
      "Epoch 227/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0424 - accuracy: 0.5505 - val_loss: 1.1909 - val_accuracy: 0.4631\n",
      "Epoch 228/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9656 - accuracy: 0.5707 - val_loss: 1.1476 - val_accuracy: 0.4774\n",
      "Epoch 229/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0022 - accuracy: 0.5781 - val_loss: 1.1917 - val_accuracy: 0.4585\n",
      "Epoch 230/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9830 - accuracy: 0.5827 - val_loss: 1.1481 - val_accuracy: 0.4841\n",
      "Epoch 231/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9708 - accuracy: 0.5858 - val_loss: 1.1976 - val_accuracy: 0.4595\n",
      "Epoch 232/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9653 - accuracy: 0.5789 - val_loss: 1.2328 - val_accuracy: 0.4210\n",
      "Epoch 233/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9716 - accuracy: 0.5897 - val_loss: 1.2139 - val_accuracy: 0.4682\n",
      "Epoch 234/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9853 - accuracy: 0.5608 - val_loss: 1.1966 - val_accuracy: 0.4344\n",
      "Epoch 235/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9968 - accuracy: 0.5589 - val_loss: 1.2263 - val_accuracy: 0.4190\n",
      "Epoch 236/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0403 - accuracy: 0.5516 - val_loss: 1.3670 - val_accuracy: 0.3421\n",
      "Epoch 237/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0511 - accuracy: 0.5385 - val_loss: 1.1237 - val_accuracy: 0.4933\n",
      "Epoch 238/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9964 - accuracy: 0.5567 - val_loss: 1.1182 - val_accuracy: 0.5036\n",
      "Epoch 239/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9750 - accuracy: 0.5756 - val_loss: 1.1548 - val_accuracy: 0.4913\n",
      "Epoch 240/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9809 - accuracy: 0.5822 - val_loss: 1.1228 - val_accuracy: 0.5062\n",
      "Epoch 241/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9852 - accuracy: 0.5763 - val_loss: 1.1453 - val_accuracy: 0.5056\n",
      "Epoch 242/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9682 - accuracy: 0.5781 - val_loss: 1.2259 - val_accuracy: 0.4615\n",
      "Epoch 243/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0062 - accuracy: 0.5623 - val_loss: 1.1516 - val_accuracy: 0.4949\n",
      "Epoch 244/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9960 - accuracy: 0.5801 - val_loss: 1.1313 - val_accuracy: 0.5000\n",
      "Epoch 245/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0026 - accuracy: 0.5678 - val_loss: 1.1601 - val_accuracy: 0.5092\n",
      "Epoch 246/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9801 - accuracy: 0.5737 - val_loss: 1.2094 - val_accuracy: 0.4487\n",
      "Epoch 247/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9794 - accuracy: 0.5817 - val_loss: 1.1927 - val_accuracy: 0.4528\n",
      "Epoch 248/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9689 - accuracy: 0.5762 - val_loss: 1.1279 - val_accuracy: 0.5128\n",
      "Epoch 249/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9931 - accuracy: 0.5695 - val_loss: 1.1779 - val_accuracy: 0.4908\n",
      "Epoch 250/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9714 - accuracy: 0.5763 - val_loss: 1.2101 - val_accuracy: 0.4256\n",
      "Epoch 251/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0103 - accuracy: 0.5457 - val_loss: 1.1315 - val_accuracy: 0.4892\n",
      "Epoch 252/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9770 - accuracy: 0.5726 - val_loss: 1.1618 - val_accuracy: 0.5005\n",
      "Epoch 253/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9866 - accuracy: 0.5800 - val_loss: 1.1242 - val_accuracy: 0.5067\n",
      "Epoch 254/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9891 - accuracy: 0.5738 - val_loss: 1.1734 - val_accuracy: 0.4882\n",
      "Epoch 255/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9826 - accuracy: 0.5825 - val_loss: 1.1431 - val_accuracy: 0.4954\n",
      "Epoch 256/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9751 - accuracy: 0.5807 - val_loss: 1.1641 - val_accuracy: 0.4974\n",
      "Epoch 257/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9534 - accuracy: 0.5976 - val_loss: 1.1595 - val_accuracy: 0.4703\n",
      "Epoch 258/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9828 - accuracy: 0.5777 - val_loss: 1.1276 - val_accuracy: 0.5051\n",
      "Epoch 259/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.5616 - val_loss: 1.2108 - val_accuracy: 0.4636\n",
      "Epoch 260/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9883 - accuracy: 0.5769 - val_loss: 1.2110 - val_accuracy: 0.4579\n",
      "Epoch 261/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9669 - accuracy: 0.5817 - val_loss: 1.1858 - val_accuracy: 0.4769\n",
      "Epoch 262/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9599 - accuracy: 0.5901 - val_loss: 1.1844 - val_accuracy: 0.4759\n",
      "Epoch 263/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9942 - accuracy: 0.5800 - val_loss: 1.2612 - val_accuracy: 0.4513\n",
      "Epoch 264/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9833 - accuracy: 0.5640 - val_loss: 1.1476 - val_accuracy: 0.4928\n",
      "Epoch 265/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9561 - accuracy: 0.5916 - val_loss: 1.1680 - val_accuracy: 0.5000\n",
      "Epoch 266/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9601 - accuracy: 0.5841 - val_loss: 1.2552 - val_accuracy: 0.4195\n",
      "Epoch 267/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9758 - accuracy: 0.5776 - val_loss: 1.1350 - val_accuracy: 0.5195\n",
      "Epoch 268/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9931 - accuracy: 0.5651 - val_loss: 1.2750 - val_accuracy: 0.4303\n",
      "Epoch 269/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9645 - accuracy: 0.5737 - val_loss: 1.4057 - val_accuracy: 0.3564\n",
      "Epoch 270/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0836 - accuracy: 0.5211 - val_loss: 1.1564 - val_accuracy: 0.4795\n",
      "Epoch 271/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9954 - accuracy: 0.5664 - val_loss: 1.2634 - val_accuracy: 0.4154\n",
      "Epoch 272/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0106 - accuracy: 0.5546 - val_loss: 1.3896 - val_accuracy: 0.3436\n",
      "Epoch 273/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9900 - accuracy: 0.5623 - val_loss: 1.1929 - val_accuracy: 0.4846\n",
      "Epoch 274/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9838 - accuracy: 0.5725 - val_loss: 1.1350 - val_accuracy: 0.5077\n",
      "Epoch 275/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9956 - accuracy: 0.5721 - val_loss: 1.1234 - val_accuracy: 0.5077\n",
      "Epoch 276/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9723 - accuracy: 0.5711 - val_loss: 1.1782 - val_accuracy: 0.4949\n",
      "Epoch 277/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9575 - accuracy: 0.5775 - val_loss: 1.2042 - val_accuracy: 0.4682\n",
      "Epoch 278/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9706 - accuracy: 0.5684 - val_loss: 1.1471 - val_accuracy: 0.5041\n",
      "Epoch 279/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0035 - accuracy: 0.5548 - val_loss: 1.1456 - val_accuracy: 0.4754\n",
      "Epoch 280/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9891 - accuracy: 0.5591 - val_loss: 1.1675 - val_accuracy: 0.4764\n",
      "Epoch 281/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9801 - accuracy: 0.5861 - val_loss: 1.2050 - val_accuracy: 0.4759\n",
      "Epoch 282/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9758 - accuracy: 0.5650 - val_loss: 1.2402 - val_accuracy: 0.4256\n",
      "Epoch 283/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0032 - accuracy: 0.5560 - val_loss: 1.2727 - val_accuracy: 0.4318\n",
      "Epoch 284/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9955 - accuracy: 0.5646 - val_loss: 1.2801 - val_accuracy: 0.4205\n",
      "Epoch 285/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0077 - accuracy: 0.5590 - val_loss: 1.1464 - val_accuracy: 0.5108\n",
      "Epoch 286/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.5661 - val_loss: 1.1290 - val_accuracy: 0.5026\n",
      "Epoch 287/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0446 - accuracy: 0.5449 - val_loss: 1.2551 - val_accuracy: 0.4026\n",
      "Epoch 288/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0118 - accuracy: 0.5551 - val_loss: 1.2033 - val_accuracy: 0.4446\n",
      "Epoch 289/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0195 - accuracy: 0.5675 - val_loss: 1.1104 - val_accuracy: 0.5164\n",
      "Epoch 290/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0252 - accuracy: 0.5565 - val_loss: 1.1483 - val_accuracy: 0.4779\n",
      "Epoch 291/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0027 - accuracy: 0.5616 - val_loss: 1.1042 - val_accuracy: 0.5128\n",
      "Epoch 292/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0133 - accuracy: 0.5557 - val_loss: 1.1140 - val_accuracy: 0.5092\n",
      "Epoch 293/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9617 - accuracy: 0.5854 - val_loss: 1.1277 - val_accuracy: 0.4990\n",
      "Epoch 294/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9851 - accuracy: 0.5795 - val_loss: 1.1052 - val_accuracy: 0.5128\n",
      "Epoch 295/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9871 - accuracy: 0.5626 - val_loss: 1.1279 - val_accuracy: 0.5103\n",
      "Epoch 296/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9759 - accuracy: 0.5760 - val_loss: 1.1828 - val_accuracy: 0.4513\n",
      "Epoch 297/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9789 - accuracy: 0.5789 - val_loss: 1.1092 - val_accuracy: 0.5056\n",
      "Epoch 298/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9598 - accuracy: 0.5761 - val_loss: 1.1813 - val_accuracy: 0.4462\n",
      "Epoch 299/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9800 - accuracy: 0.5710 - val_loss: 1.2991 - val_accuracy: 0.3918\n",
      "Epoch 300/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0525 - accuracy: 0.5493 - val_loss: 1.1236 - val_accuracy: 0.4974\n",
      "Epoch 301/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9723 - accuracy: 0.5871 - val_loss: 1.1250 - val_accuracy: 0.4928\n",
      "Epoch 302/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9531 - accuracy: 0.5843 - val_loss: 1.1302 - val_accuracy: 0.4728\n",
      "Epoch 303/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9905 - accuracy: 0.5717 - val_loss: 1.2056 - val_accuracy: 0.4297\n",
      "Epoch 304/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9542 - accuracy: 0.5908 - val_loss: 1.2194 - val_accuracy: 0.4149\n",
      "Epoch 305/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.5787 - val_loss: 1.1409 - val_accuracy: 0.4892\n",
      "Epoch 306/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9797 - accuracy: 0.5689 - val_loss: 1.1231 - val_accuracy: 0.5021\n",
      "Epoch 307/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0116 - accuracy: 0.5709 - val_loss: 1.1382 - val_accuracy: 0.5072\n",
      "Epoch 308/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0416 - accuracy: 0.5590 - val_loss: 1.2016 - val_accuracy: 0.4590\n",
      "Epoch 309/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9808 - accuracy: 0.5706 - val_loss: 1.2246 - val_accuracy: 0.4287\n",
      "Epoch 310/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0079 - accuracy: 0.5576 - val_loss: 1.1570 - val_accuracy: 0.4887\n",
      "Epoch 311/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9848 - accuracy: 0.5704 - val_loss: 1.4102 - val_accuracy: 0.3585\n",
      "Epoch 312/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0586 - accuracy: 0.5376 - val_loss: 1.2043 - val_accuracy: 0.4667\n",
      "Epoch 313/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.5878 - val_loss: 1.1931 - val_accuracy: 0.4774\n",
      "Epoch 314/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9491 - accuracy: 0.5777 - val_loss: 1.2663 - val_accuracy: 0.4159\n",
      "Epoch 315/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9486 - accuracy: 0.5955 - val_loss: 1.2035 - val_accuracy: 0.4733\n",
      "Epoch 316/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9776 - accuracy: 0.5749 - val_loss: 1.1817 - val_accuracy: 0.4744\n",
      "Epoch 317/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9944 - accuracy: 0.5812 - val_loss: 1.1968 - val_accuracy: 0.4656\n",
      "Epoch 318/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.5847 - val_loss: 1.2457 - val_accuracy: 0.4364\n",
      "Epoch 319/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9791 - accuracy: 0.5627 - val_loss: 1.1705 - val_accuracy: 0.4856\n",
      "Epoch 320/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9635 - accuracy: 0.5824 - val_loss: 1.2437 - val_accuracy: 0.4487\n",
      "Epoch 321/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9690 - accuracy: 0.5784 - val_loss: 1.1766 - val_accuracy: 0.5041\n",
      "Epoch 322/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9822 - accuracy: 0.5767 - val_loss: 1.1700 - val_accuracy: 0.4979\n",
      "Epoch 323/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9796 - accuracy: 0.5814 - val_loss: 1.2087 - val_accuracy: 0.5000\n",
      "Epoch 324/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9705 - accuracy: 0.5664 - val_loss: 1.1700 - val_accuracy: 0.5026\n",
      "Epoch 325/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9703 - accuracy: 0.5890 - val_loss: 1.1809 - val_accuracy: 0.5062\n",
      "Epoch 326/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9677 - accuracy: 0.5760 - val_loss: 1.2231 - val_accuracy: 0.4708\n",
      "Epoch 327/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9508 - accuracy: 0.5868 - val_loss: 1.1820 - val_accuracy: 0.4923\n",
      "Epoch 328/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9497 - accuracy: 0.5839 - val_loss: 1.2838 - val_accuracy: 0.4251\n",
      "Epoch 329/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9962 - accuracy: 0.5603 - val_loss: 1.1878 - val_accuracy: 0.4882\n",
      "Epoch 330/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9360 - accuracy: 0.5932 - val_loss: 1.1587 - val_accuracy: 0.4949\n",
      "Epoch 331/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9447 - accuracy: 0.5879 - val_loss: 1.4534 - val_accuracy: 0.3385\n",
      "Epoch 332/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0475 - accuracy: 0.5382 - val_loss: 1.2367 - val_accuracy: 0.4477\n",
      "Epoch 333/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9720 - accuracy: 0.5775 - val_loss: 1.2002 - val_accuracy: 0.4831\n",
      "Epoch 334/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9686 - accuracy: 0.5858 - val_loss: 1.2043 - val_accuracy: 0.4656\n",
      "Epoch 335/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9896 - accuracy: 0.5712 - val_loss: 1.1636 - val_accuracy: 0.4790\n",
      "Epoch 336/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9421 - accuracy: 0.5946 - val_loss: 1.3119 - val_accuracy: 0.3892\n",
      "Epoch 337/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9707 - accuracy: 0.5822 - val_loss: 1.2715 - val_accuracy: 0.4323\n",
      "Epoch 338/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9643 - accuracy: 0.5789 - val_loss: 1.1932 - val_accuracy: 0.5041\n",
      "Epoch 339/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9805 - accuracy: 0.5571 - val_loss: 1.2126 - val_accuracy: 0.4554\n",
      "Epoch 340/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9566 - accuracy: 0.5848 - val_loss: 1.2386 - val_accuracy: 0.4682\n",
      "Epoch 341/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9604 - accuracy: 0.5914 - val_loss: 1.2015 - val_accuracy: 0.4728\n",
      "Epoch 342/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5433 - val_loss: 1.3192 - val_accuracy: 0.4236\n",
      "Epoch 343/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9652 - accuracy: 0.5872 - val_loss: 1.1733 - val_accuracy: 0.5041\n",
      "Epoch 344/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0054 - accuracy: 0.5634 - val_loss: 1.2523 - val_accuracy: 0.4436\n",
      "Epoch 345/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0051 - accuracy: 0.56 - 0s 2ms/step - loss: 1.0031 - accuracy: 0.5690 - val_loss: 1.2227 - val_accuracy: 0.4718\n",
      "Epoch 346/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9557 - accuracy: 0.5803 - val_loss: 1.1673 - val_accuracy: 0.5118\n",
      "Epoch 347/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9656 - accuracy: 0.5820 - val_loss: 1.3022 - val_accuracy: 0.4200\n",
      "Epoch 348/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9907 - accuracy: 0.5741 - val_loss: 1.2277 - val_accuracy: 0.4492\n",
      "Epoch 349/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9643 - accuracy: 0.5799 - val_loss: 1.1630 - val_accuracy: 0.5015\n",
      "Epoch 350/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9540 - accuracy: 0.5872 - val_loss: 1.2624 - val_accuracy: 0.4287\n",
      "Epoch 351/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9651 - accuracy: 0.5878 - val_loss: 1.1961 - val_accuracy: 0.5036\n",
      "Epoch 352/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9666 - accuracy: 0.5769 - val_loss: 1.1981 - val_accuracy: 0.4677\n",
      "Epoch 353/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9443 - accuracy: 0.6017 - val_loss: 1.2874 - val_accuracy: 0.4364\n",
      "Epoch 354/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9676 - accuracy: 0.5765 - val_loss: 1.2712 - val_accuracy: 0.4462\n",
      "Epoch 355/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9521 - accuracy: 0.5847 - val_loss: 1.1878 - val_accuracy: 0.5041\n",
      "Epoch 356/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9361 - accuracy: 0.5938 - val_loss: 1.1793 - val_accuracy: 0.4933\n",
      "Epoch 357/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9600 - accuracy: 0.5796 - val_loss: 1.2752 - val_accuracy: 0.4518\n",
      "Epoch 358/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9380 - accuracy: 0.5933 - val_loss: 1.2197 - val_accuracy: 0.4733\n",
      "Epoch 359/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9497 - accuracy: 0.5792 - val_loss: 1.2175 - val_accuracy: 0.4826\n",
      "Epoch 360/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9566 - accuracy: 0.5922 - val_loss: 1.2354 - val_accuracy: 0.4795\n",
      "Epoch 361/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9326 - accuracy: 0.5979 - val_loss: 1.2167 - val_accuracy: 0.4821\n",
      "Epoch 362/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9384 - accuracy: 0.5991 - val_loss: 1.1700 - val_accuracy: 0.4995\n",
      "Epoch 363/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9328 - accuracy: 0.5955 - val_loss: 1.2647 - val_accuracy: 0.4349\n",
      "Epoch 364/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9660 - accuracy: 0.5906 - val_loss: 1.1765 - val_accuracy: 0.4933\n",
      "Epoch 365/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9417 - accuracy: 0.5742 - val_loss: 1.1775 - val_accuracy: 0.4938\n",
      "Epoch 366/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9694 - accuracy: 0.5774 - val_loss: 1.2694 - val_accuracy: 0.4513\n",
      "Epoch 367/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9532 - accuracy: 0.5777 - val_loss: 1.2180 - val_accuracy: 0.4790\n",
      "Epoch 368/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9372 - accuracy: 0.5903 - val_loss: 1.2341 - val_accuracy: 0.4785\n",
      "Epoch 369/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9377 - accuracy: 0.5929 - val_loss: 1.2035 - val_accuracy: 0.5262\n",
      "Epoch 370/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9573 - accuracy: 0.5782 - val_loss: 1.3039 - val_accuracy: 0.4262\n",
      "Epoch 371/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9925 - accuracy: 0.5599 - val_loss: 1.2377 - val_accuracy: 0.4436\n",
      "Epoch 372/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9565 - accuracy: 0.5832 - val_loss: 1.1510 - val_accuracy: 0.4969\n",
      "Epoch 373/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9630 - accuracy: 0.5768 - val_loss: 1.1984 - val_accuracy: 0.4979\n",
      "Epoch 374/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9666 - accuracy: 0.58 - 0s 2ms/step - loss: 0.9635 - accuracy: 0.5830 - val_loss: 1.3430 - val_accuracy: 0.3985\n",
      "Epoch 375/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9626 - accuracy: 0.5812 - val_loss: 1.2248 - val_accuracy: 0.4872\n",
      "Epoch 376/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9674 - accuracy: 0.5799 - val_loss: 1.2051 - val_accuracy: 0.4728\n",
      "Epoch 377/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9387 - accuracy: 0.5925 - val_loss: 1.2060 - val_accuracy: 0.4759\n",
      "Epoch 378/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9496 - accuracy: 0.5832 - val_loss: 1.2520 - val_accuracy: 0.4528\n",
      "Epoch 379/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9287 - accuracy: 0.5988 - val_loss: 1.2896 - val_accuracy: 0.4113\n",
      "Epoch 380/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9593 - accuracy: 0.5754 - val_loss: 1.2457 - val_accuracy: 0.4477\n",
      "Epoch 381/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9315 - accuracy: 0.5945 - val_loss: 1.2023 - val_accuracy: 0.4938\n",
      "Epoch 382/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9399 - accuracy: 0.5887 - val_loss: 1.3232 - val_accuracy: 0.4108\n",
      "Epoch 383/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9594 - accuracy: 0.5893 - val_loss: 1.2647 - val_accuracy: 0.4492\n",
      "Epoch 384/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9443 - accuracy: 0.5941 - val_loss: 1.2146 - val_accuracy: 0.5000\n",
      "Epoch 385/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9359 - accuracy: 0.5929 - val_loss: 1.2513 - val_accuracy: 0.4887\n",
      "Epoch 386/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9634 - accuracy: 0.5854 - val_loss: 1.3007 - val_accuracy: 0.4390\n",
      "Epoch 387/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9572 - accuracy: 0.5975 - val_loss: 1.2541 - val_accuracy: 0.4769\n",
      "Epoch 388/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9237 - accuracy: 0.5872 - val_loss: 1.3302 - val_accuracy: 0.4062\n",
      "Epoch 389/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9287 - accuracy: 0.6086 - val_loss: 1.2154 - val_accuracy: 0.5133\n",
      "Epoch 390/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9586 - accuracy: 0.5753 - val_loss: 1.2696 - val_accuracy: 0.4154\n",
      "Epoch 391/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9411 - accuracy: 0.5918 - val_loss: 1.3168 - val_accuracy: 0.4308\n",
      "Epoch 392/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.9583 - accuracy: 0.5807 - val_loss: 1.2384 - val_accuracy: 0.4687\n",
      "Epoch 393/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9390 - accuracy: 0.5928 - val_loss: 1.2255 - val_accuracy: 0.4892\n",
      "Epoch 394/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9282 - accuracy: 0.6070 - val_loss: 1.2099 - val_accuracy: 0.5062\n",
      "Epoch 395/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9560 - accuracy: 0.5852 - val_loss: 1.2279 - val_accuracy: 0.4908\n",
      "Epoch 396/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9342 - accuracy: 0.5905 - val_loss: 1.2284 - val_accuracy: 0.4892\n",
      "Epoch 397/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9531 - accuracy: 0.5940 - val_loss: 1.3150 - val_accuracy: 0.4272\n",
      "Epoch 398/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.5697 - val_loss: 1.2006 - val_accuracy: 0.4933\n",
      "Epoch 399/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9418 - accuracy: 0.5850 - val_loss: 1.2403 - val_accuracy: 0.4718\n",
      "Epoch 400/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9186 - accuracy: 0.6023 - val_loss: 1.3264 - val_accuracy: 0.4292\n",
      "Epoch 401/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9302 - accuracy: 0.5917 - val_loss: 1.2488 - val_accuracy: 0.4738\n",
      "Epoch 402/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9471 - accuracy: 0.5897 - val_loss: 1.3091 - val_accuracy: 0.4333\n",
      "Epoch 403/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9536 - accuracy: 0.5774 - val_loss: 1.2176 - val_accuracy: 0.5026\n",
      "Epoch 404/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9632 - accuracy: 0.5731 - val_loss: 1.2703 - val_accuracy: 0.4841\n",
      "Epoch 405/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9281 - accuracy: 0.6012 - val_loss: 1.2319 - val_accuracy: 0.4913\n",
      "Epoch 406/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9181 - accuracy: 0.6006 - val_loss: 1.2494 - val_accuracy: 0.5082\n",
      "Epoch 407/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9480 - accuracy: 0.5834 - val_loss: 1.2832 - val_accuracy: 0.4882\n",
      "Epoch 408/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9262 - accuracy: 0.5946 - val_loss: 1.2652 - val_accuracy: 0.4703\n",
      "Epoch 409/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9024 - accuracy: 0.6101 - val_loss: 1.3193 - val_accuracy: 0.4621\n",
      "Epoch 410/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9556 - accuracy: 0.5894 - val_loss: 1.3824 - val_accuracy: 0.4077\n",
      "Epoch 411/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9361 - accuracy: 0.5926 - val_loss: 1.2861 - val_accuracy: 0.4441\n",
      "Epoch 412/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9373 - accuracy: 0.5983 - val_loss: 1.2417 - val_accuracy: 0.4897\n",
      "Epoch 413/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9730 - accuracy: 0.5815 - val_loss: 1.4452 - val_accuracy: 0.3954\n",
      "Epoch 414/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0173 - accuracy: 0.5624 - val_loss: 1.3509 - val_accuracy: 0.4015\n",
      "Epoch 415/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0693 - accuracy: 0.5382 - val_loss: 1.2123 - val_accuracy: 0.4779\n",
      "Epoch 416/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9578 - accuracy: 0.5784 - val_loss: 1.2222 - val_accuracy: 0.5005\n",
      "Epoch 417/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9441 - accuracy: 0.5840 - val_loss: 1.3120 - val_accuracy: 0.4328\n",
      "Epoch 418/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9406 - accuracy: 0.6036 - val_loss: 1.2812 - val_accuracy: 0.4610\n",
      "Epoch 419/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9747 - accuracy: 0.5635 - val_loss: 1.3922 - val_accuracy: 0.4031\n",
      "Epoch 420/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9487 - accuracy: 0.5808 - val_loss: 1.2250 - val_accuracy: 0.4908\n",
      "Epoch 421/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9412 - accuracy: 0.5863 - val_loss: 1.2307 - val_accuracy: 0.4938\n",
      "Epoch 422/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9364 - accuracy: 0.6028 - val_loss: 1.2342 - val_accuracy: 0.4933\n",
      "Epoch 423/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9791 - accuracy: 0.5757 - val_loss: 1.2822 - val_accuracy: 0.4569\n",
      "Epoch 424/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9570 - accuracy: 0.5893 - val_loss: 1.2426 - val_accuracy: 0.5000\n",
      "Epoch 425/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9299 - accuracy: 0.5894 - val_loss: 1.2844 - val_accuracy: 0.4672\n",
      "Epoch 426/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9203 - accuracy: 0.6020 - val_loss: 1.2314 - val_accuracy: 0.4892\n",
      "Epoch 427/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9504 - accuracy: 0.5884 - val_loss: 1.4115 - val_accuracy: 0.3949\n",
      "Epoch 428/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0035 - accuracy: 0.5645 - val_loss: 1.2435 - val_accuracy: 0.4733\n",
      "Epoch 429/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9359 - accuracy: 0.5816 - val_loss: 1.2376 - val_accuracy: 0.5031\n",
      "Epoch 430/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9247 - accuracy: 0.5888 - val_loss: 1.3253 - val_accuracy: 0.4667\n",
      "Epoch 431/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9225 - accuracy: 0.5985 - val_loss: 1.2986 - val_accuracy: 0.4564\n",
      "Epoch 432/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9240 - accuracy: 0.5997 - val_loss: 1.2827 - val_accuracy: 0.4785\n",
      "Epoch 433/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9515 - accuracy: 0.5852 - val_loss: 1.2689 - val_accuracy: 0.5123\n",
      "Epoch 434/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9650 - accuracy: 0.5774 - val_loss: 1.2990 - val_accuracy: 0.4631\n",
      "Epoch 435/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9168 - accuracy: 0.5955 - val_loss: 1.3675 - val_accuracy: 0.4272\n",
      "Epoch 436/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9210 - accuracy: 0.6006 - val_loss: 1.3045 - val_accuracy: 0.4323\n",
      "Epoch 437/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9668 - accuracy: 0.5884 - val_loss: 1.2550 - val_accuracy: 0.4554\n",
      "Epoch 438/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9210 - accuracy: 0.5928 - val_loss: 1.2573 - val_accuracy: 0.4867\n",
      "Epoch 439/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9212 - accuracy: 0.6001 - val_loss: 1.2515 - val_accuracy: 0.4851\n",
      "Epoch 440/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9299 - accuracy: 0.5981 - val_loss: 1.2957 - val_accuracy: 0.4503\n",
      "Epoch 441/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9341 - accuracy: 0.5874 - val_loss: 1.3146 - val_accuracy: 0.4349\n",
      "Epoch 442/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.6052 - val_loss: 1.2546 - val_accuracy: 0.4826\n",
      "Epoch 443/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9318 - accuracy: 0.5888 - val_loss: 1.3551 - val_accuracy: 0.4379\n",
      "Epoch 444/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9047 - accuracy: 0.6056 - val_loss: 1.2775 - val_accuracy: 0.4831\n",
      "Epoch 445/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.5888 - val_loss: 1.2677 - val_accuracy: 0.4990\n",
      "Epoch 446/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9004 - accuracy: 0.6048 - val_loss: 1.2534 - val_accuracy: 0.4723\n",
      "Epoch 447/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9239 - accuracy: 0.6061 - val_loss: 1.3781 - val_accuracy: 0.4262\n",
      "Epoch 448/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9462 - accuracy: 0.5868 - val_loss: 1.2693 - val_accuracy: 0.4944\n",
      "Epoch 449/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9325 - accuracy: 0.6028 - val_loss: 1.2686 - val_accuracy: 0.4697\n",
      "Epoch 450/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9137 - accuracy: 0.6056 - val_loss: 1.2456 - val_accuracy: 0.4949\n",
      "Epoch 451/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9107 - accuracy: 0.6077 - val_loss: 1.2946 - val_accuracy: 0.4569\n",
      "Epoch 452/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9246 - accuracy: 0.5998 - val_loss: 1.3881 - val_accuracy: 0.4113\n",
      "Epoch 453/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9446 - accuracy: 0.5840 - val_loss: 1.2243 - val_accuracy: 0.5000\n",
      "Epoch 454/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9314 - accuracy: 0.6006 - val_loss: 1.2672 - val_accuracy: 0.4928\n",
      "Epoch 455/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9190 - accuracy: 0.6047 - val_loss: 1.2585 - val_accuracy: 0.4703\n",
      "Epoch 456/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9348 - accuracy: 0.5962 - val_loss: 1.2376 - val_accuracy: 0.4974\n",
      "Epoch 457/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9403 - accuracy: 0.5883 - val_loss: 1.2826 - val_accuracy: 0.4749\n",
      "Epoch 458/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9308 - accuracy: 0.5976 - val_loss: 1.2644 - val_accuracy: 0.4897\n",
      "Epoch 459/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9415 - accuracy: 0.5862 - val_loss: 1.2679 - val_accuracy: 0.5077\n",
      "Epoch 460/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0110 - accuracy: 0.5619 - val_loss: 1.2750 - val_accuracy: 0.4846\n",
      "Epoch 461/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9555 - accuracy: 0.5947 - val_loss: 1.2884 - val_accuracy: 0.4641\n",
      "Epoch 462/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9084 - accuracy: 0.6073 - val_loss: 1.3927 - val_accuracy: 0.4128\n",
      "Epoch 463/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8924 - accuracy: 0.6189 - val_loss: 1.2767 - val_accuracy: 0.4826\n",
      "Epoch 464/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9425 - accuracy: 0.5862 - val_loss: 1.3843 - val_accuracy: 0.4169\n",
      "Epoch 465/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9334 - accuracy: 0.6025 - val_loss: 1.2874 - val_accuracy: 0.4856\n",
      "Epoch 466/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9252 - accuracy: 0.5983 - val_loss: 1.3762 - val_accuracy: 0.4262\n",
      "Epoch 467/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9367 - accuracy: 0.5960 - val_loss: 1.2757 - val_accuracy: 0.4897\n",
      "Epoch 468/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9278 - accuracy: 0.6098 - val_loss: 1.2485 - val_accuracy: 0.4867\n",
      "Epoch 469/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9175 - accuracy: 0.5993 - val_loss: 1.3581 - val_accuracy: 0.4256\n",
      "Epoch 470/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9546 - accuracy: 0.5857 - val_loss: 1.3046 - val_accuracy: 0.4626\n",
      "Epoch 471/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9334 - accuracy: 0.5965 - val_loss: 1.3008 - val_accuracy: 0.4759\n",
      "Epoch 472/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9305 - accuracy: 0.5962 - val_loss: 1.2808 - val_accuracy: 0.4923\n",
      "Epoch 473/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9264 - accuracy: 0.6022 - val_loss: 1.2641 - val_accuracy: 0.4805\n",
      "Epoch 474/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.5933 - val_loss: 1.2870 - val_accuracy: 0.4759\n",
      "Epoch 475/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9233 - accuracy: 0.5936 - val_loss: 1.3409 - val_accuracy: 0.4579\n",
      "Epoch 476/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9382 - accuracy: 0.5922 - val_loss: 1.2338 - val_accuracy: 0.4959\n",
      "Epoch 477/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9433 - accuracy: 0.5931 - val_loss: 1.3675 - val_accuracy: 0.4210\n",
      "Epoch 478/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9259 - accuracy: 0.5895 - val_loss: 1.3339 - val_accuracy: 0.4277\n",
      "Epoch 479/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9141 - accuracy: 0.5994 - val_loss: 1.2713 - val_accuracy: 0.4815\n",
      "Epoch 480/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9008 - accuracy: 0.6010 - val_loss: 1.2723 - val_accuracy: 0.4969\n",
      "Epoch 481/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.5991 - val_loss: 1.3338 - val_accuracy: 0.4333\n",
      "Epoch 482/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.5792 - val_loss: 1.2752 - val_accuracy: 0.4892\n",
      "Epoch 483/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9068 - accuracy: 0.5991 - val_loss: 1.2984 - val_accuracy: 0.4667\n",
      "Epoch 484/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9090 - accuracy: 0.6130 - val_loss: 1.2636 - val_accuracy: 0.5000\n",
      "Epoch 485/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8973 - accuracy: 0.6109 - val_loss: 1.3347 - val_accuracy: 0.4415\n",
      "Epoch 486/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9960 - accuracy: 0.5560 - val_loss: 1.2647 - val_accuracy: 0.4923\n",
      "Epoch 487/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9443 - accuracy: 0.5824 - val_loss: 1.2826 - val_accuracy: 0.4774\n",
      "Epoch 488/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9053 - accuracy: 0.5912 - val_loss: 1.2004 - val_accuracy: 0.5046\n",
      "Epoch 489/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9142 - accuracy: 0.6025 - val_loss: 1.2788 - val_accuracy: 0.4867\n",
      "Epoch 490/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9163 - accuracy: 0.6037 - val_loss: 1.3040 - val_accuracy: 0.4728\n",
      "Epoch 491/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9007 - accuracy: 0.6155 - val_loss: 1.3260 - val_accuracy: 0.4482\n",
      "Epoch 492/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9241 - accuracy: 0.6057 - val_loss: 1.3052 - val_accuracy: 0.4718\n",
      "Epoch 493/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9236 - accuracy: 0.5918 - val_loss: 1.3514 - val_accuracy: 0.4590\n",
      "Epoch 494/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9289 - accuracy: 0.6032 - val_loss: 1.3199 - val_accuracy: 0.4718\n",
      "Epoch 495/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8964 - accuracy: 0.6088 - val_loss: 1.3121 - val_accuracy: 0.4923\n",
      "Epoch 496/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9265 - accuracy: 0.5959 - val_loss: 1.2606 - val_accuracy: 0.4964\n",
      "Epoch 497/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8893 - accuracy: 0.6110 - val_loss: 1.3923 - val_accuracy: 0.4138\n",
      "Epoch 498/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9034 - accuracy: 0.6011 - val_loss: 1.2779 - val_accuracy: 0.4923\n",
      "Epoch 499/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9095 - accuracy: 0.6087 - val_loss: 1.2838 - val_accuracy: 0.4718\n",
      "Epoch 500/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9178 - accuracy: 0.5947 - val_loss: 1.3802 - val_accuracy: 0.4133\n",
      "Epoch 501/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9014 - accuracy: 0.6141 - val_loss: 1.2860 - val_accuracy: 0.4590\n",
      "Epoch 502/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9317 - accuracy: 0.5853 - val_loss: 1.2915 - val_accuracy: 0.4646\n",
      "Epoch 503/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9083 - accuracy: 0.6130 - val_loss: 1.3011 - val_accuracy: 0.4872\n",
      "Epoch 504/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.6010 - val_loss: 1.3374 - val_accuracy: 0.4826\n",
      "Epoch 505/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9186 - accuracy: 0.6072 - val_loss: 1.2769 - val_accuracy: 0.4821\n",
      "Epoch 506/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9136 - accuracy: 0.6117 - val_loss: 1.2815 - val_accuracy: 0.5138\n",
      "Epoch 507/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9297 - accuracy: 0.5974 - val_loss: 1.3497 - val_accuracy: 0.4728\n",
      "Epoch 508/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9399 - accuracy: 0.5887 - val_loss: 1.3552 - val_accuracy: 0.4969\n",
      "Epoch 509/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8999 - accuracy: 0.6096 - val_loss: 1.3234 - val_accuracy: 0.4821\n",
      "Epoch 510/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8921 - accuracy: 0.6165 - val_loss: 1.5196 - val_accuracy: 0.3795\n",
      "Epoch 511/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0152 - accuracy: 0.5501 - val_loss: 1.2808 - val_accuracy: 0.5097\n",
      "Epoch 512/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9232 - accuracy: 0.6027 - val_loss: 1.3121 - val_accuracy: 0.4969\n",
      "Epoch 513/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.6111 - val_loss: 1.3110 - val_accuracy: 0.4677\n",
      "Epoch 514/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9284 - accuracy: 0.5935 - val_loss: 1.3141 - val_accuracy: 0.4887\n",
      "Epoch 515/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9078 - accuracy: 0.6152 - val_loss: 1.3045 - val_accuracy: 0.4908\n",
      "Epoch 516/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9140 - accuracy: 0.6147 - val_loss: 1.3615 - val_accuracy: 0.4456\n",
      "Epoch 517/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8994 - accuracy: 0.6052 - val_loss: 1.3979 - val_accuracy: 0.4159\n",
      "Epoch 518/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9161 - accuracy: 0.5968 - val_loss: 1.2765 - val_accuracy: 0.4856\n",
      "Epoch 519/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9128 - accuracy: 0.6030 - val_loss: 1.3259 - val_accuracy: 0.4626\n",
      "Epoch 520/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9384 - accuracy: 0.5749 - val_loss: 1.3402 - val_accuracy: 0.4692\n",
      "Epoch 521/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9100 - accuracy: 0.6094 - val_loss: 1.3862 - val_accuracy: 0.4605\n",
      "Epoch 522/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9110 - accuracy: 0.6160 - val_loss: 1.3222 - val_accuracy: 0.4831\n",
      "Epoch 523/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8740 - accuracy: 0.6131 - val_loss: 1.3389 - val_accuracy: 0.4821\n",
      "Epoch 524/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9104 - accuracy: 0.6007 - val_loss: 1.3467 - val_accuracy: 0.4785\n",
      "Epoch 525/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9777 - accuracy: 0.5936 - val_loss: 1.3396 - val_accuracy: 0.4656\n",
      "Epoch 526/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.6108 - val_loss: 1.4015 - val_accuracy: 0.4246\n",
      "Epoch 527/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8944 - accuracy: 0.6094 - val_loss: 1.4166 - val_accuracy: 0.4569\n",
      "Epoch 528/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9166 - accuracy: 0.6013 - val_loss: 1.3229 - val_accuracy: 0.4903\n",
      "Epoch 529/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8858 - accuracy: 0.6117 - val_loss: 1.3447 - val_accuracy: 0.4708\n",
      "Epoch 530/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9087 - accuracy: 0.6033 - val_loss: 1.3571 - val_accuracy: 0.4692\n",
      "Epoch 531/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9096 - accuracy: 0.6005 - val_loss: 1.3537 - val_accuracy: 0.4513\n",
      "Epoch 532/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8916 - accuracy: 0.6151 - val_loss: 1.2632 - val_accuracy: 0.5010\n",
      "Epoch 533/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9826 - accuracy: 0.5893 - val_loss: 1.3064 - val_accuracy: 0.4928\n",
      "Epoch 534/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8901 - accuracy: 0.6150 - val_loss: 1.3729 - val_accuracy: 0.4718\n",
      "Epoch 535/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8998 - accuracy: 0.6115 - val_loss: 1.3285 - val_accuracy: 0.4718\n",
      "Epoch 536/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8910 - accuracy: 0.6163 - val_loss: 1.3397 - val_accuracy: 0.4938\n",
      "Epoch 537/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9152 - accuracy: 0.5995 - val_loss: 1.3217 - val_accuracy: 0.4769\n",
      "Epoch 538/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9079 - accuracy: 0.6142 - val_loss: 1.3301 - val_accuracy: 0.4923\n",
      "Epoch 539/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8970 - accuracy: 0.6076 - val_loss: 1.3645 - val_accuracy: 0.4395\n",
      "Epoch 540/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9178 - accuracy: 0.6080 - val_loss: 1.4163 - val_accuracy: 0.4569\n",
      "Epoch 541/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.6259 - val_loss: 1.3276 - val_accuracy: 0.4877\n",
      "Epoch 542/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8785 - accuracy: 0.6135 - val_loss: 1.3695 - val_accuracy: 0.4713\n",
      "Epoch 543/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9036 - accuracy: 0.6033 - val_loss: 1.3123 - val_accuracy: 0.4897\n",
      "Epoch 544/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9241 - accuracy: 0.5999 - val_loss: 1.3799 - val_accuracy: 0.4682\n",
      "Epoch 545/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9025 - accuracy: 0.6039 - val_loss: 1.3046 - val_accuracy: 0.4810\n",
      "Epoch 546/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9126 - accuracy: 0.6087 - val_loss: 1.3836 - val_accuracy: 0.4492\n",
      "Epoch 547/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.5956 - val_loss: 1.3771 - val_accuracy: 0.5031\n",
      "Epoch 548/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9156 - accuracy: 0.5970 - val_loss: 1.4083 - val_accuracy: 0.4441\n",
      "Epoch 549/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9103 - accuracy: 0.6152 - val_loss: 1.4572 - val_accuracy: 0.4487\n",
      "Epoch 550/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9447 - accuracy: 0.5877 - val_loss: 1.4279 - val_accuracy: 0.4395\n",
      "Epoch 551/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9173 - accuracy: 0.6041 - val_loss: 1.3347 - val_accuracy: 0.4903\n",
      "Epoch 552/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8975 - accuracy: 0.6181 - val_loss: 1.3519 - val_accuracy: 0.4903\n",
      "Epoch 553/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8928 - accuracy: 0.6101 - val_loss: 1.3658 - val_accuracy: 0.4662\n",
      "Epoch 554/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8711 - accuracy: 0.6211 - val_loss: 1.3957 - val_accuracy: 0.4472\n",
      "Epoch 555/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9060 - accuracy: 0.6029 - val_loss: 1.4139 - val_accuracy: 0.4621\n",
      "Epoch 556/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8850 - accuracy: 0.6284 - val_loss: 1.3917 - val_accuracy: 0.4974\n",
      "Epoch 557/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8820 - accuracy: 0.6139 - val_loss: 1.4229 - val_accuracy: 0.4877\n",
      "Epoch 558/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9205 - accuracy: 0.6016 - val_loss: 1.3699 - val_accuracy: 0.4523\n",
      "Epoch 559/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8865 - accuracy: 0.6120 - val_loss: 1.3604 - val_accuracy: 0.4595\n",
      "Epoch 560/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8917 - accuracy: 0.6065 - val_loss: 1.3852 - val_accuracy: 0.5010\n",
      "Epoch 561/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9205 - accuracy: 0.5980 - val_loss: 1.4162 - val_accuracy: 0.4277\n",
      "Epoch 562/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9011 - accuracy: 0.6106 - val_loss: 1.3447 - val_accuracy: 0.4841\n",
      "Epoch 563/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8888 - accuracy: 0.6160 - val_loss: 1.4080 - val_accuracy: 0.4718\n",
      "Epoch 564/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9069 - accuracy: 0.6090 - val_loss: 1.4109 - val_accuracy: 0.4318\n",
      "Epoch 565/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9091 - accuracy: 0.6024 - val_loss: 1.3701 - val_accuracy: 0.4749\n",
      "Epoch 566/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9079 - accuracy: 0.6008 - val_loss: 1.3315 - val_accuracy: 0.4897\n",
      "Epoch 567/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9081 - accuracy: 0.6034 - val_loss: 1.3388 - val_accuracy: 0.4774\n",
      "Epoch 568/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9248 - accuracy: 0.6020 - val_loss: 1.4379 - val_accuracy: 0.4728\n",
      "Epoch 569/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9263 - accuracy: 0.6003 - val_loss: 1.4182 - val_accuracy: 0.4564\n",
      "Epoch 570/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8773 - accuracy: 0.6160 - val_loss: 1.5175 - val_accuracy: 0.3949\n",
      "Epoch 571/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9026 - accuracy: 0.6143 - val_loss: 1.4937 - val_accuracy: 0.4215\n",
      "Epoch 572/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9721 - accuracy: 0.5670 - val_loss: 1.3469 - val_accuracy: 0.5031\n",
      "Epoch 573/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9412 - accuracy: 0.6011 - val_loss: 1.3926 - val_accuracy: 0.4723\n",
      "Epoch 574/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8866 - accuracy: 0.6094 - val_loss: 1.3973 - val_accuracy: 0.4938\n",
      "Epoch 575/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9073 - accuracy: 0.6159 - val_loss: 1.5169 - val_accuracy: 0.4051\n",
      "Epoch 576/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9295 - accuracy: 0.5989 - val_loss: 1.4511 - val_accuracy: 0.4405\n",
      "Epoch 577/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8984 - accuracy: 0.6105 - val_loss: 1.3633 - val_accuracy: 0.5005\n",
      "Epoch 578/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9061 - accuracy: 0.6097 - val_loss: 1.4569 - val_accuracy: 0.4615\n",
      "Epoch 579/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9169 - accuracy: 0.6025 - val_loss: 1.2966 - val_accuracy: 0.4928\n",
      "Epoch 580/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8881 - accuracy: 0.6216 - val_loss: 1.3493 - val_accuracy: 0.4856\n",
      "Epoch 581/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9818 - accuracy: 0.5787 - val_loss: 1.3342 - val_accuracy: 0.5000\n",
      "Epoch 582/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8949 - accuracy: 0.6017 - val_loss: 1.3975 - val_accuracy: 0.4564\n",
      "Epoch 583/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9150 - accuracy: 0.6024 - val_loss: 1.3610 - val_accuracy: 0.4841\n",
      "Epoch 584/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8893 - accuracy: 0.6162 - val_loss: 1.4179 - val_accuracy: 0.4949\n",
      "Epoch 585/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9040 - accuracy: 0.6108 - val_loss: 1.3797 - val_accuracy: 0.5000\n",
      "Epoch 586/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9342 - accuracy: 0.5958 - val_loss: 1.3420 - val_accuracy: 0.4831\n",
      "Epoch 587/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8878 - accuracy: 0.6104 - val_loss: 1.4243 - val_accuracy: 0.4749\n",
      "Epoch 588/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9312 - accuracy: 0.5942 - val_loss: 1.3445 - val_accuracy: 0.4733\n",
      "Epoch 589/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9148 - accuracy: 0.6067 - val_loss: 1.4208 - val_accuracy: 0.4374\n",
      "Epoch 590/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8989 - accuracy: 0.6123 - val_loss: 1.3793 - val_accuracy: 0.4903\n",
      "Epoch 591/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9250 - accuracy: 0.6001 - val_loss: 1.4268 - val_accuracy: 0.4892\n",
      "Epoch 592/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8762 - accuracy: 0.6252 - val_loss: 1.3745 - val_accuracy: 0.4754\n",
      "Epoch 593/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8957 - accuracy: 0.6056 - val_loss: 1.3904 - val_accuracy: 0.4651\n",
      "Epoch 594/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8891 - accuracy: 0.6165 - val_loss: 1.4488 - val_accuracy: 0.4615\n",
      "Epoch 595/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8768 - accuracy: 0.6249 - val_loss: 1.3329 - val_accuracy: 0.4908\n",
      "Epoch 596/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0337 - accuracy: 0.5681 - val_loss: 1.3567 - val_accuracy: 0.4744\n",
      "Epoch 597/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9044 - accuracy: 0.6097 - val_loss: 1.4679 - val_accuracy: 0.4667\n",
      "Epoch 598/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9046 - accuracy: 0.6100 - val_loss: 1.4654 - val_accuracy: 0.4903\n",
      "Epoch 599/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9857 - accuracy: 0.5931 - val_loss: 1.4073 - val_accuracy: 0.4769\n",
      "Epoch 600/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8819 - accuracy: 0.6137 - val_loss: 1.4494 - val_accuracy: 0.4605\n",
      "Epoch 601/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8829 - accuracy: 0.6209 - val_loss: 1.3388 - val_accuracy: 0.4923\n",
      "Epoch 602/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8936 - accuracy: 0.6108 - val_loss: 1.3660 - val_accuracy: 0.4928\n",
      "Epoch 603/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8777 - accuracy: 0.6122 - val_loss: 1.3743 - val_accuracy: 0.4723\n",
      "Epoch 604/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9772 - accuracy: 0.5699 - val_loss: 1.3582 - val_accuracy: 0.4728\n",
      "Epoch 605/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8849 - accuracy: 0.6243 - val_loss: 1.3742 - val_accuracy: 0.4708\n",
      "Epoch 606/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8756 - accuracy: 0.6123 - val_loss: 1.3897 - val_accuracy: 0.4918\n",
      "Epoch 607/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8637 - accuracy: 0.6289 - val_loss: 1.3636 - val_accuracy: 0.4856\n",
      "Epoch 608/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8756 - accuracy: 0.6126 - val_loss: 1.4024 - val_accuracy: 0.4795\n",
      "Epoch 609/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9206 - accuracy: 0.6137 - val_loss: 1.3769 - val_accuracy: 0.4892\n",
      "Epoch 610/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9008 - accuracy: 0.6102 - val_loss: 1.3339 - val_accuracy: 0.4815\n",
      "Epoch 611/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8927 - accuracy: 0.6200 - val_loss: 1.4298 - val_accuracy: 0.4795\n",
      "Epoch 612/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9024 - accuracy: 0.6087 - val_loss: 1.3568 - val_accuracy: 0.4667\n",
      "Epoch 613/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9028 - accuracy: 0.5983 - val_loss: 1.3801 - val_accuracy: 0.4851\n",
      "Epoch 614/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9045 - accuracy: 0.6129 - val_loss: 1.3685 - val_accuracy: 0.4790\n",
      "Epoch 615/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8897 - accuracy: 0.6146 - val_loss: 1.5128 - val_accuracy: 0.4395\n",
      "Epoch 616/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9544 - accuracy: 0.5881 - val_loss: 1.3377 - val_accuracy: 0.4795\n",
      "Epoch 617/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8983 - accuracy: 0.6197 - val_loss: 1.3792 - val_accuracy: 0.4621\n",
      "Epoch 618/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8803 - accuracy: 0.6189 - val_loss: 1.4400 - val_accuracy: 0.4892\n",
      "Epoch 619/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8979 - accuracy: 0.6175 - val_loss: 1.4361 - val_accuracy: 0.4646\n",
      "Epoch 620/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9144 - accuracy: 0.6000 - val_loss: 1.4204 - val_accuracy: 0.4913\n",
      "Epoch 621/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8995 - accuracy: 0.6117 - val_loss: 1.4440 - val_accuracy: 0.4667\n",
      "Epoch 622/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8988 - accuracy: 0.6122 - val_loss: 1.4314 - val_accuracy: 0.4938\n",
      "Epoch 623/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.6088 - val_loss: 1.4667 - val_accuracy: 0.4677\n",
      "Epoch 624/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8801 - accuracy: 0.6116 - val_loss: 1.3647 - val_accuracy: 0.4959\n",
      "Epoch 625/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9080 - accuracy: 0.5961 - val_loss: 1.4642 - val_accuracy: 0.4682\n",
      "Epoch 626/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8868 - accuracy: 0.6207 - val_loss: 1.4139 - val_accuracy: 0.4595\n",
      "Epoch 627/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8553 - accuracy: 0.6289 - val_loss: 1.3922 - val_accuracy: 0.4887\n",
      "Epoch 628/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9103 - accuracy: 0.6011 - val_loss: 1.4685 - val_accuracy: 0.4651\n",
      "Epoch 629/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8719 - accuracy: 0.6120 - val_loss: 1.4091 - val_accuracy: 0.4769\n",
      "Epoch 630/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9097 - accuracy: 0.5980 - val_loss: 1.3613 - val_accuracy: 0.4985\n",
      "Epoch 631/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8968 - accuracy: 0.5972 - val_loss: 1.5407 - val_accuracy: 0.3892\n",
      "Epoch 632/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9142 - accuracy: 0.6119 - val_loss: 1.4261 - val_accuracy: 0.4682\n",
      "Epoch 633/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8927 - accuracy: 0.6105 - val_loss: 1.5024 - val_accuracy: 0.4349\n",
      "Epoch 634/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8725 - accuracy: 0.6265 - val_loss: 1.3971 - val_accuracy: 0.4872\n",
      "Epoch 635/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8888 - accuracy: 0.6031 - val_loss: 1.4086 - val_accuracy: 0.4862\n",
      "Epoch 636/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8714 - accuracy: 0.6237 - val_loss: 1.4156 - val_accuracy: 0.4821\n",
      "Epoch 637/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8844 - accuracy: 0.6275 - val_loss: 1.4877 - val_accuracy: 0.4692\n",
      "Epoch 638/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9002 - accuracy: 0.6224 - val_loss: 1.5069 - val_accuracy: 0.4508\n",
      "Epoch 639/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8699 - accuracy: 0.6302 - val_loss: 1.4058 - val_accuracy: 0.4821\n",
      "Epoch 640/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8937 - accuracy: 0.6055 - val_loss: 1.5385 - val_accuracy: 0.4292\n",
      "Epoch 641/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9431 - accuracy: 0.5878 - val_loss: 1.6066 - val_accuracy: 0.3892\n",
      "Epoch 642/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9364 - accuracy: 0.5868 - val_loss: 1.4627 - val_accuracy: 0.4626\n",
      "Epoch 643/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8824 - accuracy: 0.6156 - val_loss: 1.4315 - val_accuracy: 0.4733\n",
      "Epoch 644/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8990 - accuracy: 0.6140 - val_loss: 1.4985 - val_accuracy: 0.4754\n",
      "Epoch 645/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8905 - accuracy: 0.6237 - val_loss: 1.5346 - val_accuracy: 0.4138\n",
      "Epoch 646/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8835 - accuracy: 0.6152 - val_loss: 1.4187 - val_accuracy: 0.4687\n",
      "Epoch 647/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8782 - accuracy: 0.6267 - val_loss: 1.4234 - val_accuracy: 0.4882\n",
      "Epoch 648/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0514 - accuracy: 0.5771 - val_loss: 1.4017 - val_accuracy: 0.4769\n",
      "Epoch 649/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8894 - accuracy: 0.6161 - val_loss: 1.4380 - val_accuracy: 0.4754\n",
      "Epoch 650/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8682 - accuracy: 0.6207 - val_loss: 1.4424 - val_accuracy: 0.4692\n",
      "Epoch 651/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9513 - accuracy: 0.5902 - val_loss: 1.4453 - val_accuracy: 0.4600\n",
      "Epoch 652/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9428 - accuracy: 0.5868 - val_loss: 1.4267 - val_accuracy: 0.4877\n",
      "Epoch 653/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9237 - accuracy: 0.5969 - val_loss: 1.3640 - val_accuracy: 0.4821\n",
      "Epoch 654/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.5924 - val_loss: 1.4713 - val_accuracy: 0.4410\n",
      "Epoch 655/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8926 - accuracy: 0.6140 - val_loss: 1.4378 - val_accuracy: 0.4672\n",
      "Epoch 656/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9139 - accuracy: 0.6074 - val_loss: 1.4260 - val_accuracy: 0.4723\n",
      "Epoch 657/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8935 - accuracy: 0.6158 - val_loss: 1.5088 - val_accuracy: 0.4036\n",
      "Epoch 658/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8940 - accuracy: 0.6147 - val_loss: 1.3148 - val_accuracy: 0.4949\n",
      "Epoch 659/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8821 - accuracy: 0.6084 - val_loss: 1.3688 - val_accuracy: 0.4769\n",
      "Epoch 660/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8895 - accuracy: 0.6213 - val_loss: 1.4666 - val_accuracy: 0.4677\n",
      "Epoch 661/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9001 - accuracy: 0.5960 - val_loss: 1.3986 - val_accuracy: 0.4774\n",
      "Epoch 662/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8956 - accuracy: 0.6118 - val_loss: 1.4509 - val_accuracy: 0.4733\n",
      "Epoch 663/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8930 - accuracy: 0.6064 - val_loss: 1.4706 - val_accuracy: 0.4774\n",
      "Epoch 664/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8857 - accuracy: 0.6139 - val_loss: 1.4408 - val_accuracy: 0.4815\n",
      "Epoch 665/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8681 - accuracy: 0.6242 - val_loss: 1.4379 - val_accuracy: 0.5000\n",
      "Epoch 666/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9198 - accuracy: 0.6020 - val_loss: 1.4645 - val_accuracy: 0.4549\n",
      "Epoch 667/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9058 - accuracy: 0.6133 - val_loss: 1.3814 - val_accuracy: 0.4810\n",
      "Epoch 668/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8761 - accuracy: 0.6235 - val_loss: 1.4683 - val_accuracy: 0.4872\n",
      "Epoch 669/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8782 - accuracy: 0.6125 - val_loss: 1.4426 - val_accuracy: 0.4908\n",
      "Epoch 670/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8793 - accuracy: 0.6238 - val_loss: 1.5285 - val_accuracy: 0.4456\n",
      "Epoch 671/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8688 - accuracy: 0.6311 - val_loss: 1.4517 - val_accuracy: 0.4851\n",
      "Epoch 672/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.6100 - val_loss: 1.4337 - val_accuracy: 0.4703\n",
      "Epoch 673/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8681 - accuracy: 0.6177 - val_loss: 1.5643 - val_accuracy: 0.4390\n",
      "Epoch 674/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9405 - accuracy: 0.5942 - val_loss: 1.4457 - val_accuracy: 0.4579\n",
      "Epoch 675/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9110 - accuracy: 0.6126 - val_loss: 1.4674 - val_accuracy: 0.4846\n",
      "Epoch 676/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8846 - accuracy: 0.6119 - val_loss: 1.4323 - val_accuracy: 0.4656\n",
      "Epoch 677/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8861 - accuracy: 0.6124 - val_loss: 1.4279 - val_accuracy: 0.4718\n",
      "Epoch 678/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8832 - accuracy: 0.6197 - val_loss: 1.5181 - val_accuracy: 0.4949\n",
      "Epoch 679/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8643 - accuracy: 0.6182 - val_loss: 1.4105 - val_accuracy: 0.4938\n",
      "Epoch 680/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8992 - accuracy: 0.6056 - val_loss: 1.5056 - val_accuracy: 0.4923\n",
      "Epoch 681/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9179 - accuracy: 0.6014 - val_loss: 1.5130 - val_accuracy: 0.4626\n",
      "Epoch 682/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9085 - accuracy: 0.6115 - val_loss: 1.4870 - val_accuracy: 0.4610\n",
      "Epoch 683/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8607 - accuracy: 0.6336 - val_loss: 1.4883 - val_accuracy: 0.4333\n",
      "Epoch 684/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8620 - accuracy: 0.6322 - val_loss: 1.4352 - val_accuracy: 0.4990\n",
      "Epoch 685/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9131 - accuracy: 0.6052 - val_loss: 1.4935 - val_accuracy: 0.4877\n",
      "Epoch 686/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8822 - accuracy: 0.6123 - val_loss: 1.4482 - val_accuracy: 0.4759\n",
      "Epoch 687/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8565 - accuracy: 0.6320 - val_loss: 1.5278 - val_accuracy: 0.4703\n",
      "Epoch 688/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8706 - accuracy: 0.6211 - val_loss: 1.4799 - val_accuracy: 0.4790\n",
      "Epoch 689/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9061 - accuracy: 0.6074 - val_loss: 1.5060 - val_accuracy: 0.4446\n",
      "Epoch 690/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9145 - accuracy: 0.6075 - val_loss: 1.5054 - val_accuracy: 0.4605\n",
      "Epoch 691/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8841 - accuracy: 0.6217 - val_loss: 1.4709 - val_accuracy: 0.4677\n",
      "Epoch 692/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9334 - accuracy: 0.5989 - val_loss: 1.5205 - val_accuracy: 0.4821\n",
      "Epoch 693/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8842 - accuracy: 0.6261 - val_loss: 1.4900 - val_accuracy: 0.4728\n",
      "Epoch 694/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8716 - accuracy: 0.6218 - val_loss: 1.5337 - val_accuracy: 0.4800\n",
      "Epoch 695/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8833 - accuracy: 0.6262 - val_loss: 1.4666 - val_accuracy: 0.4754\n",
      "Epoch 696/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8897 - accuracy: 0.6136 - val_loss: 1.4452 - val_accuracy: 0.4841\n",
      "Epoch 697/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8962 - accuracy: 0.6112 - val_loss: 1.5168 - val_accuracy: 0.4713\n",
      "Epoch 698/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8811 - accuracy: 0.6154 - val_loss: 1.5176 - val_accuracy: 0.4133\n",
      "Epoch 699/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.5993 - val_loss: 1.5046 - val_accuracy: 0.4349\n",
      "Epoch 700/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9009 - accuracy: 0.6074 - val_loss: 1.4767 - val_accuracy: 0.4831\n",
      "Epoch 701/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9089 - accuracy: 0.6098 - val_loss: 1.5464 - val_accuracy: 0.4513\n",
      "Epoch 702/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9063 - accuracy: 0.6120 - val_loss: 1.5661 - val_accuracy: 0.4795\n",
      "Epoch 703/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8619 - accuracy: 0.6274 - val_loss: 1.4268 - val_accuracy: 0.4872\n",
      "Epoch 704/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8895 - accuracy: 0.6104 - val_loss: 1.5064 - val_accuracy: 0.4600\n",
      "Epoch 705/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8989 - accuracy: 0.6252 - val_loss: 1.5005 - val_accuracy: 0.4533\n",
      "Epoch 706/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8629 - accuracy: 0.6223 - val_loss: 1.5144 - val_accuracy: 0.4708\n",
      "Epoch 707/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8857 - accuracy: 0.6179 - val_loss: 1.5400 - val_accuracy: 0.4508\n",
      "Epoch 708/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9218 - accuracy: 0.6011 - val_loss: 1.4918 - val_accuracy: 0.4923\n",
      "Epoch 709/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8872 - accuracy: 0.6214 - val_loss: 1.4908 - val_accuracy: 0.4918\n",
      "Epoch 710/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8968 - accuracy: 0.6062 - val_loss: 1.5281 - val_accuracy: 0.4277\n",
      "Epoch 711/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8726 - accuracy: 0.6247 - val_loss: 1.6709 - val_accuracy: 0.4385\n",
      "Epoch 712/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8871 - accuracy: 0.6229 - val_loss: 1.4343 - val_accuracy: 0.4703\n",
      "Epoch 713/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8660 - accuracy: 0.6356 - val_loss: 1.5658 - val_accuracy: 0.4615\n",
      "Epoch 714/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9118 - accuracy: 0.6069 - val_loss: 1.5006 - val_accuracy: 0.4785\n",
      "Epoch 715/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8862 - accuracy: 0.6193 - val_loss: 1.4651 - val_accuracy: 0.4513\n",
      "Epoch 716/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8790 - accuracy: 0.6210 - val_loss: 1.6057 - val_accuracy: 0.4138\n",
      "Epoch 717/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9832 - accuracy: 0.5748 - val_loss: 1.4510 - val_accuracy: 0.4918\n",
      "Epoch 718/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8824 - accuracy: 0.6112 - val_loss: 1.4649 - val_accuracy: 0.4815\n",
      "Epoch 719/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8593 - accuracy: 0.6252 - val_loss: 1.4823 - val_accuracy: 0.4795\n",
      "Epoch 720/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8727 - accuracy: 0.6157 - val_loss: 1.5033 - val_accuracy: 0.4708\n",
      "Epoch 721/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8878 - accuracy: 0.6183 - val_loss: 1.5808 - val_accuracy: 0.4077\n",
      "Epoch 722/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8762 - accuracy: 0.6200 - val_loss: 1.5375 - val_accuracy: 0.4908\n",
      "Epoch 723/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9362 - accuracy: 0.5974 - val_loss: 1.5018 - val_accuracy: 0.4610\n",
      "Epoch 724/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8919 - accuracy: 0.6084 - val_loss: 1.4346 - val_accuracy: 0.4928\n",
      "Epoch 725/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9092 - accuracy: 0.6161 - val_loss: 1.5259 - val_accuracy: 0.4810\n",
      "Epoch 726/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8691 - accuracy: 0.6305 - val_loss: 1.5446 - val_accuracy: 0.4713\n",
      "Epoch 727/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9024 - accuracy: 0.6042 - val_loss: 1.5354 - val_accuracy: 0.4467\n",
      "Epoch 728/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8722 - accuracy: 0.6195 - val_loss: 1.4595 - val_accuracy: 0.5000\n",
      "Epoch 729/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8480 - accuracy: 0.6382 - val_loss: 1.5019 - val_accuracy: 0.4846\n",
      "Epoch 730/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8507 - accuracy: 0.6446 - val_loss: 1.5287 - val_accuracy: 0.4672\n",
      "Epoch 731/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8603 - accuracy: 0.6357 - val_loss: 1.6080 - val_accuracy: 0.4185\n",
      "Epoch 732/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9096 - accuracy: 0.6114 - val_loss: 1.5554 - val_accuracy: 0.4549\n",
      "Epoch 733/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9182 - accuracy: 0.5969 - val_loss: 1.4839 - val_accuracy: 0.4897\n",
      "Epoch 734/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8526 - accuracy: 0.6326 - val_loss: 1.5642 - val_accuracy: 0.4882\n",
      "Epoch 735/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9024 - accuracy: 0.6142 - val_loss: 1.5773 - val_accuracy: 0.4846\n",
      "Epoch 736/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8587 - accuracy: 0.6337 - val_loss: 1.5905 - val_accuracy: 0.4815\n",
      "Epoch 737/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8721 - accuracy: 0.6185 - val_loss: 1.5859 - val_accuracy: 0.5046\n",
      "Epoch 738/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9064 - accuracy: 0.5952 - val_loss: 1.5839 - val_accuracy: 0.4564\n",
      "Epoch 739/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8695 - accuracy: 0.6298 - val_loss: 1.6609 - val_accuracy: 0.4749\n",
      "Epoch 740/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9297 - accuracy: 0.6092 - val_loss: 1.5677 - val_accuracy: 0.4472\n",
      "Epoch 741/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8570 - accuracy: 0.6279 - val_loss: 1.5546 - val_accuracy: 0.4882\n",
      "Epoch 742/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9227 - accuracy: 0.6107 - val_loss: 1.5925 - val_accuracy: 0.4513\n",
      "Epoch 743/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8894 - accuracy: 0.6234 - val_loss: 1.6284 - val_accuracy: 0.4446\n",
      "Epoch 744/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8756 - accuracy: 0.6316 - val_loss: 1.5419 - val_accuracy: 0.4708\n",
      "Epoch 745/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8563 - accuracy: 0.6274 - val_loss: 1.5381 - val_accuracy: 0.5026\n",
      "Epoch 746/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9156 - accuracy: 0.6072 - val_loss: 1.5644 - val_accuracy: 0.4841\n",
      "Epoch 747/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8653 - accuracy: 0.6311 - val_loss: 1.5952 - val_accuracy: 0.4518\n",
      "Epoch 748/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8788 - accuracy: 0.6189 - val_loss: 1.5464 - val_accuracy: 0.5005\n",
      "Epoch 749/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8668 - accuracy: 0.6259 - val_loss: 1.6451 - val_accuracy: 0.4805\n",
      "Epoch 750/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8602 - accuracy: 0.6297 - val_loss: 1.5680 - val_accuracy: 0.4549\n",
      "Epoch 751/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8469 - accuracy: 0.6319 - val_loss: 1.5675 - val_accuracy: 0.4677\n",
      "Epoch 752/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8590 - accuracy: 0.6276 - val_loss: 1.5886 - val_accuracy: 0.4872\n",
      "Epoch 753/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8526 - accuracy: 0.6309 - val_loss: 1.4188 - val_accuracy: 0.4923\n",
      "Epoch 754/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8764 - accuracy: 0.6220 - val_loss: 1.5003 - val_accuracy: 0.4979\n",
      "Epoch 755/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6126 - val_loss: 1.5279 - val_accuracy: 0.4467\n",
      "Epoch 756/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8826 - accuracy: 0.6217 - val_loss: 1.5660 - val_accuracy: 0.4318\n",
      "Epoch 757/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8690 - accuracy: 0.6188 - val_loss: 1.5519 - val_accuracy: 0.4749\n",
      "Epoch 758/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8450 - accuracy: 0.6510 - val_loss: 1.5601 - val_accuracy: 0.5010\n",
      "Epoch 759/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8819 - accuracy: 0.6249 - val_loss: 1.5707 - val_accuracy: 0.4477\n",
      "Epoch 760/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8675 - accuracy: 0.6299 - val_loss: 1.5571 - val_accuracy: 0.4851\n",
      "Epoch 761/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8703 - accuracy: 0.6220 - val_loss: 1.5556 - val_accuracy: 0.4656\n",
      "Epoch 762/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8668 - accuracy: 0.6226 - val_loss: 1.5929 - val_accuracy: 0.4544\n",
      "Epoch 763/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8693 - accuracy: 0.6175 - val_loss: 1.5643 - val_accuracy: 0.4974\n",
      "Epoch 764/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8615 - accuracy: 0.6283 - val_loss: 1.7170 - val_accuracy: 0.3995\n",
      "Epoch 765/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8705 - accuracy: 0.6256 - val_loss: 1.6053 - val_accuracy: 0.4056\n",
      "Epoch 766/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8705 - accuracy: 0.6257 - val_loss: 1.6148 - val_accuracy: 0.4528\n",
      "Epoch 767/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9073 - accuracy: 0.6147 - val_loss: 1.5357 - val_accuracy: 0.4841\n",
      "Epoch 768/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8775 - accuracy: 0.6215 - val_loss: 1.5156 - val_accuracy: 0.4497\n",
      "Epoch 769/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8847 - accuracy: 0.6112 - val_loss: 1.5840 - val_accuracy: 0.4103\n",
      "Epoch 770/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8981 - accuracy: 0.6120 - val_loss: 1.4154 - val_accuracy: 0.4836\n",
      "Epoch 771/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8547 - accuracy: 0.6263 - val_loss: 1.4940 - val_accuracy: 0.4641\n",
      "Epoch 772/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.6072 - val_loss: 1.5683 - val_accuracy: 0.4687\n",
      "Epoch 773/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8800 - accuracy: 0.6285 - val_loss: 1.5744 - val_accuracy: 0.4862\n",
      "Epoch 774/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8513 - accuracy: 0.6342 - val_loss: 1.5572 - val_accuracy: 0.4846\n",
      "Epoch 775/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8704 - accuracy: 0.6300 - val_loss: 1.6049 - val_accuracy: 0.4508\n",
      "Epoch 776/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8914 - accuracy: 0.6119 - val_loss: 1.5970 - val_accuracy: 0.4600\n",
      "Epoch 777/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8751 - accuracy: 0.6252 - val_loss: 1.5787 - val_accuracy: 0.4549\n",
      "Epoch 778/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8975 - accuracy: 0.6219 - val_loss: 1.5882 - val_accuracy: 0.4544\n",
      "Epoch 779/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8955 - accuracy: 0.6148 - val_loss: 1.6313 - val_accuracy: 0.4764\n",
      "Epoch 780/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8633 - accuracy: 0.6254 - val_loss: 1.6091 - val_accuracy: 0.4164\n",
      "Epoch 781/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8462 - accuracy: 0.6394 - val_loss: 1.5406 - val_accuracy: 0.4785\n",
      "Epoch 782/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9774 - accuracy: 0.5813 - val_loss: 1.5276 - val_accuracy: 0.4651\n",
      "Epoch 783/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8697 - accuracy: 0.6267 - val_loss: 1.5067 - val_accuracy: 0.4703\n",
      "Epoch 784/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8643 - accuracy: 0.6265 - val_loss: 1.5237 - val_accuracy: 0.4800\n",
      "Epoch 785/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8795 - accuracy: 0.6135 - val_loss: 1.5867 - val_accuracy: 0.4169\n",
      "Epoch 786/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9031 - accuracy: 0.6094 - val_loss: 1.5986 - val_accuracy: 0.4215\n",
      "Epoch 787/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9005 - accuracy: 0.6030 - val_loss: 1.5634 - val_accuracy: 0.4636\n",
      "Epoch 788/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8590 - accuracy: 0.6208 - val_loss: 1.5136 - val_accuracy: 0.4821\n",
      "Epoch 789/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8675 - accuracy: 0.6331 - val_loss: 1.5138 - val_accuracy: 0.4795\n",
      "Epoch 790/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8852 - accuracy: 0.6067 - val_loss: 1.5897 - val_accuracy: 0.4672\n",
      "Epoch 791/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8481 - accuracy: 0.6410 - val_loss: 1.5969 - val_accuracy: 0.4426\n",
      "Epoch 792/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8549 - accuracy: 0.6250 - val_loss: 1.5322 - val_accuracy: 0.4718\n",
      "Epoch 793/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8651 - accuracy: 0.6232 - val_loss: 1.5762 - val_accuracy: 0.4728\n",
      "Epoch 794/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8753 - accuracy: 0.6161 - val_loss: 1.5623 - val_accuracy: 0.4718\n",
      "Epoch 795/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8358 - accuracy: 0.6422 - val_loss: 1.5518 - val_accuracy: 0.4897\n",
      "Epoch 796/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9820 - accuracy: 0.5712 - val_loss: 1.5137 - val_accuracy: 0.4641\n",
      "Epoch 797/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9203 - accuracy: 0.5930 - val_loss: 1.5806 - val_accuracy: 0.4969\n",
      "Epoch 798/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8663 - accuracy: 0.6236 - val_loss: 1.7690 - val_accuracy: 0.3497\n",
      "Epoch 799/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0391 - accuracy: 0.5362 - val_loss: 1.4812 - val_accuracy: 0.4882\n",
      "Epoch 800/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8873 - accuracy: 0.6218 - val_loss: 1.5126 - val_accuracy: 0.4621\n",
      "Epoch 801/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9336 - accuracy: 0.6005 - val_loss: 1.6120 - val_accuracy: 0.4749\n",
      "Epoch 802/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8928 - accuracy: 0.6050 - val_loss: 1.5886 - val_accuracy: 0.4790\n",
      "Epoch 803/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8718 - accuracy: 0.6220 - val_loss: 1.5858 - val_accuracy: 0.4697\n",
      "Epoch 804/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.6242 - val_loss: 1.6407 - val_accuracy: 0.4610\n",
      "Epoch 805/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8622 - accuracy: 0.6368 - val_loss: 1.5590 - val_accuracy: 0.4938\n",
      "Epoch 806/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8572 - accuracy: 0.6304 - val_loss: 1.5898 - val_accuracy: 0.4503\n",
      "Epoch 807/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8582 - accuracy: 0.6376 - val_loss: 1.6841 - val_accuracy: 0.4205\n",
      "Epoch 808/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8801 - accuracy: 0.6240 - val_loss: 1.6207 - val_accuracy: 0.4610\n",
      "Epoch 809/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8663 - accuracy: 0.6261 - val_loss: 1.4942 - val_accuracy: 0.5051\n",
      "Epoch 810/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8623 - accuracy: 0.6293 - val_loss: 1.5886 - val_accuracy: 0.4949\n",
      "Epoch 811/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8346 - accuracy: 0.6442 - val_loss: 1.5707 - val_accuracy: 0.4672\n",
      "Epoch 812/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8664 - accuracy: 0.6252 - val_loss: 1.6463 - val_accuracy: 0.4544\n",
      "Epoch 813/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8616 - accuracy: 0.6370 - val_loss: 1.6715 - val_accuracy: 0.4723\n",
      "Epoch 814/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8571 - accuracy: 0.6198 - val_loss: 1.5149 - val_accuracy: 0.4513\n",
      "Epoch 815/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9244 - accuracy: 0.5944 - val_loss: 1.6316 - val_accuracy: 0.4713\n",
      "Epoch 816/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8617 - accuracy: 0.6369 - val_loss: 1.6219 - val_accuracy: 0.4733\n",
      "Epoch 817/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8780 - accuracy: 0.6289 - val_loss: 1.6959 - val_accuracy: 0.4738\n",
      "Epoch 818/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9222 - accuracy: 0.6076 - val_loss: 1.6069 - val_accuracy: 0.4764\n",
      "Epoch 819/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8574 - accuracy: 0.6258 - val_loss: 1.5768 - val_accuracy: 0.4856\n",
      "Epoch 820/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8618 - accuracy: 0.6236 - val_loss: 1.6880 - val_accuracy: 0.4056\n",
      "Epoch 821/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8618 - accuracy: 0.6246 - val_loss: 1.5780 - val_accuracy: 0.4754\n",
      "Epoch 822/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8763 - accuracy: 0.6271 - val_loss: 1.6235 - val_accuracy: 0.4395\n",
      "Epoch 823/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8603 - accuracy: 0.6275 - val_loss: 1.6620 - val_accuracy: 0.4482\n",
      "Epoch 824/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8698 - accuracy: 0.6273 - val_loss: 1.6794 - val_accuracy: 0.4882\n",
      "Epoch 825/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8538 - accuracy: 0.6412 - val_loss: 1.5628 - val_accuracy: 0.4851\n",
      "Epoch 826/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8480 - accuracy: 0.6267 - val_loss: 1.6745 - val_accuracy: 0.4738\n",
      "Epoch 827/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8408 - accuracy: 0.6297 - val_loss: 1.6250 - val_accuracy: 0.4836\n",
      "Epoch 828/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8545 - accuracy: 0.6367 - val_loss: 1.7016 - val_accuracy: 0.4964\n",
      "Epoch 829/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8985 - accuracy: 0.6123 - val_loss: 1.6187 - val_accuracy: 0.4790\n",
      "Epoch 830/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8687 - accuracy: 0.6215 - val_loss: 1.6079 - val_accuracy: 0.4754\n",
      "Epoch 831/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9066 - accuracy: 0.6050 - val_loss: 1.6334 - val_accuracy: 0.4456\n",
      "Epoch 832/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8859 - accuracy: 0.6083 - val_loss: 1.6033 - val_accuracy: 0.4574\n",
      "Epoch 833/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8528 - accuracy: 0.6307 - val_loss: 1.7013 - val_accuracy: 0.3928\n",
      "Epoch 834/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8716 - accuracy: 0.6202 - val_loss: 1.6767 - val_accuracy: 0.5015\n",
      "Epoch 835/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9003 - accuracy: 0.6147 - val_loss: 1.6796 - val_accuracy: 0.4262\n",
      "Epoch 836/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8818 - accuracy: 0.6152 - val_loss: 1.6562 - val_accuracy: 0.4292\n",
      "Epoch 837/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8743 - accuracy: 0.6198 - val_loss: 1.6411 - val_accuracy: 0.4959\n",
      "Epoch 838/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8591 - accuracy: 0.6283 - val_loss: 1.5007 - val_accuracy: 0.4544\n",
      "Epoch 839/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8840 - accuracy: 0.61 - 0s 2ms/step - loss: 0.8804 - accuracy: 0.6174 - val_loss: 1.6162 - val_accuracy: 0.4882\n",
      "Epoch 840/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8725 - accuracy: 0.6206 - val_loss: 1.6132 - val_accuracy: 0.4641\n",
      "Epoch 841/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8434 - accuracy: 0.6280 - val_loss: 1.5967 - val_accuracy: 0.4769\n",
      "Epoch 842/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8625 - accuracy: 0.6299 - val_loss: 1.6206 - val_accuracy: 0.4477\n",
      "Epoch 843/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8988 - accuracy: 0.6188 - val_loss: 1.6592 - val_accuracy: 0.4421\n",
      "Epoch 844/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8720 - accuracy: 0.6209 - val_loss: 1.6785 - val_accuracy: 0.4790\n",
      "Epoch 845/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8686 - accuracy: 0.6211 - val_loss: 1.6893 - val_accuracy: 0.4621\n",
      "Epoch 846/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8556 - accuracy: 0.6328 - val_loss: 1.5999 - val_accuracy: 0.4446\n",
      "Epoch 847/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8819 - accuracy: 0.6244 - val_loss: 1.6314 - val_accuracy: 0.4569\n",
      "Epoch 848/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8621 - accuracy: 0.6243 - val_loss: 1.6275 - val_accuracy: 0.4790\n",
      "Epoch 849/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8523 - accuracy: 0.6374 - val_loss: 1.7370 - val_accuracy: 0.4021\n",
      "Epoch 850/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9480 - accuracy: 0.5927 - val_loss: 1.6365 - val_accuracy: 0.4687\n",
      "Epoch 851/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8668 - accuracy: 0.6212 - val_loss: 1.6917 - val_accuracy: 0.4815\n",
      "Epoch 852/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8734 - accuracy: 0.6250 - val_loss: 1.6353 - val_accuracy: 0.4892\n",
      "Epoch 853/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8643 - accuracy: 0.6203 - val_loss: 1.7191 - val_accuracy: 0.4733\n",
      "Epoch 854/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8732 - accuracy: 0.6133 - val_loss: 1.5123 - val_accuracy: 0.4985\n",
      "Epoch 855/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9059 - accuracy: 0.6004 - val_loss: 1.5875 - val_accuracy: 0.4631\n",
      "Epoch 856/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8645 - accuracy: 0.6306 - val_loss: 1.5916 - val_accuracy: 0.4041\n",
      "Epoch 857/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8859 - accuracy: 0.6130 - val_loss: 1.5952 - val_accuracy: 0.4821\n",
      "Epoch 858/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8379 - accuracy: 0.6443 - val_loss: 1.5720 - val_accuracy: 0.4990\n",
      "Epoch 859/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8446 - accuracy: 0.6393 - val_loss: 1.7502 - val_accuracy: 0.4026\n",
      "Epoch 860/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9378 - accuracy: 0.6078 - val_loss: 1.6359 - val_accuracy: 0.4903\n",
      "Epoch 861/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8648 - accuracy: 0.6244 - val_loss: 1.6707 - val_accuracy: 0.4687\n",
      "Epoch 862/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8616 - accuracy: 0.6334 - val_loss: 1.7110 - val_accuracy: 0.4236\n",
      "Epoch 863/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8847 - accuracy: 0.61 - 0s 2ms/step - loss: 0.8836 - accuracy: 0.6193 - val_loss: 1.6116 - val_accuracy: 0.4626\n",
      "Epoch 864/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8553 - accuracy: 0.6236 - val_loss: 1.6931 - val_accuracy: 0.4272\n",
      "Epoch 865/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8583 - accuracy: 0.6264 - val_loss: 1.7058 - val_accuracy: 0.4815\n",
      "Epoch 866/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8843 - accuracy: 0.6143 - val_loss: 1.5458 - val_accuracy: 0.4831\n",
      "Epoch 867/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8584 - accuracy: 0.6258 - val_loss: 1.6038 - val_accuracy: 0.4677\n",
      "Epoch 868/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8503 - accuracy: 0.6416 - val_loss: 1.7131 - val_accuracy: 0.4626\n",
      "Epoch 869/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8859 - accuracy: 0.6260 - val_loss: 1.7337 - val_accuracy: 0.4610\n",
      "Epoch 870/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8713 - accuracy: 0.6213 - val_loss: 1.6905 - val_accuracy: 0.4615\n",
      "Epoch 871/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8951 - accuracy: 0.6159 - val_loss: 1.7438 - val_accuracy: 0.4667\n",
      "Epoch 872/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8471 - accuracy: 0.6328 - val_loss: 1.5918 - val_accuracy: 0.4769\n",
      "Epoch 873/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8573 - accuracy: 0.6319 - val_loss: 1.6706 - val_accuracy: 0.4272\n",
      "Epoch 874/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8588 - accuracy: 0.6243 - val_loss: 1.7403 - val_accuracy: 0.4626\n",
      "Epoch 875/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8488 - accuracy: 0.6297 - val_loss: 1.7147 - val_accuracy: 0.4692\n",
      "Epoch 876/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8425 - accuracy: 0.6471 - val_loss: 1.6750 - val_accuracy: 0.4846\n",
      "Epoch 877/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8635 - accuracy: 0.6343 - val_loss: 1.6649 - val_accuracy: 0.4851\n",
      "Epoch 878/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8621 - accuracy: 0.6304 - val_loss: 1.6565 - val_accuracy: 0.4754\n",
      "Epoch 879/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8543 - accuracy: 0.6299 - val_loss: 1.6949 - val_accuracy: 0.4651\n",
      "Epoch 880/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8461 - accuracy: 0.6403 - val_loss: 1.7303 - val_accuracy: 0.4415\n",
      "Epoch 881/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8906 - accuracy: 0.6098 - val_loss: 1.6243 - val_accuracy: 0.4667\n",
      "Epoch 882/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8622 - accuracy: 0.6286 - val_loss: 1.6989 - val_accuracy: 0.4385\n",
      "Epoch 883/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8752 - accuracy: 0.6211 - val_loss: 1.6760 - val_accuracy: 0.4795\n",
      "Epoch 884/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8554 - accuracy: 0.6343 - val_loss: 1.5637 - val_accuracy: 0.4862\n",
      "Epoch 885/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8679 - accuracy: 0.6209 - val_loss: 1.6907 - val_accuracy: 0.4738\n",
      "Epoch 886/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8624 - accuracy: 0.6305 - val_loss: 1.6092 - val_accuracy: 0.5051\n",
      "Epoch 887/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9852 - accuracy: 0.5744 - val_loss: 1.5048 - val_accuracy: 0.4579\n",
      "Epoch 888/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9061 - accuracy: 0.6013 - val_loss: 1.6944 - val_accuracy: 0.4831\n",
      "Epoch 889/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8808 - accuracy: 0.6149 - val_loss: 1.5725 - val_accuracy: 0.4641\n",
      "Epoch 890/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8695 - accuracy: 0.6280 - val_loss: 1.6246 - val_accuracy: 0.4774\n",
      "Epoch 891/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8264 - accuracy: 0.6466 - val_loss: 1.6443 - val_accuracy: 0.4769\n",
      "Epoch 892/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8754 - accuracy: 0.6218 - val_loss: 1.6501 - val_accuracy: 0.4497\n",
      "Epoch 893/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8707 - accuracy: 0.6295 - val_loss: 1.5649 - val_accuracy: 0.4949\n",
      "Epoch 894/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8731 - accuracy: 0.6327 - val_loss: 1.6594 - val_accuracy: 0.4867\n",
      "Epoch 895/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8650 - accuracy: 0.6306 - val_loss: 1.6513 - val_accuracy: 0.4656\n",
      "Epoch 896/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8442 - accuracy: 0.6397 - val_loss: 1.6832 - val_accuracy: 0.3954\n",
      "Epoch 897/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9325 - accuracy: 0.5964 - val_loss: 1.5984 - val_accuracy: 0.4815\n",
      "Epoch 898/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8614 - accuracy: 0.6304 - val_loss: 1.6810 - val_accuracy: 0.4923\n",
      "Epoch 899/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8863 - accuracy: 0.6091 - val_loss: 1.7246 - val_accuracy: 0.4205\n",
      "Epoch 900/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8534 - accuracy: 0.6338 - val_loss: 1.7214 - val_accuracy: 0.4744\n",
      "Epoch 901/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8821 - accuracy: 0.6295 - val_loss: 1.7170 - val_accuracy: 0.4938\n",
      "Epoch 902/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8632 - accuracy: 0.6313 - val_loss: 1.5862 - val_accuracy: 0.4815\n",
      "Epoch 903/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8476 - accuracy: 0.6273 - val_loss: 1.8159 - val_accuracy: 0.4518\n",
      "Epoch 904/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8535 - accuracy: 0.6252 - val_loss: 1.6719 - val_accuracy: 0.4872\n",
      "Epoch 905/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8864 - accuracy: 0.6163 - val_loss: 1.6951 - val_accuracy: 0.4600\n",
      "Epoch 906/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8199 - accuracy: 0.6480 - val_loss: 1.6638 - val_accuracy: 0.4626\n",
      "Epoch 907/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8639 - accuracy: 0.6228 - val_loss: 1.5509 - val_accuracy: 0.5077\n",
      "Epoch 908/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8854 - accuracy: 0.6160 - val_loss: 1.5817 - val_accuracy: 0.4790\n",
      "Epoch 909/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8457 - accuracy: 0.6327 - val_loss: 1.6399 - val_accuracy: 0.4872\n",
      "Epoch 910/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8858 - accuracy: 0.6156 - val_loss: 1.6489 - val_accuracy: 0.4564\n",
      "Epoch 911/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8837 - accuracy: 0.6252 - val_loss: 1.6614 - val_accuracy: 0.4667\n",
      "Epoch 912/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8284 - accuracy: 0.6397 - val_loss: 1.6157 - val_accuracy: 0.4954\n",
      "Epoch 913/1000\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.8445 - accuracy: 0.6328 - val_loss: 1.7064 - val_accuracy: 0.4897\n",
      "Epoch 914/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8447 - accuracy: 0.6459 - val_loss: 1.6726 - val_accuracy: 0.4292\n",
      "Epoch 915/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8461 - accuracy: 0.6361 - val_loss: 1.6460 - val_accuracy: 0.4846\n",
      "Epoch 916/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8844 - accuracy: 0.6293 - val_loss: 1.7386 - val_accuracy: 0.4369\n",
      "Epoch 917/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9093 - accuracy: 0.6123 - val_loss: 1.6946 - val_accuracy: 0.4908\n",
      "Epoch 918/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8446 - accuracy: 0.6374 - val_loss: 1.7307 - val_accuracy: 0.4810\n",
      "Epoch 919/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8450 - accuracy: 0.6318 - val_loss: 1.6124 - val_accuracy: 0.4667\n",
      "Epoch 920/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8885 - accuracy: 0.6155 - val_loss: 1.6567 - val_accuracy: 0.4656\n",
      "Epoch 921/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8686 - accuracy: 0.6251 - val_loss: 1.7207 - val_accuracy: 0.4790\n",
      "Epoch 922/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8786 - accuracy: 0.6107 - val_loss: 1.6708 - val_accuracy: 0.4651\n",
      "Epoch 923/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8493 - accuracy: 0.6430 - val_loss: 1.6648 - val_accuracy: 0.4677\n",
      "Epoch 924/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8616 - accuracy: 0.6285 - val_loss: 1.7297 - val_accuracy: 0.4928\n",
      "Epoch 925/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8566 - accuracy: 0.6357 - val_loss: 1.6838 - val_accuracy: 0.4508\n",
      "Epoch 926/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8740 - accuracy: 0.6235 - val_loss: 1.6993 - val_accuracy: 0.4610\n",
      "Epoch 927/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8614 - accuracy: 0.6324 - val_loss: 1.6180 - val_accuracy: 0.4872\n",
      "Epoch 928/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9831 - accuracy: 0.6003 - val_loss: 1.5989 - val_accuracy: 0.4856\n",
      "Epoch 929/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8781 - accuracy: 0.6270 - val_loss: 1.5394 - val_accuracy: 0.4990\n",
      "Epoch 930/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9198 - accuracy: 0.6034 - val_loss: 1.6786 - val_accuracy: 0.4621\n",
      "Epoch 931/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8376 - accuracy: 0.6476 - val_loss: 1.7220 - val_accuracy: 0.4656\n",
      "Epoch 932/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8333 - accuracy: 0.6384 - val_loss: 1.7289 - val_accuracy: 0.4318\n",
      "Epoch 933/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8281 - accuracy: 0.6568 - val_loss: 1.7142 - val_accuracy: 0.4231\n",
      "Epoch 934/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8873 - accuracy: 0.6170 - val_loss: 1.7318 - val_accuracy: 0.4159\n",
      "Epoch 935/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8676 - accuracy: 0.6228 - val_loss: 1.6810 - val_accuracy: 0.4128\n",
      "Epoch 936/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9201 - accuracy: 0.6015 - val_loss: 1.7154 - val_accuracy: 0.4769\n",
      "Epoch 937/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8962 - accuracy: 0.6236 - val_loss: 1.6511 - val_accuracy: 0.4785\n",
      "Epoch 938/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8509 - accuracy: 0.6336 - val_loss: 1.7019 - val_accuracy: 0.4892\n",
      "Epoch 939/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9139 - accuracy: 0.6054 - val_loss: 1.5568 - val_accuracy: 0.4723\n",
      "Epoch 940/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8700 - accuracy: 0.6243 - val_loss: 1.6682 - val_accuracy: 0.4031\n",
      "Epoch 941/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8713 - accuracy: 0.6170 - val_loss: 1.5857 - val_accuracy: 0.4769\n",
      "Epoch 942/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8468 - accuracy: 0.6386 - val_loss: 1.5822 - val_accuracy: 0.4733\n",
      "Epoch 943/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8458 - accuracy: 0.6438 - val_loss: 1.7127 - val_accuracy: 0.4123\n",
      "Epoch 944/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8529 - accuracy: 0.6406 - val_loss: 1.6744 - val_accuracy: 0.4554\n",
      "Epoch 945/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8342 - accuracy: 0.6487 - val_loss: 1.6752 - val_accuracy: 0.4610\n",
      "Epoch 946/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8847 - accuracy: 0.6309 - val_loss: 1.6797 - val_accuracy: 0.4205\n",
      "Epoch 947/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8317 - accuracy: 0.6435 - val_loss: 1.7171 - val_accuracy: 0.4503\n",
      "Epoch 948/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8540 - accuracy: 0.6401 - val_loss: 1.7037 - val_accuracy: 0.4697\n",
      "Epoch 949/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8799 - accuracy: 0.6236 - val_loss: 1.7916 - val_accuracy: 0.4641\n",
      "Epoch 950/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8807 - accuracy: 0.6233 - val_loss: 1.6652 - val_accuracy: 0.4246\n",
      "Epoch 951/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8928 - accuracy: 0.6065 - val_loss: 1.7993 - val_accuracy: 0.4718\n",
      "Epoch 952/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8574 - accuracy: 0.6386 - val_loss: 1.7256 - val_accuracy: 0.4631\n",
      "Epoch 953/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8359 - accuracy: 0.6412 - val_loss: 1.7983 - val_accuracy: 0.4492\n",
      "Epoch 954/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8512 - accuracy: 0.6294 - val_loss: 1.7444 - val_accuracy: 0.4318\n",
      "Epoch 955/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8605 - accuracy: 0.6272 - val_loss: 1.7538 - val_accuracy: 0.4590\n",
      "Epoch 956/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8610 - accuracy: 0.6260 - val_loss: 1.6299 - val_accuracy: 0.4800\n",
      "Epoch 957/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8371 - accuracy: 0.6426 - val_loss: 1.7429 - val_accuracy: 0.4785\n",
      "Epoch 958/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8360 - accuracy: 0.6491 - val_loss: 1.8297 - val_accuracy: 0.4456\n",
      "Epoch 959/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.6139 - val_loss: 1.6189 - val_accuracy: 0.4610\n",
      "Epoch 960/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9000 - accuracy: 0.6069 - val_loss: 1.6670 - val_accuracy: 0.4559\n",
      "Epoch 961/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8471 - accuracy: 0.6248 - val_loss: 1.6870 - val_accuracy: 0.4579\n",
      "Epoch 962/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8958 - accuracy: 0.6216 - val_loss: 1.6642 - val_accuracy: 0.4549\n",
      "Epoch 963/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8648 - accuracy: 0.6266 - val_loss: 1.6178 - val_accuracy: 0.4841\n",
      "Epoch 964/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8314 - accuracy: 0.6406 - val_loss: 1.7394 - val_accuracy: 0.3949\n",
      "Epoch 965/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9015 - accuracy: 0.6085 - val_loss: 1.6540 - val_accuracy: 0.4836\n",
      "Epoch 966/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8493 - accuracy: 0.6328 - val_loss: 1.7606 - val_accuracy: 0.4882\n",
      "Epoch 967/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8457 - accuracy: 0.6367 - val_loss: 1.6988 - val_accuracy: 0.5036\n",
      "Epoch 968/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8602 - accuracy: 0.6246 - val_loss: 1.7201 - val_accuracy: 0.4790\n",
      "Epoch 969/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8412 - accuracy: 0.6410 - val_loss: 1.7916 - val_accuracy: 0.4933\n",
      "Epoch 970/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8568 - accuracy: 0.6437 - val_loss: 1.6852 - val_accuracy: 0.4892\n",
      "Epoch 971/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8652 - accuracy: 0.6220 - val_loss: 1.8077 - val_accuracy: 0.4949\n",
      "Epoch 972/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8698 - accuracy: 0.6218 - val_loss: 1.7113 - val_accuracy: 0.4744\n",
      "Epoch 973/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8363 - accuracy: 0.6526 - val_loss: 1.7896 - val_accuracy: 0.4292\n",
      "Epoch 974/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8385 - accuracy: 0.6374 - val_loss: 1.8219 - val_accuracy: 0.4195\n",
      "Epoch 975/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8297 - accuracy: 0.6374 - val_loss: 1.7044 - val_accuracy: 0.4256\n",
      "Epoch 976/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0168 - accuracy: 0.5790 - val_loss: 1.4733 - val_accuracy: 0.4564\n",
      "Epoch 977/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8984 - accuracy: 0.6166 - val_loss: 1.5320 - val_accuracy: 0.4221\n",
      "Epoch 978/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8997 - accuracy: 0.6089 - val_loss: 1.4371 - val_accuracy: 0.4754\n",
      "Epoch 979/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8725 - accuracy: 0.6195 - val_loss: 1.5058 - val_accuracy: 0.4728\n",
      "Epoch 980/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8795 - accuracy: 0.6255 - val_loss: 1.5300 - val_accuracy: 0.4662\n",
      "Epoch 981/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8741 - accuracy: 0.6228 - val_loss: 1.6179 - val_accuracy: 0.4323\n",
      "Epoch 982/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8221 - accuracy: 0.6468 - val_loss: 1.6203 - val_accuracy: 0.4882\n",
      "Epoch 983/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8527 - accuracy: 0.6349 - val_loss: 1.6694 - val_accuracy: 0.4492\n",
      "Epoch 984/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8190 - accuracy: 0.6504 - val_loss: 1.7902 - val_accuracy: 0.4087\n",
      "Epoch 985/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8431 - accuracy: 0.6458 - val_loss: 1.8290 - val_accuracy: 0.4749\n",
      "Epoch 986/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8238 - accuracy: 0.6431 - val_loss: 1.7558 - val_accuracy: 0.4995\n",
      "Epoch 987/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8598 - accuracy: 0.6356 - val_loss: 1.7990 - val_accuracy: 0.4744\n",
      "Epoch 988/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8498 - accuracy: 0.6375 - val_loss: 1.7192 - val_accuracy: 0.4559\n",
      "Epoch 989/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8231 - accuracy: 0.6408 - val_loss: 1.8236 - val_accuracy: 0.4913\n",
      "Epoch 990/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8437 - accuracy: 0.6335 - val_loss: 1.8159 - val_accuracy: 0.4226\n",
      "Epoch 991/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8202 - accuracy: 0.6482 - val_loss: 1.6998 - val_accuracy: 0.4723\n",
      "Epoch 992/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8609 - accuracy: 0.6397 - val_loss: 1.7739 - val_accuracy: 0.4785\n",
      "Epoch 993/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8307 - accuracy: 0.6483 - val_loss: 1.9083 - val_accuracy: 0.4482\n",
      "Epoch 994/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8215 - accuracy: 0.6489 - val_loss: 1.8754 - val_accuracy: 0.4533\n",
      "Epoch 995/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8369 - accuracy: 0.6428 - val_loss: 1.7509 - val_accuracy: 0.4779\n",
      "Epoch 996/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8501 - accuracy: 0.6221 - val_loss: 1.7990 - val_accuracy: 0.4738\n",
      "Epoch 997/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8680 - accuracy: 0.6179 - val_loss: 1.7937 - val_accuracy: 0.4333\n",
      "Epoch 998/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8726 - accuracy: 0.6272 - val_loss: 1.7023 - val_accuracy: 0.4810\n",
      "Epoch 999/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8775 - accuracy: 0.6269 - val_loss: 1.7290 - val_accuracy: 0.4877\n",
      "Epoch 1000/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.8667 - accuracy: 0.6307 - val_loss: 1.7150 - val_accuracy: 0.4544\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "model2_w =keras. models.Sequential()\n",
    "\n",
    "model2_w.add(keras.layers.Dense(units = 64,input_dim = 11,activation = 'relu'))\n",
    "model2_w.add(keras.layers.Dense(units = 32,activation = 'relu'))\n",
    "model2_w.add(keras.layers.Dense(units = 16,activation = 'relu'))\n",
    "model2_w.add(keras.layers.Dense(units = 32,activation = 'relu'))\n",
    "\n",
    "model2_w.add(keras.layers.Dense(11,activation = 'softmax'))\n",
    "\n",
    "model2_w.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model2_w.summary()\n",
    "\n",
    "hist2_W = model2_w.fit(X_train,Y_train,epochs=1000,batch_size=64,validation_data = (X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "acc_ax = ax1.twinx()\n",
    "\n",
    "ax1.plot(hist2_W.history['loss'], 'y', label='train loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "\n",
    "\n",
    "ax2.plot(hist2_W.history['val_loss'], 'r', label='val loss')\n",
    "ax2.set_ylabel('val_loss')\n",
    "\n",
    "\n",
    "ax3.plot(hist2_W.history['accuracy'], 'b', label='accuracy')\n",
    "ax3.set_ylabel('accuray')\n",
    "\n",
    "ax4.plot(hist2_W.history['val_accuracy'], 'g', label='val_accuracy')\n",
    "ax4.set_ylabel('val_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 - 0s - loss: 1.7150 - accuracy: 0.4544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7149666547775269, 0.4543589651584625]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2_w.evaluate(X_test,Y_test,verbose =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 화이트 와인과 레드 와인을 하나의 모델만 사용하여 분류\n",
    "* 화이트 와인과 레드 와인 데이터를 합쳐 wine 데이터 셋 생성\n",
    "* 입력이 화이트 와인인지 레드 와인인지에 관계없이 와인 품질을 분류하는 모델 생성\n",
    "* 모델의 성능을 향상시킬 수 있는 방법을 찾아 적용할 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.concat([red_wine,white_wine],ignore_index = True)\n",
    "X_train, Y_train, X_test, Y_test = generate_data(wine, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 5.3849 - accuracy: 0.2710 - val_loss: 1.3676 - val_accuracy: 0.3636\n",
      "Epoch 2/200\n",
      "414/414 [==============================] - 0s 855us/step - loss: 1.4186 - accuracy: 0.3816 - val_loss: 1.3491 - val_accuracy: 0.3554\n",
      "Epoch 3/200\n",
      "414/414 [==============================] - 0s 884us/step - loss: 1.3667 - accuracy: 0.3902 - val_loss: 1.2730 - val_accuracy: 0.4574\n",
      "Epoch 4/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.3233 - accuracy: 0.4331 - val_loss: 1.3023 - val_accuracy: 0.4877\n",
      "Epoch 5/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.2908 - accuracy: 0.4486 - val_loss: 1.2149 - val_accuracy: 0.5010\n",
      "Epoch 6/200\n",
      "414/414 [==============================] - 0s 949us/step - loss: 1.2811 - accuracy: 0.4494 - val_loss: 1.3832 - val_accuracy: 0.3113\n",
      "Epoch 7/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.2691 - accuracy: 0.4555 - val_loss: 1.1803 - val_accuracy: 0.5010\n",
      "Epoch 8/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.2553 - accuracy: 0.4618 - val_loss: 1.1650 - val_accuracy: 0.5021\n",
      "Epoch 9/200\n",
      "414/414 [==============================] - 0s 897us/step - loss: 1.2945 - accuracy: 0.4697 - val_loss: 1.1502 - val_accuracy: 0.5523\n",
      "Epoch 10/200\n",
      "414/414 [==============================] - 0s 913us/step - loss: 1.2426 - accuracy: 0.4804 - val_loss: 1.1796 - val_accuracy: 0.5015\n",
      "Epoch 11/200\n",
      "414/414 [==============================] - 0s 905us/step - loss: 1.2419 - accuracy: 0.4750 - val_loss: 1.2363 - val_accuracy: 0.4128\n",
      "Epoch 12/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.2267 - accuracy: 0.4832 - val_loss: 1.2323 - val_accuracy: 0.5051\n",
      "Epoch 13/200\n",
      "414/414 [==============================] - 0s 967us/step - loss: 1.2409 - accuracy: 0.4855 - val_loss: 1.2264 - val_accuracy: 0.4918\n",
      "Epoch 14/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.2104 - accuracy: 0.4846 - val_loss: 1.2978 - val_accuracy: 0.5036\n",
      "Epoch 15/200\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 1.2436 - accuracy: 0.4728 - val_loss: 1.1094 - val_accuracy: 0.5097\n",
      "Epoch 16/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.2048 - accuracy: 0.4841 - val_loss: 1.0958 - val_accuracy: 0.5559\n",
      "Epoch 17/200\n",
      "414/414 [==============================] - 0s 959us/step - loss: 1.2477 - accuracy: 0.4719 - val_loss: 1.1731 - val_accuracy: 0.5036\n",
      "Epoch 18/200\n",
      "414/414 [==============================] - 0s 891us/step - loss: 1.1722 - accuracy: 0.5033 - val_loss: 1.5585 - val_accuracy: 0.3077\n",
      "Epoch 19/200\n",
      "414/414 [==============================] - 0s 895us/step - loss: 1.2154 - accuracy: 0.4859 - val_loss: 1.1555 - val_accuracy: 0.5313\n",
      "Epoch 20/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.2184 - accuracy: 0.4832 - val_loss: 1.1220 - val_accuracy: 0.5056\n",
      "Epoch 21/200\n",
      "414/414 [==============================] - 0s 970us/step - loss: 1.1499 - accuracy: 0.4974 - val_loss: 1.2929 - val_accuracy: 0.4990\n",
      "Epoch 22/200\n",
      "414/414 [==============================] - 0s 949us/step - loss: 1.2037 - accuracy: 0.5009 - val_loss: 1.0880 - val_accuracy: 0.5538\n",
      "Epoch 23/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1894 - accuracy: 0.5057 - val_loss: 1.2360 - val_accuracy: 0.4236\n",
      "Epoch 24/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1638 - accuracy: 0.4932 - val_loss: 1.3145 - val_accuracy: 0.3815\n",
      "Epoch 25/200\n",
      "414/414 [==============================] - 0s 964us/step - loss: 1.1818 - accuracy: 0.5087 - val_loss: 1.1248 - val_accuracy: 0.5246\n",
      "Epoch 26/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1878 - accuracy: 0.5010 - val_loss: 1.1893 - val_accuracy: 0.4313\n",
      "Epoch 27/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1671 - accuracy: 0.5023 - val_loss: 1.1080 - val_accuracy: 0.5118\n",
      "Epoch 28/200\n",
      "414/414 [==============================] - 0s 960us/step - loss: 1.1699 - accuracy: 0.4951 - val_loss: 1.0786 - val_accuracy: 0.5303\n",
      "Epoch 29/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1854 - accuracy: 0.5030 - val_loss: 1.0850 - val_accuracy: 0.5364\n",
      "Epoch 30/200\n",
      "414/414 [==============================] - 0s 991us/step - loss: 1.1622 - accuracy: 0.5109 - val_loss: 1.1280 - val_accuracy: 0.4836\n",
      "Epoch 31/200\n",
      "414/414 [==============================] - 0s 950us/step - loss: 1.1537 - accuracy: 0.5080 - val_loss: 1.2141 - val_accuracy: 0.4923\n",
      "Epoch 32/200\n",
      "414/414 [==============================] - 0s 964us/step - loss: 1.1738 - accuracy: 0.4901 - val_loss: 1.2802 - val_accuracy: 0.3821\n",
      "Epoch 33/200\n",
      "414/414 [==============================] - 0s 974us/step - loss: 1.1454 - accuracy: 0.5016 - val_loss: 1.2646 - val_accuracy: 0.3579\n",
      "Epoch 34/200\n",
      "414/414 [==============================] - 0s 939us/step - loss: 1.1583 - accuracy: 0.5061 - val_loss: 1.1113 - val_accuracy: 0.5021\n",
      "Epoch 35/200\n",
      "414/414 [==============================] - 0s 988us/step - loss: 1.1521 - accuracy: 0.5054 - val_loss: 1.1538 - val_accuracy: 0.4400\n",
      "Epoch 36/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1534 - accuracy: 0.5055 - val_loss: 1.1532 - val_accuracy: 0.4528\n",
      "Epoch 37/200\n",
      "414/414 [==============================] - 0s 980us/step - loss: 1.1748 - accuracy: 0.5033 - val_loss: 1.0959 - val_accuracy: 0.5149\n",
      "Epoch 38/200\n",
      "414/414 [==============================] - 0s 956us/step - loss: 1.1559 - accuracy: 0.4983 - val_loss: 1.1178 - val_accuracy: 0.4990\n",
      "Epoch 39/200\n",
      "414/414 [==============================] - 0s 966us/step - loss: 1.1717 - accuracy: 0.5009 - val_loss: 1.2033 - val_accuracy: 0.4067\n",
      "Epoch 40/200\n",
      "414/414 [==============================] - 0s 928us/step - loss: 1.1553 - accuracy: 0.4925 - val_loss: 1.1409 - val_accuracy: 0.4590\n",
      "Epoch 41/200\n",
      "414/414 [==============================] - 0s 934us/step - loss: 1.1567 - accuracy: 0.5033 - val_loss: 1.1184 - val_accuracy: 0.5385\n",
      "Epoch 42/200\n",
      "414/414 [==============================] - 0s 933us/step - loss: 1.1751 - accuracy: 0.4886 - val_loss: 1.1264 - val_accuracy: 0.5267\n",
      "Epoch 43/200\n",
      "414/414 [==============================] - 0s 954us/step - loss: 1.1243 - accuracy: 0.5074 - val_loss: 1.1036 - val_accuracy: 0.4944\n",
      "Epoch 44/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1119 - accuracy: 0.5147 - val_loss: 1.0888 - val_accuracy: 0.5103\n",
      "Epoch 45/200\n",
      "414/414 [==============================] - 0s 977us/step - loss: 1.1674 - accuracy: 0.5025 - val_loss: 1.2882 - val_accuracy: 0.3631\n",
      "Epoch 46/200\n",
      "414/414 [==============================] - 0s 971us/step - loss: 1.1422 - accuracy: 0.5077 - val_loss: 1.0654 - val_accuracy: 0.5533\n",
      "Epoch 47/200\n",
      "414/414 [==============================] - 0s 925us/step - loss: 1.1239 - accuracy: 0.5225 - val_loss: 1.0885 - val_accuracy: 0.5200\n",
      "Epoch 48/200\n",
      "414/414 [==============================] - 0s 896us/step - loss: 1.1169 - accuracy: 0.5199 - val_loss: 1.1364 - val_accuracy: 0.4667\n",
      "Epoch 49/200\n",
      "414/414 [==============================] - 0s 939us/step - loss: 1.1593 - accuracy: 0.5063 - val_loss: 1.1223 - val_accuracy: 0.4790\n",
      "Epoch 50/200\n",
      "414/414 [==============================] - 0s 942us/step - loss: 1.1540 - accuracy: 0.5251 - val_loss: 1.1030 - val_accuracy: 0.4903\n",
      "Epoch 51/200\n",
      "414/414 [==============================] - 0s 956us/step - loss: 1.1220 - accuracy: 0.5060 - val_loss: 1.0960 - val_accuracy: 0.5385\n",
      "Epoch 52/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1035 - accuracy: 0.5185 - val_loss: 1.3263 - val_accuracy: 0.3533\n",
      "Epoch 53/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1566 - accuracy: 0.5041 - val_loss: 1.1869 - val_accuracy: 0.4636\n",
      "Epoch 54/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1478 - accuracy: 0.5138 - val_loss: 1.2968 - val_accuracy: 0.3544\n",
      "Epoch 55/200\n",
      "414/414 [==============================] - 0s 1000us/step - loss: 1.1409 - accuracy: 0.5183 - val_loss: 1.0989 - val_accuracy: 0.4974\n",
      "Epoch 56/200\n",
      "414/414 [==============================] - 0s 915us/step - loss: 1.1336 - accuracy: 0.5120 - val_loss: 1.0840 - val_accuracy: 0.5097\n",
      "Epoch 57/200\n",
      "414/414 [==============================] - 0s 994us/step - loss: 1.1620 - accuracy: 0.5016 - val_loss: 1.1350 - val_accuracy: 0.4646\n",
      "Epoch 58/200\n",
      "414/414 [==============================] - 0s 910us/step - loss: 1.1277 - accuracy: 0.5299 - val_loss: 1.1404 - val_accuracy: 0.4969\n",
      "Epoch 59/200\n",
      "414/414 [==============================] - 0s 915us/step - loss: 1.1423 - accuracy: 0.5203 - val_loss: 1.1506 - val_accuracy: 0.4354\n",
      "Epoch 60/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1339 - accuracy: 0.5198 - val_loss: 1.0717 - val_accuracy: 0.5313\n",
      "Epoch 61/200\n",
      "414/414 [==============================] - 0s 945us/step - loss: 1.1511 - accuracy: 0.5152 - val_loss: 1.1466 - val_accuracy: 0.4523\n",
      "Epoch 62/200\n",
      "414/414 [==============================] - 0s 941us/step - loss: 1.1097 - accuracy: 0.5081 - val_loss: 1.0684 - val_accuracy: 0.5374\n",
      "Epoch 63/200\n",
      "414/414 [==============================] - 0s 938us/step - loss: 1.1066 - accuracy: 0.5195 - val_loss: 1.1461 - val_accuracy: 0.4472\n",
      "Epoch 64/200\n",
      "414/414 [==============================] - 0s 911us/step - loss: 1.1219 - accuracy: 0.5152 - val_loss: 1.2469 - val_accuracy: 0.4123\n",
      "Epoch 65/200\n",
      "414/414 [==============================] - 0s 904us/step - loss: 1.1126 - accuracy: 0.5266 - val_loss: 1.2797 - val_accuracy: 0.3738\n",
      "Epoch 66/200\n",
      "414/414 [==============================] - 0s 934us/step - loss: 1.1239 - accuracy: 0.5219 - val_loss: 1.1282 - val_accuracy: 0.4651\n",
      "Epoch 67/200\n",
      "414/414 [==============================] - 0s 879us/step - loss: 1.0990 - accuracy: 0.5198 - val_loss: 1.0864 - val_accuracy: 0.5185\n",
      "Epoch 68/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1416 - accuracy: 0.5016 - val_loss: 1.0915 - val_accuracy: 0.5087\n",
      "Epoch 69/200\n",
      "414/414 [==============================] - 0s 978us/step - loss: 1.1283 - accuracy: 0.5170 - val_loss: 1.0591 - val_accuracy: 0.5195\n",
      "Epoch 70/200\n",
      "414/414 [==============================] - 0s 919us/step - loss: 1.0898 - accuracy: 0.5145 - val_loss: 1.1389 - val_accuracy: 0.4769\n",
      "Epoch 71/200\n",
      "414/414 [==============================] - 0s 919us/step - loss: 1.1254 - accuracy: 0.5053 - val_loss: 1.1928 - val_accuracy: 0.4769\n",
      "Epoch 72/200\n",
      "414/414 [==============================] - 0s 947us/step - loss: 1.0896 - accuracy: 0.5337 - val_loss: 1.2259 - val_accuracy: 0.4749\n",
      "Epoch 73/200\n",
      "414/414 [==============================] - 0s 938us/step - loss: 1.1136 - accuracy: 0.5210 - val_loss: 1.0641 - val_accuracy: 0.5292\n",
      "Epoch 74/200\n",
      "414/414 [==============================] - 0s 903us/step - loss: 1.0933 - accuracy: 0.5318 - val_loss: 1.2777 - val_accuracy: 0.4497\n",
      "Epoch 75/200\n",
      "414/414 [==============================] - 0s 913us/step - loss: 1.1303 - accuracy: 0.5272 - val_loss: 1.1336 - val_accuracy: 0.4718\n",
      "Epoch 76/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1117 - accuracy: 0.5153 - val_loss: 1.1065 - val_accuracy: 0.4887\n",
      "Epoch 77/200\n",
      "414/414 [==============================] - 0s 993us/step - loss: 1.1120 - accuracy: 0.5244 - val_loss: 1.0720 - val_accuracy: 0.5308\n",
      "Epoch 78/200\n",
      "414/414 [==============================] - 0s 896us/step - loss: 1.1042 - accuracy: 0.5200 - val_loss: 1.1120 - val_accuracy: 0.4887\n",
      "Epoch 79/200\n",
      "414/414 [==============================] - 0s 927us/step - loss: 1.1090 - accuracy: 0.5267 - val_loss: 1.2223 - val_accuracy: 0.4415\n",
      "Epoch 80/200\n",
      "414/414 [==============================] - 0s 926us/step - loss: 1.0904 - accuracy: 0.5224 - val_loss: 1.1599 - val_accuracy: 0.4897\n",
      "Epoch 81/200\n",
      "414/414 [==============================] - 0s 949us/step - loss: 1.0745 - accuracy: 0.5306 - val_loss: 1.0798 - val_accuracy: 0.5251\n",
      "Epoch 82/200\n",
      "414/414 [==============================] - 0s 955us/step - loss: 1.0682 - accuracy: 0.5410 - val_loss: 1.0874 - val_accuracy: 0.5015\n",
      "Epoch 83/200\n",
      "414/414 [==============================] - 0s 919us/step - loss: 1.0931 - accuracy: 0.5365 - val_loss: 1.2157 - val_accuracy: 0.4400\n",
      "Epoch 84/200\n",
      "414/414 [==============================] - 0s 973us/step - loss: 1.0992 - accuracy: 0.5263 - val_loss: 1.2657 - val_accuracy: 0.4231\n",
      "Epoch 85/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1142 - accuracy: 0.5217 - val_loss: 1.0815 - val_accuracy: 0.4959\n",
      "Epoch 86/200\n",
      "414/414 [==============================] - 0s 880us/step - loss: 1.1141 - accuracy: 0.5160 - val_loss: 1.1279 - val_accuracy: 0.4872\n",
      "Epoch 87/200\n",
      "414/414 [==============================] - 0s 888us/step - loss: 1.1057 - accuracy: 0.5127 - val_loss: 1.1492 - val_accuracy: 0.4872\n",
      "Epoch 88/200\n",
      "414/414 [==============================] - 0s 878us/step - loss: 1.0960 - accuracy: 0.5361 - val_loss: 1.0978 - val_accuracy: 0.4944\n",
      "Epoch 89/200\n",
      "414/414 [==============================] - 0s 878us/step - loss: 1.0979 - accuracy: 0.5397 - val_loss: 1.0903 - val_accuracy: 0.5333\n",
      "Epoch 90/200\n",
      "414/414 [==============================] - 0s 922us/step - loss: 1.1161 - accuracy: 0.5210 - val_loss: 1.1075 - val_accuracy: 0.5108\n",
      "Epoch 91/200\n",
      "414/414 [==============================] - 0s 916us/step - loss: 1.0903 - accuracy: 0.5272 - val_loss: 1.0868 - val_accuracy: 0.4933\n",
      "Epoch 92/200\n",
      "414/414 [==============================] - 0s 970us/step - loss: 1.0914 - accuracy: 0.5367 - val_loss: 1.0686 - val_accuracy: 0.5210\n",
      "Epoch 93/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0785 - accuracy: 0.5337 - val_loss: 1.1531 - val_accuracy: 0.4538\n",
      "Epoch 94/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.1091 - accuracy: 0.5298 - val_loss: 1.1575 - val_accuracy: 0.4574\n",
      "Epoch 95/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0913 - accuracy: 0.5357 - val_loss: 1.1843 - val_accuracy: 0.3944\n",
      "Epoch 96/200\n",
      "414/414 [==============================] - 0s 930us/step - loss: 1.1094 - accuracy: 0.5239 - val_loss: 1.0548 - val_accuracy: 0.5308\n",
      "Epoch 97/200\n",
      "414/414 [==============================] - 0s 924us/step - loss: 1.0671 - accuracy: 0.5395 - val_loss: 1.2923 - val_accuracy: 0.3513\n",
      "Epoch 98/200\n",
      "414/414 [==============================] - 0s 900us/step - loss: 1.0973 - accuracy: 0.5152 - val_loss: 1.1714 - val_accuracy: 0.4323\n",
      "Epoch 99/200\n",
      "414/414 [==============================] - 0s 882us/step - loss: 1.0823 - accuracy: 0.5389 - val_loss: 1.0496 - val_accuracy: 0.5410\n",
      "Epoch 100/200\n",
      "414/414 [==============================] - 0s 901us/step - loss: 1.0802 - accuracy: 0.5351 - val_loss: 1.1675 - val_accuracy: 0.4513\n",
      "Epoch 101/200\n",
      "414/414 [==============================] - 0s 954us/step - loss: 1.0664 - accuracy: 0.5410 - val_loss: 1.1673 - val_accuracy: 0.4708\n",
      "Epoch 102/200\n",
      "414/414 [==============================] - 0s 933us/step - loss: 1.0776 - accuracy: 0.5361 - val_loss: 1.1357 - val_accuracy: 0.4708\n",
      "Epoch 103/200\n",
      "414/414 [==============================] - 0s 940us/step - loss: 1.0860 - accuracy: 0.5266 - val_loss: 1.1498 - val_accuracy: 0.4462\n",
      "Epoch 104/200\n",
      "414/414 [==============================] - 0s 945us/step - loss: 1.0693 - accuracy: 0.5161 - val_loss: 1.0652 - val_accuracy: 0.5118\n",
      "Epoch 105/200\n",
      "414/414 [==============================] - 0s 925us/step - loss: 1.0770 - accuracy: 0.5441 - val_loss: 1.1621 - val_accuracy: 0.4282\n",
      "Epoch 106/200\n",
      "414/414 [==============================] - 0s 999us/step - loss: 1.0764 - accuracy: 0.5347 - val_loss: 1.1171 - val_accuracy: 0.4846\n",
      "Epoch 107/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0735 - accuracy: 0.5470 - val_loss: 1.0949 - val_accuracy: 0.5272\n",
      "Epoch 108/200\n",
      "414/414 [==============================] - 0s 970us/step - loss: 1.0881 - accuracy: 0.5208 - val_loss: 1.1312 - val_accuracy: 0.4846\n",
      "Epoch 109/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0635 - accuracy: 0.5389 - val_loss: 1.0709 - val_accuracy: 0.5169\n",
      "Epoch 110/200\n",
      "414/414 [==============================] - 0s 999us/step - loss: 1.0635 - accuracy: 0.5450 - val_loss: 1.1559 - val_accuracy: 0.4851\n",
      "Epoch 111/200\n",
      "414/414 [==============================] - 0s 934us/step - loss: 1.0791 - accuracy: 0.5342 - val_loss: 1.1662 - val_accuracy: 0.4574\n",
      "Epoch 112/200\n",
      "414/414 [==============================] - 0s 948us/step - loss: 1.0622 - accuracy: 0.5304 - val_loss: 1.3387 - val_accuracy: 0.3610\n",
      "Epoch 113/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0732 - accuracy: 0.5312 - val_loss: 1.1528 - val_accuracy: 0.4395\n",
      "Epoch 114/200\n",
      "414/414 [==============================] - 0s 929us/step - loss: 1.0741 - accuracy: 0.5365 - val_loss: 1.0580 - val_accuracy: 0.5221\n",
      "Epoch 115/200\n",
      "414/414 [==============================] - 0s 972us/step - loss: 1.0615 - accuracy: 0.5461 - val_loss: 1.0850 - val_accuracy: 0.5031\n",
      "Epoch 116/200\n",
      "414/414 [==============================] - 0s 922us/step - loss: 1.0916 - accuracy: 0.5253 - val_loss: 1.1072 - val_accuracy: 0.4903\n",
      "Epoch 117/200\n",
      "414/414 [==============================] - 0s 922us/step - loss: 1.0826 - accuracy: 0.5388 - val_loss: 1.0761 - val_accuracy: 0.5272\n",
      "Epoch 118/200\n",
      "414/414 [==============================] - 0s 975us/step - loss: 1.0778 - accuracy: 0.5239 - val_loss: 1.1198 - val_accuracy: 0.4908\n",
      "Epoch 119/200\n",
      "414/414 [==============================] - 0s 935us/step - loss: 1.0751 - accuracy: 0.5297 - val_loss: 1.1428 - val_accuracy: 0.4728\n",
      "Epoch 120/200\n",
      "414/414 [==============================] - 0s 902us/step - loss: 1.0457 - accuracy: 0.5348 - val_loss: 1.0708 - val_accuracy: 0.5221\n",
      "Epoch 121/200\n",
      "414/414 [==============================] - 0s 938us/step - loss: 1.0653 - accuracy: 0.5405 - val_loss: 1.1498 - val_accuracy: 0.4641\n",
      "Epoch 122/200\n",
      "414/414 [==============================] - 0s 935us/step - loss: 1.0513 - accuracy: 0.5447 - val_loss: 1.1132 - val_accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0818 - accuracy: 0.5297 - val_loss: 1.0985 - val_accuracy: 0.5097\n",
      "Epoch 124/200\n",
      "414/414 [==============================] - 0s 936us/step - loss: 1.0867 - accuracy: 0.5271 - val_loss: 1.1231 - val_accuracy: 0.4651\n",
      "Epoch 125/200\n",
      "414/414 [==============================] - 0s 924us/step - loss: 1.0723 - accuracy: 0.5415 - val_loss: 1.1316 - val_accuracy: 0.4995\n",
      "Epoch 126/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0681 - accuracy: 0.5326 - val_loss: 1.0863 - val_accuracy: 0.5046\n",
      "Epoch 127/200\n",
      "414/414 [==============================] - 0s 909us/step - loss: 1.0590 - accuracy: 0.5361 - val_loss: 1.0723 - val_accuracy: 0.5210\n",
      "Epoch 128/200\n",
      "414/414 [==============================] - 0s 924us/step - loss: 1.0763 - accuracy: 0.5371 - val_loss: 1.0835 - val_accuracy: 0.5185\n",
      "Epoch 129/200\n",
      "414/414 [==============================] - 0s 961us/step - loss: 1.0879 - accuracy: 0.5175 - val_loss: 1.1479 - val_accuracy: 0.4677\n",
      "Epoch 130/200\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 1.0662 - accuracy: 0.5535 - val_loss: 1.0709 - val_accuracy: 0.5236\n",
      "Epoch 131/200\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 1.0970 - accuracy: 0.5218 - val_loss: 1.0924 - val_accuracy: 0.5174\n",
      "Epoch 132/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0811 - accuracy: 0.5330 - val_loss: 1.0561 - val_accuracy: 0.5405\n",
      "Epoch 133/200\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 1.0717 - accuracy: 0.5244 - val_loss: 1.1017 - val_accuracy: 0.4897\n",
      "Epoch 134/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0807 - accuracy: 0.5306 - val_loss: 1.0778 - val_accuracy: 0.5349\n",
      "Epoch 135/200\n",
      "414/414 [==============================] - 0s 967us/step - loss: 1.0484 - accuracy: 0.5382 - val_loss: 1.0657 - val_accuracy: 0.5179\n",
      "Epoch 136/200\n",
      "414/414 [==============================] - 0s 893us/step - loss: 1.0351 - accuracy: 0.5575 - val_loss: 1.0768 - val_accuracy: 0.5303\n",
      "Epoch 137/200\n",
      "414/414 [==============================] - 0s 957us/step - loss: 1.0403 - accuracy: 0.5493 - val_loss: 1.0962 - val_accuracy: 0.5251\n",
      "Epoch 138/200\n",
      "414/414 [==============================] - 0s 876us/step - loss: 1.0678 - accuracy: 0.5281 - val_loss: 1.0647 - val_accuracy: 0.5226\n",
      "Epoch 139/200\n",
      "414/414 [==============================] - 0s 942us/step - loss: 1.0671 - accuracy: 0.5305 - val_loss: 1.1454 - val_accuracy: 0.4395\n",
      "Epoch 140/200\n",
      "414/414 [==============================] - 0s 964us/step - loss: 1.0695 - accuracy: 0.5490 - val_loss: 1.0842 - val_accuracy: 0.4985\n",
      "Epoch 141/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0593 - accuracy: 0.5301 - val_loss: 1.0922 - val_accuracy: 0.5062\n",
      "Epoch 142/200\n",
      "414/414 [==============================] - 0s 965us/step - loss: 1.0381 - accuracy: 0.5505 - val_loss: 1.0921 - val_accuracy: 0.5154\n",
      "Epoch 143/200\n",
      "414/414 [==============================] - 0s 975us/step - loss: 1.0579 - accuracy: 0.5445 - val_loss: 1.1427 - val_accuracy: 0.4949\n",
      "Epoch 144/200\n",
      "414/414 [==============================] - 0s 928us/step - loss: 1.0536 - accuracy: 0.5432 - val_loss: 1.0970 - val_accuracy: 0.5062\n",
      "Epoch 145/200\n",
      "414/414 [==============================] - 0s 961us/step - loss: 1.0542 - accuracy: 0.5283 - val_loss: 1.1275 - val_accuracy: 0.4626\n",
      "Epoch 146/200\n",
      "414/414 [==============================] - 0s 891us/step - loss: 1.0435 - accuracy: 0.5454 - val_loss: 1.1056 - val_accuracy: 0.5015\n",
      "Epoch 147/200\n",
      "414/414 [==============================] - 0s 902us/step - loss: 1.0651 - accuracy: 0.5369 - val_loss: 1.0958 - val_accuracy: 0.5103\n",
      "Epoch 148/200\n",
      "414/414 [==============================] - 0s 925us/step - loss: 1.0651 - accuracy: 0.5375 - val_loss: 1.1168 - val_accuracy: 0.5026\n",
      "Epoch 149/200\n",
      "414/414 [==============================] - 0s 985us/step - loss: 1.0548 - accuracy: 0.5427 - val_loss: 1.1083 - val_accuracy: 0.4831\n",
      "Epoch 150/200\n",
      "414/414 [==============================] - 0s 930us/step - loss: 1.0524 - accuracy: 0.5449 - val_loss: 1.1740 - val_accuracy: 0.4344\n",
      "Epoch 151/200\n",
      "414/414 [==============================] - 0s 949us/step - loss: 1.0578 - accuracy: 0.5409 - val_loss: 1.1349 - val_accuracy: 0.4974\n",
      "Epoch 152/200\n",
      "414/414 [==============================] - 0s 942us/step - loss: 1.0583 - accuracy: 0.5332 - val_loss: 1.1793 - val_accuracy: 0.4528\n",
      "Epoch 153/200\n",
      "414/414 [==============================] - 0s 970us/step - loss: 1.0448 - accuracy: 0.5482 - val_loss: 1.1693 - val_accuracy: 0.4456\n",
      "Epoch 154/200\n",
      "414/414 [==============================] - 0s 926us/step - loss: 1.0497 - accuracy: 0.5574 - val_loss: 1.0736 - val_accuracy: 0.5067\n",
      "Epoch 155/200\n",
      "414/414 [==============================] - 0s 893us/step - loss: 1.0588 - accuracy: 0.5422 - val_loss: 1.1215 - val_accuracy: 0.4923\n",
      "Epoch 156/200\n",
      "414/414 [==============================] - 0s 952us/step - loss: 1.0419 - accuracy: 0.5352 - val_loss: 1.1475 - val_accuracy: 0.4882\n",
      "Epoch 157/200\n",
      "414/414 [==============================] - 0s 962us/step - loss: 1.0544 - accuracy: 0.5317 - val_loss: 1.0733 - val_accuracy: 0.5169\n",
      "Epoch 158/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0793 - accuracy: 0.5491 - val_loss: 1.0668 - val_accuracy: 0.5113\n",
      "Epoch 159/200\n",
      "414/414 [==============================] - 0s 948us/step - loss: 1.0443 - accuracy: 0.5420 - val_loss: 1.1398 - val_accuracy: 0.4569\n",
      "Epoch 160/200\n",
      "414/414 [==============================] - 0s 911us/step - loss: 1.0469 - accuracy: 0.5467 - val_loss: 1.1508 - val_accuracy: 0.4549\n",
      "Epoch 161/200\n",
      "414/414 [==============================] - 0s 950us/step - loss: 1.0516 - accuracy: 0.5515 - val_loss: 1.1046 - val_accuracy: 0.4995\n",
      "Epoch 162/200\n",
      "414/414 [==============================] - 0s 937us/step - loss: 1.0682 - accuracy: 0.5437 - val_loss: 1.1469 - val_accuracy: 0.4477\n",
      "Epoch 163/200\n",
      "414/414 [==============================] - 0s 920us/step - loss: 1.0476 - accuracy: 0.5504 - val_loss: 1.0868 - val_accuracy: 0.5077\n",
      "Epoch 164/200\n",
      "414/414 [==============================] - 0s 881us/step - loss: 1.0553 - accuracy: 0.5416 - val_loss: 1.1130 - val_accuracy: 0.4990\n",
      "Epoch 165/200\n",
      "414/414 [==============================] - 0s 883us/step - loss: 1.0550 - accuracy: 0.5504 - val_loss: 1.0449 - val_accuracy: 0.5267\n",
      "Epoch 166/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0390 - accuracy: 0.5454 - val_loss: 1.2007 - val_accuracy: 0.4472\n",
      "Epoch 167/200\n",
      "414/414 [==============================] - 0s 904us/step - loss: 1.0529 - accuracy: 0.5451 - val_loss: 1.1724 - val_accuracy: 0.4605\n",
      "Epoch 168/200\n",
      "414/414 [==============================] - 0s 909us/step - loss: 1.0769 - accuracy: 0.5419 - val_loss: 1.1283 - val_accuracy: 0.4733\n",
      "Epoch 169/200\n",
      "414/414 [==============================] - 0s 910us/step - loss: 1.0421 - accuracy: 0.5498 - val_loss: 1.0715 - val_accuracy: 0.5154\n",
      "Epoch 170/200\n",
      "414/414 [==============================] - 0s 886us/step - loss: 1.0434 - accuracy: 0.5494 - val_loss: 1.1458 - val_accuracy: 0.4651\n",
      "Epoch 171/200\n",
      "414/414 [==============================] - 0s 873us/step - loss: 1.0509 - accuracy: 0.5449 - val_loss: 1.1047 - val_accuracy: 0.4979\n",
      "Epoch 172/200\n",
      "414/414 [==============================] - 0s 906us/step - loss: 1.0536 - accuracy: 0.5451 - val_loss: 1.0800 - val_accuracy: 0.5277\n",
      "Epoch 173/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0229 - accuracy: 0.5527 - val_loss: 1.1152 - val_accuracy: 0.4908\n",
      "Epoch 174/200\n",
      "414/414 [==============================] - 1s 1ms/step - loss: 1.0275 - accuracy: 0.5569 - val_loss: 1.0519 - val_accuracy: 0.5400\n",
      "Epoch 175/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0589 - accuracy: 0.5266 - val_loss: 1.1391 - val_accuracy: 0.4610\n",
      "Epoch 176/200\n",
      "414/414 [==============================] - 0s 960us/step - loss: 1.0486 - accuracy: 0.5440 - val_loss: 1.2463 - val_accuracy: 0.4221\n",
      "Epoch 177/200\n",
      "414/414 [==============================] - 0s 940us/step - loss: 1.0498 - accuracy: 0.5466 - val_loss: 1.1405 - val_accuracy: 0.4841\n",
      "Epoch 178/200\n",
      "414/414 [==============================] - 0s 891us/step - loss: 1.0390 - accuracy: 0.5523 - val_loss: 1.1180 - val_accuracy: 0.4867\n",
      "Epoch 179/200\n",
      "414/414 [==============================] - 0s 867us/step - loss: 1.0320 - accuracy: 0.5611 - val_loss: 1.1520 - val_accuracy: 0.4595\n",
      "Epoch 180/200\n",
      "414/414 [==============================] - 0s 898us/step - loss: 1.0396 - accuracy: 0.5477 - val_loss: 1.0910 - val_accuracy: 0.5174\n",
      "Epoch 181/200\n",
      "414/414 [==============================] - 0s 897us/step - loss: 1.0378 - accuracy: 0.5490 - val_loss: 1.0825 - val_accuracy: 0.5185\n",
      "Epoch 182/200\n",
      "414/414 [==============================] - 0s 910us/step - loss: 1.0412 - accuracy: 0.5393 - val_loss: 1.1025 - val_accuracy: 0.4985\n",
      "Epoch 183/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0492 - accuracy: 0.5405 - val_loss: 1.1495 - val_accuracy: 0.4744\n",
      "Epoch 184/200\n",
      "414/414 [==============================] - 0s 897us/step - loss: 1.0300 - accuracy: 0.5613 - val_loss: 1.1007 - val_accuracy: 0.5097\n",
      "Epoch 185/200\n",
      "414/414 [==============================] - 0s 974us/step - loss: 1.0471 - accuracy: 0.5454 - val_loss: 1.0862 - val_accuracy: 0.5144\n",
      "Epoch 186/200\n",
      "414/414 [==============================] - 0s 946us/step - loss: 1.0526 - accuracy: 0.5447 - val_loss: 1.0582 - val_accuracy: 0.5205\n",
      "Epoch 187/200\n",
      "414/414 [==============================] - 0s 882us/step - loss: 1.0243 - accuracy: 0.5506 - val_loss: 1.1793 - val_accuracy: 0.4549\n",
      "Epoch 188/200\n",
      "414/414 [==============================] - 0s 985us/step - loss: 1.0568 - accuracy: 0.5493 - val_loss: 1.0793 - val_accuracy: 0.5092\n",
      "Epoch 189/200\n",
      "414/414 [==============================] - 0s 924us/step - loss: 1.0549 - accuracy: 0.5458 - val_loss: 1.0804 - val_accuracy: 0.5051\n",
      "Epoch 190/200\n",
      "414/414 [==============================] - 0s 924us/step - loss: 1.0482 - accuracy: 0.5447 - val_loss: 1.0939 - val_accuracy: 0.5123\n",
      "Epoch 191/200\n",
      "414/414 [==============================] - 0s 981us/step - loss: 1.0552 - accuracy: 0.5525 - val_loss: 1.0589 - val_accuracy: 0.5149\n",
      "Epoch 192/200\n",
      "414/414 [==============================] - 0s 1ms/step - loss: 1.0333 - accuracy: 0.5559 - val_loss: 1.1214 - val_accuracy: 0.4774\n",
      "Epoch 193/200\n",
      "414/414 [==============================] - 0s 960us/step - loss: 1.0326 - accuracy: 0.5578 - val_loss: 1.1000 - val_accuracy: 0.5026\n",
      "Epoch 194/200\n",
      "414/414 [==============================] - 0s 952us/step - loss: 1.0336 - accuracy: 0.5477 - val_loss: 1.1245 - val_accuracy: 0.4636\n",
      "Epoch 195/200\n",
      "414/414 [==============================] - 0s 891us/step - loss: 1.0428 - accuracy: 0.5417 - val_loss: 1.1342 - val_accuracy: 0.4903\n",
      "Epoch 196/200\n",
      "414/414 [==============================] - 0s 882us/step - loss: 1.0461 - accuracy: 0.5467 - val_loss: 1.0923 - val_accuracy: 0.4995\n",
      "Epoch 197/200\n",
      "414/414 [==============================] - 0s 908us/step - loss: 1.0281 - accuracy: 0.5586 - val_loss: 1.1875 - val_accuracy: 0.4354\n",
      "Epoch 198/200\n",
      "414/414 [==============================] - 0s 870us/step - loss: 1.0317 - accuracy: 0.5442 - val_loss: 1.1313 - val_accuracy: 0.4851\n",
      "Epoch 199/200\n",
      "414/414 [==============================] - 0s 908us/step - loss: 1.0384 - accuracy: 0.5436 - val_loss: 1.1417 - val_accuracy: 0.4569\n",
      "Epoch 200/200\n",
      "414/414 [==============================] - 0s 951us/step - loss: 1.0383 - accuracy: 0.5576 - val_loss: 1.1386 - val_accuracy: 0.4872\n"
     ]
    }
   ],
   "source": [
    "model_all_ = keras.models.Sequential()\n",
    "model_all_.add(keras.layers.Dense(units = 32,input_dim = 11,activation = 'relu'))\n",
    "model_all_.add(keras.layers.Dense(units = 11,activation = 'softmax'))\n",
    "\n",
    "model_all_.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist_ = model_all_.fit(X_train,Y_train,epochs=200,batch_size=11,validation_data = (X_test,Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEYCAYAAADmugmLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABdjklEQVR4nO2deZgcVfW/39OzZ98XSCCBBMIqhLAEIougBBQjCgiygyL7ov4E3BD0q6CCIij7qiyCIKJEFJGwQ0ggAUIICYFAErKQPTOT2fr8/rhd3dXV1cvMdE/39Jz3eebprlu3qm7XdN1Pn3PPPVdUFcMwDMMoRSLFboBhGIZhpMNEyjAMwyhZTKQMwzCMksVEyjAMwyhZTKQMwzCMksVEyjAMwyhZTKQMIwQRuVNEVonI22n2i4j8XkQWicibIjKxq9toGD0BEynDCOduYGqG/UcA42N/ZwE3dUGbDKPHYSJlGCGo6nPA2gxVpgH3quMVYICIjOya1hlGz6Gy2A1oL5FIROvq6ordDKOb09DQoMDrvqJbVfXWdpxia+Bj3/bSWNkneWheyTJkyBAdM2ZMsZthdHNmz579qaoOzaVutxOpuro66uvri90Mo5sjIo2qOqkzpwgpK/scY2PGjGHWrFnFbobRzRGRJbnWNXefYXSMpcBo3/YoYHmR2mIYZYuJlGF0jMeBU2JRfvsBG1S1rF19hlEMykak5s07jqVLbyh2M4wyQUQeAF4GdhSRpSJypoicLSJnx6pMBxYDi4DbgHOL1NTux+zZ8NOfFrsVRjeh241JpWP9+hlUVQ0udjOMMkFVT8iyX4Hzuqg55cWk2FCgCZWRA2VjSYlUoBotdjMMw8gVW8vOyIGyESn3UUykDKPb0NZW7BYY3YCyESmRCKr2pTeMbkPUflQa2SkbkQJz9xlGt8JEysiBgomUiIwWkWdEZL6IzBORi0LqHCwiG0RkTuzvJx2/XgQwS8owug3m7jNyoJDRfa3Ad1X1dRHpC8wWkadU9Z1AvedV9UudvZgFThhGN8MsKSMHCmZJqeonqvp67P0mYD4ut1mBsDEpw+hWmEgZOdAlY1IiMgbYE3g1ZPdkEZkrIv8SkV3SHH+WiMwSkVmtra1prmHRfYbRrTB3n5EDBZ/MKyJ9gEeAi1V1Y2D368C2qrpZRI4EHsOtz5NELDv1rQC9e/dOM7nC3H2G0a0wS8rIgYJaUiJShROo+1T10eB+Vd2oqptj76cDVSIypGPXssAJw+hWmEgZOVDI6D4B7gDmq+p1aeqMiNVDRPaJtWdNx65nlpRhdCvM3WfkQCHdfQcAJwNvicicWNkPgG0AVPVm4BjgHBFpBRqB42M50TqABU4YRrfCLCkjBwomUqr6AuELw/nr3AjcmI/riVRggRNGPhGRqcD1QAVwu6peHdjfH/gz7odXJfAbVb2ryxvaXTGRMnKgjDJORMzdZ+QNcb96/gAcAewMnCAiOweqnQe8o6qfAQ4GrhWR6i5taHfG3H1GDpSNSFnghJFn9gEWqepiVW0GHgSmBeoo0Dc2rtoHWIubxG7kgllSRg6UkUhZ4ITRLiq9uXexv7MC+7cGPvZtLyV1MvqNwE64ZePfAi5S+xLmjllSRg6UzaKHFjhhtJNWVZ2UYX/YeGowqOdwYA7wOWB74CkReT5kPqARhllSRg6UlSVlgRNGHlkKjPZtj8JZTH5OBx5VxyLgA2BCF7Wv+2MiZeRA2YiUBU4YeeY1YLyIjI0FQxwPPB6o8xFwKICIDAd2BBZ3aSu7M+buM3KgbNx9Fjhh5BNVbRWR84F/40LQ71TVeSJydmz/zcDPgLtF5C2ce/BSVf20aI3ubpglZeRAGYmUBU4Y+SWWqmt6oOxm3/vlwBe6ul1lg4mUkQNl5u4zS8owug3m7jNyoGxEygInDKObYZaUkQNlI1JmSRlGN8NEysiBshEpW/TQMBKIyJ0iskpE3s5Sb28RaRORY7qqbXHM3WfkQBmJlAVOGIaPu4GpmSrE8hNeg4tg7HrMkjJyoGxEytx9hpFAVZ/D5RLMxAW4RUlXFb5FIZhIGTlQNiJlgROGkTsisjVwNHBztroFw9x9Rg6UjUiZJWUY7eJ3uMnHWR8aETnLS8S7evXq/LXALCkjB8pGpCxwwihXRORYEekbe/8jEXlURCZ28rSTgAdF5EPcCtl/FJGvhFVU1VtVdZKqTho6dGj2M0ejsGVLbvUMIwtlJFIWOGGULT9W1U0iMgWXef0e4KbOnFBVx6rqGFUdA/wVOFdVH+t0SwHOPhvq6rLXM3efkQNlI1Lm7jPKGO+L/UXgJlX9O5BxBWAReQB4GdhRRJaKyJkicraXe7Cg3Habe81mKZklZeRAwXL3icho4F5gBM4Pd6uqXh+oI8D1wJFAA3Caqr7esetZ4ISRX0RkKu77WQHcrqpXh9Q5GDe+UwV8qqoHFaApy0TkFuAw4BoRqSHLD0xVPSHXk6vqaZ1rHjBjBtTUwOTJibKWFleWDrOkjBwopCXVCnxXVXcC9gPOE5GdA3WOAMbH/s6iUy4Ms6SM/BGbQ/QH3Hd0Z+CE4PdXRAYAfwS+rKq7AMcWqDnH4eYyTVXV9cAg4P8V6Fod49vfhmuuSS5rbc18jFlSRg4UTKRU9RPPKlLVTcB8UpffngbcG1s07hVggIiM7Mj1zJIy8sw+wCJVXayqzcCDuO+rn2/gFj38CEBVCzXfaCTwhKoujFluxwIzC3StjrHXXjB7dnJZS0vmY0ykjBzokjEpERkD7Am8Gti1NfCxb3spqUKW4zVs0UOjXVR6YdWxv7MC+3P5bu4ADBSRGSIyW0ROKVBbHwHaRGQccAcwFri/QNfqGJMmwdKlsMqn09lEytx9Rg4UfD0pEemDe8guVtWNwd0hh2jIOc7CuQOprk43XmzuPqNdtKrqpAz7c/luVgJ74VbnrQNeFpFXVPW9PLXRIxpbhPGrwO9U9QYReSPP1+gce+3lXt/wNcvcfUYeKKhIiUgVTqDuU9VHQ6osBUb7tkcBy4OVVPVW4FaA3r17p4iYu5a5+4y8kst3cykuWKIeqBeR54DPAPkWqRYROQE4BTgqVlaV52t0jq22cq/+yb7m7kulrQ1EIFJGgdUFpmB3Kha5dwcwX1WvS1PtceAUcewHbFDVTzp2RbOkjLzyGjBeRMaKSDVwPO776ufvwGdFpFJEegH74sZe883pwGTg/1T1AxEZC/y5ANfpOH37utdNmxJl5u5LpaoKJnZ2HnbPIidLSkQuAu4CNgG348aXLlPV/2Q47ADgZOAtEZkTK/sBsA3El+Gejgs/X4QLQT+9/R/Ba6NZUkb+iLnXzsdF1VUAd6rqPG+ekarerKrzReRJ4E3cl+92Vc24NEYH2/KOiHwP2EFEdgUWhIXDF5U+fdzr5s2JMnP3paIKc+cWuxXdilzdfWeo6vUicjgwFCcmdwFpRUpVXyDcr++vo8B5ObYhIy5wogf+MjMKhqpOx/2Q8pfdHNj+NfDrQrYjFtF3D/Ah7pkaLSKnxjKdlwa9ejk3ll+kiuHuO/lkGD8efvKT/J/bKAq5ipQnNkcCd6nq3Jg7r4Sw6D6jbLkW+IKqLgAQkR2AB3BBG6VBJAK9exff3ffnmBfURKpsyHVMaraI/AcnUv+OJbssKUUwd59RxlR5AgUQix4srcAJcONSHXH3vfoqfP/7hWuX0a3J1ZI6E9gDWKyqDSIyiE6MHxWGCKCoKiVn5BlG55glIncAf4ptnwjMzlC/OPTp0z5LyhOp/fZzr1dfbVFvRgq5fiMm4wZr14vIScCPgA2Fa1b7cZYUmDVllCHnAPOAC4GLgHeAwieKbS99+sBDDyW22+vuy1bf6JHkKlI3AQ0i8hng+8ASXPLYksGtJ4UFTxhlh6o2qep1qvpVVT1aVX+rqk3FblcKffsmB0P43X1btsCZZ8KKFYmyYOBEPkXq3pLqnoxOkKu7r1VVVUSmAder6h0icmohG9Z+PJEyS8ooD0TkLUIysHio6u5d2JzsBLPB+EXn4YfhzjuTrae//hUefTS8fmc59VQ48USoqMheNx/ccAMMHw7HHdc11+tB5CpSm0Tkcty8p8/GMkSX1MCtufuMMuRLxW5Au1i3LnnbLzoNDe7VL2QzZqSvnwu/+hVceqmzyMLGoVtbu06kbr4Ztt8+s0j1xMnLeSBXd9/XgSbcfKkVuESbBZ0b0n7M3WeUF6q6JNOfV09EXi5mO+N8+mnydtDdB1Bbm/54v0hFo3DddbAxmO7Tx6WXJupmO5+HKtx/PzQ25lY/V1pbE58xHTbm1iFyEqmYMN0H9BeRLwFbVLWknL5mSRk9mAw9fxcSFCl/p+x14JmWlffXf+kl+O534axgcvoQ0oW6h4nC9OnODXjVVcnlixY5K+/+DiaXb22FpizDhM3NHTt3DycnkRKR43Dr1xyLW4DtVRE5ppANay8WOGH0YNKOW3UpRx+dvB0mUplW6vXX91xjTz+d/brtEan3Yrl//fO5AN56y736oxPbg1lSBSNXd98Pgb1V9VRVPQW3INyPC9esjmCBE4ZRVO64A772tcS2Xzw891rapXZI7sQ3xGa4BK2zTMcF3X5h4uWtdzV8eHK5Nz8rzHV4003Qv79zFaajrc1EqkDkKlKRwKqja9pxbJdg7j4j34jIVBFZICKLROSyDPX2FpG2InoXSmP2enU1bLddYjvMkso0Wddf3z8WlS3gwBOjXOZdeSLVv39yuRdgESZS557r2pPJXZeLJWXuvg6Ra3TfkyLyb1y+MHCBFNMz1C8C5u4z8kcsgvUPwOdx60a9JiKPq+o7IfWuwWVLLxYnF/HayfgDI8JEKtO4TTqRamnJHKXniVTQcgoTqZUrw+tmsqT850vnrjR3X8HINXDi/+EWHdwdt6jbrap6aSEb1l7MkjLyzD7AIlVdrKrNwIPAtJB6F+AW9lwVsq9TiMgmEdkY8rdJROK9eCGWB+kwVb6ZKWHuvlxFaoMvoU02C6QjIhU8Z64ilakN7bGkMrkOS4VHH01MHSgiOa/Mq6qP4B7GksQCJ4x2Uikis3zbt8ZWgPbYGvjYt70Ut6hhHBHZGjga+Bywd74bqKp9833OguMXKX+nXl/vXjN15OksqWwi5R0XFJEwUfHELyiW+RCpbPiPb21NvlelxsyZbnzxW9+CW2/NXr+AZBQpEdlEeOSQ4JaD6leQVnUIZ0lZ4ISRI62qOinD/rBxnuCz8DvgUlVt64qkxiIyDF+4uap+VPCLtpegSDU1uflMb7zhyjri7ssW2p3OkgoTDu9cQeHzxKkzIpVNqPzXbGkpbZHyxHzx4uK2gywi1Z1+yXmWFJglZeSFpcBo3/YoYHmgziTgwZhADQGOFJFWVX0snw0RkS/j1pTaCudW3Ba3TP0u+bxOXgi6+958E66/PlFWbHef53YMntOrmylII5tItbU5N166Hyz+4218KmdKKkKvc1gIupFXXgPGi8hYEakGjgce91dQ1bGqOkZVxwB/Bc7Nt0DF+BmwH/Ceqo4FDgVeLMB1Ok/Qklq/Pnl/Id19uYiUN8biP+eLL8K3v+3ee5ZUc7M73m9ZpRMW1YS4ZRLhoCVl5ETZiJQFThj5RFVbgfNxUXvzgYdUdZ6InC0iXb1MRouqrgEiIhJR1Wdw67uVHv55UC0tiXx+3/ueey2mJaUaHsAxZQp88ol774lSTQ1MnJhbO/zWV64iXOrh6CWUZzDnwIlSxwInjHyjqtMJTLVQ1ZvT1D2tgE1ZLyJ9gOeB+0RkFZBxAERE7sQlqF2lqruG7D8R8CJ0NwPnqOrcTrfUn/aotTUhUhdfDA88UBhLKtcxKb9llO6cfsvp7bdh7drw9qW7TrlYUmG5DYtEwSwpEblTRFaJSGh4rIgcLCIbRGRO7O8nnbuiBU4YZctzwADcgodPAu8DR2U55m5gaob9HwAHxZb7+BluiknnOeYYuOQS995vSQ0c6FyBuVpSmzbB4MHufUcDJ4JC4A+nzkWkIBGVGHa+4PUhdxE2kcqZQrr77ibzQwLwvKruEfu7KkvdjFjghFHGCM7tOAPoA/wl5v5Li6o+B6zNsP8lVfXW1ngFFxjSeaqrXfbyAQNc571+vSurq3MilWsnXl/vhA0SgvLGG/DTn6Y/LptI+TveXFx3kNzezopUKVpSa9YkuzQ9eoJIZXtI8o8FThjliapeqaq7AOfhIvyeFZH/5vESZwL/yuP5nCB5ltSAAS7irT2WVJhITZkCV16Zeo7OWFLBOkFLyn+tcrSkhgxxf0G8z1ECk46LHTgxWUTmisi/RKRT4bQWOGH0AFYBK3C5M4fl44QicghOpNJmkBGRs0RklojMWr16dW4n9ouUJzbZLKnly12nqBouUp5gBH/55ypSfuvAO5cXMOERjSZ3zPkUqVK0pCB8fldPsKRy4HVgW1X9DHAD8Fi6iv6HpDXNhDkLnDDKFRE5R0RmAE/j5mN9Kx9Lx4vI7sDtwLRM7kNVvVVVJ6nqpKFDh+Z28srKROBEriJ15ZVw111OGKLRVJGqjMV55SpSwe0wd5+XcNYjGk0fZZhOWN72Dbt3N0vKI2gxefeqvZZUfT3svrvLWJEniiZSqrpRVTfH3k8HqkQkxO5MfkgqK9MFJFrghFG2bAtcrKq7qOoVwSS3HUFEtgEeBU5W1fc63cIgQXefV5YtCOK//00EKwwa5F69Y9KJVDAtkpeMNhd339rAiEQ0mixmfhELE5aZM+Hzn09sl1J033/+k3uou5fT0MO7B+myaCxYAB9+mFo+e7Zbm+u73825mdkomkiJyAiJTdUXkX1ibck4GJz5fBY4YZQnqnqZqs5pzzEi8gDwMrCjiCwVkTMDc7x+AgwG/hiLrp2V9mQdYehQ+OgjWL06MeaRzZICJzCeSKWzpIIThIOW1H33udd07r7+/RPn9KIPPYIi5e+8wzr8V15J3i4FS2rNGvjjH+Hww+G003I7Jpj+yLsH6dx+EybA2LGp5V6W+Gw/RtpBweZJxR6Sg4EhIrIUuAKogvhck2OAc0SkFWgEjlftzCidBU4YhoeqnpBl/zeBbxasAVOmwO9/76LlxoxxZVVV2cc6Kiuzi1Q2d583VyudJTVgQKITDbOk/EKTzZJaujR5+4MPnHU1aVLq2ll+kSvkZN5jjoEZM9z7Bx6A++/PfsyHH8L++ye2vXvQ3rEp73/QHUQqh4fkRuDGfF3PAicMo4Q46CD4zW/ce79IBZdtD5KLJZWrSKUbkxowIL0l1draPnffxx8nb198sXt99FGYOhWWLYNx41zZpk2Zz5Uv5s9P3m5ogF69Mh+Tzt3XXpHyfgjkUaSKHd2XN6qqnP+6qSmYA9QwjC5nypREolW/SGUjEkkvUt7x6caksllSYe6+oCXV1JRsSfk771wsKY8FC+DUU2H8+ESH/fjj6duWT/xZPyDzmlBeGqtg1KaJVP7p1WsnRKrZvPmNYjfFMIwBA2CPPdx7b+wiF5Hyws8hIVLf+Y7L/ee5z7KNSXmrA3tCsGyZO6/f3ZfOkmpuTu6YP/008T4oLK+84pLThrFkiQsCATdGtGSJywh/8snh54L8zUkKWk1+kVq1KnH/VBPtCEY5+kWqPYsfmkilJxKppnfvXU2kDKNUOPRQJxijYsks/CLVu3f4MQ0NqSIFcO21ic61PWNSM2a46190Ebz2miv3i1Q2S2qNL5brxhth5MjEhN/p00nLzTcnBHDVqsR5dtwxcR0/w4c769PP3Llw+eXh4rViRWrbPYIi9cYbcPXV7jzDh8M228Cf/5xYWsRr48svJ0TLE6n1693ih9//vgvGEMk8nmYilZm+ffdmw4aX2bIljQluGO1ARKaKyAIRWSQil4XsP1FE3oz9vSQinylGO0uWn/wEXn014VLyi5Q3ThNk8+aESPULrKnqJZ3NJlLV1c7qamlxwRsAN9zgOmbvvF4num6di0T0CFpSfpGaN8+Jg9eO+vr0Yutn9erEZ/Ku5XXm9fUu0GHVKnjppeTjDjrIiYs/f6DHyJEwbJhr63HHwaJFiX3BaTpf+YoTO8/q27TJWXR+K/GZZ1zgxOWXu+1glOLy5fCDH7j3azIEYXufa+1aeOih9PXaQVmJ1Dbb/D9Aef/9S4rdFKObIy4S5w/AEcDOwAkisnOgWmGStJYLffu6iZ0efpHafvvwYzZvTnR06QRgxYpk62LOHNeZeyJVWemutXAh/O1vycf26ePCpP3uvuHDE/uDllQ0mtrpe5305s2dF6lHHnF/YfiFLIy2NmcpPvwwnHdeojxdcMqjjyZv+1183jGekAXHovr0SbwPBll4tLa6OVIeX/96XpaeLyuRqqvbnm22+T6rV/+VdetmFLs5RvdmH2CRqi5W1WbgQWCav0LBkrSWK55IRSKw7bbhderrE51yOgGYPz85EeyddzoL4L3YnGRPpMJ+yffp4ywtT6T82dbBdbT+ZUK8Y/x4brZ0ltRuuyVvP/WUczdCqkgFAy/Wr3eW1cKFCbeiPyowiBec4s85GJYwFty8NT9esIR/DTC/MPo/W+/eiR8G/jb7r3vssXDbbYntKVPcZ+kkZSVSAKNHf4+6unEsWPBNotGMS+4YPZtKL9VW7O+swP6tAX988dJYWTryn6S13PBEqk8fGDEivM7mzYlf9WFh0yNHuiCEz30udd+TT7rXysqE9TN4cCIDBTjrrrbWuQLb2ty1vMwWHgsWJG8HhcizpOrrUwUM4KST4PjjE9t3350Q0AEDXNs8MQiGsF94obOs/vSnhBBnCtv3BOy//4UjjnDvN26E88932R/8LA9EPnuW1Cjfbyu/SO29d6K8sTEhUsuWJZeDa+tjjyXKv/1tZ+UF720HKDuRqqjozXbb/ZotW97nueeqeOedE+nUHGGjXGn1Um3F/oJ+CQk5JvSLlEuSVoNkkdo54Dk98kj3unmzGysZPDh1MizAXnu51+efT933+uvu1bOkwHWS/vP06ZOwnD79NFykvFx8XrmXRcEjmyVVW5veCuzd24mvJwYLFybv/9OfUq8ZFCm/9eIfH3rySeeu3LDBiWGwDelEyu/u9IuU/3+0fn16kXrooVSX6M03J/846ARlJ1IAQ4YcRb9+B1BR0YdVq+5n3br/EI2W+HLNRqmxFBjt2x4FpEzCyzVJq0GySH3xi8m/vJ94As4913WOq1a5oIAwvvCF3K7jXWvw4OTxqz59Ep3y8uWukw2K1Lx57tVL5+SFtHtkG5Nqj0gtWRJezz9vKeju848XBec3eW7U/v1TLdGgSHmuOb9IrV7t0imtXZsYvwMnfGEi1dCQCKgoEGUpUiIVTJz4ApMnLyMS6c2bb07l1Ve3p6FhQfaDDcPxGjBeRMaKSDVwPPC4v0LBk7SWG36REoFp05L39+7tOv6VK9OL1KGHpna2QfyWVJhIeef28tX5Q91raxOJUz2RClpS773nkrd2xJLq1SshUv/9b3KH78cvPkFLyr8dFDkvqGHjxlSRCs7N8sTYf69bWtxnA/cZ1q9PiJYnrEFLalRhh2LLUqQ8Kiv7seeez7HDDjcTjTYxe/bevP32Mbz33jnMnLkL779v3hkjHFVtBc7HrYg7H3hIVed1aZLWcmO77dxrcADfY+BAF1n3wQeJjnPBguROcfz48PEsf0cZdPf5qatLWA5hIuW1cciQRAi835KqqnLzpQ4/3LUrnUiFjVWBc4H16uWCKT7/+fQZHYIiNW+euy+QHO3nlQX56lfDx/SC2Sgg2ZLy07u3+yxDh7rrhAVONDSkH1/MEwXL3Vcq9O07kb59J9Kv3wEsWnQBn376KE6b22hoeIdIpIattz6f6uq8rCFnlBGxJWSmB8pu9r0vbJLWcsNb0sI/P8ePlz5p6dKESO2wQ3IdT3zGjUueG3TUUXDTTe59JksKUkWqb9/EvlGj4J13XMfrCY3fkho1KiEMa9aEi1EmSwqceAQzPPjZe+9Ud9+uu7r3qslRi8Hs5QCzZrlsH2Fj8VOnwiGHuAANj0wiBc516Hc5+u97Y2P2zPadpKwtKT99+uzKHns8w957v8X++y/nwAObqavbgSVLfsZLLw3npZdGMmvWnnzwwRVs2PAyK1c+wMyZO1Nf/26xm24Y5cE227jXww8P3++JFKS6+yorYc89E9sHHJC8f8cd4YRYTuuKisS5Bg1K7az793evN8d+b/iFxrPIhg8PF6lgeHk2d19YqH26ZK+33AJXXeUEyW+teOHrAM89l5hwCwnX5LhxiblSXsCDhMT+9OsHF1yQXJbOtep9Bm89MHARhP5sEgccAH//u/sx8P774efpJD1GpDx6996F6uphRCJV7Lrro4wc+S0qKwfR3LyCzZvnsGTJVbzxxv7Mn/8NGhrm89prOzF//sksXvwDPvzwZ6xb9zTvvXcODQ0Ls1/MMIxkGhrgn/8M35dJpDZvdtkrPI46Knn/kCFuHamGBtc5e2ISlp4n2Hn7RWrr2CyDwYPDReqyQOKRbCI1aZJLN+QnnUjttx/8+MfOvZbO2gyGlYNzPy5c6LJqbNgQ7tLzrum3Gj2yWVLejwuAM88Mrzt5snOVXn893HNPeJ0O0uNEyk/v3ruw4463MmXKGnbe+S9MmPAnhg8/iUgk+Uu0cuWf+eijX/Lhhz9h7tzDWL78Zt54Y38WLryQ2bP3Ye3ap9i8+S1eemkk69bN4NNP/0402kRLy1o2bZpNW1thzWHD6DbU1SWHK//rX849BcmdZXBBvZqa5IwVX/1qYl4UuA5SJNFBeyHt22wT7vbyu7vCRAoS4eH77psomzzZZanwzp9OpLwJsqpOfPykEymvHemycUByRCTAJZckLCiR1FRSwXN7IvXb3yb2ZQrygOQ5X0EL1sOzTi+8EE45JbxOByn7MalcGTbsOABGjDiJCRPuBaK0tm6ksfF9VFuord0WiLB+/dNUVg5k4cLzWbbsBgDefPNwvCk0c+ceEnr+QYO+CLQxcuRZDBhwMJFIHRUVbkC2qWkZNTWZ5okaRpkydWrifSTiOszGxuQl2cMQSXYb7rRT8v6DDnLBBhMmuImlQa6/PpHXz99Je518a6vLb/fvfzsRGDw4Yd0NGOBcj9Onpxcpb25WmEAGowU9PCEJm6js8dxzifdPPeWiHXPBE3hPpC6+2AkcJGec2H//RA5B77P16+c+a//+6a2udIEiecBEKgS3qn0FVVUDqaqalLRv+PATAejb92WWL7+F4cNPYfnyP7By5Z+pq9uBaLSR+vp5RKPJqe03b55Nc/MK1q71fv1VUFU1hJYWFzJaUdGPXr12olevHYhE6ujbdxJDh36NqqpBtLXVs2HDi0QiNfTv/9lYG3u0EWyUK4sWOWsobCJvJvzjJh7e2MyECfBubGw5bJzG38GOHOlex42DE0+Eb3zDHRMUOm98LF3gRFi6Ig8vO/p557l23367Cx33RCGTJeVn113DP0+QMWMSE2vDrDi/SL34YuKcfgH2sln4eecdl1Xi3HMLGjxhItVBqquHM2bMTwDYfvtfs/32v07arxqlvv5tampGU1HRl0ikkoaG91iz5gmamj5GpIrW1vWsWvUX2to2EI1uob7+bTZtepWKir588smtLF58OdXVw2lomI9nqUUivVBtZtiwE+jbdxKqLYjUUFnZn2i0gd69d0O1laqqIVRXj4xfW1Vj4msYJUwhwpn/9z+XhPWii5zoBPELzcEHu6S0Xqec7pnZf39nXU2YkLrP7+7zwtcfeiiR6eKTT9zr0Uc7S+jkk+Ef/0iIgohL1Nqrl3OFfv3r4W3IJbltY6M73113wTnnhFtxNTXw7LOJ+1BR4dIcZTv/4MGJEP9sKy53AuluKYN69+6t9emyAndD2trqEamira0BEWHLliX07r0bmza9xpIlvyAabaB//yn07bsXzc0r2LDBmeIrVtwDtGU+OVBZOTB2vtnU1o6mqmoY/fpNpqZmK+rr36J378/Q1raZIUO+QkvLKurr5/HJJ7czduz/MWjQFxCJoBotO8tNRBpUNYen3PAzadIkneWNIZUCDz/sAg0OPrj9x3oC1NDg3F/bbQeXdmDuZEVFssW0cqXrvH/0I7dgYzAIZMQIV+eDD5KDRdJRWelE45lnnHhNnuzSJ/3ud7lZUuDcjk8/7ZK+esLpHbtsGWy1VaJuba0LOPn44/CJut5x69fDCy/Al77kRD3T+lopp5DZqjope00TqW5LU9MnNDQsYMuWxVRVDaWysj+NjYtobFxE//5TaG5eQX39O6xZ83eampbF1tp6jrq68TQ2epGJQpp0dPH9NTWjaWpaSl3d9kSjTbS2rqOioh91deOoqOhNdfVIqqoGIlLFgAEHI1KBSCWqUVpb11FTMwqRKqqqBtHaup7Gxveprh6OSA2trWvo1WtCbLwPVBXVNiKRwhv4JlIdo+REqjO88go8+KALIuiMl2HcuOTw6w0b0gcwgItCvPhiZ1EFc96FccwxLulsY2NqiqbO4H3m1asT2TXAWVT19S7LhH+is8df/gJXXOHG/Fpa4PTTXej8+PHtuHQJiJSI3Al8CVilqruG7BfgeuBIoAE4TVVfz3ZeE6n247n6mptXU109lNbWDbS1NVJVNYRPP32MhoZ5bNmyhIEDD6Oh4T369NmDLVvep7l5FU1Ny6io6ENLy2oaG9+joWEhQ4YcRXPzCtraGqmvfxNQXIKGjlFdPRLVVqLRJlRbqKsbR3PzKmpqRqKq9Oq1A21tDUQiVTF3ZyvV1SOpqdmalpZVtLR8Su/eu8ZcqOvYvHkuffrsSVXVEAYPPjIugn5MpDpGWYlUvli61FkU11zj1rbasiV9cERHaGx0WTq8VX3zRXW1E5mgqF59tZuL1dSUPF6VR0pFpA4ENgP3phGpI4ELcCK1L3C9qu4brBfERKp4RKMttLaup7o6sZJpc/PqmLtyA1u2fBSr10BbWwM1NaNobl4es6rWIlJNXd04mpqWsWnTTOrqtqe1dRObN89GpIaKit5AlMbGRVRWDmTduqfp1WsCLS2rYgmCo0SjzUQiNbS0rIkFp1QQdHtGIrVEo24gd7fdnmDw4CNTPouJVMcwkcrAqlVuHlNYkEEpMm0aPP54/i20HGiPSBXMr6Kqz4nImAxVpuEETIFXRGSAiIxU1U8K1Sajc0QiVUkCBcS3q6oGhFos6Rg2rHOLoalGaWlZQ1XVEFpbN9DQ8C69eo2noqIvIpW0tq4jGm2isnJAp65jGDkzbFj3EShwrs4PPuhygWovxRwNb++icoYRRyRCdfVQRISqqgH0778fVVWDiUSqEYlQVTWYmpqtqKhIM3Eyp2vIVBFZICKLROSykP0iIr+P7X9TRCZ26kMZRldSV5e6rlcJUkyRas+icmd5K6i2ttpqu0bhEZEK4A/AEcDOwAkiEnyijwDGx/7OAm7q0kYaRg+gmCKV06JyAKp6q7eCamUu0TCG0Xn2ARap6mJVbQYexLmo/cRd1qr6CjBAREZ2dUMNo5wpZo//OHC+iDyIC5zYkMt4VENDg4pImkVYqATM1HLYvXCkuw91gfWfbg0sIR/mjg4G9qRzWZftuOrs2bM/FZE0y8kyBEiTGbXHYffCke4+5DyAXTCREpEHgIOBISKyFLgCqIL4mjzTcZF9i3Ah6Kfncl5VTWv9icisXCNGyh27F45O3Idc3NE5u6zLBVUdmm6ffecS2L1w5OM+FDK674Qs+xU4r1DXN4xOkos7OmeXtWEYHaO8ct0YRv54DRgvImNFpBo4Huei9vM4cEosym8/cnRZG4aRO+UWhXBr9io9BrsXjg7dB1VtFZHzgX/jZgzfqarzROTs2P4Ou6zLGPvOJbB74ej0feh2ufsMwzCMnoO5+wzDMIySxUTKMAzDKFnKQqSypa8pN0TkThFZJSJv+8oGichTIrIw9jrQt+/y2L1ZICKHh5+1+yEio0XkGRGZLyLzROSiWHmPuxfFxJ6/nvmd67Lnz63h033/cIPa7wPbAdXAXGDnYrerwJ/5QGAi8Lav7FfAZbH3lwHXxN7vHLsnNcDY2L2qKPZnyNN9GAlMjL3vC7wX+7w97l4U8X9gz5/a81fI568cLKlc0teUFar6HLA2UDwNuCf2/h7gK77yB1W1SVU/wEWi7dMV7Sw0qvqJxtYgU9VNwHxcxocedy+KiD1/jh73neuq568cRMqyqTuGa2yOTuzVW7O6R9yf2LIwewKv0sPvRRdj99TRo79zhXz+ykGkelxqmnZS9vdHRPoAjwAXq+rGTFVDysrqXhQBu6eZKfv7U+jnrxxEylLTOFZ6Gbhjr6ti5WV9f0SkCveA3Keqj8aKe+S9KBJ2Tx098jvXFc9fOYhULulregKPA6fG3p8K/N1XfryI1IjIWNzaRzOL0L68IyIC3AHMV9XrfLt63L0oIvb8OXrcd67Lnr9iR4jkKcrkSFxkyfvAD4vdni74vA/gloNowf06ORMYDDwNLIy9DvLV/2Hs3iwAjih2+/N4H6bg3AVvAnNif0f2xHtR5P+DPX898DvXVc+fpUUyDMMwSpZycPcZhmEYZYqJlGEYhlGymEgZhmEYJYuJlGEYhlGymEgZhmEYJYuJVA9FRA4WkX8Wux2GYRiZMJEyDMMwShYTqRJHRE4SkZkiMkdEbhGRChHZLCLXisjrIvK0iAyN1d1DRF4RkTdF5G/eOi4iMk5E/isic2PHbB87fR8R+auIvCsi98VmkBuGYZQMJlIljIjsBHwdOEBV9wDagBOB3sDrqjoReBa4InbIvcClqro78Jav/D7gD6r6GWB/3Gx5cFmLL8at87IdcECBP5JhGEa7qCx2A4yMHArsBbwWM3LqcMkao8BfYnX+DDwqIv2BAar6bKz8HuBhEekLbK2qfwNQ1S0AsfPNVNWlse05wBjghYJ/KsMwjBwxkSptBLhHVS9PKhT5caBeptxWmVx4Tb73bdj3wTCMEsPcfaXN08AxIjIMQEQGici2uP/bMbE63wBeUNUNwDoR+Wys/GTgWXXruywVka/EzlEjIr268kMYhmF0FPvlXMKo6jsi8iPgPyISwWVdPg+oB3YRkdnABty4Fbi0+DfHRGgxcHqs/GTgFhG5KnaOY7vwYxiGYXQYy4LeDRGRzarap9jtMAzDKDTm7jMMwzBKFrOkDMMwjJLFLCnDMAyjZDGRMgzDMEoWEynDMAyjZDGRMgzDMEoWEynDMAyjZDGRMgzDMEoWEynDMAyjZDGRMgzDMEoWEynDMAyjZOl2CWaHDBmiY8aMKXYzjG7O7NmzP1XVocVuR3fDnj8jH7Tn+et2IjVmzBhmzZpV7GYY3RwRWVLsNnRH7Pkz8kF7nj9z9xmGYRgli4mU0a1oboa2tmK3wugordFWohotdjOMboSJlFESzJsHn3ySvd7++8OIEbB4MWzZ4kTrjjvgb38Df0L/TZvg5z+H998vXJuN9lP1syr2v2P/+PbCNQv5ZFMO//g0NLY00tzWnI+mGSWKiZSRd1ShpSV7vbVr4Y03nDjtuit85jOufN48iEbhz3+Gv/4Vli1z5StXwuzZ8OmncOaZUFcHgwbBN78JX/0qXH89rF/vrj9zJvz4xyZSxeSFj17gwn9dmFL+6rJX4+93uHEHtrpuqw5fo9cverHbTbt1+Hij9DGRMvLOxRdDdbUTmnQceywMHgwTJ8JWsT5q9Wr405+cYJ1zDpx8sqv31a864Xn5ZVdv/HiYMcO9r69319tjD7jkEhg4EHbcEQ47DERg330L9zmNzHz2rs9yw8wbaIsW1j/73pr3Cnp+o7iYSBkAtLYmu8vCWLECnn8+tXz16uTt3//evb77Lpx6Kvz618n7X37ZWUhhfPvb7vXWWxPbM2dCJAJHH+2spx/9KPmYSy6B/fZLbPfp415VoX//zJ/JKDyNrY3FboLRjTGRMlB1nf8552Sut+++cOCBTtDWrYOTTnLjQcOGwe23Q00NvPhiov5xx8G998L3vw//+pezeu64w40r+Rk8OPG+0def7b03/PGPcOWVMGmSu85tt8EhhyTqPP44bLMN7LST2z76aHjtNZgyBa66qmP3w8gvjS3un2qrgBsdwUTK4NVXnfDcckvqvsMOc+61006Djz5yZR99BNddB/fd58aDAC67zAUxTJmSOHbePPj8552I/N//OdeeV9/juuucJdbamijbe2/3es45zoL6yU+c8KxcCSeeCKNHu/0TJ8JRR7n3u+ziXg8+GCoqnMX34x935q4Y+cKzpJramorcksKyZP0S7p5zd97Pu7FpI68ufTV7xTzRFm1jbePaLrteNkykyohZs1zwgJ+mJudu81soK1a4oIRVq9z23/7mXnv1gu9+F+6/34V5/+xn8PTTsGgR3HNP4viFC+HNN5Ovs2ZN8vaUKVBV5cTrwgudhfWeb+hgxgxnBV1wgRs7qqhI7Hv4YdiwAU4/Pf1nXbECnn02sX3oofDKK+58RmnhWVINLQ1J5R0Zq2qLtnHVs1exrnFdyr6FaxZy02s3pT32ow0fFdSaO+jugzj976fT1JpfMf7yA19mvzv2y/t503HBvy5g8K8Gs6V1S5dcLxsmUt2Utja46y5nMYwaBS+84ITh4otd+LXHjTc6d9stt7iQ7X32gZEjXVDCeee5yLrXXnN1GxqcZXPiifDvfzsLJow5c+B//0ts19Ul3v/lL/DOO/Dcc+58n/scnHJKYv/dd7sxqYMOclZQZWXyPs/y6tcv8+cfPjwx9uSx775O8IzSwrOkgiIV1gmuql/FIfccwsI1C0PP9eySZ7lixhV86x/fSipXVfa5fR/OnX5u6DysN1e+yba/25YbZt7Q0Y+RlRWbVwBuLlg+eXaJ+zX2+ievd8kcsz+9+Scg/P9TDEykSoh333VWRDY++gj+8Q844ww3RrRsGRxzjLOaAF5/3b2++ip873vufXMz/OY3CUECF7yw1Vau3rBhydeYOdO91tUlQsCrq50wXHMNbN6cqOsFOXzhC24caqednFh4AjR0qBubev55F0jhD3Lwc+qp8J//mNCUG+ksqbBO8LqXr2PGhzPiHWWQPtXul8mbK5NN+cbWRtZvWQ8Q2pF7EYBeh99RWtpauGD6BaFzuyT2xW2J5jD/ogPsf+f+/Py5nxfk3H48CzffYttRTKQKzHPPwYcf5lZ3p51cJ+/3SKi6uUFe2fTpsO22cNFFyceuXJl4f/DBTuz8gRBPPQW/+EX4dRsa4Nxzk8uuvBJ22MEFSGy1Fbz1FixZ4iLrJkxwAQqTJrm6xx8Pc+cmuwSDnHxy8niV0XMIs6QO//PhnP3E2Sl1//eBM9G37b9t6Lm8DvSD9R8klW9s2phSx+P212/n2IePzdjG+uZ6mlqbaGpt4oy/n8HSjUtD6z39wdPc+NqNnDs98cDMXj6b//ef/xffbmkrjEgBXDHjCl786MXsFTuBJ06lMknaRKrAHHQQjB2b2N6wAb71rczZFd5+272qOjGaNMm53/76V/jiF92+jz5yc4M8evdOPsdxx7mJsh7//a8blzrsMLe9zz7J9U89FV56yYnTzju7sgMOcBF74OYujRgBl17q6j36qGvTnDnOYtp9d7ffMIKEWVL/ef8//PWd1HkI76x+B0jvavI6zuCvfL9IBS2ps/5xVvy9EG6m9/llH3b54y48sfAJ7ppzFxc/eXFovcpIZcr1Jt8xmd+8/Jt424KW1L8X/Tu0w1/XuI7nl4TM6cjClLum5GVsraWthZWbVyaV/fO9f8bbX0ixbQ8mUgUkLOvCE0+4cO3jj09/3O67Q9++LmLthpgL/dhj3Z+f885zAQO//nVi0uo118AHvh+Zjz/usjKAG2/685+dRfOXvzg33i23OAEbMwYmT3bjUG++6YIwrrsu8+cbNCiRJcIw0pFuTMrPa8teY+GahdS31APZRQqSxSjJktKOTR5+f9378c5fUd799F2ufenapDreNT3h9eMJoL9zf/njl5l631R++PQPU+p/+cEvc+DdB2Yc+0knRrM/mZ3l02Tn2//8NiOuHZEUkHHUA0fF35eKJdXtluroTnz6aWrZO+6HIs8951L4DBjg8tAdcURyvc2bYf58Z8EsWpQYA/ra11zI9nPPOWvJC+luanLBDH37OsF56CGX8eFLX0pEzp14oht78k/IPessUqiogL326sQHNwwf6cak/Oxze7Jpn24CsL/j3NycGBjd1JSIFgpaUiIS7+wly4CnEquHcMg9h7Bi8wrOnnQ2vaudq6K+OSGiLW0tVFVUxY/xruu3pFY3uJnuC9YsiJet2LyCV5a+wmvL3ADx+2vfZ+HahXxlwleSPqcg7H3b3qHtvOBfF/DSGS9l/TyZuGfuPfFr1VTWpOw3keoBeCHeAH/4g7N25sxJlJ14ootiq61NDs/2M2VKwv0HcPnlbt7SqlXJEXDf+54LIT/tNLftt7qefNJF1AWDIwyjK8jFkko5JsRSgWQB8FtPG5o2xN+niFSIi6+xpZFlm5bx6tJXOXH3E+PlfsvFE741jWsSIhWz9N5a9RbVP6/m/q/en2R9QXY32bQHpzFz2cz49n537Mfm5s00/rCR2spaAA6991CWblzKh+s/TDl+6ripPLnoSba0bqGuqi5lf6549ymdGPnLG1saiUiEmsoa7n/rfn77ym955cxXqIhUhB6bT8zdVyA+/tgFMHicf74bT5o1C044Abbe2gVBPPigC72eOjU5VdCBB7rX/faDv//dpQeKRp2F068fjBuXfL2aGpceqC7kOztxonMNGkYxyMWSCpKLu88vUv5zBwMnIpLazfX5ZR/G3zCek/52UpKoeCIoIlRXVAOwpiExCdCz3rwxsccWPBYXp+A5/Dyx8Ale+vglIBGqHjyn3+32wkcvhAoUwMQRE9NeJx3/fO+fzPhwRug+754Gxd0rn7V8Fr1+0Sse6HLioycya/msuGAXGhOpTvLOOy5o4eGH3fjM4sVOTE47zbnz/Kxa5aLwvvxlN8nVz777Oleex4wZLgz8lFNc/ZtvttBso/vgt0g6ZEkF3H1XPHMFt8y6Ja1I+S2vMHdf/H3MqvLX8Xe2njtPkLgL7NOGhN/e72IE6FXVK2XcyC96fgE44M4DABhUN4gwPGHONEZ14xE3MqLPiPh19rp1L0597NS09T2OeuAoDrnnkNB9zW3N7HHzHhx272HJnyMmgk8uehKA55c8n9S2ptYmVm5eyRfv/yJvr3qbQmEi1UnuusuFcB93nAs4ePxxl2/OP9l11iwXDAFO0L78ZWfZvPiim2wLiXx2//2vy+gg4tIDmTAZ3RF/CiRPQNK58IIMqB2QIlJXPXcVZz9xdpIA+LNO+DvP9gZO+M/jF6yaCidSaxpTLSmPusq6FEuqua2Z1mgr33/q+3ywLjlUHmBw3eCUMkjcs+WblieVT9txWvz9GXueEbfwGlsbef2T17l37r2A+2GQbRxp/ur5KWUt0RbmrpzLMx8+k/I5IHFvW6OtPL7g8aT2HvvwsUxfOJ1/L/p3xut2BhOpNKxc6cQnG7NmJW9fconL+uAPhJg4Eb7xDfd+zz3d2JGIE6bzzoMFC1ymBXDRekFXntGzEZHfiMguxW5He/ALkmdBbWrelK56nIhEGNZ7WE7uviPvPzJxvdZkS2rl5pVs89ttmLtibtqwcw+/CHmWFBBqSfn3g7OkgrREW3hy0ZP8+qVf8/3/fj9lfzpL6u45d7P3bXvz8YaPk8oH1g2Mv6+trKWqogogxXq5+oWrqfl5TUaL1RsL87sWs41Jef+LlfUr44IIcNKjJ/H8Ry4KqzMBHNkwkQqhsdHN+Tn1VDe2dMQRieSqHosXu/GfGTPcZNfPf94lQwU3KfeOO9w8oh/+0AmSN49p25A5ijvsYBaTkZF3gVtF5FUROVtEclqARESmisgCEVkkIpeF7D9YRDaIyJzYX5pEWO3HLxqbmjexrnFdfEwmE9UV1dRV1qW1utIlqfXXb4u28cj8R/h448fcOPPG0DEpP/4xJ8+Sao22xudEhY1JefSuCkxQxLnhMgVP9KsJz/l1xYwrmLV8Vsr6WANrEyLlHyt7Zekr8fLbX7+dq55zaf+9qEGAG169ISnprSc4I68dGS/LVaS2tG5h7sq58f3+7B3+6Mp8U1CRKuZD0l6+8x0XuPDee87SAed6u+oqFx139dXw2GMuWSq4si2xH3uPP+7S+XiTWf/xD5cf7wtfcEuYA0yb5kLDf/CDrvxURjmgqrer6gHAKcAY4E0RuV9EwgcZABGpAP4AHAHsDJwgIjuHVH1eVfeI/eVtcRO/aNwy+xYG/WoQz3z4DIeOPTSlricG4ESqtrI2bQh6cPKph9/yimqUZRtdLq+t+m6V8ivfG0Pab5TLzxVmSdW31Mc/Q5K7ryVZpMJoibZkzLGXzR0ZtJD8IgVQFXGW1IsfJzJPfOsf34oHc/jLL3zyQk7/eyJTs3df121JuDjTiZQntP57u3Tj0pT2AHy88eOkMcJ8UjCRKvZDkisffOACGn77Wxe2/cILiX277JLIEH777S4V0A03uEmsDz7oyg891LnzAP75T5fHbsyY1OuMHu2utXPYHTCMLMSepwmxv0+BucB3ROTBNIfsAyxS1cWq2gw8CExLUzdvNLc1c9l/L+N3r/wuZV9Uo0wdNzWl3Ot0IWZJVSUsqRG/GZE0wXTx+sWh102K7tM2lm1yItW/tn+Su09E4taYNzYUZkk1tDTE3ZOZAifCLLuWtvQi1RZtyzpu9MDbD7DniD3j231r+ibt9ywpL4WUhydS/vD2IGFu1Gyu1eD+Ib2GxN9ffejVDO01lDveuIPRvx1NVKN5zzRfSEuqKA9Je4hGYbvtEusTgcvIUFPjliyfPdstQXHFFS7TuMe6dW5C7MSJztryfqjtuadLeWQY+URErgMWAEcCv1DVvVT1GlU9CtgzzWFbA/7BjaWxsiCTRWSuiPwr3biXiJwlIrNEZNbq4DLMAe6Zcw/XvHgNN752I9v034Zxg5IHWHcemvorzW9JVUWqqK2sTRoH+ed7/4zvf3/t+6HXXd+0Pv4+qtF48MHGpo0plot37sG9YiLVmEakYi4svzBtbt7MDoN3iG+HCU5LtCUlmMJjY9PGrCK1umE1x++aSEnjzZ3y8MakohrlM8NTU74s37Scjzd8HGp1LlyzELky2bL0EvMG8doZFGK/SO299d7xpL8bmzYy7NfDOPTeVGu5MxRSpIrykLSHefPca7PvO/PMM24ZiOHDE+68I490WbyDHHRQ3ppiGJl4G9hdVb+tqsGfyfuEHQCh0QLBnvN1YFtV/QxwA/BY2IlU9VZVnaSqk4YOHZqxoQvXJpbY+Ow2n00ZsxkzYEz8/ZHjj3Qh3L5mxcek0rj71jaupUJSJ5D6F+lri7bxyWaXHPPKZ69MsQQ8Ky3Ukoq5+zZs2RDvnJvamrjh1Rv4y9t/ob65nm36bxOvH7bGUyZLakPThpxy4vmFMChSniUFsO/W+ybtG9prKCvrV7LN77ZhxLWpyTRfW/5aSlnY2lyQbEl5Ye+QLFJ1lXVxkQIn+MEowc5SSJEqykPSHl4KjON6rr66Ore8hMduu7nMD9Goc+/98pcu+i9dVnHDyDPrgLhPTEQGiMhXAFR1Q5pjlgI+HwGjgKTYZlXdqKqbY++nA1UiMoRO4J+AGpFI/Fe/h9+1t9OQnThv7/OSksV67r63V70dOpm1oaUhqZP28ItUVKMZhcATLa+z/bTRF70Xs6RW1ieskKbWJi588kKOf+R4Pm34lP41ibiVUHdftCWty2v9lvU5pRvqV9Mv7qasq0yeoe+/h7sMS/5dP27QuLTjdpDsFj1w2wPjbQrDL1Jb903YF36Rqq2sTRHRfFNIkSrKQ5ILzc1uou2Lvoz3hx7qsn4/8ICbmOuJ1KhRiSwOIs69d9llLsVQbWH/N4bhcYVfjFR1PXBFlmNeA8aLyFgRqQaOBx73VxCRERKLKhCRfXD9wZqUM7WDFJHydagj+oxIirSLSITKSGVShoiqiipqK9yDtdMfdko5f31LPVUVVcz8ZrJBmWRJaVvatZBao61xK82zpPzHepaU38Xnt8QWrl3IpK0mcdtRtwHpx6TSBUds2LIhJ5HqW50Yh8pkSe0weAf+eULCHbr9oO3TRkBCctSldw1/EIUfbzLvltYt9K9NCHOSJVVVl3KvwyIeO0MhRaooD0kuHH88DBzokrQefbSbeDt9emLfbrtB/9j/ZKfU58Qwupqw5zRj3k1VbQXOB/4NzAceUtV5sRB2byGnY4C3RWQu8HvgeO3kqLdfpCqkIt6hVkWqeOfcd5JyvUUkQoVUJKX3qa6ojufhCxvQr2+up7qimu0GbpdU/tGGxByRqEbTikRLW0vqmJTP3RcWoRbs9A8eczDfnPhNJgyZEO7ui7akXep9Q5MTqT1H7MlB2x6U1OH76VvTNx6VWFtZy/YDt+fw7Q8HSLJOaypq4p8DYPuB24eeD5y4+C0pLxTeb0mN6jeKS/a7BHCW1JL1S/hw/YdJQhm0pIL3Z9sB27KxaSM//t+PeeOTN+gsBROpYj0k6bj/fpfctb4+EbG3ZImzng45xK0668eb13T44YVojWG0i1kicp2IbC8i24nIb4GsazWo6nRV3UFVt1fV/4uV3ayqN8fe36iqu6jqZ1R1P1XNPpEpC17Wb0h2923TfxsG1g0MtaT8VFdUM2+1GywOC3Vu0zaqK6pTEpv6LZ+oRlPy93m0RFviY1L9avpRGalMit7zix04V5tfLMcOGMteI/eKtzU0cKKtJa01s37LelqiLQztPZQZp83gkDHhswj87r7ayloWXbiIJ096Mn5dj9rK2iTLJUykTtvjNK79wrUM7TU0SZDCRGpg7UCuOewaAD7e8DFjrh/D0o1L04pUXWVdyj14Z/U7nPToSfz8+Z/nJV1SQedJFeMhCWPLFpdxfM893dIXftKJ0NFHu/lOl1xSiBYZRru4AGgG/gI8DGwBSj5lcEWkIu7u88QqKFJBsamuqI5HAO46LPCw+uoExc1PW7QtJ0vK6+CD0X3+ybYD6wbS1NrEgNoBXLjPhSy+aHH8s9RU1KQdk0prScXcfd59GdlnZGi9vtXJlpQfvwu1trI2nqEdnLsvyG7DduM7k7+TkjE9zN3nCTfAnXPujJd7KaIg1ZIKG//7x3v/AFyKq87SIzJO+JfH+PBDl8j19793CxAGRctDxK3FFOkRd8goZVS1XlUviwUP7aWql6tq16SgbgdBJ4jfkvI6Vn9kXpglVRWp4u5pd9Ovpl/oGkfgRCosws8jqyUVG5epq6yjd3XvlLlP4weNj78fWDuQLa1bQtdcqqmsSRvd57cuTtztRJp/5LY9d59nDflTHvnpXd07yZLyE7Sk/KmZwkTPOz54Hm/+lT+6r39t/3hWC79rMJO7L9MYm38sq6P0iPWkXn01efuyy9yS7IbRHRCRocD3gV2AeG+hqp8rWqNCCHb2/sCJtJaUpFpSfWv6sseIPdIGP1RFqkLXMepV1YuGloaMgRN+S6quqi409974wePjK98OrBvIJ5s/oam1KSWqsKaiJjRUvrmtOcmS8/Lt9arq5dx9bS3xc6WzNPz3Kd08KXBC6Xf3BSf+eu0MO0+YJeVFLgZdmbWVtfEyv0hVV1TTv7Z/POQ/iD8SsqPkZCeISBp7o/R56SWX2siPLXludDPuw+XvGwtcCXyIC0wqKfwLD4KzmoKWVLYxKU98KiOVaYUmnSW10xAX5ZQxcMI3JlVbWctxOx+XUidoSXnCFxSp6orqnAInPHHoX9M/7u6LW1Ih424e3r0KuukyWVLBcHX/9YP7wsakvDK/S9E7hyd2wVyCT3zjCfbZOny6Xj4sqVydWTeLyEwROVdEBnT6ql1EfT0cdhisXevCyufNc3OhqqqyH2sYJcRgVb0DaFHVZ1X1DGC/YjcqyIYtySIVZkmlRPcFLCLPxZVNpMIsjZ2GOpFqi7ald/e1Jbv7/u/Q/+PNs99k8qjJ8Tr+ibQD6wbGLa8US6qyJtTV9cj8R3jy/SdT2jegdgDrm9YnjUlNGDIhtJ1AzmNS/nsYtlKv56YMnscTJH/giN+S8qOq/O/U/3H2XmenRCRuN3A7fnzgj0M/Qz4sqZzcfao6RUTGA2fgIo1mAnep6lOdbkEBmT7dZTS/7TY45phit8YwOow3Mv2JiHwRN99wVIb6RSHFkookh6BDdkvKozJSmXZCbnVFdVLS2N5VvdnSuiVnS8ofOAGw2/DduGS/S3j5ry8DyeM6fqvBHzzgbYcFTgQj2uKWVK2zpFqiCXffvqP25eUzX2byHZNTzuMJdvC6QUvKT1jG97glFRAwL1OEP3rRs3yCItXY2sikrSYxaavwcRJ/1gk/6TK+t4ecwwJUdSHwI+BS4CDg9yLyroh8tdOtKBCPPOIm3Z5+eva6hlHC/Dy2PMd3ge8BtwMlF3eaiyWVbUzKE5/KSGXa5dGDWSy8DtKLCmzTLJZUzN3n77T9nbI/Ws4vUmGWVLooPj9+SyoYOAGJbOxBvjLhK0nHewTnSWUjPiZVkXye2sra+P/Hm9jsiUqYSGUi6B70CBs7bC+5jkntHpubMR/4HHCUqu4Ue//bTreiAGzZ4qL3pk2Dis7fJ8MoCrHs5+NVdYOqvq2qh8Qi/B7PenAXk8uYVLboPs96qIpUpY0aC3agJ+1+Etd+4dq4G+qCf12Qdp6S35Lyd/D+jt8/xuMfUwkLnMiU3cHDGwvqX9M/nhYpKLR+vM9x17S7WHLxkpSoQn87chGBdJaUFwwBTiirIlXx3IopIpVlVeV0PyjyQa7RfTcCtwE/UNV4a1V1uYj8qCAt6yRPPw2bN7ts5obRXVHVNhH5MiX6Y9BPMAdcTpZUcEzKZ0mls1KCHeguQ3fhhN1OiC+q+M7qdwA4f+/zWbppKY+9+1i8bktbCy3RlpRre+fsVdUrbSBCmFjkkuIoU+CExz9O+AcDagew27Dd4sJdU1mTlMzWI134fVhdf7uDFllNZQ3VFdXUt9QzedRkbj3q1rirMyii2SypyaMmc/yuxzOyz0h++0p+v6q5jkkdmGHfn/LXnPzx6KPQrx98rqSCdA2jQ7wkIjfiJvPG50ep6uvFa1Iqoe6+dkb3+QMnglaKF2IedC155wx23kN7D2X84PFJItXc1kxLW0vKOTzR6F/TPymk2y9MYZaUP+9fOpICJ7aspzXamnKuL+3wpazn8Qhbqr3+B/VpxSvdPCn/UvTbD9qerfpuFd/niXPf6r5sat7EHsP3yNimmsoaHvjaA9z5xp0Z63WEnEQqFjTxS9zihf55GtulPajITJ/ultgIpjsyjG7I/rFX/2QKxbnbS4bgPCm/pZI2ui/DmFTQkupT3YeGloaUztY7ZzBooEIqUsSoJeosqaClEBep2v5JlpT/WkFhSbdYYBDvHH1r+saFN90YTkcJm+/l4bk1B9UNSmmX95mC6ZS8cb5JW03i2i9cy27Dd8upHbmMkbWXXN19d+GyLv8WOAQ4nfClOEqCVatgxQrYd9/sdQ2j1FHVtMvElxIt0Zak0PGIRIhUROLv/a/e+0yWVFAE+lb3ZVX9qpT5PnFLKuA6rIhUpAhXS1tLqCXlrf/UvyZZpPydblCkch2H8UQquAJxV+Fd/4w9z+A3L/0mvmpxTUVNQqQC6ZS84JGayhr2HJm6rua4QeNC3Yue5Tmq3yjmfHtOXtqfq0jVqerTIiKqugT4qYg8T/blArqc1lb47nfd+3QpjwyjOyEiPwkrV9WrwsqLRUtbCzUVNXGRqpCKtPOgIHxMyiNMpNIFAHjWWJglFTx/OkvKy37ev7Z/0j6/JRW0En5x6C+47fXbQtsf1m7/ebtSpDzh6FfTj48u+Yh+v+xHfUt93JIaUDsgxcryLKl0a0UtvGBhaLlXf2SfkUnZ2TtDriHoW0QkAiwUkfNF5GhgWF5akGeeesotAQ8mUkbZUO/7awOOAMYUs0FhtEZbkzri4HpSkDyeEmpJSSK6LzjXyTt3urlBQZGqjFTGBez0PU7nR5/9UVpLaq+RexGRCD+Y8oOk8kxjUkN6DeHQsclLpX9r4rf46OLkTOphllSm6L58479fEYnERb4yUklVpCo0c3qfKidS7XXfefXD5mt1lFwtqYuBXsCFwM9wLr9T89aKPLLGtxrV8OHFa4dh5AtVvda/LSK/IbA2WynQEk3u/MNW5vUTOiblc/f5GVg7MF436O7zrKXgufzuvjZto6ayBkXjCyf6Gdp7KG0/SZ1blcndB6kRf7sM3YXR/UcnlXW1JRWRSNLy9UFR/98p/+OBtx+gX00/po6bGp8j5cezpNIl+U2HV79LRSo2T+M4Vf1/wGbceFTJsjK2cvLixS6TuWGUIb2Akgtaao22JomLf6mOMCqkImPGCT+j+4+Od7xBd186S8rv7muLtiUlVM01cCFT4ERwPySEaNl3ljH6t67Nfssl07nyhSdSM785M2UtKHAZNrxAiF99/leh5/BEqjrSvnamc712hqwiFZunsVdsPKogCxLmk1WroKYGxowpdksMIz+IyFu4aD6ACmAoyZF+JUFwrCcnSyowZuR1bkGR2nXYrvF0Q+0JnPA6zahG4x3v2sa1Wd1tE4ZMYLdhuyVZEmFWRdAd5rV7q75bMaB2AGsb13Z54IR3P0b1G8XeW+/doXN4gRN+iywXvPrFcPe9AfxdRB4meZ7Go3lrSZ5YudKlQjIryigj/JNoWoGVsZWvS4oUSyokBNxPpjEpf/kuQ3fhpi/eFM9vlxKCnkPgRJu2Ja2flC7XnMf88+YDsGLzinhZLu4+f7u9DjvM3dfZEPTrvnBd2qXnvfvQXledH+/+tLbza+aNIxZDpAYBa0iel6FASYqUjUUZZcZIYJ6qbgIQkT4isouqvprluC4lGJAQkUi8swpzwoSNSXn4O/vLp1xOv5p+8ajBdO6+4LkqI5WMHTAWgIkjJiZZUukWGwwyrHciPixUpNJYUkA8f2AhLKlLJqdP3dinug9bWrd0Sgi9Cc3pkvymY0SfEQDsP3r/LDVzJ9eMEyU9DuVn1SoYMaLYrTCMvHITMNG33RBSVnSCllS2X9MZc/f5rA7PGoqLVJrAiRRLKlLB3lvvzdyz57LrsF158aMXAZe+KdcO3H/OXMakkkRKk0Wqq8aknj3tWR6e93BWazETXpvTLZeSjglDJvDm2W/Gk/3mg1wzTtxFwiceJ7auTUmxahXsvnuxW2EYeSVpPFhVoyJScqtqB8ekKiIVoSl8PMJE6sqDrwRIcRtCwjJJa0kFx6Rix+0+3HUIXqetaIdCwMPCsTMto+G116uT5O4rYAj6zkN35oqDOzeF1bv/7RUpIOfsFLmSq+Pwn8ATsb+ngX64SL+SY906GDQoez3D6EYsFpELRaQq9ncRsLjYjQrSEUvKLyyvfvNVdhyyI5AsUsEOM9d5UkHR8i+t3hFXWC5jUv7zXvuFa5PaW6yMEx3Bu+eFzG6eKzmJlKo+4vu7DzgOKLmpsm1tbjXefp1fZ8swSomzcfn7lgFLgX2Bs4raohDCAicyEbSk/PWDoeze+SHE3Sdp5kkFtv3ur45YMmHCErakvMd5+5yHXqHx9hcr40RH8Nra3jGpQtBRl8F4IDwvfBHZHLPt+vbNXM8wuhOqugo4vtjtyEZY4EQmIhJJcpeFWU+QEJtsgRNZLanqjllSD37tQa575bpQYQm6KzOJj79uvhPM5htvXal8BkB0lFzHpDaRPCa1ArdCb0mx0aXfMkvKKCtE5B7gIlVdH9seCFxbamPCHXH3+VfB9YtKJksqXRb0oCgFBaRXVS8EafeY1Nd3/Tpf3/XrofuC18h03u7k7tt56M68e967jBs0rthNyTm6r1vYJiZSRpmyuydQAKq6TkRSU1MXmZZoS5KV4xcNTY27ciLlW7sprbtPEnOdIP1k3rB5Un5EhD7VfdjUvClvItEeS6o7ufuA+Phgscl1+fijRaS/b3uAiHylYK3qICZSRpkSiVlPAIjIIDruqi8YYZZUOgHxyvzLYiStPxXJEILeQXcfJMal8uVu66i7rzuIVKmQa3TfFaoaX3Yz9quu5Jbp2LTJvdqYlFFmXItbnfdnIvIz4CUgPOlaEQmOSVVIBV/b6WucvdfZ8Ug3PxGJJHXW6SypYHRfRwMnIBHhVyiRynTeYmVB7+7k+mssTMxK7pecWVJGOaKq94rIbNzqAwJ8VVXfKXKzUgizpGoqa7jpSzeF1o9IJGkeVa6BEx0NQQefJZUnkShnd1+pkKslNUtErhOR7UVkOxH5LTC7kA3rCCZSRrmiqvOAh4C/A5tFJGt0rYhMFZEFIrJIRC7LUG9vEWkTkWM608awBLOZyCQqYYETVx96NZDawecaOAGJCL98WVJBay2jSHWjwIlSIleRugBoBv6Ce1AagfOyHdTVD4mJlFGOiMiXRWQh8AHwLPAh8K8sx1QAf8AtkLgzcIKIpOSqidW7Bvh3Z9sZtlRHJjIFOoRZUpdOuRS9QlOyWOQaOAGFt6Qynbc7haCXErlG99UDaUUmDN9D8nncBMTXROTxoJsinw+JjUkZZcrPgP2A/6rqniJyCHBClmP2ARap6mIAEXkQmAYE3YQXAI8AHVvTwUdH5kn5yWZJZTtP2KKHQfI9JhUUJXP35Z9co/ueEpEBvu2BIpJNVOIPiao2A95DEsR7SFbl1uT0bNwIdXVQWXKjZYbRKVpUdQ0uyi+iqs8Ae2Q5ZmvgY9/20lhZHBHZGjgauDnTiUTkLBGZJSKzVq9enbZeRzJO+PHX93fo6RZGDB4XtLBCLamq/FpSHXX3ZRNeI0Gu7r4hwXkawLD01YEiPCSrV1vePqMsWS8ifYDngPtE5HrculKZCMvsGpys9DvgUlVNXTfdf5Dqrao6SVUnDR06NG29sOXjMxHcny1wItfzxI/rAkvKPxk523ktoq9j5CpSUf9ArYiMISQreoAuf0g++ADGjs3SKsPofkzDLc9xCfAk8D5wVJZjlgKjfdujgOWBOpOAB0XkQ+AY4I+dmf/YkYwTfjrq7ku3P8wCy/eY1NRxU/nlob+Mb+c6T8rInVzv2g+BF0Tk2dj2gWRPcNmehwRgCHCkiLSq6mM5tiuJDz6Agw/uyJGGUbrExoQBosA9wf0i8rKqTg4UvwaMF5GxuMS0xwPfCJw3/pNORO4G/tnRZw9iY1Ih60ClI93SGpAnSypsnlSeo/siEuGyKZdx+dOXA5mFyIIlOkaugRNPisgknDDNwYXBNmY5rEsfkuZmWLoUttuuI0cbRremNligqq0icj4uIKkCuFNV54nI2bH9GV3sHaFollQaEeuKeVJBMq2fZZZUx8g1wew3gYtw1tAcXKTRyyQvJ59EVz8kS5aAqrn7jB5JqOtdVacD0wNloc+dqp7W2UYEx6Q6EzhRMEsqz2NS7SGTgBnpyVXaL8KFqL6iqoeIyATgymwHdeVDsjzmSBw9OnM9wzDyT1SjRDXaIUtq0laTmLV8Vtql2rNZIO0JnCi0JWXkn1xFaouqbhERRKRGVd8VkdJIkRtjyxb3WleXuZ5hlCFF/4nupSzqiEg9dfJTLFyzMMnSGFgbz6fb4cCJrhiTMgpPriK1NDZP6jHgKRFZR2oQRFFpbnav1TZHzuh5nFzsBngi1Z7ACU+kBtQOYO+tk+cSD+41OHGeDrr7uiK6zyg8uQZOHB17+1MReQbojwuFLRlMpIxyI2Sx0fguQFW1H+7N213asBC8ZcY7EzjhJyk7eh4DJ0b2HUlEIgzrnW2ap1EqtDvcRFWfzV6r6zGRMsqN7rLYKPgsqU4ETqQjn4ET2/TfhoUXLGTsAIuw6i6UTUykJ1I1NcVth2EUChEZhi/cXFU/KmJzkmiJ5teS8pPPwAmA7QbaPJXuRK4ZJ0oes6SMcqUjWdC7mj+/+WeATi3VkY58Bk4Y3Y+yEammJvdqImWUIV4W9PdiE+APBV4sbpOS+emMnwIdy16ejXRic9QOLjOUpAlutMmz5UHZiJRZUkYZ05Es6F3KXlvtBRTG3ZdO7B469iGWXLwk7STZUsw0PnbAWI4Yd0Sxm9GtMJEyjNLHy4L+PLlnQe9S9hrpROrD9R/GyzobOHHS7idlrFdbWcs2/dMvUFyK7r7FFy1m+onTs1c04pSdSFXZ9Aej/HgOGIDL/JJrFvQu5Ru7ubSce4zYI17WWUvqrml3sf7S9R1uUylaUkb7KRunbXMzVFS4P8MoMwSXA3MtbvHQv8TcfyXDpK0mUf+DenpV9YqXdVakKiOV9K/t3652fG2nr9G3pi9f3uHLObsTjdKmrETKws+NckRVrwSuFJHdga8Dz4rIUlU9rMhNS8IvUJC/wIn28Nfj/pr3c+bCfV+9j6G90q91Z3ScshGppiYbjzLKnlXACmAN2VfGLjr5CpzoDnjuTiP/lM23pLnZRMooT0TkHBGZATyNWxz0W6q6e3FblZ18ZZwwejZlY0mZSBllzLbAxao6p9gNaQ89yZIyCoeJlGGUOKp6WbHb0BGyiVAphogbpUfZ/JQxkTKM0qIYgRNG+VE23xITKcMoLczdZ+SDsvmWWHSfYZQWFjhh5IOy+ZbYPCnDKC3MkjLyQdl8S8zdZxilhYmUkQ/K5ltiImUYpYUFThj5oGy+JSZShlFamCVl5IOy+ZaYSBlGaWGBE0Y+KJtviUX3GUZpYZaUkQ/K5ltilpRhlAaD6gYBpF0x18NEysiFskqLZCHohlF8Zn5zJi9+/GLWetlEzDCgjCypfv2gf/vWRzOMskZEporIAhFZJCIp+f9EZJqIvCkic0RklohMycd1tx+0Pad85pS0++/48h1sN3C7fFzK6AGUjSW1YEGxW2AYpYOIVAB/AD4PLAVeE5HHVfUdX7WngcdVVWMLKj4ETCh0287Y8wzO2POMQl/GKBPKxpIyDCOJfYBFqrpYVZtxy85P81dQ1c2qqrHN3oBiGCWGiZRhlCdbAx/7tpfGypIQkaNF5F3gCSDUvBGRs2LuwFmrV68uSGMNIx0mUoZRnoRFJaRYSqr6N1WdAHwF+FnYiVT1VlWdpKqThg4dmt9WGkYWut2Y1OzZsz8VkSVpdg8BPu3K9pQwdi8c6e7Dtl3dkC5mKTDatz0KWJ6usqo+JyLbi8gQVU37vbHnL2fsXjg6/fx1O5FS1bQ/5URklqpO6sr2lCp2Lxw9+D68BowXkbHAMuB44Bv+CiIyDng/FjgxEagG1mQ6qT1/uWH3wpGP+9DtRMowjOyoaquInA/8G6gA7lTVeSJydmz/zcDXgFNEpAVoBL7uC6QwjJLARMowyhRVnQ5MD5Td7Ht/DXBNV7fLMNpDuQVO3FrsBpQQdi8cdh+6DrvXCexeODp9H8Sse8MwDKNUKTdLyjAMwygjTKQMwzCMkqUsRCpbIs1yQ0TuFJFVIvK2r2yQiDwlIgtjrwN9+y6P3ZsFInJ4cVqdf0RktIg8IyLzRWSeiFwUK+9x96KY2PPXM79zXfb8qWq3/sOF174PbIeb5zEX2LnY7SrwZz4QmAi87Sv7FXBZ7P1lwDWx9zvH7kkNMDZ2ryqK/RnydB9GAhNj7/sC78U+b4+7F0X8H9jzp/b8FfL5KwdLKmsizXJDVZ8D1gaKpwH3xN7fg0tz45U/qKpNqvoBsAh3z7o9qvqJqr4ee78JmI/LT9fj7kURsefP0eO+c131/JWDSOWUSLMHMFxVPwH35QGGxcp7xP0RkTHAnsCr9PB70cXYPXX06O9cIZ+/chCpnBJp9mDK/v6ISB/gEeBiVd2YqWpIWVndiyJg9zQzZX9/Cv38lYNItSuRZhmzUkRGAsReV8XKy/r+iEgV7gG5T1UfjRX3yHtRJOyeOnrkd64rnr9yEKl4Ik0RqcYl0ny8yG0qBo8Dp8benwr83Vd+vIjUxJKNjgdmFqF9eUdEBLgDmK+q1/l29bh7UUTs+XP0uO9clz1/xY4QyVOUyZG4yJL3gR8Wuz1d8HkfAD4BWnC/Ts4EBuOWA18Yex3kq//D2L1ZABxR7Pbn8T5MwbkL3gTmxP6O7In3osj/B3v+euB3rqueP0uLZBiGYZQs5eDuMwzDMMoUEynDMAyjZDGRMgzDMEoWEynDMAyjZDGRMgzDMEoWEynDMAyjZDGRMgzDMEqW/w9gwTGrZhqcNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "acc_ax = ax1.twinx()\n",
    "\n",
    "ax1.plot(hist_.history['loss'], 'y', label='train loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "\n",
    "\n",
    "ax2.plot(hist_.history['val_loss'], 'r', label='val loss')\n",
    "ax2.set_ylabel('val_loss')\n",
    "\n",
    "\n",
    "ax3.plot(hist_.history['accuracy'], 'b', label='accuracy')\n",
    "ax3.set_ylabel('accuray')\n",
    "\n",
    "ax4.plot(hist_.history['val_accuracy'], 'g', label='val_accuracy')\n",
    "ax4.set_ylabel('val_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 - 0s - loss: 1.1386 - accuracy: 0.4872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.138594150543213, 0.4871794879436493]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_.evaluate(X_test,Y_test,verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_86 (Dense)             (None, 32)                384       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 11)                363       \n",
      "=================================================================\n",
      "Total params: 747\n",
      "Trainable params: 747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/800\n",
      "72/72 [==============================] - 1s 4ms/step - loss: 19.1334 - accuracy: 0.0912 - val_loss: 2.4662 - val_accuracy: 0.3221\n",
      "Epoch 2/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 2.1379 - accuracy: 0.3631 - val_loss: 1.4842 - val_accuracy: 0.4938\n",
      "Epoch 3/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.4365 - accuracy: 0.4130 - val_loss: 1.3058 - val_accuracy: 0.4764\n",
      "Epoch 4/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.3569 - accuracy: 0.4253 - val_loss: 1.2695 - val_accuracy: 0.4477\n",
      "Epoch 5/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3275 - accuracy: 0.4422 - val_loss: 1.2610 - val_accuracy: 0.4862\n",
      "Epoch 6/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3042 - accuracy: 0.4406 - val_loss: 1.2664 - val_accuracy: 0.4585\n",
      "Epoch 7/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2989 - accuracy: 0.4359 - val_loss: 1.2188 - val_accuracy: 0.5026\n",
      "Epoch 8/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2783 - accuracy: 0.4531 - val_loss: 1.3039 - val_accuracy: 0.4969\n",
      "Epoch 9/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2844 - accuracy: 0.4514 - val_loss: 1.1994 - val_accuracy: 0.5221\n",
      "Epoch 10/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2678 - accuracy: 0.4693 - val_loss: 1.2581 - val_accuracy: 0.4913\n",
      "Epoch 11/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2371 - accuracy: 0.4614 - val_loss: 1.2275 - val_accuracy: 0.5072\n",
      "Epoch 12/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2620 - accuracy: 0.4610 - val_loss: 1.2190 - val_accuracy: 0.5108\n",
      "Epoch 13/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2306 - accuracy: 0.4771 - val_loss: 1.1796 - val_accuracy: 0.5072\n",
      "Epoch 14/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2558 - accuracy: 0.4487 - val_loss: 1.1867 - val_accuracy: 0.5200\n",
      "Epoch 15/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2498 - accuracy: 0.4777 - val_loss: 1.1879 - val_accuracy: 0.5179\n",
      "Epoch 16/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2107 - accuracy: 0.4800 - val_loss: 1.1576 - val_accuracy: 0.5190\n",
      "Epoch 17/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2335 - accuracy: 0.4664 - val_loss: 1.2391 - val_accuracy: 0.5015\n",
      "Epoch 18/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2648 - accuracy: 0.4718 - val_loss: 1.1588 - val_accuracy: 0.5426\n",
      "Epoch 19/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2156 - accuracy: 0.4869 - val_loss: 1.3096 - val_accuracy: 0.3728\n",
      "Epoch 20/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1986 - accuracy: 0.4805 - val_loss: 1.1560 - val_accuracy: 0.5344\n",
      "Epoch 21/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1835 - accuracy: 0.4895 - val_loss: 1.1561 - val_accuracy: 0.5026\n",
      "Epoch 22/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1743 - accuracy: 0.4989 - val_loss: 1.1429 - val_accuracy: 0.5426\n",
      "Epoch 23/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1761 - accuracy: 0.4887 - val_loss: 1.1413 - val_accuracy: 0.5097\n",
      "Epoch 24/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1626 - accuracy: 0.4952 - val_loss: 1.1394 - val_accuracy: 0.5303\n",
      "Epoch 25/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1554 - accuracy: 0.5088 - val_loss: 1.1532 - val_accuracy: 0.5169\n",
      "Epoch 26/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1532 - accuracy: 0.5127 - val_loss: 1.1531 - val_accuracy: 0.5015\n",
      "Epoch 27/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1456 - accuracy: 0.5044 - val_loss: 1.1722 - val_accuracy: 0.4636\n",
      "Epoch 28/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1917 - accuracy: 0.4907 - val_loss: 1.1375 - val_accuracy: 0.5344\n",
      "Epoch 29/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1737 - accuracy: 0.4897 - val_loss: 1.1523 - val_accuracy: 0.5241\n",
      "Epoch 30/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1634 - accuracy: 0.4932 - val_loss: 1.1651 - val_accuracy: 0.5026\n",
      "Epoch 31/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1888 - accuracy: 0.4705 - val_loss: 1.1327 - val_accuracy: 0.5354\n",
      "Epoch 32/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1564 - accuracy: 0.5194 - val_loss: 1.1437 - val_accuracy: 0.5082\n",
      "Epoch 33/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1727 - accuracy: 0.5006 - val_loss: 1.2330 - val_accuracy: 0.4323\n",
      "Epoch 34/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1828 - accuracy: 0.4833 - val_loss: 1.1616 - val_accuracy: 0.4682\n",
      "Epoch 35/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1643 - accuracy: 0.4969 - val_loss: 1.1170 - val_accuracy: 0.5236\n",
      "Epoch 36/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1276 - accuracy: 0.5234 - val_loss: 1.1220 - val_accuracy: 0.5144\n",
      "Epoch 37/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1823 - accuracy: 0.4989 - val_loss: 1.1371 - val_accuracy: 0.5041\n",
      "Epoch 38/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1380 - accuracy: 0.5073 - val_loss: 1.0979 - val_accuracy: 0.5308\n",
      "Epoch 39/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1548 - accuracy: 0.4920 - val_loss: 1.1463 - val_accuracy: 0.4841\n",
      "Epoch 40/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1321 - accuracy: 0.4985 - val_loss: 1.1205 - val_accuracy: 0.5056\n",
      "Epoch 41/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1523 - accuracy: 0.4998 - val_loss: 1.2137 - val_accuracy: 0.5051\n",
      "Epoch 42/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1762 - accuracy: 0.4887 - val_loss: 1.1058 - val_accuracy: 0.5226\n",
      "Epoch 43/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1199 - accuracy: 0.5071 - val_loss: 1.1601 - val_accuracy: 0.4923\n",
      "Epoch 44/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1369 - accuracy: 0.5098 - val_loss: 1.1545 - val_accuracy: 0.4518\n",
      "Epoch 45/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1567 - accuracy: 0.5013 - val_loss: 1.0925 - val_accuracy: 0.5462\n",
      "Epoch 46/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1395 - accuracy: 0.5044 - val_loss: 1.2038 - val_accuracy: 0.3846\n",
      "Epoch 47/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1356 - accuracy: 0.5000 - val_loss: 1.0828 - val_accuracy: 0.5267\n",
      "Epoch 48/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1363 - accuracy: 0.5069 - val_loss: 1.1242 - val_accuracy: 0.4969\n",
      "Epoch 49/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1431 - accuracy: 0.5147 - val_loss: 1.1084 - val_accuracy: 0.5092\n",
      "Epoch 50/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1496 - accuracy: 0.5080 - val_loss: 1.2151 - val_accuracy: 0.3713\n",
      "Epoch 51/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1662 - accuracy: 0.4933 - val_loss: 1.1523 - val_accuracy: 0.4662\n",
      "Epoch 52/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1262 - accuracy: 0.5197 - val_loss: 1.1225 - val_accuracy: 0.4892\n",
      "Epoch 53/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1034 - accuracy: 0.5099 - val_loss: 1.1593 - val_accuracy: 0.4672\n",
      "Epoch 54/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1350 - accuracy: 0.4988 - val_loss: 1.1411 - val_accuracy: 0.4826\n",
      "Epoch 55/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1628 - accuracy: 0.4884 - val_loss: 1.1762 - val_accuracy: 0.4472\n",
      "Epoch 56/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1372 - accuracy: 0.5185 - val_loss: 1.1189 - val_accuracy: 0.5000\n",
      "Epoch 57/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1310 - accuracy: 0.4942 - val_loss: 1.0774 - val_accuracy: 0.5333\n",
      "Epoch 58/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1331 - accuracy: 0.5031 - val_loss: 1.2609 - val_accuracy: 0.3626\n",
      "Epoch 59/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.2218 - accuracy: 0.4728 - val_loss: 1.0982 - val_accuracy: 0.5210\n",
      "Epoch 60/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1229 - accuracy: 0.5215 - val_loss: 1.1422 - val_accuracy: 0.4744\n",
      "Epoch 61/800\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1050 - accuracy: 0.51 - 0s 2ms/step - loss: 1.1067 - accuracy: 0.5160 - val_loss: 1.1176 - val_accuracy: 0.5005\n",
      "Epoch 62/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1287 - accuracy: 0.5129 - val_loss: 1.1215 - val_accuracy: 0.4969\n",
      "Epoch 63/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1478 - accuracy: 0.4996 - val_loss: 1.1283 - val_accuracy: 0.4795\n",
      "Epoch 64/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1362 - accuracy: 0.5040 - val_loss: 1.0976 - val_accuracy: 0.5205\n",
      "Epoch 65/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0911 - accuracy: 0.5245 - val_loss: 1.1484 - val_accuracy: 0.4897\n",
      "Epoch 66/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1018 - accuracy: 0.5220 - val_loss: 1.1694 - val_accuracy: 0.4990\n",
      "Epoch 67/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1653 - accuracy: 0.4944 - val_loss: 1.1006 - val_accuracy: 0.5241\n",
      "Epoch 68/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1275 - accuracy: 0.5128 - val_loss: 1.1118 - val_accuracy: 0.4990\n",
      "Epoch 69/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1164 - accuracy: 0.5246 - val_loss: 1.1520 - val_accuracy: 0.4944\n",
      "Epoch 70/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1160 - accuracy: 0.5250 - val_loss: 1.1115 - val_accuracy: 0.4928\n",
      "Epoch 71/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1258 - accuracy: 0.5034 - val_loss: 1.0849 - val_accuracy: 0.5236\n",
      "Epoch 72/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1360 - accuracy: 0.5021 - val_loss: 1.1062 - val_accuracy: 0.5097\n",
      "Epoch 73/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1420 - accuracy: 0.5031 - val_loss: 1.0844 - val_accuracy: 0.5379\n",
      "Epoch 74/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0968 - accuracy: 0.5301 - val_loss: 1.1991 - val_accuracy: 0.3928\n",
      "Epoch 75/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1090 - accuracy: 0.5093 - val_loss: 1.0948 - val_accuracy: 0.5179\n",
      "Epoch 76/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1137 - accuracy: 0.5107 - val_loss: 1.1037 - val_accuracy: 0.5190\n",
      "Epoch 77/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1259 - accuracy: 0.5089 - val_loss: 1.0803 - val_accuracy: 0.5262\n",
      "Epoch 78/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1255 - accuracy: 0.4994 - val_loss: 1.0852 - val_accuracy: 0.5395\n",
      "Epoch 79/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0813 - accuracy: 0.5399 - val_loss: 1.1147 - val_accuracy: 0.5103\n",
      "Epoch 80/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0935 - accuracy: 0.5148 - val_loss: 1.1037 - val_accuracy: 0.5385\n",
      "Epoch 81/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0966 - accuracy: 0.5414 - val_loss: 1.1698 - val_accuracy: 0.4190\n",
      "Epoch 82/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1385 - accuracy: 0.5139 - val_loss: 1.0913 - val_accuracy: 0.5113\n",
      "Epoch 83/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1338 - accuracy: 0.4999 - val_loss: 1.1928 - val_accuracy: 0.4056\n",
      "Epoch 84/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1187 - accuracy: 0.5186 - val_loss: 1.0930 - val_accuracy: 0.5195\n",
      "Epoch 85/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1173 - accuracy: 0.5215 - val_loss: 1.0965 - val_accuracy: 0.5108\n",
      "Epoch 86/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1008 - accuracy: 0.5301 - val_loss: 1.0795 - val_accuracy: 0.5200\n",
      "Epoch 87/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0948 - accuracy: 0.5209 - val_loss: 1.2093 - val_accuracy: 0.3867\n",
      "Epoch 88/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1200 - accuracy: 0.5141 - val_loss: 1.1598 - val_accuracy: 0.4395\n",
      "Epoch 89/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1390 - accuracy: 0.5116 - val_loss: 1.2040 - val_accuracy: 0.3928\n",
      "Epoch 90/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1136 - accuracy: 0.5156 - val_loss: 1.0935 - val_accuracy: 0.5138\n",
      "Epoch 91/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0953 - accuracy: 0.5237 - val_loss: 1.0946 - val_accuracy: 0.5062\n",
      "Epoch 92/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0873 - accuracy: 0.5326 - val_loss: 1.1021 - val_accuracy: 0.5092\n",
      "Epoch 93/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1031 - accuracy: 0.5247 - val_loss: 1.0887 - val_accuracy: 0.5313\n",
      "Epoch 94/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0758 - accuracy: 0.5408 - val_loss: 1.1338 - val_accuracy: 0.4923\n",
      "Epoch 95/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1433 - accuracy: 0.5069 - val_loss: 1.0908 - val_accuracy: 0.5082\n",
      "Epoch 96/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0849 - accuracy: 0.5220 - val_loss: 1.1438 - val_accuracy: 0.4810\n",
      "Epoch 97/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0809 - accuracy: 0.5280 - val_loss: 1.1849 - val_accuracy: 0.4497\n",
      "Epoch 98/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1092 - accuracy: 0.5138 - val_loss: 1.1020 - val_accuracy: 0.4892\n",
      "Epoch 99/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1159 - accuracy: 0.5170 - val_loss: 1.2049 - val_accuracy: 0.4190\n",
      "Epoch 100/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1257 - accuracy: 0.5076 - val_loss: 1.2072 - val_accuracy: 0.4026\n",
      "Epoch 101/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1054 - accuracy: 0.5155 - val_loss: 1.2108 - val_accuracy: 0.3892\n",
      "Epoch 102/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0881 - accuracy: 0.5239 - val_loss: 1.1563 - val_accuracy: 0.4769\n",
      "Epoch 103/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1626 - accuracy: 0.4812 - val_loss: 1.0756 - val_accuracy: 0.5456\n",
      "Epoch 104/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1215 - accuracy: 0.5109 - val_loss: 1.3278 - val_accuracy: 0.3415\n",
      "Epoch 105/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1662 - accuracy: 0.4982 - val_loss: 1.0647 - val_accuracy: 0.5354\n",
      "Epoch 106/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1042 - accuracy: 0.5160 - val_loss: 1.1995 - val_accuracy: 0.3990\n",
      "Epoch 107/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1112 - accuracy: 0.5240 - val_loss: 1.1156 - val_accuracy: 0.4923\n",
      "Epoch 108/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1156 - accuracy: 0.5163 - val_loss: 1.0944 - val_accuracy: 0.5144\n",
      "Epoch 109/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1111 - accuracy: 0.5376 - val_loss: 1.2833 - val_accuracy: 0.3708\n",
      "Epoch 110/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0959 - accuracy: 0.5276 - val_loss: 1.1090 - val_accuracy: 0.5000\n",
      "Epoch 111/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0925 - accuracy: 0.5325 - val_loss: 1.1108 - val_accuracy: 0.4990\n",
      "Epoch 112/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0944 - accuracy: 0.5151 - val_loss: 1.1467 - val_accuracy: 0.4856\n",
      "Epoch 113/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1076 - accuracy: 0.5190 - val_loss: 1.0864 - val_accuracy: 0.5031\n",
      "Epoch 114/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0642 - accuracy: 0.5287 - val_loss: 1.1230 - val_accuracy: 0.5159\n",
      "Epoch 115/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0856 - accuracy: 0.5329 - val_loss: 1.1112 - val_accuracy: 0.4944\n",
      "Epoch 116/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0999 - accuracy: 0.5190 - val_loss: 1.1362 - val_accuracy: 0.4697\n",
      "Epoch 117/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1121 - accuracy: 0.5118 - val_loss: 1.1606 - val_accuracy: 0.4400\n",
      "Epoch 118/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0751 - accuracy: 0.5341 - val_loss: 1.1771 - val_accuracy: 0.4364\n",
      "Epoch 119/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1211 - accuracy: 0.5129 - val_loss: 1.1845 - val_accuracy: 0.4682\n",
      "Epoch 120/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1046 - accuracy: 0.5274 - val_loss: 1.1249 - val_accuracy: 0.4708\n",
      "Epoch 121/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0826 - accuracy: 0.5325 - val_loss: 1.1259 - val_accuracy: 0.4872\n",
      "Epoch 122/800\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0296 - accuracy: 0.60 - 0s 1ms/step - loss: 1.0808 - accuracy: 0.5506 - val_loss: 1.1123 - val_accuracy: 0.4897\n",
      "Epoch 123/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0947 - accuracy: 0.5319 - val_loss: 1.2054 - val_accuracy: 0.3897\n",
      "Epoch 124/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0878 - accuracy: 0.5290 - val_loss: 1.1506 - val_accuracy: 0.4672\n",
      "Epoch 125/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0981 - accuracy: 0.5156 - val_loss: 1.1671 - val_accuracy: 0.5056\n",
      "Epoch 126/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1353 - accuracy: 0.5163 - val_loss: 1.1845 - val_accuracy: 0.4144\n",
      "Epoch 127/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0881 - accuracy: 0.5336 - val_loss: 1.0875 - val_accuracy: 0.5015\n",
      "Epoch 128/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0683 - accuracy: 0.5410 - val_loss: 1.1696 - val_accuracy: 0.4677\n",
      "Epoch 129/800\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.3640 - accuracy: 0.42 - 0s 1ms/step - loss: 1.1002 - accuracy: 0.5195 - val_loss: 1.1553 - val_accuracy: 0.4677\n",
      "Epoch 130/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0780 - accuracy: 0.5269 - val_loss: 1.0944 - val_accuracy: 0.5308\n",
      "Epoch 131/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0802 - accuracy: 0.5374 - val_loss: 1.1052 - val_accuracy: 0.5082\n",
      "Epoch 132/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1057 - accuracy: 0.5242 - val_loss: 1.0688 - val_accuracy: 0.5236\n",
      "Epoch 133/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0849 - accuracy: 0.5291 - val_loss: 1.1198 - val_accuracy: 0.5195\n",
      "Epoch 134/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0962 - accuracy: 0.5259 - val_loss: 1.2067 - val_accuracy: 0.4262\n",
      "Epoch 135/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0802 - accuracy: 0.5302 - val_loss: 1.1035 - val_accuracy: 0.4959\n",
      "Epoch 136/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0890 - accuracy: 0.5279 - val_loss: 1.1371 - val_accuracy: 0.4672\n",
      "Epoch 137/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0811 - accuracy: 0.5295 - val_loss: 1.1671 - val_accuracy: 0.4374\n",
      "Epoch 138/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0898 - accuracy: 0.5285 - val_loss: 1.2785 - val_accuracy: 0.3569\n",
      "Epoch 139/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1245 - accuracy: 0.5113 - val_loss: 1.1152 - val_accuracy: 0.4928\n",
      "Epoch 140/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1171 - accuracy: 0.5197 - val_loss: 1.3190 - val_accuracy: 0.3497\n",
      "Epoch 141/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1177 - accuracy: 0.5239 - val_loss: 1.2230 - val_accuracy: 0.4000\n",
      "Epoch 142/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1081 - accuracy: 0.5206 - val_loss: 1.1742 - val_accuracy: 0.4415\n",
      "Epoch 143/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0998 - accuracy: 0.5237 - val_loss: 1.0701 - val_accuracy: 0.5410\n",
      "Epoch 144/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0853 - accuracy: 0.5419 - val_loss: 1.0745 - val_accuracy: 0.5344\n",
      "Epoch 145/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0785 - accuracy: 0.5219 - val_loss: 1.1607 - val_accuracy: 0.4733\n",
      "Epoch 146/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1057 - accuracy: 0.5124 - val_loss: 1.1121 - val_accuracy: 0.5046\n",
      "Epoch 147/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1030 - accuracy: 0.5147 - val_loss: 1.1057 - val_accuracy: 0.5159\n",
      "Epoch 148/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0928 - accuracy: 0.5357 - val_loss: 1.0832 - val_accuracy: 0.5190\n",
      "Epoch 149/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1146 - accuracy: 0.5345 - val_loss: 1.2035 - val_accuracy: 0.3887\n",
      "Epoch 150/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1173 - accuracy: 0.5198 - val_loss: 1.0610 - val_accuracy: 0.5369\n",
      "Epoch 151/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0953 - accuracy: 0.5339 - val_loss: 1.1028 - val_accuracy: 0.4933\n",
      "Epoch 152/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0889 - accuracy: 0.5409 - val_loss: 1.1859 - val_accuracy: 0.4149\n",
      "Epoch 153/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1241 - accuracy: 0.5073 - val_loss: 1.2808 - val_accuracy: 0.3610\n",
      "Epoch 154/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1231 - accuracy: 0.5040 - val_loss: 1.0738 - val_accuracy: 0.5133\n",
      "Epoch 155/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0776 - accuracy: 0.5417 - val_loss: 1.0805 - val_accuracy: 0.5185\n",
      "Epoch 156/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0896 - accuracy: 0.5332 - val_loss: 1.1485 - val_accuracy: 0.4569\n",
      "Epoch 157/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0811 - accuracy: 0.5347 - val_loss: 1.1149 - val_accuracy: 0.4851\n",
      "Epoch 158/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0605 - accuracy: 0.5419 - val_loss: 1.1067 - val_accuracy: 0.5395\n",
      "Epoch 159/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1054 - accuracy: 0.5176 - val_loss: 1.1244 - val_accuracy: 0.4774\n",
      "Epoch 160/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0990 - accuracy: 0.5283 - val_loss: 1.1080 - val_accuracy: 0.5103\n",
      "Epoch 161/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0726 - accuracy: 0.5470 - val_loss: 1.0880 - val_accuracy: 0.5179\n",
      "Epoch 162/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0944 - accuracy: 0.5222 - val_loss: 1.1393 - val_accuracy: 0.4851\n",
      "Epoch 163/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0950 - accuracy: 0.5265 - val_loss: 1.1862 - val_accuracy: 0.4231\n",
      "Epoch 164/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0953 - accuracy: 0.5117 - val_loss: 1.1817 - val_accuracy: 0.4344\n",
      "Epoch 165/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0937 - accuracy: 0.5313 - val_loss: 1.1424 - val_accuracy: 0.4805\n",
      "Epoch 166/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1065 - accuracy: 0.5292 - val_loss: 1.3170 - val_accuracy: 0.3513\n",
      "Epoch 167/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1142 - accuracy: 0.5204 - val_loss: 1.1271 - val_accuracy: 0.4862\n",
      "Epoch 168/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0791 - accuracy: 0.5409 - val_loss: 1.1540 - val_accuracy: 0.4405\n",
      "Epoch 169/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0643 - accuracy: 0.5457 - val_loss: 1.3182 - val_accuracy: 0.3579\n",
      "Epoch 170/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1098 - accuracy: 0.5231 - val_loss: 1.2156 - val_accuracy: 0.3995\n",
      "Epoch 171/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1044 - accuracy: 0.5095 - val_loss: 1.0974 - val_accuracy: 0.5128\n",
      "Epoch 172/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0925 - accuracy: 0.5303 - val_loss: 1.1504 - val_accuracy: 0.4682\n",
      "Epoch 173/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0924 - accuracy: 0.5283 - val_loss: 1.2251 - val_accuracy: 0.4774\n",
      "Epoch 174/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1631 - accuracy: 0.5091 - val_loss: 1.1898 - val_accuracy: 0.4179\n",
      "Epoch 175/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0880 - accuracy: 0.5313 - val_loss: 1.1551 - val_accuracy: 0.4272\n",
      "Epoch 176/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0837 - accuracy: 0.5311 - val_loss: 1.1637 - val_accuracy: 0.4559\n",
      "Epoch 177/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1518 - accuracy: 0.5110 - val_loss: 1.0911 - val_accuracy: 0.5062\n",
      "Epoch 178/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0884 - accuracy: 0.5403 - val_loss: 1.1010 - val_accuracy: 0.4923\n",
      "Epoch 179/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0639 - accuracy: 0.5375 - val_loss: 1.1199 - val_accuracy: 0.4815\n",
      "Epoch 180/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0750 - accuracy: 0.5329 - val_loss: 1.1412 - val_accuracy: 0.4595\n",
      "Epoch 181/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0989 - accuracy: 0.5198 - val_loss: 1.1344 - val_accuracy: 0.4738\n",
      "Epoch 182/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0648 - accuracy: 0.5358 - val_loss: 1.0913 - val_accuracy: 0.5133\n",
      "Epoch 183/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0884 - accuracy: 0.5258 - val_loss: 1.0941 - val_accuracy: 0.5400\n",
      "Epoch 184/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0816 - accuracy: 0.5132 - val_loss: 1.1707 - val_accuracy: 0.4559\n",
      "Epoch 185/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1058 - accuracy: 0.5225 - val_loss: 1.1748 - val_accuracy: 0.4662\n",
      "Epoch 186/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1138 - accuracy: 0.5070 - val_loss: 1.1378 - val_accuracy: 0.4862\n",
      "Epoch 187/800\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0987 - accuracy: 0.51 - 0s 1ms/step - loss: 1.0982 - accuracy: 0.5189 - val_loss: 1.0867 - val_accuracy: 0.5215\n",
      "Epoch 188/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0899 - accuracy: 0.5428 - val_loss: 1.2569 - val_accuracy: 0.4062\n",
      "Epoch 189/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1000 - accuracy: 0.5197 - val_loss: 1.1758 - val_accuracy: 0.4482\n",
      "Epoch 190/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0697 - accuracy: 0.5478 - val_loss: 1.1494 - val_accuracy: 0.4615\n",
      "Epoch 191/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1136 - accuracy: 0.5402 - val_loss: 1.2987 - val_accuracy: 0.4010\n",
      "Epoch 192/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1107 - accuracy: 0.5100 - val_loss: 1.1414 - val_accuracy: 0.4610\n",
      "Epoch 193/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0860 - accuracy: 0.5340 - val_loss: 1.1029 - val_accuracy: 0.4985\n",
      "Epoch 194/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0641 - accuracy: 0.5539 - val_loss: 1.1098 - val_accuracy: 0.4933\n",
      "Epoch 195/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0694 - accuracy: 0.5413 - val_loss: 1.1025 - val_accuracy: 0.5123\n",
      "Epoch 196/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1323 - accuracy: 0.5063 - val_loss: 1.1224 - val_accuracy: 0.4821\n",
      "Epoch 197/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0874 - accuracy: 0.5202 - val_loss: 1.1487 - val_accuracy: 0.4862\n",
      "Epoch 198/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0556 - accuracy: 0.5602 - val_loss: 1.0906 - val_accuracy: 0.5118\n",
      "Epoch 199/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1006 - accuracy: 0.5353 - val_loss: 1.2043 - val_accuracy: 0.4221\n",
      "Epoch 200/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1297 - accuracy: 0.5176 - val_loss: 1.1170 - val_accuracy: 0.4903\n",
      "Epoch 201/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0768 - accuracy: 0.5228 - val_loss: 1.1236 - val_accuracy: 0.4964\n",
      "Epoch 202/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0937 - accuracy: 0.5228 - val_loss: 1.0786 - val_accuracy: 0.5226\n",
      "Epoch 203/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0887 - accuracy: 0.5348 - val_loss: 1.1279 - val_accuracy: 0.4687\n",
      "Epoch 204/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0868 - accuracy: 0.5376 - val_loss: 1.3161 - val_accuracy: 0.3574\n",
      "Epoch 205/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0954 - accuracy: 0.5213 - val_loss: 1.0963 - val_accuracy: 0.5123\n",
      "Epoch 206/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0734 - accuracy: 0.5310 - val_loss: 1.1481 - val_accuracy: 0.4651\n",
      "Epoch 207/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0857 - accuracy: 0.5305 - val_loss: 1.0952 - val_accuracy: 0.5133\n",
      "Epoch 208/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0625 - accuracy: 0.5465 - val_loss: 1.0934 - val_accuracy: 0.4995\n",
      "Epoch 209/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0649 - accuracy: 0.5485 - val_loss: 1.1077 - val_accuracy: 0.5026\n",
      "Epoch 210/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0612 - accuracy: 0.5484 - val_loss: 1.2042 - val_accuracy: 0.4949\n",
      "Epoch 211/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1244 - accuracy: 0.5181 - val_loss: 1.0809 - val_accuracy: 0.5200\n",
      "Epoch 212/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0714 - accuracy: 0.5400 - val_loss: 1.1355 - val_accuracy: 0.5056\n",
      "Epoch 213/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0751 - accuracy: 0.5367 - val_loss: 1.1238 - val_accuracy: 0.4867\n",
      "Epoch 214/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0795 - accuracy: 0.5360 - val_loss: 1.1582 - val_accuracy: 0.4754\n",
      "Epoch 215/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0901 - accuracy: 0.5378 - val_loss: 1.0679 - val_accuracy: 0.5179\n",
      "Epoch 216/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0977 - accuracy: 0.5248 - val_loss: 1.1619 - val_accuracy: 0.4610\n",
      "Epoch 217/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0921 - accuracy: 0.5239 - val_loss: 1.1525 - val_accuracy: 0.4467\n",
      "Epoch 218/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0952 - accuracy: 0.5376 - val_loss: 1.1266 - val_accuracy: 0.4779\n",
      "Epoch 219/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0856 - accuracy: 0.5357 - val_loss: 1.1279 - val_accuracy: 0.4795\n",
      "Epoch 220/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1215 - accuracy: 0.5274 - val_loss: 1.1468 - val_accuracy: 0.4749\n",
      "Epoch 221/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1088 - accuracy: 0.5218 - val_loss: 1.1092 - val_accuracy: 0.4974\n",
      "Epoch 222/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0766 - accuracy: 0.5285 - val_loss: 1.1411 - val_accuracy: 0.4826\n",
      "Epoch 223/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0800 - accuracy: 0.5396 - val_loss: 1.1300 - val_accuracy: 0.5282\n",
      "Epoch 224/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1169 - accuracy: 0.5222 - val_loss: 1.0773 - val_accuracy: 0.5195\n",
      "Epoch 225/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0756 - accuracy: 0.5443 - val_loss: 1.1529 - val_accuracy: 0.4574\n",
      "Epoch 226/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0505 - accuracy: 0.5616 - val_loss: 1.1617 - val_accuracy: 0.4703\n",
      "Epoch 227/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0814 - accuracy: 0.5405 - val_loss: 1.1601 - val_accuracy: 0.4887\n",
      "Epoch 228/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1180 - accuracy: 0.5135 - val_loss: 1.1587 - val_accuracy: 0.4723\n",
      "Epoch 229/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1067 - accuracy: 0.5079 - val_loss: 1.0807 - val_accuracy: 0.5210\n",
      "Epoch 230/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1272 - accuracy: 0.5137 - val_loss: 1.1352 - val_accuracy: 0.4851\n",
      "Epoch 231/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0837 - accuracy: 0.5321 - val_loss: 1.0974 - val_accuracy: 0.4985\n",
      "Epoch 232/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0892 - accuracy: 0.5298 - val_loss: 1.0614 - val_accuracy: 0.5282\n",
      "Epoch 233/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0812 - accuracy: 0.5319 - val_loss: 1.1984 - val_accuracy: 0.4000\n",
      "Epoch 234/800\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0991 - accuracy: 0.51 - 0s 2ms/step - loss: 1.0948 - accuracy: 0.5182 - val_loss: 1.1368 - val_accuracy: 0.4697\n",
      "Epoch 235/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0858 - accuracy: 0.5364 - val_loss: 1.1618 - val_accuracy: 0.4497\n",
      "Epoch 236/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0632 - accuracy: 0.5374 - val_loss: 1.1139 - val_accuracy: 0.4918\n",
      "Epoch 237/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0651 - accuracy: 0.5393 - val_loss: 1.1256 - val_accuracy: 0.4800\n",
      "Epoch 238/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0619 - accuracy: 0.5504 - val_loss: 1.1206 - val_accuracy: 0.4785\n",
      "Epoch 239/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0801 - accuracy: 0.5256 - val_loss: 1.1018 - val_accuracy: 0.4944\n",
      "Epoch 240/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0807 - accuracy: 0.5383 - val_loss: 1.1038 - val_accuracy: 0.5128\n",
      "Epoch 241/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0916 - accuracy: 0.5205 - val_loss: 1.1386 - val_accuracy: 0.4605\n",
      "Epoch 242/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0965 - accuracy: 0.5181 - val_loss: 1.2499 - val_accuracy: 0.3892\n",
      "Epoch 243/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1549 - accuracy: 0.5088 - val_loss: 1.2157 - val_accuracy: 0.4205\n",
      "Epoch 244/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0677 - accuracy: 0.5502 - val_loss: 1.0964 - val_accuracy: 0.5190\n",
      "Epoch 245/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0669 - accuracy: 0.5439 - val_loss: 1.0723 - val_accuracy: 0.5282\n",
      "Epoch 246/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0644 - accuracy: 0.5454 - val_loss: 1.2011 - val_accuracy: 0.4708\n",
      "Epoch 247/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0979 - accuracy: 0.5265 - val_loss: 1.1107 - val_accuracy: 0.5062\n",
      "Epoch 248/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0903 - accuracy: 0.5311 - val_loss: 1.1857 - val_accuracy: 0.4610\n",
      "Epoch 249/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0858 - accuracy: 0.5304 - val_loss: 1.2262 - val_accuracy: 0.4390\n",
      "Epoch 250/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0705 - accuracy: 0.5200 - val_loss: 1.1234 - val_accuracy: 0.4856\n",
      "Epoch 251/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0830 - accuracy: 0.5398 - val_loss: 1.1443 - val_accuracy: 0.4744\n",
      "Epoch 252/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0811 - accuracy: 0.5369 - val_loss: 1.1751 - val_accuracy: 0.4138\n",
      "Epoch 253/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1009 - accuracy: 0.5170 - val_loss: 1.1076 - val_accuracy: 0.5000\n",
      "Epoch 254/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0962 - accuracy: 0.5206 - val_loss: 1.1563 - val_accuracy: 0.4636\n",
      "Epoch 255/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0880 - accuracy: 0.5242 - val_loss: 1.0955 - val_accuracy: 0.4938\n",
      "Epoch 256/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0798 - accuracy: 0.5349 - val_loss: 1.1282 - val_accuracy: 0.4764\n",
      "Epoch 257/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1025 - accuracy: 0.5292 - val_loss: 1.1399 - val_accuracy: 0.4723\n",
      "Epoch 258/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0599 - accuracy: 0.5451 - val_loss: 1.1393 - val_accuracy: 0.4497\n",
      "Epoch 259/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0931 - accuracy: 0.5239 - val_loss: 1.1106 - val_accuracy: 0.5015\n",
      "Epoch 260/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0506 - accuracy: 0.5602 - val_loss: 1.0673 - val_accuracy: 0.5205\n",
      "Epoch 261/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0667 - accuracy: 0.5470 - val_loss: 1.1537 - val_accuracy: 0.4574\n",
      "Epoch 262/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0849 - accuracy: 0.5355 - val_loss: 1.1344 - val_accuracy: 0.4749\n",
      "Epoch 263/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1130 - accuracy: 0.5116 - val_loss: 1.1323 - val_accuracy: 0.4913\n",
      "Epoch 264/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0757 - accuracy: 0.5427 - val_loss: 1.0771 - val_accuracy: 0.5087\n",
      "Epoch 265/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0736 - accuracy: 0.5293 - val_loss: 1.1098 - val_accuracy: 0.5108\n",
      "Epoch 266/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0843 - accuracy: 0.5315 - val_loss: 1.1412 - val_accuracy: 0.4805\n",
      "Epoch 267/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0789 - accuracy: 0.5356 - val_loss: 1.1218 - val_accuracy: 0.5021\n",
      "Epoch 268/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0785 - accuracy: 0.5243 - val_loss: 1.1673 - val_accuracy: 0.4579\n",
      "Epoch 269/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1077 - accuracy: 0.5182 - val_loss: 1.0894 - val_accuracy: 0.5144\n",
      "Epoch 270/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0612 - accuracy: 0.5406 - val_loss: 1.2282 - val_accuracy: 0.3974\n",
      "Epoch 271/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0761 - accuracy: 0.5405 - val_loss: 1.1709 - val_accuracy: 0.4697\n",
      "Epoch 272/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0544 - accuracy: 0.5542 - val_loss: 1.1142 - val_accuracy: 0.5108\n",
      "Epoch 273/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0834 - accuracy: 0.5351 - val_loss: 1.0735 - val_accuracy: 0.5318\n",
      "Epoch 274/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0743 - accuracy: 0.5363 - val_loss: 1.1268 - val_accuracy: 0.4764\n",
      "Epoch 275/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0537 - accuracy: 0.5554 - val_loss: 1.1416 - val_accuracy: 0.4513\n",
      "Epoch 276/800\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.1467 - accuracy: 0.56 - 0s 1ms/step - loss: 1.0768 - accuracy: 0.5375 - val_loss: 1.1120 - val_accuracy: 0.4795\n",
      "Epoch 277/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0495 - accuracy: 0.5462 - val_loss: 1.0792 - val_accuracy: 0.5113\n",
      "Epoch 278/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0548 - accuracy: 0.5455 - val_loss: 1.1400 - val_accuracy: 0.5144\n",
      "Epoch 279/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1229 - accuracy: 0.5076 - val_loss: 1.1115 - val_accuracy: 0.5005\n",
      "Epoch 280/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0941 - accuracy: 0.5235 - val_loss: 1.1203 - val_accuracy: 0.4882\n",
      "Epoch 281/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0862 - accuracy: 0.5218 - val_loss: 1.0889 - val_accuracy: 0.4979\n",
      "Epoch 282/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0718 - accuracy: 0.5425 - val_loss: 1.1887 - val_accuracy: 0.4631\n",
      "Epoch 283/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0780 - accuracy: 0.5435 - val_loss: 1.2320 - val_accuracy: 0.3785\n",
      "Epoch 284/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0906 - accuracy: 0.5171 - val_loss: 1.1619 - val_accuracy: 0.4369\n",
      "Epoch 285/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0813 - accuracy: 0.5235 - val_loss: 1.0990 - val_accuracy: 0.4964\n",
      "Epoch 286/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0889 - accuracy: 0.5385 - val_loss: 1.0978 - val_accuracy: 0.5072\n",
      "Epoch 287/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0938 - accuracy: 0.5308 - val_loss: 1.1250 - val_accuracy: 0.5041\n",
      "Epoch 288/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0866 - accuracy: 0.5167 - val_loss: 1.0661 - val_accuracy: 0.5262\n",
      "Epoch 289/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0816 - accuracy: 0.5375 - val_loss: 1.1376 - val_accuracy: 0.5046\n",
      "Epoch 290/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0918 - accuracy: 0.5322 - val_loss: 1.0926 - val_accuracy: 0.4990\n",
      "Epoch 291/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0666 - accuracy: 0.5348 - val_loss: 1.1379 - val_accuracy: 0.4626\n",
      "Epoch 292/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0994 - accuracy: 0.5327 - val_loss: 1.1006 - val_accuracy: 0.5051\n",
      "Epoch 293/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0866 - accuracy: 0.5299 - val_loss: 1.1642 - val_accuracy: 0.4641\n",
      "Epoch 294/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0898 - accuracy: 0.5265 - val_loss: 1.1025 - val_accuracy: 0.5082\n",
      "Epoch 295/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0913 - accuracy: 0.5190 - val_loss: 1.0915 - val_accuracy: 0.5128\n",
      "Epoch 296/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0996 - accuracy: 0.5418 - val_loss: 1.2866 - val_accuracy: 0.3621\n",
      "Epoch 297/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1081 - accuracy: 0.5145 - val_loss: 1.2109 - val_accuracy: 0.4205\n",
      "Epoch 298/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1035 - accuracy: 0.5109 - val_loss: 1.1822 - val_accuracy: 0.4513\n",
      "Epoch 299/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0522 - accuracy: 0.5492 - val_loss: 1.1591 - val_accuracy: 0.4662\n",
      "Epoch 300/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0581 - accuracy: 0.5506 - val_loss: 1.0844 - val_accuracy: 0.5236\n",
      "Epoch 301/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0749 - accuracy: 0.5370 - val_loss: 1.1012 - val_accuracy: 0.5026\n",
      "Epoch 302/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0707 - accuracy: 0.5306 - val_loss: 1.0818 - val_accuracy: 0.5231\n",
      "Epoch 303/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0632 - accuracy: 0.5492 - val_loss: 1.0973 - val_accuracy: 0.5103\n",
      "Epoch 304/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0826 - accuracy: 0.5338 - val_loss: 1.1943 - val_accuracy: 0.4400\n",
      "Epoch 305/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0673 - accuracy: 0.5450 - val_loss: 1.0710 - val_accuracy: 0.5338\n",
      "Epoch 306/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0820 - accuracy: 0.5311 - val_loss: 1.1181 - val_accuracy: 0.4846\n",
      "Epoch 307/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0988 - accuracy: 0.5301 - val_loss: 1.1465 - val_accuracy: 0.4600\n",
      "Epoch 308/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0697 - accuracy: 0.5314 - val_loss: 1.1442 - val_accuracy: 0.4482\n",
      "Epoch 309/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0686 - accuracy: 0.5351 - val_loss: 1.2299 - val_accuracy: 0.3959\n",
      "Epoch 310/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1064 - accuracy: 0.5261 - val_loss: 1.1360 - val_accuracy: 0.4692\n",
      "Epoch 311/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0830 - accuracy: 0.5356 - val_loss: 1.0987 - val_accuracy: 0.5082\n",
      "Epoch 312/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0768 - accuracy: 0.5339 - val_loss: 1.1126 - val_accuracy: 0.4800\n",
      "Epoch 313/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1195 - accuracy: 0.5084 - val_loss: 1.1179 - val_accuracy: 0.4831\n",
      "Epoch 314/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0556 - accuracy: 0.5677 - val_loss: 1.1846 - val_accuracy: 0.4815\n",
      "Epoch 315/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1165 - accuracy: 0.5007 - val_loss: 1.1502 - val_accuracy: 0.4585\n",
      "Epoch 316/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0783 - accuracy: 0.5361 - val_loss: 1.1368 - val_accuracy: 0.4790\n",
      "Epoch 317/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0638 - accuracy: 0.5404 - val_loss: 1.1598 - val_accuracy: 0.4687\n",
      "Epoch 318/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0943 - accuracy: 0.5104 - val_loss: 1.1515 - val_accuracy: 0.4467\n",
      "Epoch 319/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0726 - accuracy: 0.5397 - val_loss: 1.2811 - val_accuracy: 0.3646\n",
      "Epoch 320/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0855 - accuracy: 0.5404 - val_loss: 1.0982 - val_accuracy: 0.4964\n",
      "Epoch 321/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0481 - accuracy: 0.5588 - val_loss: 1.1334 - val_accuracy: 0.5026\n",
      "Epoch 322/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0574 - accuracy: 0.5400 - val_loss: 1.1635 - val_accuracy: 0.4497\n",
      "Epoch 323/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0796 - accuracy: 0.5381 - val_loss: 1.2042 - val_accuracy: 0.4205\n",
      "Epoch 324/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1017 - accuracy: 0.5386 - val_loss: 1.1104 - val_accuracy: 0.4810\n",
      "Epoch 325/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0778 - accuracy: 0.5368 - val_loss: 1.1037 - val_accuracy: 0.4918\n",
      "Epoch 326/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0734 - accuracy: 0.5470 - val_loss: 1.0772 - val_accuracy: 0.5174\n",
      "Epoch 327/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0686 - accuracy: 0.5375 - val_loss: 1.1146 - val_accuracy: 0.4805\n",
      "Epoch 328/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0853 - accuracy: 0.5335 - val_loss: 1.1166 - val_accuracy: 0.4918\n",
      "Epoch 329/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0885 - accuracy: 0.5375 - val_loss: 1.1512 - val_accuracy: 0.4523\n",
      "Epoch 330/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0299 - accuracy: 0.5695 - val_loss: 1.0972 - val_accuracy: 0.5015\n",
      "Epoch 331/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0807 - accuracy: 0.5376 - val_loss: 1.1339 - val_accuracy: 0.4815\n",
      "Epoch 332/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0884 - accuracy: 0.5188 - val_loss: 1.1439 - val_accuracy: 0.4779\n",
      "Epoch 333/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1058 - accuracy: 0.5357 - val_loss: 1.1495 - val_accuracy: 0.4595\n",
      "Epoch 334/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0602 - accuracy: 0.5325 - val_loss: 1.0980 - val_accuracy: 0.4979\n",
      "Epoch 335/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0768 - accuracy: 0.5307 - val_loss: 1.0787 - val_accuracy: 0.5185\n",
      "Epoch 336/800\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.0704 - accuracy: 0.53 - 0s 2ms/step - loss: 1.0698 - accuracy: 0.5394 - val_loss: 1.2454 - val_accuracy: 0.4051\n",
      "Epoch 337/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1147 - accuracy: 0.5185 - val_loss: 1.1305 - val_accuracy: 0.5056\n",
      "Epoch 338/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0772 - accuracy: 0.5361 - val_loss: 1.1236 - val_accuracy: 0.4923\n",
      "Epoch 339/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0580 - accuracy: 0.5373 - val_loss: 1.1314 - val_accuracy: 0.4692\n",
      "Epoch 340/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0784 - accuracy: 0.5372 - val_loss: 1.1344 - val_accuracy: 0.5231\n",
      "Epoch 341/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0706 - accuracy: 0.5386 - val_loss: 1.1508 - val_accuracy: 0.4713\n",
      "Epoch 342/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0664 - accuracy: 0.5582 - val_loss: 1.1265 - val_accuracy: 0.4800\n",
      "Epoch 343/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0626 - accuracy: 0.5532 - val_loss: 1.0839 - val_accuracy: 0.5174\n",
      "Epoch 344/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0604 - accuracy: 0.5403 - val_loss: 1.1717 - val_accuracy: 0.4323\n",
      "Epoch 345/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0856 - accuracy: 0.5189 - val_loss: 1.1380 - val_accuracy: 0.4656\n",
      "Epoch 346/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0476 - accuracy: 0.5537 - val_loss: 1.1008 - val_accuracy: 0.5067\n",
      "Epoch 347/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0425 - accuracy: 0.5644 - val_loss: 1.1500 - val_accuracy: 0.4672\n",
      "Epoch 348/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0670 - accuracy: 0.5268 - val_loss: 1.1338 - val_accuracy: 0.4723\n",
      "Epoch 349/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0553 - accuracy: 0.5518 - val_loss: 1.1437 - val_accuracy: 0.4559\n",
      "Epoch 350/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0857 - accuracy: 0.5352 - val_loss: 1.0831 - val_accuracy: 0.5056\n",
      "Epoch 351/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0437 - accuracy: 0.5659 - val_loss: 1.1681 - val_accuracy: 0.4421\n",
      "Epoch 352/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0905 - accuracy: 0.5275 - val_loss: 1.2809 - val_accuracy: 0.3585\n",
      "Epoch 353/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1243 - accuracy: 0.5182 - val_loss: 1.0934 - val_accuracy: 0.5072\n",
      "Epoch 354/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0672 - accuracy: 0.5447 - val_loss: 1.1072 - val_accuracy: 0.4933\n",
      "Epoch 355/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0499 - accuracy: 0.5512 - val_loss: 1.1378 - val_accuracy: 0.4590\n",
      "Epoch 356/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0530 - accuracy: 0.5492 - val_loss: 1.1350 - val_accuracy: 0.4713\n",
      "Epoch 357/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0784 - accuracy: 0.5274 - val_loss: 1.1065 - val_accuracy: 0.5015\n",
      "Epoch 358/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0743 - accuracy: 0.5320 - val_loss: 1.0963 - val_accuracy: 0.4974\n",
      "Epoch 359/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0534 - accuracy: 0.5486 - val_loss: 1.1924 - val_accuracy: 0.4195\n",
      "Epoch 360/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0434 - accuracy: 0.5531 - val_loss: 1.1629 - val_accuracy: 0.4333\n",
      "Epoch 361/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0699 - accuracy: 0.5301 - val_loss: 1.1308 - val_accuracy: 0.5077\n",
      "Epoch 362/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0800 - accuracy: 0.5319 - val_loss: 1.0675 - val_accuracy: 0.5395\n",
      "Epoch 363/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0440 - accuracy: 0.5573 - val_loss: 1.2069 - val_accuracy: 0.4318\n",
      "Epoch 364/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0685 - accuracy: 0.5222 - val_loss: 1.2056 - val_accuracy: 0.4051\n",
      "Epoch 365/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0430 - accuracy: 0.5490 - val_loss: 1.2093 - val_accuracy: 0.4138\n",
      "Epoch 366/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0652 - accuracy: 0.5456 - val_loss: 1.1338 - val_accuracy: 0.4826\n",
      "Epoch 367/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0655 - accuracy: 0.5438 - val_loss: 1.0883 - val_accuracy: 0.5190\n",
      "Epoch 368/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1037 - accuracy: 0.5027 - val_loss: 1.0985 - val_accuracy: 0.4897\n",
      "Epoch 369/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0605 - accuracy: 0.5553 - val_loss: 1.0849 - val_accuracy: 0.5087\n",
      "Epoch 370/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0449 - accuracy: 0.5392 - val_loss: 1.1018 - val_accuracy: 0.5190\n",
      "Epoch 371/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0631 - accuracy: 0.5403 - val_loss: 1.1485 - val_accuracy: 0.4615\n",
      "Epoch 372/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0574 - accuracy: 0.5497 - val_loss: 1.0843 - val_accuracy: 0.5262\n",
      "Epoch 373/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0492 - accuracy: 0.5454 - val_loss: 1.1358 - val_accuracy: 0.4713\n",
      "Epoch 374/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0414 - accuracy: 0.5660 - val_loss: 1.0793 - val_accuracy: 0.5123\n",
      "Epoch 375/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0544 - accuracy: 0.5447 - val_loss: 1.0610 - val_accuracy: 0.5195\n",
      "Epoch 376/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1149 - accuracy: 0.5212 - val_loss: 1.2126 - val_accuracy: 0.4108\n",
      "Epoch 377/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1017 - accuracy: 0.5267 - val_loss: 1.1940 - val_accuracy: 0.4318\n",
      "Epoch 378/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1413 - accuracy: 0.5264 - val_loss: 1.1056 - val_accuracy: 0.4995\n",
      "Epoch 379/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1280 - accuracy: 0.5215 - val_loss: 1.1038 - val_accuracy: 0.4944\n",
      "Epoch 380/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0553 - accuracy: 0.5537 - val_loss: 1.2203 - val_accuracy: 0.4374\n",
      "Epoch 381/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1083 - accuracy: 0.5271 - val_loss: 1.1034 - val_accuracy: 0.4923\n",
      "Epoch 382/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0678 - accuracy: 0.5358 - val_loss: 1.0977 - val_accuracy: 0.5051\n",
      "Epoch 383/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0932 - accuracy: 0.5226 - val_loss: 1.1593 - val_accuracy: 0.4754\n",
      "Epoch 384/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0587 - accuracy: 0.5400 - val_loss: 1.0647 - val_accuracy: 0.5164\n",
      "Epoch 385/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0740 - accuracy: 0.5455 - val_loss: 1.1142 - val_accuracy: 0.4867\n",
      "Epoch 386/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0912 - accuracy: 0.5176 - val_loss: 1.1144 - val_accuracy: 0.4744\n",
      "Epoch 387/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0623 - accuracy: 0.5334 - val_loss: 1.0755 - val_accuracy: 0.5144\n",
      "Epoch 388/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0473 - accuracy: 0.5606 - val_loss: 1.1088 - val_accuracy: 0.5128\n",
      "Epoch 389/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0630 - accuracy: 0.5458 - val_loss: 1.1088 - val_accuracy: 0.4969\n",
      "Epoch 390/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0523 - accuracy: 0.5536 - val_loss: 1.1830 - val_accuracy: 0.4585\n",
      "Epoch 391/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0778 - accuracy: 0.5441 - val_loss: 1.1055 - val_accuracy: 0.4918\n",
      "Epoch 392/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0619 - accuracy: 0.5372 - val_loss: 1.0708 - val_accuracy: 0.5369\n",
      "Epoch 393/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0546 - accuracy: 0.5391 - val_loss: 1.0649 - val_accuracy: 0.5210\n",
      "Epoch 394/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0259 - accuracy: 0.5518 - val_loss: 1.2763 - val_accuracy: 0.3656\n",
      "Epoch 395/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1188 - accuracy: 0.5258 - val_loss: 1.2339 - val_accuracy: 0.3703\n",
      "Epoch 396/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.1043 - accuracy: 0.5199 - val_loss: 1.0797 - val_accuracy: 0.5108\n",
      "Epoch 397/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0745 - accuracy: 0.5340 - val_loss: 1.1591 - val_accuracy: 0.4621\n",
      "Epoch 398/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0638 - accuracy: 0.5466 - val_loss: 1.1126 - val_accuracy: 0.4836\n",
      "Epoch 399/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0675 - accuracy: 0.5427 - val_loss: 1.0957 - val_accuracy: 0.4913\n",
      "Epoch 400/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0476 - accuracy: 0.5523 - val_loss: 1.1616 - val_accuracy: 0.4703\n",
      "Epoch 401/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0856 - accuracy: 0.5188 - val_loss: 1.1839 - val_accuracy: 0.4297\n",
      "Epoch 402/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0827 - accuracy: 0.5400 - val_loss: 1.1050 - val_accuracy: 0.5026\n",
      "Epoch 403/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0674 - accuracy: 0.5287 - val_loss: 1.2223 - val_accuracy: 0.4046\n",
      "Epoch 404/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0622 - accuracy: 0.5443 - val_loss: 1.0920 - val_accuracy: 0.5046\n",
      "Epoch 405/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0939 - accuracy: 0.5327 - val_loss: 1.1108 - val_accuracy: 0.4923\n",
      "Epoch 406/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0453 - accuracy: 0.5531 - val_loss: 1.1178 - val_accuracy: 0.5005\n",
      "Epoch 407/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0745 - accuracy: 0.5379 - val_loss: 1.1126 - val_accuracy: 0.4949\n",
      "Epoch 408/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0480 - accuracy: 0.5493 - val_loss: 1.0807 - val_accuracy: 0.5174\n",
      "Epoch 409/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0604 - accuracy: 0.5405 - val_loss: 1.1394 - val_accuracy: 0.4646\n",
      "Epoch 410/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0190 - accuracy: 0.5720 - val_loss: 1.1198 - val_accuracy: 0.4728\n",
      "Epoch 411/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0420 - accuracy: 0.5470 - val_loss: 1.1797 - val_accuracy: 0.4651\n",
      "Epoch 412/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0653 - accuracy: 0.5431 - val_loss: 1.0987 - val_accuracy: 0.5036\n",
      "Epoch 413/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0597 - accuracy: 0.5423 - val_loss: 1.0819 - val_accuracy: 0.5221\n",
      "Epoch 414/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0947 - accuracy: 0.5377 - val_loss: 1.0775 - val_accuracy: 0.5154\n",
      "Epoch 415/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0926 - accuracy: 0.5368 - val_loss: 1.1256 - val_accuracy: 0.4754\n",
      "Epoch 416/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0855 - accuracy: 0.5175 - val_loss: 1.1982 - val_accuracy: 0.4138\n",
      "Epoch 417/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0702 - accuracy: 0.5291 - val_loss: 1.0975 - val_accuracy: 0.5164\n",
      "Epoch 418/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0885 - accuracy: 0.5177 - val_loss: 1.1185 - val_accuracy: 0.5051\n",
      "Epoch 419/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0546 - accuracy: 0.5374 - val_loss: 1.0786 - val_accuracy: 0.5205\n",
      "Epoch 420/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0654 - accuracy: 0.5479 - val_loss: 1.1426 - val_accuracy: 0.4738\n",
      "Epoch 421/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0769 - accuracy: 0.5316 - val_loss: 1.0948 - val_accuracy: 0.5036\n",
      "Epoch 422/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0633 - accuracy: 0.5542 - val_loss: 1.0803 - val_accuracy: 0.5149\n",
      "Epoch 423/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0579 - accuracy: 0.5345 - val_loss: 1.1163 - val_accuracy: 0.4928\n",
      "Epoch 424/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0747 - accuracy: 0.5422 - val_loss: 1.2308 - val_accuracy: 0.4010\n",
      "Epoch 425/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0726 - accuracy: 0.5493 - val_loss: 1.1950 - val_accuracy: 0.4210\n",
      "Epoch 426/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0479 - accuracy: 0.5480 - val_loss: 1.1317 - val_accuracy: 0.4631\n",
      "Epoch 427/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0697 - accuracy: 0.5375 - val_loss: 1.0996 - val_accuracy: 0.4974\n",
      "Epoch 428/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0498 - accuracy: 0.5511 - val_loss: 1.0730 - val_accuracy: 0.5159\n",
      "Epoch 429/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0529 - accuracy: 0.5389 - val_loss: 1.2005 - val_accuracy: 0.4677\n",
      "Epoch 430/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0675 - accuracy: 0.5399 - val_loss: 1.1899 - val_accuracy: 0.4544\n",
      "Epoch 431/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0492 - accuracy: 0.5473 - val_loss: 1.0770 - val_accuracy: 0.5246\n",
      "Epoch 432/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0648 - accuracy: 0.5378 - val_loss: 1.1841 - val_accuracy: 0.4308\n",
      "Epoch 433/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0682 - accuracy: 0.5416 - val_loss: 1.1528 - val_accuracy: 0.4667\n",
      "Epoch 434/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0650 - accuracy: 0.5294 - val_loss: 1.1066 - val_accuracy: 0.4903\n",
      "Epoch 435/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0769 - accuracy: 0.5268 - val_loss: 1.1183 - val_accuracy: 0.4831\n",
      "Epoch 436/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0556 - accuracy: 0.5502 - val_loss: 1.0949 - val_accuracy: 0.5026\n",
      "Epoch 437/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0391 - accuracy: 0.5609 - val_loss: 1.0917 - val_accuracy: 0.5395\n",
      "Epoch 438/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0856 - accuracy: 0.5280 - val_loss: 1.1854 - val_accuracy: 0.4497\n",
      "Epoch 439/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0711 - accuracy: 0.5362 - val_loss: 1.1395 - val_accuracy: 0.4646\n",
      "Epoch 440/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0357 - accuracy: 0.5568 - val_loss: 1.1033 - val_accuracy: 0.4954\n",
      "Epoch 441/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0360 - accuracy: 0.5511 - val_loss: 1.1022 - val_accuracy: 0.5005\n",
      "Epoch 442/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0638 - accuracy: 0.5484 - val_loss: 1.0876 - val_accuracy: 0.5133\n",
      "Epoch 443/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0395 - accuracy: 0.5569 - val_loss: 1.1479 - val_accuracy: 0.4738\n",
      "Epoch 444/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0938 - accuracy: 0.5300 - val_loss: 1.1453 - val_accuracy: 0.4974\n",
      "Epoch 445/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0585 - accuracy: 0.5465 - val_loss: 1.1656 - val_accuracy: 0.4641\n",
      "Epoch 446/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0423 - accuracy: 0.5454 - val_loss: 1.0754 - val_accuracy: 0.5169\n",
      "Epoch 447/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0603 - accuracy: 0.5443 - val_loss: 1.2433 - val_accuracy: 0.3938\n",
      "Epoch 448/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0775 - accuracy: 0.5321 - val_loss: 1.0965 - val_accuracy: 0.4867\n",
      "Epoch 449/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0478 - accuracy: 0.5450 - val_loss: 1.0824 - val_accuracy: 0.5010\n",
      "Epoch 450/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0529 - accuracy: 0.5538 - val_loss: 1.1561 - val_accuracy: 0.4703\n",
      "Epoch 451/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0491 - accuracy: 0.5484 - val_loss: 1.1373 - val_accuracy: 0.4841\n",
      "Epoch 452/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0343 - accuracy: 0.5573 - val_loss: 1.1794 - val_accuracy: 0.4323\n",
      "Epoch 453/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0481 - accuracy: 0.5437 - val_loss: 1.1049 - val_accuracy: 0.5021\n",
      "Epoch 454/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0815 - accuracy: 0.5194 - val_loss: 1.0950 - val_accuracy: 0.5108\n",
      "Epoch 455/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0555 - accuracy: 0.5396 - val_loss: 1.0884 - val_accuracy: 0.5067\n",
      "Epoch 456/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0593 - accuracy: 0.5449 - val_loss: 1.1627 - val_accuracy: 0.4421\n",
      "Epoch 457/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0517 - accuracy: 0.5474 - val_loss: 1.1295 - val_accuracy: 0.4544\n",
      "Epoch 458/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0405 - accuracy: 0.5422 - val_loss: 1.1415 - val_accuracy: 0.4826\n",
      "Epoch 459/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0490 - accuracy: 0.5482 - val_loss: 1.1634 - val_accuracy: 0.4482\n",
      "Epoch 460/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0772 - accuracy: 0.5207 - val_loss: 1.0996 - val_accuracy: 0.5113\n",
      "Epoch 461/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0485 - accuracy: 0.5465 - val_loss: 1.1781 - val_accuracy: 0.4718\n",
      "Epoch 462/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0694 - accuracy: 0.5366 - val_loss: 1.1279 - val_accuracy: 0.5097\n",
      "Epoch 463/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0919 - accuracy: 0.5355 - val_loss: 1.1452 - val_accuracy: 0.4610\n",
      "Epoch 464/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0793 - accuracy: 0.5156 - val_loss: 1.1046 - val_accuracy: 0.5067\n",
      "Epoch 465/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0357 - accuracy: 0.5434 - val_loss: 1.1013 - val_accuracy: 0.4944\n",
      "Epoch 466/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0497 - accuracy: 0.5405 - val_loss: 1.1989 - val_accuracy: 0.4149\n",
      "Epoch 467/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0373 - accuracy: 0.5569 - val_loss: 1.1057 - val_accuracy: 0.4759\n",
      "Epoch 468/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0583 - accuracy: 0.5544 - val_loss: 1.1343 - val_accuracy: 0.4918\n",
      "Epoch 469/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0406 - accuracy: 0.5537 - val_loss: 1.0937 - val_accuracy: 0.5062\n",
      "Epoch 470/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0553 - accuracy: 0.5379 - val_loss: 1.2166 - val_accuracy: 0.3933\n",
      "Epoch 471/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0699 - accuracy: 0.5420 - val_loss: 1.1247 - val_accuracy: 0.4933\n",
      "Epoch 472/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0541 - accuracy: 0.5448 - val_loss: 1.1366 - val_accuracy: 0.4851\n",
      "Epoch 473/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0596 - accuracy: 0.5322 - val_loss: 1.2496 - val_accuracy: 0.3851\n",
      "Epoch 474/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0788 - accuracy: 0.5283 - val_loss: 1.1809 - val_accuracy: 0.4697\n",
      "Epoch 475/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0594 - accuracy: 0.5409 - val_loss: 1.1842 - val_accuracy: 0.4297\n",
      "Epoch 476/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0502 - accuracy: 0.5431 - val_loss: 1.1409 - val_accuracy: 0.4836\n",
      "Epoch 477/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0643 - accuracy: 0.5288 - val_loss: 1.1468 - val_accuracy: 0.4600\n",
      "Epoch 478/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0509 - accuracy: 0.5540 - val_loss: 1.1048 - val_accuracy: 0.5272\n",
      "Epoch 479/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0273 - accuracy: 0.5546 - val_loss: 1.1639 - val_accuracy: 0.4564\n",
      "Epoch 480/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0698 - accuracy: 0.5600 - val_loss: 1.0623 - val_accuracy: 0.5159\n",
      "Epoch 481/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0467 - accuracy: 0.5506 - val_loss: 1.1710 - val_accuracy: 0.4328\n",
      "Epoch 482/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0782 - accuracy: 0.5215 - val_loss: 1.0845 - val_accuracy: 0.5123\n",
      "Epoch 483/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0456 - accuracy: 0.5419 - val_loss: 1.0850 - val_accuracy: 0.5292\n",
      "Epoch 484/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0695 - accuracy: 0.5514 - val_loss: 1.1137 - val_accuracy: 0.4990\n",
      "Epoch 485/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0531 - accuracy: 0.5461 - val_loss: 1.1274 - val_accuracy: 0.4959\n",
      "Epoch 486/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0361 - accuracy: 0.5446 - val_loss: 1.1147 - val_accuracy: 0.5103\n",
      "Epoch 487/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0294 - accuracy: 0.5497 - val_loss: 1.1084 - val_accuracy: 0.4795\n",
      "Epoch 488/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0901 - accuracy: 0.5375 - val_loss: 1.1584 - val_accuracy: 0.4456\n",
      "Epoch 489/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0423 - accuracy: 0.5432 - val_loss: 1.0903 - val_accuracy: 0.5200\n",
      "Epoch 490/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0468 - accuracy: 0.5481 - val_loss: 1.1108 - val_accuracy: 0.4836\n",
      "Epoch 491/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0663 - accuracy: 0.5600 - val_loss: 1.1513 - val_accuracy: 0.4764\n",
      "Epoch 492/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0984 - accuracy: 0.5194 - val_loss: 1.1891 - val_accuracy: 0.4272\n",
      "Epoch 493/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0886 - accuracy: 0.5291 - val_loss: 1.2591 - val_accuracy: 0.3944\n",
      "Epoch 494/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0695 - accuracy: 0.5365 - val_loss: 1.2083 - val_accuracy: 0.4036\n",
      "Epoch 495/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0842 - accuracy: 0.5164 - val_loss: 1.1264 - val_accuracy: 0.4728\n",
      "Epoch 496/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0333 - accuracy: 0.5477 - val_loss: 1.1081 - val_accuracy: 0.4990\n",
      "Epoch 497/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0491 - accuracy: 0.5346 - val_loss: 1.1751 - val_accuracy: 0.4144\n",
      "Epoch 498/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0971 - accuracy: 0.5219 - val_loss: 1.1635 - val_accuracy: 0.4800\n",
      "Epoch 499/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0506 - accuracy: 0.5357 - val_loss: 1.2036 - val_accuracy: 0.4256\n",
      "Epoch 500/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0585 - accuracy: 0.5375 - val_loss: 1.1191 - val_accuracy: 0.4810\n",
      "Epoch 501/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0421 - accuracy: 0.5575 - val_loss: 1.1183 - val_accuracy: 0.4979\n",
      "Epoch 502/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0426 - accuracy: 0.5423 - val_loss: 1.1339 - val_accuracy: 0.4759\n",
      "Epoch 503/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0393 - accuracy: 0.5457 - val_loss: 1.1193 - val_accuracy: 0.4908\n",
      "Epoch 504/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0713 - accuracy: 0.5386 - val_loss: 1.1044 - val_accuracy: 0.4990\n",
      "Epoch 505/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0196 - accuracy: 0.5623 - val_loss: 1.1227 - val_accuracy: 0.4892\n",
      "Epoch 506/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0652 - accuracy: 0.5384 - val_loss: 1.1678 - val_accuracy: 0.4472\n",
      "Epoch 507/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0509 - accuracy: 0.5406 - val_loss: 1.1138 - val_accuracy: 0.4800\n",
      "Epoch 508/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0370 - accuracy: 0.5596 - val_loss: 1.2755 - val_accuracy: 0.3703\n",
      "Epoch 509/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0772 - accuracy: 0.5428 - val_loss: 1.0673 - val_accuracy: 0.5292\n",
      "Epoch 510/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0781 - accuracy: 0.5331 - val_loss: 1.1226 - val_accuracy: 0.4754\n",
      "Epoch 511/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0414 - accuracy: 0.5458 - val_loss: 1.0692 - val_accuracy: 0.5262\n",
      "Epoch 512/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0421 - accuracy: 0.5570 - val_loss: 1.1009 - val_accuracy: 0.4810\n",
      "Epoch 513/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0420 - accuracy: 0.5342 - val_loss: 1.2013 - val_accuracy: 0.4200\n",
      "Epoch 514/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0618 - accuracy: 0.5603 - val_loss: 1.1260 - val_accuracy: 0.4841\n",
      "Epoch 515/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0533 - accuracy: 0.5450 - val_loss: 1.1038 - val_accuracy: 0.4908\n",
      "Epoch 516/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0782 - accuracy: 0.5310 - val_loss: 1.0767 - val_accuracy: 0.5056\n",
      "Epoch 517/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0316 - accuracy: 0.5654 - val_loss: 1.1032 - val_accuracy: 0.5062\n",
      "Epoch 518/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0398 - accuracy: 0.5488 - val_loss: 1.1199 - val_accuracy: 0.4805\n",
      "Epoch 519/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0998 - accuracy: 0.5146 - val_loss: 1.1817 - val_accuracy: 0.4415\n",
      "Epoch 520/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0570 - accuracy: 0.5501 - val_loss: 1.1863 - val_accuracy: 0.4579\n",
      "Epoch 521/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0245 - accuracy: 0.5615 - val_loss: 1.0818 - val_accuracy: 0.5185\n",
      "Epoch 522/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0478 - accuracy: 0.5550 - val_loss: 1.1270 - val_accuracy: 0.5072\n",
      "Epoch 523/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0384 - accuracy: 0.5450 - val_loss: 1.1775 - val_accuracy: 0.4262\n",
      "Epoch 524/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0473 - accuracy: 0.5524 - val_loss: 1.1513 - val_accuracy: 0.4764\n",
      "Epoch 525/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0474 - accuracy: 0.5454 - val_loss: 1.1080 - val_accuracy: 0.4836\n",
      "Epoch 526/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0432 - accuracy: 0.5484 - val_loss: 1.1001 - val_accuracy: 0.4856\n",
      "Epoch 527/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0371 - accuracy: 0.5580 - val_loss: 1.1864 - val_accuracy: 0.4569\n",
      "Epoch 528/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.1065 - accuracy: 0.5227 - val_loss: 1.3431 - val_accuracy: 0.3533\n",
      "Epoch 529/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0660 - accuracy: 0.5429 - val_loss: 1.1378 - val_accuracy: 0.4764\n",
      "Epoch 530/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0714 - accuracy: 0.5402 - val_loss: 1.2199 - val_accuracy: 0.4497\n",
      "Epoch 531/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1058 - accuracy: 0.5239 - val_loss: 1.1121 - val_accuracy: 0.4882\n",
      "Epoch 532/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0322 - accuracy: 0.5591 - val_loss: 1.1146 - val_accuracy: 0.4944\n",
      "Epoch 533/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0526 - accuracy: 0.5464 - val_loss: 1.1807 - val_accuracy: 0.4585\n",
      "Epoch 534/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0840 - accuracy: 0.5296 - val_loss: 1.2441 - val_accuracy: 0.3764\n",
      "Epoch 535/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0675 - accuracy: 0.5473 - val_loss: 1.1815 - val_accuracy: 0.4282\n",
      "Epoch 536/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0811 - accuracy: 0.5246 - val_loss: 1.0918 - val_accuracy: 0.4928\n",
      "Epoch 537/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0537 - accuracy: 0.5447 - val_loss: 1.1549 - val_accuracy: 0.4569\n",
      "Epoch 538/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0640 - accuracy: 0.5348 - val_loss: 1.0787 - val_accuracy: 0.5205\n",
      "Epoch 539/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0687 - accuracy: 0.5455 - val_loss: 1.0961 - val_accuracy: 0.5092\n",
      "Epoch 540/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0305 - accuracy: 0.5373 - val_loss: 1.2371 - val_accuracy: 0.3867\n",
      "Epoch 541/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1040 - accuracy: 0.5227 - val_loss: 1.1992 - val_accuracy: 0.4564\n",
      "Epoch 542/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0369 - accuracy: 0.5506 - val_loss: 1.2185 - val_accuracy: 0.4195\n",
      "Epoch 543/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0634 - accuracy: 0.5463 - val_loss: 1.1002 - val_accuracy: 0.5097\n",
      "Epoch 544/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0420 - accuracy: 0.5454 - val_loss: 1.0935 - val_accuracy: 0.5174\n",
      "Epoch 545/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0514 - accuracy: 0.5415 - val_loss: 1.0907 - val_accuracy: 0.5056\n",
      "Epoch 546/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.5447 - val_loss: 1.1796 - val_accuracy: 0.4538\n",
      "Epoch 547/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0606 - accuracy: 0.5369 - val_loss: 1.1380 - val_accuracy: 0.4764\n",
      "Epoch 548/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0797 - accuracy: 0.5411 - val_loss: 1.1538 - val_accuracy: 0.4513\n",
      "Epoch 549/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0463 - accuracy: 0.5530 - val_loss: 1.1047 - val_accuracy: 0.4933\n",
      "Epoch 550/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0357 - accuracy: 0.5520 - val_loss: 1.1924 - val_accuracy: 0.4226\n",
      "Epoch 551/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0529 - accuracy: 0.5510 - val_loss: 1.1141 - val_accuracy: 0.5149\n",
      "Epoch 552/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0588 - accuracy: 0.5444 - val_loss: 1.1793 - val_accuracy: 0.4272\n",
      "Epoch 553/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0516 - accuracy: 0.5465 - val_loss: 1.0982 - val_accuracy: 0.5251\n",
      "Epoch 554/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0365 - accuracy: 0.5522 - val_loss: 1.1253 - val_accuracy: 0.4897\n",
      "Epoch 555/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0188 - accuracy: 0.5565 - val_loss: 1.0827 - val_accuracy: 0.5026\n",
      "Epoch 556/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0764 - accuracy: 0.5410 - val_loss: 1.0806 - val_accuracy: 0.5077\n",
      "Epoch 557/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0682 - accuracy: 0.5323 - val_loss: 1.3416 - val_accuracy: 0.3431\n",
      "Epoch 558/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1232 - accuracy: 0.5086 - val_loss: 1.0937 - val_accuracy: 0.5159\n",
      "Epoch 559/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0664 - accuracy: 0.5349 - val_loss: 1.0820 - val_accuracy: 0.4990\n",
      "Epoch 560/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0424 - accuracy: 0.5434 - val_loss: 1.1137 - val_accuracy: 0.5077\n",
      "Epoch 561/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0592 - accuracy: 0.5491 - val_loss: 1.0962 - val_accuracy: 0.4995\n",
      "Epoch 562/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0214 - accuracy: 0.5540 - val_loss: 1.2206 - val_accuracy: 0.4149\n",
      "Epoch 563/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0407 - accuracy: 0.5563 - val_loss: 1.0912 - val_accuracy: 0.4964\n",
      "Epoch 564/800\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0532 - accuracy: 0.5462 - val_loss: 1.0856 - val_accuracy: 0.5056\n",
      "Epoch 565/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0723 - accuracy: 0.5299 - val_loss: 1.1390 - val_accuracy: 0.4708\n",
      "Epoch 566/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0384 - accuracy: 0.5542 - val_loss: 1.1609 - val_accuracy: 0.4590\n",
      "Epoch 567/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0413 - accuracy: 0.5572 - val_loss: 1.1003 - val_accuracy: 0.5031\n",
      "Epoch 568/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0390 - accuracy: 0.5544 - val_loss: 1.1067 - val_accuracy: 0.5349\n",
      "Epoch 569/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0542 - accuracy: 0.5352 - val_loss: 1.1514 - val_accuracy: 0.4774\n",
      "Epoch 570/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0496 - accuracy: 0.5417 - val_loss: 1.0783 - val_accuracy: 0.5190\n",
      "Epoch 571/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0804 - accuracy: 0.5367 - val_loss: 1.2036 - val_accuracy: 0.4185\n",
      "Epoch 572/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0550 - accuracy: 0.5382 - val_loss: 1.0840 - val_accuracy: 0.5021\n",
      "Epoch 573/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0364 - accuracy: 0.5459 - val_loss: 1.1198 - val_accuracy: 0.4964\n",
      "Epoch 574/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0402 - accuracy: 0.5474 - val_loss: 1.1608 - val_accuracy: 0.4344\n",
      "Epoch 575/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0691 - accuracy: 0.5312 - val_loss: 1.2062 - val_accuracy: 0.4595\n",
      "Epoch 576/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0627 - accuracy: 0.5394 - val_loss: 1.0958 - val_accuracy: 0.5000\n",
      "Epoch 577/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0678 - accuracy: 0.5319 - val_loss: 1.0778 - val_accuracy: 0.5236\n",
      "Epoch 578/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0182 - accuracy: 0.5567 - val_loss: 1.0793 - val_accuracy: 0.4949\n",
      "Epoch 579/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0339 - accuracy: 0.5718 - val_loss: 1.1591 - val_accuracy: 0.4610\n",
      "Epoch 580/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0863 - accuracy: 0.5156 - val_loss: 1.1870 - val_accuracy: 0.4185\n",
      "Epoch 581/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0398 - accuracy: 0.5458 - val_loss: 1.2186 - val_accuracy: 0.3990\n",
      "Epoch 582/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0405 - accuracy: 0.5480 - val_loss: 1.1062 - val_accuracy: 0.4969\n",
      "Epoch 583/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0536 - accuracy: 0.5412 - val_loss: 1.1791 - val_accuracy: 0.4651\n",
      "Epoch 584/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0370 - accuracy: 0.5461 - val_loss: 1.1007 - val_accuracy: 0.4856\n",
      "Epoch 585/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.5446 - val_loss: 1.1018 - val_accuracy: 0.5015\n",
      "Epoch 586/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0185 - accuracy: 0.5591 - val_loss: 1.1801 - val_accuracy: 0.4497\n",
      "Epoch 587/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0580 - accuracy: 0.5435 - val_loss: 1.1303 - val_accuracy: 0.4692\n",
      "Epoch 588/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0686 - accuracy: 0.5517 - val_loss: 1.0836 - val_accuracy: 0.5313\n",
      "Epoch 589/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0472 - accuracy: 0.5501 - val_loss: 1.1550 - val_accuracy: 0.4682\n",
      "Epoch 590/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0209 - accuracy: 0.5568 - val_loss: 1.1334 - val_accuracy: 0.4672\n",
      "Epoch 591/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0328 - accuracy: 0.5593 - val_loss: 1.1568 - val_accuracy: 0.4841\n",
      "Epoch 592/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0888 - accuracy: 0.5189 - val_loss: 1.1306 - val_accuracy: 0.4938\n",
      "Epoch 593/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0390 - accuracy: 0.5436 - val_loss: 1.1524 - val_accuracy: 0.4687\n",
      "Epoch 594/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0374 - accuracy: 0.5555 - val_loss: 1.1375 - val_accuracy: 0.4667\n",
      "Epoch 595/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0437 - accuracy: 0.5293 - val_loss: 1.1307 - val_accuracy: 0.4549\n",
      "Epoch 596/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0435 - accuracy: 0.5575 - val_loss: 1.0867 - val_accuracy: 0.4954\n",
      "Epoch 597/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0514 - accuracy: 0.5541 - val_loss: 1.1217 - val_accuracy: 0.4938\n",
      "Epoch 598/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0314 - accuracy: 0.5626 - val_loss: 1.1190 - val_accuracy: 0.4759\n",
      "Epoch 599/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0653 - accuracy: 0.5317 - val_loss: 1.0748 - val_accuracy: 0.5118\n",
      "Epoch 600/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0468 - accuracy: 0.5563 - val_loss: 1.0858 - val_accuracy: 0.5000\n",
      "Epoch 601/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0350 - accuracy: 0.5472 - val_loss: 1.1211 - val_accuracy: 0.4985\n",
      "Epoch 602/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0558 - accuracy: 0.5365 - val_loss: 1.1731 - val_accuracy: 0.4492\n",
      "Epoch 603/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0513 - accuracy: 0.5420 - val_loss: 1.1212 - val_accuracy: 0.4851\n",
      "Epoch 604/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0727 - accuracy: 0.5439 - val_loss: 1.1123 - val_accuracy: 0.4923\n",
      "Epoch 605/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0374 - accuracy: 0.5612 - val_loss: 1.0675 - val_accuracy: 0.5246\n",
      "Epoch 606/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0595 - accuracy: 0.5341 - val_loss: 1.0929 - val_accuracy: 0.5262\n",
      "Epoch 607/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0624 - accuracy: 0.5324 - val_loss: 1.1801 - val_accuracy: 0.4482\n",
      "Epoch 608/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0573 - accuracy: 0.5450 - val_loss: 1.1672 - val_accuracy: 0.4410\n",
      "Epoch 609/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0827 - accuracy: 0.5272 - val_loss: 1.1039 - val_accuracy: 0.4790\n",
      "Epoch 610/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0294 - accuracy: 0.5629 - val_loss: 1.1099 - val_accuracy: 0.5005\n",
      "Epoch 611/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0408 - accuracy: 0.5431 - val_loss: 1.0947 - val_accuracy: 0.5128\n",
      "Epoch 612/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0410 - accuracy: 0.5514 - val_loss: 1.1174 - val_accuracy: 0.4831\n",
      "Epoch 613/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0527 - accuracy: 0.5464 - val_loss: 1.1193 - val_accuracy: 0.4979\n",
      "Epoch 614/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0422 - accuracy: 0.5503 - val_loss: 1.1266 - val_accuracy: 0.4764\n",
      "Epoch 615/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0417 - accuracy: 0.5515 - val_loss: 1.1186 - val_accuracy: 0.5133\n",
      "Epoch 616/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0096 - accuracy: 0.5699 - val_loss: 1.0757 - val_accuracy: 0.5308\n",
      "Epoch 617/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0598 - accuracy: 0.5459 - val_loss: 1.1180 - val_accuracy: 0.5097\n",
      "Epoch 618/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0478 - accuracy: 0.5391 - val_loss: 1.1442 - val_accuracy: 0.4964\n",
      "Epoch 619/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0439 - accuracy: 0.5420 - val_loss: 1.0979 - val_accuracy: 0.4938\n",
      "Epoch 620/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0433 - accuracy: 0.5476 - val_loss: 1.1323 - val_accuracy: 0.4564\n",
      "Epoch 621/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0211 - accuracy: 0.5698 - val_loss: 1.0898 - val_accuracy: 0.5169\n",
      "Epoch 622/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0658 - accuracy: 0.5429 - val_loss: 1.1674 - val_accuracy: 0.4646\n",
      "Epoch 623/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0902 - accuracy: 0.5310 - val_loss: 1.1159 - val_accuracy: 0.4682\n",
      "Epoch 624/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0406 - accuracy: 0.5566 - val_loss: 1.0663 - val_accuracy: 0.5349\n",
      "Epoch 625/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0594 - accuracy: 0.5462 - val_loss: 1.1803 - val_accuracy: 0.4887\n",
      "Epoch 626/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0532 - accuracy: 0.5415 - val_loss: 1.1612 - val_accuracy: 0.4472\n",
      "Epoch 627/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0587 - accuracy: 0.5377 - val_loss: 1.1463 - val_accuracy: 0.4528\n",
      "Epoch 628/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0212 - accuracy: 0.5618 - val_loss: 1.1176 - val_accuracy: 0.4785\n",
      "Epoch 629/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0211 - accuracy: 0.5579 - val_loss: 1.1682 - val_accuracy: 0.4421\n",
      "Epoch 630/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0557 - accuracy: 0.5437 - val_loss: 1.1142 - val_accuracy: 0.4821\n",
      "Epoch 631/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0153 - accuracy: 0.5688 - val_loss: 1.1630 - val_accuracy: 0.4528\n",
      "Epoch 632/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0353 - accuracy: 0.5531 - val_loss: 1.0739 - val_accuracy: 0.5292\n",
      "Epoch 633/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0586 - accuracy: 0.5499 - val_loss: 1.1515 - val_accuracy: 0.4482\n",
      "Epoch 634/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0524 - accuracy: 0.5419 - val_loss: 1.0956 - val_accuracy: 0.5010\n",
      "Epoch 635/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0299 - accuracy: 0.5406 - val_loss: 1.0846 - val_accuracy: 0.5200\n",
      "Epoch 636/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0412 - accuracy: 0.5595 - val_loss: 1.0878 - val_accuracy: 0.5097\n",
      "Epoch 637/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0438 - accuracy: 0.5478 - val_loss: 1.1099 - val_accuracy: 0.5144\n",
      "Epoch 638/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0420 - accuracy: 0.5398 - val_loss: 1.1667 - val_accuracy: 0.4574\n",
      "Epoch 639/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0361 - accuracy: 0.5462 - val_loss: 1.1283 - val_accuracy: 0.4697\n",
      "Epoch 640/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0389 - accuracy: 0.5443 - val_loss: 1.1775 - val_accuracy: 0.4549\n",
      "Epoch 641/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0328 - accuracy: 0.5592 - val_loss: 1.1156 - val_accuracy: 0.5036\n",
      "Epoch 642/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0539 - accuracy: 0.5427 - val_loss: 1.1245 - val_accuracy: 0.4754\n",
      "Epoch 643/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0661 - accuracy: 0.5367 - val_loss: 1.1243 - val_accuracy: 0.4867\n",
      "Epoch 644/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0323 - accuracy: 0.5490 - val_loss: 1.1791 - val_accuracy: 0.4349\n",
      "Epoch 645/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0387 - accuracy: 0.5455 - val_loss: 1.1155 - val_accuracy: 0.4764\n",
      "Epoch 646/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0309 - accuracy: 0.5671 - val_loss: 1.0769 - val_accuracy: 0.5236\n",
      "Epoch 647/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0238 - accuracy: 0.5629 - val_loss: 1.1839 - val_accuracy: 0.4369\n",
      "Epoch 648/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0560 - accuracy: 0.5523 - val_loss: 1.1356 - val_accuracy: 0.4918\n",
      "Epoch 649/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0385 - accuracy: 0.5428 - val_loss: 1.1137 - val_accuracy: 0.4872\n",
      "Epoch 650/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0416 - accuracy: 0.5588 - val_loss: 1.1736 - val_accuracy: 0.4251\n",
      "Epoch 651/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0380 - accuracy: 0.5471 - val_loss: 1.2258 - val_accuracy: 0.3821\n",
      "Epoch 652/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0290 - accuracy: 0.5606 - val_loss: 1.1067 - val_accuracy: 0.4887\n",
      "Epoch 653/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0244 - accuracy: 0.5582 - val_loss: 1.1353 - val_accuracy: 0.4779\n",
      "Epoch 654/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0487 - accuracy: 0.5433 - val_loss: 1.1016 - val_accuracy: 0.5026\n",
      "Epoch 655/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0533 - accuracy: 0.5458 - val_loss: 1.1091 - val_accuracy: 0.4949\n",
      "Epoch 656/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0814 - accuracy: 0.5318 - val_loss: 1.1326 - val_accuracy: 0.4667\n",
      "Epoch 657/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0324 - accuracy: 0.5522 - val_loss: 1.1093 - val_accuracy: 0.4774\n",
      "Epoch 658/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0240 - accuracy: 0.5582 - val_loss: 1.1100 - val_accuracy: 0.4754\n",
      "Epoch 659/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0655 - accuracy: 0.5417 - val_loss: 1.1424 - val_accuracy: 0.4738\n",
      "Epoch 660/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0386 - accuracy: 0.5531 - val_loss: 1.1187 - val_accuracy: 0.4708\n",
      "Epoch 661/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0522 - accuracy: 0.5396 - val_loss: 1.2692 - val_accuracy: 0.3759\n",
      "Epoch 662/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0705 - accuracy: 0.5215 - val_loss: 1.1019 - val_accuracy: 0.5144\n",
      "Epoch 663/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0265 - accuracy: 0.5560 - val_loss: 1.0714 - val_accuracy: 0.5103\n",
      "Epoch 664/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0577 - accuracy: 0.5525 - val_loss: 1.1120 - val_accuracy: 0.4872\n",
      "Epoch 665/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0297 - accuracy: 0.5515 - val_loss: 1.1384 - val_accuracy: 0.4831\n",
      "Epoch 666/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0548 - accuracy: 0.5472 - val_loss: 1.1866 - val_accuracy: 0.4338\n",
      "Epoch 667/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0579 - accuracy: 0.5420 - val_loss: 1.0755 - val_accuracy: 0.5056\n",
      "Epoch 668/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0466 - accuracy: 0.5603 - val_loss: 1.1549 - val_accuracy: 0.4303\n",
      "Epoch 669/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0612 - accuracy: 0.5375 - val_loss: 1.0923 - val_accuracy: 0.4974\n",
      "Epoch 670/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0358 - accuracy: 0.5536 - val_loss: 1.1186 - val_accuracy: 0.4713\n",
      "Epoch 671/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0334 - accuracy: 0.5489 - val_loss: 1.0938 - val_accuracy: 0.5072\n",
      "Epoch 672/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0291 - accuracy: 0.5551 - val_loss: 1.1245 - val_accuracy: 0.4682\n",
      "Epoch 673/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0444 - accuracy: 0.5406 - val_loss: 1.1265 - val_accuracy: 0.4708\n",
      "Epoch 674/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0631 - accuracy: 0.5398 - val_loss: 1.0882 - val_accuracy: 0.4969\n",
      "Epoch 675/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0756 - accuracy: 0.5300 - val_loss: 1.1338 - val_accuracy: 0.4636\n",
      "Epoch 676/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0499 - accuracy: 0.5430 - val_loss: 1.1203 - val_accuracy: 0.4831\n",
      "Epoch 677/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0460 - accuracy: 0.5542 - val_loss: 1.1592 - val_accuracy: 0.4323\n",
      "Epoch 678/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0358 - accuracy: 0.5394 - val_loss: 1.1345 - val_accuracy: 0.4692\n",
      "Epoch 679/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0587 - accuracy: 0.5416 - val_loss: 1.1068 - val_accuracy: 0.5021\n",
      "Epoch 680/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0560 - accuracy: 0.5354 - val_loss: 1.1368 - val_accuracy: 0.4677\n",
      "Epoch 681/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0441 - accuracy: 0.5391 - val_loss: 1.1514 - val_accuracy: 0.4667\n",
      "Epoch 682/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0494 - accuracy: 0.5445 - val_loss: 1.1203 - val_accuracy: 0.4810\n",
      "Epoch 683/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0413 - accuracy: 0.5477 - val_loss: 1.1144 - val_accuracy: 0.4928\n",
      "Epoch 684/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0337 - accuracy: 0.5479 - val_loss: 1.0846 - val_accuracy: 0.5062\n",
      "Epoch 685/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0389 - accuracy: 0.5437 - val_loss: 1.1594 - val_accuracy: 0.4415\n",
      "Epoch 686/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0280 - accuracy: 0.5493 - val_loss: 1.1642 - val_accuracy: 0.4436\n",
      "Epoch 687/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0333 - accuracy: 0.5649 - val_loss: 1.1399 - val_accuracy: 0.4574\n",
      "Epoch 688/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0367 - accuracy: 0.5483 - val_loss: 1.1450 - val_accuracy: 0.4621\n",
      "Epoch 689/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0575 - accuracy: 0.5421 - val_loss: 1.1104 - val_accuracy: 0.4805\n",
      "Epoch 690/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0209 - accuracy: 0.5662 - val_loss: 1.1103 - val_accuracy: 0.4805\n",
      "Epoch 691/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0580 - accuracy: 0.5654 - val_loss: 1.1229 - val_accuracy: 0.4800\n",
      "Epoch 692/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0325 - accuracy: 0.5455 - val_loss: 1.0796 - val_accuracy: 0.4959\n",
      "Epoch 693/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0424 - accuracy: 0.5524 - val_loss: 1.1013 - val_accuracy: 0.4908\n",
      "Epoch 694/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0302 - accuracy: 0.5533 - val_loss: 1.1853 - val_accuracy: 0.4210\n",
      "Epoch 695/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0117 - accuracy: 0.5662 - val_loss: 1.1060 - val_accuracy: 0.4969\n",
      "Epoch 696/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0449 - accuracy: 0.5540 - val_loss: 1.1028 - val_accuracy: 0.5010\n",
      "Epoch 697/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0364 - accuracy: 0.5537 - val_loss: 1.0992 - val_accuracy: 0.4964\n",
      "Epoch 698/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0337 - accuracy: 0.5407 - val_loss: 1.3362 - val_accuracy: 0.3821\n",
      "Epoch 699/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0602 - accuracy: 0.5326 - val_loss: 1.2213 - val_accuracy: 0.4062\n",
      "Epoch 700/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0738 - accuracy: 0.5382 - val_loss: 1.1938 - val_accuracy: 0.4574\n",
      "Epoch 701/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0497 - accuracy: 0.5564 - val_loss: 1.1048 - val_accuracy: 0.4913\n",
      "Epoch 702/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0430 - accuracy: 0.5581 - val_loss: 1.0790 - val_accuracy: 0.5103\n",
      "Epoch 703/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0586 - accuracy: 0.5428 - val_loss: 1.1012 - val_accuracy: 0.5010\n",
      "Epoch 704/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0380 - accuracy: 0.5463 - val_loss: 1.1355 - val_accuracy: 0.4472\n",
      "Epoch 705/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0395 - accuracy: 0.5599 - val_loss: 1.1036 - val_accuracy: 0.5010\n",
      "Epoch 706/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0490 - accuracy: 0.5470 - val_loss: 1.1540 - val_accuracy: 0.4621\n",
      "Epoch 707/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0256 - accuracy: 0.5612 - val_loss: 1.2543 - val_accuracy: 0.3938\n",
      "Epoch 708/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0303 - accuracy: 0.5482 - val_loss: 1.1147 - val_accuracy: 0.4928\n",
      "Epoch 709/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0225 - accuracy: 0.5548 - val_loss: 1.1047 - val_accuracy: 0.4979\n",
      "Epoch 710/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0605 - accuracy: 0.5375 - val_loss: 1.0847 - val_accuracy: 0.4995\n",
      "Epoch 711/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0447 - accuracy: 0.5475 - val_loss: 1.0947 - val_accuracy: 0.4969\n",
      "Epoch 712/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0402 - accuracy: 0.5494 - val_loss: 1.1244 - val_accuracy: 0.4979\n",
      "Epoch 713/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0604 - accuracy: 0.5434 - val_loss: 1.0863 - val_accuracy: 0.5005\n",
      "Epoch 714/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0313 - accuracy: 0.5641 - val_loss: 1.1411 - val_accuracy: 0.4862\n",
      "Epoch 715/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0159 - accuracy: 0.5544 - val_loss: 1.1151 - val_accuracy: 0.4877\n",
      "Epoch 716/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0656 - accuracy: 0.5427 - val_loss: 1.1026 - val_accuracy: 0.4897\n",
      "Epoch 717/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0331 - accuracy: 0.5461 - val_loss: 1.1239 - val_accuracy: 0.4708\n",
      "Epoch 718/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0582 - accuracy: 0.5447 - val_loss: 1.0712 - val_accuracy: 0.5333\n",
      "Epoch 719/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.5724 - val_loss: 1.1096 - val_accuracy: 0.4933\n",
      "Epoch 720/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0320 - accuracy: 0.5510 - val_loss: 1.1238 - val_accuracy: 0.4805\n",
      "Epoch 721/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0295 - accuracy: 0.5530 - val_loss: 1.2002 - val_accuracy: 0.4441\n",
      "Epoch 722/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0464 - accuracy: 0.5452 - val_loss: 1.0821 - val_accuracy: 0.5185\n",
      "Epoch 723/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1024 - accuracy: 0.5246 - val_loss: 1.1421 - val_accuracy: 0.4677\n",
      "Epoch 724/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0690 - accuracy: 0.5273 - val_loss: 1.1645 - val_accuracy: 0.4272\n",
      "Epoch 725/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0453 - accuracy: 0.5499 - val_loss: 1.1536 - val_accuracy: 0.4508\n",
      "Epoch 726/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0598 - accuracy: 0.5495 - val_loss: 1.1208 - val_accuracy: 0.4662\n",
      "Epoch 727/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.5512 - val_loss: 1.1343 - val_accuracy: 0.4733\n",
      "Epoch 728/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0244 - accuracy: 0.5546 - val_loss: 1.1000 - val_accuracy: 0.4954\n",
      "Epoch 729/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0416 - accuracy: 0.5459 - val_loss: 1.1538 - val_accuracy: 0.4728\n",
      "Epoch 730/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0639 - accuracy: 0.5288 - val_loss: 1.1147 - val_accuracy: 0.4995\n",
      "Epoch 731/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0432 - accuracy: 0.5517 - val_loss: 1.1347 - val_accuracy: 0.4856\n",
      "Epoch 732/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0217 - accuracy: 0.5605 - val_loss: 1.0746 - val_accuracy: 0.5144\n",
      "Epoch 733/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0328 - accuracy: 0.5529 - val_loss: 1.1011 - val_accuracy: 0.5036\n",
      "Epoch 734/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0548 - accuracy: 0.5355 - val_loss: 1.0637 - val_accuracy: 0.5128\n",
      "Epoch 735/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0261 - accuracy: 0.5688 - val_loss: 1.1376 - val_accuracy: 0.4662\n",
      "Epoch 736/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0407 - accuracy: 0.5553 - val_loss: 1.1319 - val_accuracy: 0.4723\n",
      "Epoch 737/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0177 - accuracy: 0.5755 - val_loss: 1.1185 - val_accuracy: 0.4682\n",
      "Epoch 738/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0588 - accuracy: 0.5417 - val_loss: 1.0905 - val_accuracy: 0.4969\n",
      "Epoch 739/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0338 - accuracy: 0.5579 - val_loss: 1.1197 - val_accuracy: 0.5021\n",
      "Epoch 740/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0497 - accuracy: 0.5310 - val_loss: 1.1331 - val_accuracy: 0.4708\n",
      "Epoch 741/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0510 - accuracy: 0.5416 - val_loss: 1.0875 - val_accuracy: 0.4990\n",
      "Epoch 742/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0367 - accuracy: 0.5458 - val_loss: 1.1758 - val_accuracy: 0.4554\n",
      "Epoch 743/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0531 - accuracy: 0.5368 - val_loss: 1.1051 - val_accuracy: 0.4954\n",
      "Epoch 744/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0329 - accuracy: 0.5596 - val_loss: 1.1367 - val_accuracy: 0.4779\n",
      "Epoch 745/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0503 - accuracy: 0.5358 - val_loss: 1.1000 - val_accuracy: 0.5041\n",
      "Epoch 746/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0629 - accuracy: 0.5361 - val_loss: 1.1682 - val_accuracy: 0.4518\n",
      "Epoch 747/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0226 - accuracy: 0.5521 - val_loss: 1.1202 - val_accuracy: 0.4897\n",
      "Epoch 748/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0248 - accuracy: 0.5612 - val_loss: 1.0935 - val_accuracy: 0.5056\n",
      "Epoch 749/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0551 - accuracy: 0.5451 - val_loss: 1.0996 - val_accuracy: 0.4815\n",
      "Epoch 750/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0603 - accuracy: 0.5437 - val_loss: 1.1958 - val_accuracy: 0.4544\n",
      "Epoch 751/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0630 - accuracy: 0.5355 - val_loss: 1.1158 - val_accuracy: 0.4790\n",
      "Epoch 752/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0422 - accuracy: 0.5509 - val_loss: 1.1223 - val_accuracy: 0.5056\n",
      "Epoch 753/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0311 - accuracy: 0.5535 - val_loss: 1.1098 - val_accuracy: 0.5118\n",
      "Epoch 754/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0476 - accuracy: 0.5447 - val_loss: 1.1725 - val_accuracy: 0.4251\n",
      "Epoch 755/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0722 - accuracy: 0.5358 - val_loss: 1.1082 - val_accuracy: 0.4749\n",
      "Epoch 756/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0572 - accuracy: 0.5406 - val_loss: 1.1262 - val_accuracy: 0.4856\n",
      "Epoch 757/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0470 - accuracy: 0.5498 - val_loss: 1.1240 - val_accuracy: 0.4923\n",
      "Epoch 758/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0348 - accuracy: 0.5395 - val_loss: 1.1339 - val_accuracy: 0.4800\n",
      "Epoch 759/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0432 - accuracy: 0.5349 - val_loss: 1.0930 - val_accuracy: 0.4821\n",
      "Epoch 760/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0326 - accuracy: 0.5513 - val_loss: 1.0852 - val_accuracy: 0.5200\n",
      "Epoch 761/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0262 - accuracy: 0.5573 - val_loss: 1.1436 - val_accuracy: 0.4851\n",
      "Epoch 762/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0112 - accuracy: 0.5652 - val_loss: 1.2011 - val_accuracy: 0.4446\n",
      "Epoch 763/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0405 - accuracy: 0.5487 - val_loss: 1.1431 - val_accuracy: 0.4933\n",
      "Epoch 764/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0658 - accuracy: 0.5427 - val_loss: 1.1323 - val_accuracy: 0.4990\n",
      "Epoch 765/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0581 - accuracy: 0.5372 - val_loss: 1.0960 - val_accuracy: 0.5046\n",
      "Epoch 766/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0467 - accuracy: 0.5532 - val_loss: 1.1189 - val_accuracy: 0.5026\n",
      "Epoch 767/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0317 - accuracy: 0.5564 - val_loss: 1.0948 - val_accuracy: 0.5077\n",
      "Epoch 768/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0254 - accuracy: 0.5556 - val_loss: 1.1459 - val_accuracy: 0.4846\n",
      "Epoch 769/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0425 - accuracy: 0.5589 - val_loss: 1.0990 - val_accuracy: 0.5036\n",
      "Epoch 770/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0302 - accuracy: 0.5616 - val_loss: 1.0879 - val_accuracy: 0.5138\n",
      "Epoch 771/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0393 - accuracy: 0.5486 - val_loss: 1.0854 - val_accuracy: 0.5051\n",
      "Epoch 772/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0581 - accuracy: 0.5415 - val_loss: 1.1079 - val_accuracy: 0.4810\n",
      "Epoch 773/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0377 - accuracy: 0.5378 - val_loss: 1.1354 - val_accuracy: 0.4590\n",
      "Epoch 774/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0599 - accuracy: 0.5358 - val_loss: 1.0892 - val_accuracy: 0.4944\n",
      "Epoch 775/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0494 - accuracy: 0.5349 - val_loss: 1.1366 - val_accuracy: 0.4723\n",
      "Epoch 776/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0380 - accuracy: 0.5438 - val_loss: 1.1563 - val_accuracy: 0.4605\n",
      "Epoch 777/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0775 - accuracy: 0.5371 - val_loss: 1.0985 - val_accuracy: 0.5051\n",
      "Epoch 778/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0430 - accuracy: 0.5472 - val_loss: 1.0921 - val_accuracy: 0.5113\n",
      "Epoch 779/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0572 - accuracy: 0.5467 - val_loss: 1.1386 - val_accuracy: 0.4687\n",
      "Epoch 780/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0263 - accuracy: 0.5407 - val_loss: 1.0988 - val_accuracy: 0.4856\n",
      "Epoch 781/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0364 - accuracy: 0.5642 - val_loss: 1.0875 - val_accuracy: 0.5092\n",
      "Epoch 782/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0523 - accuracy: 0.5478 - val_loss: 1.0994 - val_accuracy: 0.5092\n",
      "Epoch 783/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0275 - accuracy: 0.5614 - val_loss: 1.1021 - val_accuracy: 0.5031\n",
      "Epoch 784/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0525 - accuracy: 0.5481 - val_loss: 1.1347 - val_accuracy: 0.4713\n",
      "Epoch 785/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0163 - accuracy: 0.5589 - val_loss: 1.0867 - val_accuracy: 0.5077\n",
      "Epoch 786/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0444 - accuracy: 0.5595 - val_loss: 1.1614 - val_accuracy: 0.4626\n",
      "Epoch 787/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0580 - accuracy: 0.5354 - val_loss: 1.1306 - val_accuracy: 0.4908\n",
      "Epoch 788/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0434 - accuracy: 0.5384 - val_loss: 1.0998 - val_accuracy: 0.4903\n",
      "Epoch 789/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0576 - accuracy: 0.5323 - val_loss: 1.1802 - val_accuracy: 0.4528\n",
      "Epoch 790/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0375 - accuracy: 0.5470 - val_loss: 1.1076 - val_accuracy: 0.4954\n",
      "Epoch 791/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0424 - accuracy: 0.5494 - val_loss: 1.1895 - val_accuracy: 0.4482\n",
      "Epoch 792/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0404 - accuracy: 0.5543 - val_loss: 1.0728 - val_accuracy: 0.5159\n",
      "Epoch 793/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0386 - accuracy: 0.5508 - val_loss: 1.0810 - val_accuracy: 0.5021\n",
      "Epoch 794/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0399 - accuracy: 0.5508 - val_loss: 1.0748 - val_accuracy: 0.5144\n",
      "Epoch 795/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0187 - accuracy: 0.5607 - val_loss: 1.1224 - val_accuracy: 0.4718\n",
      "Epoch 796/800\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0327 - accuracy: 0.5545 - val_loss: 1.1065 - val_accuracy: 0.4892\n",
      "Epoch 797/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0221 - accuracy: 0.5608 - val_loss: 1.0850 - val_accuracy: 0.5021\n",
      "Epoch 798/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0260 - accuracy: 0.5620 - val_loss: 1.1160 - val_accuracy: 0.4867\n",
      "Epoch 799/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0452 - accuracy: 0.5536 - val_loss: 1.0678 - val_accuracy: 0.5159\n",
      "Epoch 800/800\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 1.0349 - accuracy: 0.5494 - val_loss: 1.1154 - val_accuracy: 0.4928\n"
     ]
    }
   ],
   "source": [
    "model_all_2 = keras.models.Sequential()\n",
    "model_all_2.add(keras.layers.Dense(units = 32,input_dim = 11,activation = 'relu'))\n",
    "model_all_2.add(keras.layers.Dense(units = 11,activation = 'softmax'))\n",
    "\n",
    "model_all_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_all_2.summary()\n",
    "\n",
    "\n",
    "hist_2 = model_all_2.fit(X_train,Y_train,epochs=800,batch_size=64,validation_data = (X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "acc_ax = ax1.twinx()\n",
    "\n",
    "ax1.plot(hist_2.history['loss'], 'y', label='train loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "\n",
    "\n",
    "ax2.plot(hist_2.history['val_loss'], 'r', label='val loss')\n",
    "ax2.set_ylabel('val_loss')\n",
    "\n",
    "\n",
    "ax3.plot(hist_2.history['accuracy'], 'b', label='accuracy')\n",
    "ax3.set_ylabel('accuray')\n",
    "\n",
    "ax4.plot(hist_2.history['val_accuracy'], 'g', label='val_accuracy')\n",
    "ax4.set_ylabel('val_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 - 0s - loss: 1.1154 - accuracy: 0.4928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1154253482818604, 0.49282050132751465]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_2.evaluate(X_test,Y_test,verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_82 (Dense)             (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 11)                231       \n",
      "=================================================================\n",
      "Total params: 3,819\n",
      "Trainable params: 3,779\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "72/72 [==============================] - 1s 4ms/step - loss: 2.4430 - accuracy: 0.1228 - val_loss: 2.1754 - val_accuracy: 0.0272\n",
      "Epoch 2/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 2.0338 - accuracy: 0.3508 - val_loss: 1.8656 - val_accuracy: 0.2733\n",
      "Epoch 3/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.6769 - accuracy: 0.4238 - val_loss: 1.6643 - val_accuracy: 0.4995\n",
      "Epoch 4/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.4351 - accuracy: 0.4537 - val_loss: 1.6014 - val_accuracy: 0.3605\n",
      "Epoch 5/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.3771 - accuracy: 0.4202 - val_loss: 1.5008 - val_accuracy: 0.3718\n",
      "Epoch 6/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2650 - accuracy: 0.4840 - val_loss: 1.3282 - val_accuracy: 0.3851\n",
      "Epoch 7/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.2115 - accuracy: 0.5003 - val_loss: 1.2359 - val_accuracy: 0.4656\n",
      "Epoch 8/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1790 - accuracy: 0.4968 - val_loss: 1.1732 - val_accuracy: 0.5108\n",
      "Epoch 9/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1867 - accuracy: 0.5055 - val_loss: 1.5010 - val_accuracy: 0.2564\n",
      "Epoch 10/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1843 - accuracy: 0.4928 - val_loss: 1.1777 - val_accuracy: 0.4815\n",
      "Epoch 11/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1528 - accuracy: 0.5208 - val_loss: 1.4175 - val_accuracy: 0.3159\n",
      "Epoch 12/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1361 - accuracy: 0.5154 - val_loss: 1.1250 - val_accuracy: 0.5333\n",
      "Epoch 13/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1580 - accuracy: 0.5122 - val_loss: 12.7184 - val_accuracy: 0.0241\n",
      "Epoch 14/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1492 - accuracy: 0.5088 - val_loss: 1.8839 - val_accuracy: 0.1574\n",
      "Epoch 15/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0849 - accuracy: 0.5350 - val_loss: 1.5462 - val_accuracy: 0.3600\n",
      "Epoch 16/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1622 - accuracy: 0.5168 - val_loss: 1.7242 - val_accuracy: 0.2441\n",
      "Epoch 17/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1750 - accuracy: 0.4954 - val_loss: 1.1930 - val_accuracy: 0.4267\n",
      "Epoch 18/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1471 - accuracy: 0.5315 - val_loss: 1.3923 - val_accuracy: 0.3077\n",
      "Epoch 19/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1128 - accuracy: 0.5299 - val_loss: 1.7199 - val_accuracy: 0.2421\n",
      "Epoch 20/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1020 - accuracy: 0.5354 - val_loss: 1.1189 - val_accuracy: 0.5287\n",
      "Epoch 21/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1293 - accuracy: 0.5208 - val_loss: 1.1025 - val_accuracy: 0.5318\n",
      "Epoch 22/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1111 - accuracy: 0.5383 - val_loss: 1.1597 - val_accuracy: 0.4882\n",
      "Epoch 23/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0727 - accuracy: 0.5332 - val_loss: 1.1530 - val_accuracy: 0.4626\n",
      "Epoch 24/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0942 - accuracy: 0.5299 - val_loss: 1.3036 - val_accuracy: 0.3554\n",
      "Epoch 25/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0932 - accuracy: 0.5356 - val_loss: 1.1482 - val_accuracy: 0.5072\n",
      "Epoch 26/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0766 - accuracy: 0.5394 - val_loss: 1.2069 - val_accuracy: 0.4651\n",
      "Epoch 27/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0817 - accuracy: 0.5329 - val_loss: 1.4229 - val_accuracy: 0.4164\n",
      "Epoch 28/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1315 - accuracy: 0.5080 - val_loss: 1.1626 - val_accuracy: 0.5195\n",
      "Epoch 29/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0896 - accuracy: 0.5422 - val_loss: 1.0735 - val_accuracy: 0.5415\n",
      "Epoch 30/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0842 - accuracy: 0.5504 - val_loss: 1.1983 - val_accuracy: 0.4851\n",
      "Epoch 31/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0734 - accuracy: 0.5468 - val_loss: 1.0743 - val_accuracy: 0.5292\n",
      "Epoch 32/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1028 - accuracy: 0.5319 - val_loss: 1.1153 - val_accuracy: 0.4892\n",
      "Epoch 33/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0795 - accuracy: 0.5389 - val_loss: 1.0892 - val_accuracy: 0.5241\n",
      "Epoch 34/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0731 - accuracy: 0.5433 - val_loss: 1.3551 - val_accuracy: 0.4051\n",
      "Epoch 35/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0809 - accuracy: 0.5368 - val_loss: 1.4750 - val_accuracy: 0.3682\n",
      "Epoch 36/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1865 - accuracy: 0.4843 - val_loss: 1.1544 - val_accuracy: 0.4718\n",
      "Epoch 37/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0654 - accuracy: 0.5361 - val_loss: 1.0875 - val_accuracy: 0.5154\n",
      "Epoch 38/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0981 - accuracy: 0.5187 - val_loss: 1.2234 - val_accuracy: 0.5159\n",
      "Epoch 39/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0702 - accuracy: 0.5361 - val_loss: 1.0531 - val_accuracy: 0.5426\n",
      "Epoch 40/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0788 - accuracy: 0.5351 - val_loss: 1.2337 - val_accuracy: 0.4149\n",
      "Epoch 41/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0401 - accuracy: 0.5571 - val_loss: 1.0662 - val_accuracy: 0.5385\n",
      "Epoch 42/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0698 - accuracy: 0.5426 - val_loss: 1.0675 - val_accuracy: 0.5395\n",
      "Epoch 43/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0633 - accuracy: 0.5522 - val_loss: 1.0849 - val_accuracy: 0.5144\n",
      "Epoch 44/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0504 - accuracy: 0.5426 - val_loss: 1.0514 - val_accuracy: 0.5436\n",
      "Epoch 45/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0614 - accuracy: 0.5383 - val_loss: 1.0723 - val_accuracy: 0.5379\n",
      "Epoch 46/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0464 - accuracy: 0.5502 - val_loss: 1.0909 - val_accuracy: 0.5067\n",
      "Epoch 47/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0794 - accuracy: 0.5366 - val_loss: 1.0923 - val_accuracy: 0.5015\n",
      "Epoch 48/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0499 - accuracy: 0.5505 - val_loss: 1.1023 - val_accuracy: 0.4995\n",
      "Epoch 49/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0459 - accuracy: 0.5494 - val_loss: 1.8127 - val_accuracy: 0.2585\n",
      "Epoch 50/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0566 - accuracy: 0.5532 - val_loss: 1.1394 - val_accuracy: 0.4841\n",
      "Epoch 51/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0509 - accuracy: 0.5499 - val_loss: 1.0653 - val_accuracy: 0.5241\n",
      "Epoch 52/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0667 - accuracy: 0.5340 - val_loss: 1.1008 - val_accuracy: 0.5056\n",
      "Epoch 53/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0827 - accuracy: 0.5421 - val_loss: 1.4671 - val_accuracy: 0.3256\n",
      "Epoch 54/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0706 - accuracy: 0.5426 - val_loss: 1.1301 - val_accuracy: 0.4672\n",
      "Epoch 55/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0595 - accuracy: 0.5531 - val_loss: 1.0737 - val_accuracy: 0.5103\n",
      "Epoch 56/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0424 - accuracy: 0.5532 - val_loss: 1.2306 - val_accuracy: 0.4549\n",
      "Epoch 57/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0660 - accuracy: 0.5457 - val_loss: 1.1187 - val_accuracy: 0.4949\n",
      "Epoch 58/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0642 - accuracy: 0.5474 - val_loss: 1.3631 - val_accuracy: 0.3744\n",
      "Epoch 59/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0459 - accuracy: 0.5529 - val_loss: 1.1285 - val_accuracy: 0.4944\n",
      "Epoch 60/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0519 - accuracy: 0.5446 - val_loss: 1.0961 - val_accuracy: 0.5456\n",
      "Epoch 61/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0526 - accuracy: 0.5467 - val_loss: 1.2588 - val_accuracy: 0.3949\n",
      "Epoch 62/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0661 - accuracy: 0.5416 - val_loss: 1.4992 - val_accuracy: 0.3472\n",
      "Epoch 63/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0373 - accuracy: 0.5601 - val_loss: 1.0800 - val_accuracy: 0.5128\n",
      "Epoch 64/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0372 - accuracy: 0.5509 - val_loss: 1.1190 - val_accuracy: 0.5097\n",
      "Epoch 65/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0327 - accuracy: 0.5413 - val_loss: 1.9341 - val_accuracy: 0.2631\n",
      "Epoch 66/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0743 - accuracy: 0.5322 - val_loss: 1.7536 - val_accuracy: 0.2713\n",
      "Epoch 67/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0654 - accuracy: 0.5414 - val_loss: 1.2625 - val_accuracy: 0.4195\n",
      "Epoch 68/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0612 - accuracy: 0.5551 - val_loss: 1.1716 - val_accuracy: 0.4882\n",
      "Epoch 69/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0528 - accuracy: 0.5434 - val_loss: 1.0791 - val_accuracy: 0.5154\n",
      "Epoch 70/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0737 - accuracy: 0.5376 - val_loss: 1.0776 - val_accuracy: 0.5246\n",
      "Epoch 71/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0428 - accuracy: 0.5551 - val_loss: 1.2913 - val_accuracy: 0.3995\n",
      "Epoch 72/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0536 - accuracy: 0.5428 - val_loss: 1.2081 - val_accuracy: 0.4610\n",
      "Epoch 73/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0478 - accuracy: 0.5454 - val_loss: 1.1753 - val_accuracy: 0.4908\n",
      "Epoch 74/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0889 - accuracy: 0.5371 - val_loss: 1.2294 - val_accuracy: 0.4462\n",
      "Epoch 75/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0524 - accuracy: 0.5451 - val_loss: 1.0862 - val_accuracy: 0.5067\n",
      "Epoch 76/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0784 - accuracy: 0.5375 - val_loss: 1.3950 - val_accuracy: 0.4431\n",
      "Epoch 77/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1108 - accuracy: 0.5207 - val_loss: 1.1676 - val_accuracy: 0.4651\n",
      "Epoch 78/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0717 - accuracy: 0.5337 - val_loss: 1.1096 - val_accuracy: 0.4959\n",
      "Epoch 79/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0627 - accuracy: 0.5515 - val_loss: 1.2000 - val_accuracy: 0.5005\n",
      "Epoch 80/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0596 - accuracy: 0.5434 - val_loss: 1.7590 - val_accuracy: 0.3062\n",
      "Epoch 81/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1284 - accuracy: 0.5021 - val_loss: 1.2023 - val_accuracy: 0.4682\n",
      "Epoch 82/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0442 - accuracy: 0.5651 - val_loss: 1.1478 - val_accuracy: 0.4918\n",
      "Epoch 83/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0790 - accuracy: 0.5244 - val_loss: 1.1331 - val_accuracy: 0.4826\n",
      "Epoch 84/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0581 - accuracy: 0.5381 - val_loss: 1.0540 - val_accuracy: 0.5538\n",
      "Epoch 85/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0238 - accuracy: 0.5615 - val_loss: 1.3621 - val_accuracy: 0.3821\n",
      "Epoch 86/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0596 - accuracy: 0.5423 - val_loss: 1.0853 - val_accuracy: 0.5128\n",
      "Epoch 87/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0616 - accuracy: 0.5576 - val_loss: 1.2289 - val_accuracy: 0.4636\n",
      "Epoch 88/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0558 - accuracy: 0.5409 - val_loss: 1.0527 - val_accuracy: 0.5518\n",
      "Epoch 89/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0219 - accuracy: 0.5649 - val_loss: 1.2380 - val_accuracy: 0.3944\n",
      "Epoch 90/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0672 - accuracy: 0.5413 - val_loss: 1.2585 - val_accuracy: 0.3974\n",
      "Epoch 91/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0512 - accuracy: 0.5567 - val_loss: 1.3837 - val_accuracy: 0.3733\n",
      "Epoch 92/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0932 - accuracy: 0.5277 - val_loss: 1.1542 - val_accuracy: 0.4467\n",
      "Epoch 93/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0431 - accuracy: 0.5453 - val_loss: 1.0792 - val_accuracy: 0.5410\n",
      "Epoch 94/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0573 - accuracy: 0.5531 - val_loss: 1.0684 - val_accuracy: 0.5123\n",
      "Epoch 95/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0678 - accuracy: 0.5393 - val_loss: 1.0665 - val_accuracy: 0.5277\n",
      "Epoch 96/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0378 - accuracy: 0.5646 - val_loss: 1.1297 - val_accuracy: 0.5051\n",
      "Epoch 97/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0408 - accuracy: 0.5542 - val_loss: 1.0613 - val_accuracy: 0.5251\n",
      "Epoch 98/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0385 - accuracy: 0.5577 - val_loss: 1.2682 - val_accuracy: 0.3923\n",
      "Epoch 99/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0404 - accuracy: 0.5656 - val_loss: 1.3810 - val_accuracy: 0.3697\n",
      "Epoch 100/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0441 - accuracy: 0.5455 - val_loss: 1.0555 - val_accuracy: 0.5313\n",
      "Epoch 101/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0303 - accuracy: 0.5566 - val_loss: 1.0673 - val_accuracy: 0.5354\n",
      "Epoch 102/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0391 - accuracy: 0.5614 - val_loss: 1.0595 - val_accuracy: 0.5421\n",
      "Epoch 103/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0330 - accuracy: 0.5559 - val_loss: 1.0912 - val_accuracy: 0.5103\n",
      "Epoch 104/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0387 - accuracy: 0.5515 - val_loss: 1.1189 - val_accuracy: 0.5426\n",
      "Epoch 105/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0349 - accuracy: 0.5649 - val_loss: 1.1824 - val_accuracy: 0.4426\n",
      "Epoch 106/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0412 - accuracy: 0.5702 - val_loss: 1.1584 - val_accuracy: 0.5031\n",
      "Epoch 107/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0204 - accuracy: 0.5783 - val_loss: 1.1476 - val_accuracy: 0.4749\n",
      "Epoch 108/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0252 - accuracy: 0.5473 - val_loss: 1.1040 - val_accuracy: 0.5123\n",
      "Epoch 109/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0250 - accuracy: 0.5644 - val_loss: 1.1885 - val_accuracy: 0.4667\n",
      "Epoch 110/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0525 - accuracy: 0.5525 - val_loss: 1.1627 - val_accuracy: 0.4913\n",
      "Epoch 111/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0618 - accuracy: 0.5488 - val_loss: 1.2159 - val_accuracy: 0.4431\n",
      "Epoch 112/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0409 - accuracy: 0.5639 - val_loss: 1.1411 - val_accuracy: 0.4862\n",
      "Epoch 113/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0575 - accuracy: 0.5424 - val_loss: 1.0788 - val_accuracy: 0.5205\n",
      "Epoch 114/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0382 - accuracy: 0.5462 - val_loss: 1.1111 - val_accuracy: 0.5000\n",
      "Epoch 115/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0466 - accuracy: 0.5555 - val_loss: 1.0858 - val_accuracy: 0.5241\n",
      "Epoch 116/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0026 - accuracy: 0.5676 - val_loss: 1.3662 - val_accuracy: 0.3918\n",
      "Epoch 117/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0326 - accuracy: 0.5535 - val_loss: 1.0974 - val_accuracy: 0.4969\n",
      "Epoch 118/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0453 - accuracy: 0.5491 - val_loss: 1.0936 - val_accuracy: 0.5374\n",
      "Epoch 119/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0780 - accuracy: 0.5346 - val_loss: 1.0726 - val_accuracy: 0.5133\n",
      "Epoch 120/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0422 - accuracy: 0.5553 - val_loss: 1.2670 - val_accuracy: 0.3882\n",
      "Epoch 121/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0456 - accuracy: 0.5525 - val_loss: 1.1844 - val_accuracy: 0.4805\n",
      "Epoch 122/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0573 - accuracy: 0.5591 - val_loss: 1.1468 - val_accuracy: 0.4723\n",
      "Epoch 123/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0315 - accuracy: 0.5552 - val_loss: 1.0753 - val_accuracy: 0.5087\n",
      "Epoch 124/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0438 - accuracy: 0.5615 - val_loss: 1.4941 - val_accuracy: 0.3267\n",
      "Epoch 125/1000\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 1.0444 - accuracy: 0.5506 - val_loss: 1.0564 - val_accuracy: 0.5426\n",
      "Epoch 126/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0297 - accuracy: 0.5712 - val_loss: 1.0657 - val_accuracy: 0.5318\n",
      "Epoch 127/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0380 - accuracy: 0.5681 - val_loss: 1.3005 - val_accuracy: 0.3800\n",
      "Epoch 128/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0255 - accuracy: 0.5612 - val_loss: 1.1231 - val_accuracy: 0.5010\n",
      "Epoch 129/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0525 - accuracy: 0.5602 - val_loss: 1.2685 - val_accuracy: 0.4026\n",
      "Epoch 130/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0399 - accuracy: 0.5545 - val_loss: 1.1186 - val_accuracy: 0.5205\n",
      "Epoch 131/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0476 - accuracy: 0.5563 - val_loss: 1.4118 - val_accuracy: 0.3595\n",
      "Epoch 132/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0231 - accuracy: 0.5672 - val_loss: 1.1239 - val_accuracy: 0.4949\n",
      "Epoch 133/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0463 - accuracy: 0.5514 - val_loss: 1.3837 - val_accuracy: 0.3554\n",
      "Epoch 134/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0222 - accuracy: 0.5570 - val_loss: 1.2467 - val_accuracy: 0.4297\n",
      "Epoch 135/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0351 - accuracy: 0.5547 - val_loss: 1.1356 - val_accuracy: 0.4744\n",
      "Epoch 136/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0462 - accuracy: 0.5661 - val_loss: 1.1303 - val_accuracy: 0.5108\n",
      "Epoch 137/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0407 - accuracy: 0.5580 - val_loss: 1.0779 - val_accuracy: 0.5036\n",
      "Epoch 138/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0262 - accuracy: 0.5596 - val_loss: 1.4293 - val_accuracy: 0.3590\n",
      "Epoch 139/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0425 - accuracy: 0.5512 - val_loss: 1.0749 - val_accuracy: 0.5169\n",
      "Epoch 140/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0205 - accuracy: 0.5699 - val_loss: 1.6161 - val_accuracy: 0.3133\n",
      "Epoch 141/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0419 - accuracy: 0.5535 - val_loss: 1.0958 - val_accuracy: 0.5072\n",
      "Epoch 142/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0485 - accuracy: 0.5611 - val_loss: 1.0729 - val_accuracy: 0.5087\n",
      "Epoch 143/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0452 - accuracy: 0.5615 - val_loss: 1.1136 - val_accuracy: 0.4836\n",
      "Epoch 144/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0641 - accuracy: 0.5547 - val_loss: 1.2321 - val_accuracy: 0.4297\n",
      "Epoch 145/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0213 - accuracy: 0.5620 - val_loss: 1.1057 - val_accuracy: 0.5010\n",
      "Epoch 146/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0323 - accuracy: 0.5584 - val_loss: 1.0709 - val_accuracy: 0.5200\n",
      "Epoch 147/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0201 - accuracy: 0.5660 - val_loss: 1.1383 - val_accuracy: 0.5390\n",
      "Epoch 148/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0411 - accuracy: 0.5520 - val_loss: 1.1295 - val_accuracy: 0.4933\n",
      "Epoch 149/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0064 - accuracy: 0.5702 - val_loss: 1.3142 - val_accuracy: 0.3851\n",
      "Epoch 150/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0741 - accuracy: 0.5190 - val_loss: 1.1183 - val_accuracy: 0.4887\n",
      "Epoch 151/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0471 - accuracy: 0.5572 - val_loss: 1.2798 - val_accuracy: 0.3903\n",
      "Epoch 152/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0126 - accuracy: 0.5568 - val_loss: 1.0567 - val_accuracy: 0.5451\n",
      "Epoch 153/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0232 - accuracy: 0.5709 - val_loss: 1.3676 - val_accuracy: 0.4256\n",
      "Epoch 154/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0855 - accuracy: 0.5350 - val_loss: 1.2764 - val_accuracy: 0.3990\n",
      "Epoch 155/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0548 - accuracy: 0.5431 - val_loss: 1.1368 - val_accuracy: 0.4800\n",
      "Epoch 156/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0446 - accuracy: 0.5655 - val_loss: 1.5747 - val_accuracy: 0.3969\n",
      "Epoch 157/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.3475 - accuracy: 0.4562 - val_loss: 2.3963 - val_accuracy: 0.1790\n",
      "Epoch 158/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0721 - accuracy: 0.5454 - val_loss: 1.2460 - val_accuracy: 0.4497\n",
      "Epoch 159/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0439 - accuracy: 0.5577 - val_loss: 1.0775 - val_accuracy: 0.5328\n",
      "Epoch 160/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0393 - accuracy: 0.5422 - val_loss: 1.0527 - val_accuracy: 0.5508\n",
      "Epoch 161/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0396 - accuracy: 0.5638 - val_loss: 1.0812 - val_accuracy: 0.5215\n",
      "Epoch 162/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0582 - accuracy: 0.5380 - val_loss: 1.1065 - val_accuracy: 0.4990\n",
      "Epoch 163/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0328 - accuracy: 0.5517 - val_loss: 1.1275 - val_accuracy: 0.4872\n",
      "Epoch 164/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0486 - accuracy: 0.5632 - val_loss: 1.1158 - val_accuracy: 0.5010\n",
      "Epoch 165/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0437 - accuracy: 0.5637 - val_loss: 1.1870 - val_accuracy: 0.4641\n",
      "Epoch 166/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0367 - accuracy: 0.5545 - val_loss: 1.0552 - val_accuracy: 0.5297\n",
      "Epoch 167/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0481 - accuracy: 0.5536 - val_loss: 1.2596 - val_accuracy: 0.3959\n",
      "Epoch 168/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0259 - accuracy: 0.5457 - val_loss: 1.0726 - val_accuracy: 0.5154\n",
      "Epoch 169/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0265 - accuracy: 0.5751 - val_loss: 1.0871 - val_accuracy: 0.5041\n",
      "Epoch 170/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0413 - accuracy: 0.5674 - val_loss: 1.0564 - val_accuracy: 0.5374\n",
      "Epoch 171/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0321 - accuracy: 0.5619 - val_loss: 1.0593 - val_accuracy: 0.5200\n",
      "Epoch 172/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0300 - accuracy: 0.5648 - val_loss: 1.0911 - val_accuracy: 0.5426\n",
      "Epoch 173/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0351 - accuracy: 0.5660 - val_loss: 1.0499 - val_accuracy: 0.5385\n",
      "Epoch 174/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0218 - accuracy: 0.5692 - val_loss: 1.0686 - val_accuracy: 0.5277\n",
      "Epoch 175/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0069 - accuracy: 0.5676 - val_loss: 1.0904 - val_accuracy: 0.5005\n",
      "Epoch 176/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0123 - accuracy: 0.5711 - val_loss: 1.0821 - val_accuracy: 0.5200\n",
      "Epoch 177/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0641 - accuracy: 0.5369 - val_loss: 1.2330 - val_accuracy: 0.4544\n",
      "Epoch 178/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0124 - accuracy: 0.5696 - val_loss: 1.0642 - val_accuracy: 0.5256\n",
      "Epoch 179/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0518 - accuracy: 0.5551 - val_loss: 1.0545 - val_accuracy: 0.5410\n",
      "Epoch 180/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0309 - accuracy: 0.5558 - val_loss: 1.1338 - val_accuracy: 0.4815\n",
      "Epoch 181/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0112 - accuracy: 0.5710 - val_loss: 1.3477 - val_accuracy: 0.3882\n",
      "Epoch 182/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0491 - accuracy: 0.5509 - val_loss: 1.0844 - val_accuracy: 0.5221\n",
      "Epoch 183/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0178 - accuracy: 0.5759 - val_loss: 1.0698 - val_accuracy: 0.5338\n",
      "Epoch 184/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0285 - accuracy: 0.5645 - val_loss: 1.0595 - val_accuracy: 0.5287\n",
      "Epoch 185/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0112 - accuracy: 0.5587 - val_loss: 1.1000 - val_accuracy: 0.5021\n",
      "Epoch 186/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0517 - accuracy: 0.5406 - val_loss: 1.0849 - val_accuracy: 0.4918\n",
      "Epoch 187/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0330 - accuracy: 0.5545 - val_loss: 1.1098 - val_accuracy: 0.4841\n",
      "Epoch 188/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0339 - accuracy: 0.5562 - val_loss: 1.0889 - val_accuracy: 0.5492\n",
      "Epoch 189/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0416 - accuracy: 0.5532 - val_loss: 1.1265 - val_accuracy: 0.4974\n",
      "Epoch 190/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0419 - accuracy: 0.5577 - val_loss: 1.1311 - val_accuracy: 0.5046\n",
      "Epoch 191/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0639 - accuracy: 0.5543 - val_loss: 1.2354 - val_accuracy: 0.4128\n",
      "Epoch 192/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0374 - accuracy: 0.5569 - val_loss: 1.3075 - val_accuracy: 0.4046\n",
      "Epoch 193/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0282 - accuracy: 0.5636 - val_loss: 1.2720 - val_accuracy: 0.4297\n",
      "Epoch 194/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0192 - accuracy: 0.5541 - val_loss: 1.1088 - val_accuracy: 0.5200\n",
      "Epoch 195/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0245 - accuracy: 0.5667 - val_loss: 1.3717 - val_accuracy: 0.4185\n",
      "Epoch 196/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0261 - accuracy: 0.5620 - val_loss: 1.1924 - val_accuracy: 0.5026\n",
      "Epoch 197/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0224 - accuracy: 0.5600 - val_loss: 1.1037 - val_accuracy: 0.5015\n",
      "Epoch 198/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0244 - accuracy: 0.5678 - val_loss: 1.0524 - val_accuracy: 0.5421\n",
      "Epoch 199/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0168 - accuracy: 0.5726 - val_loss: 1.0671 - val_accuracy: 0.5195\n",
      "Epoch 200/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0150 - accuracy: 0.5612 - val_loss: 1.0868 - val_accuracy: 0.5031\n",
      "Epoch 201/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0028 - accuracy: 0.5713 - val_loss: 1.0945 - val_accuracy: 0.5236\n",
      "Epoch 202/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0010 - accuracy: 0.5843 - val_loss: 1.1358 - val_accuracy: 0.4790\n",
      "Epoch 203/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0054 - accuracy: 0.5677 - val_loss: 1.1471 - val_accuracy: 0.4795\n",
      "Epoch 204/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0281 - accuracy: 0.5683 - val_loss: 1.2883 - val_accuracy: 0.3964\n",
      "Epoch 205/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0344 - accuracy: 0.5540 - val_loss: 1.1078 - val_accuracy: 0.5195\n",
      "Epoch 206/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0392 - accuracy: 0.5578 - val_loss: 1.1462 - val_accuracy: 0.4785\n",
      "Epoch 207/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0270 - accuracy: 0.5549 - val_loss: 1.0653 - val_accuracy: 0.5241\n",
      "Epoch 208/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9948 - accuracy: 0.5706 - val_loss: 1.0643 - val_accuracy: 0.5446\n",
      "Epoch 209/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0114 - accuracy: 0.5634 - val_loss: 1.3358 - val_accuracy: 0.3754\n",
      "Epoch 210/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0165 - accuracy: 0.5746 - val_loss: 1.1355 - val_accuracy: 0.4626\n",
      "Epoch 211/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0164 - accuracy: 0.5622 - val_loss: 1.0584 - val_accuracy: 0.5426\n",
      "Epoch 212/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9994 - accuracy: 0.5847 - val_loss: 1.0782 - val_accuracy: 0.5215\n",
      "Epoch 213/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0140 - accuracy: 0.5784 - val_loss: 1.1925 - val_accuracy: 0.4528\n",
      "Epoch 214/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.5555 - val_loss: 1.1674 - val_accuracy: 0.4544\n",
      "Epoch 215/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0192 - accuracy: 0.5650 - val_loss: 1.1316 - val_accuracy: 0.4815\n",
      "Epoch 216/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0376 - accuracy: 0.5526 - val_loss: 1.2188 - val_accuracy: 0.4333\n",
      "Epoch 217/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0046 - accuracy: 0.5696 - val_loss: 1.0852 - val_accuracy: 0.5087\n",
      "Epoch 218/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9914 - accuracy: 0.5786 - val_loss: 1.0578 - val_accuracy: 0.5318\n",
      "Epoch 219/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0378 - accuracy: 0.5558 - val_loss: 1.1017 - val_accuracy: 0.5256\n",
      "Epoch 220/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0305 - accuracy: 0.5612 - val_loss: 1.1593 - val_accuracy: 0.5149\n",
      "Epoch 221/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0312 - accuracy: 0.5649 - val_loss: 1.0790 - val_accuracy: 0.5149\n",
      "Epoch 222/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0140 - accuracy: 0.5762 - val_loss: 1.0692 - val_accuracy: 0.5287\n",
      "Epoch 223/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9847 - accuracy: 0.5700 - val_loss: 1.1397 - val_accuracy: 0.5174\n",
      "Epoch 224/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0098 - accuracy: 0.5564 - val_loss: 1.0655 - val_accuracy: 0.5349\n",
      "Epoch 225/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9971 - accuracy: 0.5714 - val_loss: 1.3055 - val_accuracy: 0.3856\n",
      "Epoch 226/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0181 - accuracy: 0.5737 - val_loss: 1.3345 - val_accuracy: 0.3990\n",
      "Epoch 227/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0186 - accuracy: 0.5691 - val_loss: 1.1574 - val_accuracy: 0.4856\n",
      "Epoch 228/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0122 - accuracy: 0.5708 - val_loss: 1.1023 - val_accuracy: 0.5010\n",
      "Epoch 229/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0122 - accuracy: 0.5695 - val_loss: 1.0624 - val_accuracy: 0.5349\n",
      "Epoch 230/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9949 - accuracy: 0.5754 - val_loss: 1.0813 - val_accuracy: 0.5379\n",
      "Epoch 231/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0338 - accuracy: 0.5544 - val_loss: 1.0543 - val_accuracy: 0.5410\n",
      "Epoch 232/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0210 - accuracy: 0.5674 - val_loss: 1.1591 - val_accuracy: 0.4713\n",
      "Epoch 233/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0347 - accuracy: 0.5603 - val_loss: 1.0738 - val_accuracy: 0.5267\n",
      "Epoch 234/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0183 - accuracy: 0.5695 - val_loss: 1.1155 - val_accuracy: 0.4764\n",
      "Epoch 235/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0197 - accuracy: 0.5554 - val_loss: 1.1771 - val_accuracy: 0.4856\n",
      "Epoch 236/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0107 - accuracy: 0.5600 - val_loss: 1.0668 - val_accuracy: 0.5128\n",
      "Epoch 237/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9963 - accuracy: 0.5767 - val_loss: 1.0767 - val_accuracy: 0.5390\n",
      "Epoch 238/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0221 - accuracy: 0.5618 - val_loss: 1.2289 - val_accuracy: 0.4108\n",
      "Epoch 239/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0099 - accuracy: 0.5621 - val_loss: 1.0829 - val_accuracy: 0.5051\n",
      "Epoch 240/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0187 - accuracy: 0.5634 - val_loss: 1.1931 - val_accuracy: 0.4646\n",
      "Epoch 241/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0040 - accuracy: 0.5725 - val_loss: 1.2559 - val_accuracy: 0.4118\n",
      "Epoch 242/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0245 - accuracy: 0.5547 - val_loss: 1.0662 - val_accuracy: 0.5205\n",
      "Epoch 243/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0339 - accuracy: 0.5606 - val_loss: 1.1002 - val_accuracy: 0.4918\n",
      "Epoch 244/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0358 - accuracy: 0.5655 - val_loss: 1.0839 - val_accuracy: 0.5221\n",
      "Epoch 245/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0309 - accuracy: 0.5556 - val_loss: 1.1164 - val_accuracy: 0.4990\n",
      "Epoch 246/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0207 - accuracy: 0.5594 - val_loss: 1.1070 - val_accuracy: 0.4913\n",
      "Epoch 247/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0210 - accuracy: 0.5518 - val_loss: 1.0967 - val_accuracy: 0.5051\n",
      "Epoch 248/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0095 - accuracy: 0.5697 - val_loss: 1.1612 - val_accuracy: 0.4708\n",
      "Epoch 249/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0135 - accuracy: 0.5739 - val_loss: 1.0686 - val_accuracy: 0.5256\n",
      "Epoch 250/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0086 - accuracy: 0.5624 - val_loss: 1.1325 - val_accuracy: 0.4862\n",
      "Epoch 251/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0083 - accuracy: 0.5624 - val_loss: 1.0822 - val_accuracy: 0.5108\n",
      "Epoch 252/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0173 - accuracy: 0.5624 - val_loss: 1.2319 - val_accuracy: 0.4113\n",
      "Epoch 253/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0189 - accuracy: 0.5755 - val_loss: 1.0756 - val_accuracy: 0.5210\n",
      "Epoch 254/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0112 - accuracy: 0.5725 - val_loss: 1.0895 - val_accuracy: 0.5287\n",
      "Epoch 255/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0121 - accuracy: 0.5704 - val_loss: 1.0944 - val_accuracy: 0.5190\n",
      "Epoch 256/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0025 - accuracy: 0.5714 - val_loss: 1.1079 - val_accuracy: 0.4836\n",
      "Epoch 257/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9899 - accuracy: 0.5819 - val_loss: 1.0875 - val_accuracy: 0.5087\n",
      "Epoch 258/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0171 - accuracy: 0.5680 - val_loss: 1.1142 - val_accuracy: 0.4933\n",
      "Epoch 259/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0059 - accuracy: 0.5612 - val_loss: 1.2145 - val_accuracy: 0.4446\n",
      "Epoch 260/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0360 - accuracy: 0.5586 - val_loss: 1.1754 - val_accuracy: 0.4513\n",
      "Epoch 261/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0430 - accuracy: 0.5658 - val_loss: 1.0655 - val_accuracy: 0.5292\n",
      "Epoch 262/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9962 - accuracy: 0.5841 - val_loss: 1.1575 - val_accuracy: 0.4544\n",
      "Epoch 263/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9968 - accuracy: 0.5829 - val_loss: 1.2212 - val_accuracy: 0.4000\n",
      "Epoch 264/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0156 - accuracy: 0.5686 - val_loss: 1.0839 - val_accuracy: 0.5267\n",
      "Epoch 265/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9901 - accuracy: 0.5744 - val_loss: 1.0863 - val_accuracy: 0.4954\n",
      "Epoch 266/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0046 - accuracy: 0.5683 - val_loss: 1.0763 - val_accuracy: 0.5174\n",
      "Epoch 267/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9943 - accuracy: 0.5796 - val_loss: 1.1654 - val_accuracy: 0.4426\n",
      "Epoch 268/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0164 - accuracy: 0.5798 - val_loss: 1.0658 - val_accuracy: 0.5354\n",
      "Epoch 269/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0200 - accuracy: 0.5669 - val_loss: 1.1042 - val_accuracy: 0.4872\n",
      "Epoch 270/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0052 - accuracy: 0.5711 - val_loss: 1.0770 - val_accuracy: 0.5277\n",
      "Epoch 271/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0197 - accuracy: 0.5597 - val_loss: 1.1216 - val_accuracy: 0.4892\n",
      "Epoch 272/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0110 - accuracy: 0.5679 - val_loss: 1.1264 - val_accuracy: 0.5313\n",
      "Epoch 273/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0116 - accuracy: 0.5687 - val_loss: 1.1839 - val_accuracy: 0.4523\n",
      "Epoch 274/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9999 - accuracy: 0.5712 - val_loss: 1.0941 - val_accuracy: 0.4964\n",
      "Epoch 275/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0290 - accuracy: 0.5480 - val_loss: 1.0769 - val_accuracy: 0.5405\n",
      "Epoch 276/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0215 - accuracy: 0.5555 - val_loss: 1.2615 - val_accuracy: 0.3933\n",
      "Epoch 277/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0035 - accuracy: 0.5729 - val_loss: 1.1729 - val_accuracy: 0.4544\n",
      "Epoch 278/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0018 - accuracy: 0.5725 - val_loss: 1.1543 - val_accuracy: 0.4569\n",
      "Epoch 279/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0219 - accuracy: 0.5641 - val_loss: 1.1531 - val_accuracy: 0.4426\n",
      "Epoch 280/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0118 - accuracy: 0.5650 - val_loss: 1.1775 - val_accuracy: 0.4533\n",
      "Epoch 281/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0214 - accuracy: 0.5655 - val_loss: 1.1437 - val_accuracy: 0.4908\n",
      "Epoch 282/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0086 - accuracy: 0.5713 - val_loss: 1.0941 - val_accuracy: 0.5292\n",
      "Epoch 283/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0172 - accuracy: 0.5646 - val_loss: 1.0752 - val_accuracy: 0.5154\n",
      "Epoch 284/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0324 - accuracy: 0.5549 - val_loss: 1.2495 - val_accuracy: 0.3995\n",
      "Epoch 285/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.5793 - val_loss: 1.1229 - val_accuracy: 0.4944\n",
      "Epoch 286/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9930 - accuracy: 0.5800 - val_loss: 1.0800 - val_accuracy: 0.5231\n",
      "Epoch 287/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0129 - accuracy: 0.5660 - val_loss: 1.0682 - val_accuracy: 0.5062\n",
      "Epoch 288/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9959 - accuracy: 0.5847 - val_loss: 1.0625 - val_accuracy: 0.5456\n",
      "Epoch 289/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0126 - accuracy: 0.5716 - val_loss: 1.0919 - val_accuracy: 0.5154\n",
      "Epoch 290/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0031 - accuracy: 0.5667 - val_loss: 1.1281 - val_accuracy: 0.4662\n",
      "Epoch 291/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0247 - accuracy: 0.5697 - val_loss: 1.0925 - val_accuracy: 0.5010\n",
      "Epoch 292/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0190 - accuracy: 0.5749 - val_loss: 1.0636 - val_accuracy: 0.5359\n",
      "Epoch 293/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0126 - accuracy: 0.5681 - val_loss: 1.0800 - val_accuracy: 0.5133\n",
      "Epoch 294/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0104 - accuracy: 0.5641 - val_loss: 1.1117 - val_accuracy: 0.4728\n",
      "Epoch 295/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0220 - accuracy: 0.5779 - val_loss: 1.2019 - val_accuracy: 0.4579\n",
      "Epoch 296/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0151 - accuracy: 0.5656 - val_loss: 1.1177 - val_accuracy: 0.5133\n",
      "Epoch 297/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0071 - accuracy: 0.5587 - val_loss: 1.1257 - val_accuracy: 0.4821\n",
      "Epoch 298/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0365 - accuracy: 0.5570 - val_loss: 1.1165 - val_accuracy: 0.4923\n",
      "Epoch 299/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0344 - accuracy: 0.5666 - val_loss: 1.2776 - val_accuracy: 0.3867\n",
      "Epoch 300/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0195 - accuracy: 0.5684 - val_loss: 1.1251 - val_accuracy: 0.4713\n",
      "Epoch 301/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0036 - accuracy: 0.5751 - val_loss: 1.0638 - val_accuracy: 0.5354\n",
      "Epoch 302/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9983 - accuracy: 0.5701 - val_loss: 1.0996 - val_accuracy: 0.5056\n",
      "Epoch 303/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0115 - accuracy: 0.5739 - val_loss: 1.1412 - val_accuracy: 0.5185\n",
      "Epoch 304/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0045 - accuracy: 0.5766 - val_loss: 1.2803 - val_accuracy: 0.4287\n",
      "Epoch 305/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0371 - accuracy: 0.5625 - val_loss: 1.0917 - val_accuracy: 0.5072\n",
      "Epoch 306/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0070 - accuracy: 0.5819 - val_loss: 1.1980 - val_accuracy: 0.4482\n",
      "Epoch 307/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0091 - accuracy: 0.5751 - val_loss: 1.1416 - val_accuracy: 0.4774\n",
      "Epoch 308/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0146 - accuracy: 0.5714 - val_loss: 1.0749 - val_accuracy: 0.5395\n",
      "Epoch 309/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0195 - accuracy: 0.5550 - val_loss: 1.0603 - val_accuracy: 0.5297\n",
      "Epoch 310/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0044 - accuracy: 0.5708 - val_loss: 1.1094 - val_accuracy: 0.5246\n",
      "Epoch 311/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0083 - accuracy: 0.5763 - val_loss: 1.0740 - val_accuracy: 0.5190\n",
      "Epoch 312/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0205 - accuracy: 0.5689 - val_loss: 1.4431 - val_accuracy: 0.3421\n",
      "Epoch 313/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0571 - accuracy: 0.5497 - val_loss: 1.1135 - val_accuracy: 0.5010\n",
      "Epoch 314/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0052 - accuracy: 0.5874 - val_loss: 1.1501 - val_accuracy: 0.4887\n",
      "Epoch 315/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0158 - accuracy: 0.5711 - val_loss: 1.0722 - val_accuracy: 0.4944\n",
      "Epoch 316/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9999 - accuracy: 0.5783 - val_loss: 1.1121 - val_accuracy: 0.4887\n",
      "Epoch 317/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0265 - accuracy: 0.5675 - val_loss: 1.1917 - val_accuracy: 0.4656\n",
      "Epoch 318/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0123 - accuracy: 0.5741 - val_loss: 1.4119 - val_accuracy: 0.3415\n",
      "Epoch 319/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9986 - accuracy: 0.5830 - val_loss: 1.0718 - val_accuracy: 0.5297\n",
      "Epoch 320/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9906 - accuracy: 0.5775 - val_loss: 1.1609 - val_accuracy: 0.5015\n",
      "Epoch 321/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0395 - accuracy: 0.5628 - val_loss: 1.2118 - val_accuracy: 0.4344\n",
      "Epoch 322/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0182 - accuracy: 0.5680 - val_loss: 1.0796 - val_accuracy: 0.5328\n",
      "Epoch 323/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9973 - accuracy: 0.5691 - val_loss: 1.1070 - val_accuracy: 0.5015\n",
      "Epoch 324/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0331 - accuracy: 0.5647 - val_loss: 1.1202 - val_accuracy: 0.4851\n",
      "Epoch 325/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0279 - accuracy: 0.5606 - val_loss: 1.2139 - val_accuracy: 0.4549\n",
      "Epoch 326/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0382 - accuracy: 0.5583 - val_loss: 1.1293 - val_accuracy: 0.4918\n",
      "Epoch 327/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0000 - accuracy: 0.5791 - val_loss: 1.1230 - val_accuracy: 0.5026\n",
      "Epoch 328/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0256 - accuracy: 0.5643 - val_loss: 1.2728 - val_accuracy: 0.4477\n",
      "Epoch 329/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0557 - accuracy: 0.5366 - val_loss: 1.0578 - val_accuracy: 0.5267\n",
      "Epoch 330/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0027 - accuracy: 0.5707 - val_loss: 1.2154 - val_accuracy: 0.4221\n",
      "Epoch 331/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0197 - accuracy: 0.5772 - val_loss: 1.1406 - val_accuracy: 0.5041\n",
      "Epoch 332/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0092 - accuracy: 0.5713 - val_loss: 1.0975 - val_accuracy: 0.5133\n",
      "Epoch 333/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0031 - accuracy: 0.5686 - val_loss: 1.0806 - val_accuracy: 0.5251\n",
      "Epoch 334/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9815 - accuracy: 0.5898 - val_loss: 1.1053 - val_accuracy: 0.5015\n",
      "Epoch 335/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0045 - accuracy: 0.5814 - val_loss: 1.0975 - val_accuracy: 0.5144\n",
      "Epoch 336/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0244 - accuracy: 0.5615 - val_loss: 1.1058 - val_accuracy: 0.5062\n",
      "Epoch 337/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0024 - accuracy: 0.5728 - val_loss: 1.1160 - val_accuracy: 0.4846\n",
      "Epoch 338/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0152 - accuracy: 0.5683 - val_loss: 1.2197 - val_accuracy: 0.4451\n",
      "Epoch 339/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9988 - accuracy: 0.5733 - val_loss: 1.1239 - val_accuracy: 0.4964\n",
      "Epoch 340/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9872 - accuracy: 0.5743 - val_loss: 1.1980 - val_accuracy: 0.4651\n",
      "Epoch 341/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9967 - accuracy: 0.5751 - val_loss: 1.1379 - val_accuracy: 0.5138\n",
      "Epoch 342/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9780 - accuracy: 0.5937 - val_loss: 1.1843 - val_accuracy: 0.4441\n",
      "Epoch 343/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.5799 - val_loss: 1.1812 - val_accuracy: 0.4354\n",
      "Epoch 344/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0010 - accuracy: 0.5705 - val_loss: 1.1102 - val_accuracy: 0.5005\n",
      "Epoch 345/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9957 - accuracy: 0.5726 - val_loss: 1.1005 - val_accuracy: 0.5313\n",
      "Epoch 346/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9819 - accuracy: 0.5903 - val_loss: 1.1761 - val_accuracy: 0.4759\n",
      "Epoch 347/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9830 - accuracy: 0.5854 - val_loss: 1.3046 - val_accuracy: 0.3985\n",
      "Epoch 348/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0202 - accuracy: 0.5574 - val_loss: 1.1275 - val_accuracy: 0.4862\n",
      "Epoch 349/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0031 - accuracy: 0.5736 - val_loss: 1.1793 - val_accuracy: 0.4544\n",
      "Epoch 350/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9978 - accuracy: 0.5705 - val_loss: 1.1399 - val_accuracy: 0.4862\n",
      "Epoch 351/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9910 - accuracy: 0.5769 - val_loss: 1.2083 - val_accuracy: 0.4574\n",
      "Epoch 352/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0041 - accuracy: 0.5698 - val_loss: 1.0808 - val_accuracy: 0.5297\n",
      "Epoch 353/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0112 - accuracy: 0.5701 - val_loss: 1.0911 - val_accuracy: 0.5215\n",
      "Epoch 354/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9816 - accuracy: 0.5718 - val_loss: 1.1848 - val_accuracy: 0.4200\n",
      "Epoch 355/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9679 - accuracy: 0.5811 - val_loss: 1.0998 - val_accuracy: 0.5241\n",
      "Epoch 356/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0083 - accuracy: 0.5645 - val_loss: 1.2787 - val_accuracy: 0.4323\n",
      "Epoch 357/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9912 - accuracy: 0.5863 - val_loss: 1.1654 - val_accuracy: 0.4697\n",
      "Epoch 358/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.5695 - val_loss: 1.0938 - val_accuracy: 0.5005\n",
      "Epoch 359/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.5712 - val_loss: 1.1031 - val_accuracy: 0.4954\n",
      "Epoch 360/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9890 - accuracy: 0.5815 - val_loss: 1.1004 - val_accuracy: 0.5144\n",
      "Epoch 361/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0198 - accuracy: 0.5765 - val_loss: 1.0687 - val_accuracy: 0.5236\n",
      "Epoch 362/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0035 - accuracy: 0.5660 - val_loss: 1.1715 - val_accuracy: 0.4574\n",
      "Epoch 363/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0184 - accuracy: 0.5602 - val_loss: 1.0856 - val_accuracy: 0.5097\n",
      "Epoch 364/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9892 - accuracy: 0.5616 - val_loss: 1.1984 - val_accuracy: 0.4615\n",
      "Epoch 365/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0038 - accuracy: 0.5741 - val_loss: 1.0930 - val_accuracy: 0.5113\n",
      "Epoch 366/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.5837 - val_loss: 1.2023 - val_accuracy: 0.4687\n",
      "Epoch 367/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9856 - accuracy: 0.5766 - val_loss: 1.1238 - val_accuracy: 0.4918\n",
      "Epoch 368/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9933 - accuracy: 0.5772 - val_loss: 1.3510 - val_accuracy: 0.3708\n",
      "Epoch 369/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9989 - accuracy: 0.5752 - val_loss: 1.0866 - val_accuracy: 0.4867\n",
      "Epoch 370/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0149 - accuracy: 0.5682 - val_loss: 1.1354 - val_accuracy: 0.4913\n",
      "Epoch 371/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9890 - accuracy: 0.5739 - val_loss: 1.1290 - val_accuracy: 0.4933\n",
      "Epoch 372/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9974 - accuracy: 0.5766 - val_loss: 1.1468 - val_accuracy: 0.4903\n",
      "Epoch 373/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9831 - accuracy: 0.5789 - val_loss: 1.1210 - val_accuracy: 0.4918\n",
      "Epoch 374/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0166 - accuracy: 0.5740 - val_loss: 1.1461 - val_accuracy: 0.4769\n",
      "Epoch 375/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9964 - accuracy: 0.5844 - val_loss: 1.1190 - val_accuracy: 0.4964\n",
      "Epoch 376/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0052 - accuracy: 0.5665 - val_loss: 1.1298 - val_accuracy: 0.5292\n",
      "Epoch 377/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0126 - accuracy: 0.5698 - val_loss: 1.1356 - val_accuracy: 0.4538\n",
      "Epoch 378/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9987 - accuracy: 0.5824 - val_loss: 1.0846 - val_accuracy: 0.4938\n",
      "Epoch 379/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9702 - accuracy: 0.5980 - val_loss: 1.0967 - val_accuracy: 0.5087\n",
      "Epoch 380/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9998 - accuracy: 0.5603 - val_loss: 1.1128 - val_accuracy: 0.5221\n",
      "Epoch 381/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9896 - accuracy: 0.5660 - val_loss: 1.1400 - val_accuracy: 0.4785\n",
      "Epoch 382/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9823 - accuracy: 0.5798 - val_loss: 1.1555 - val_accuracy: 0.4995\n",
      "Epoch 383/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9838 - accuracy: 0.5917 - val_loss: 1.1671 - val_accuracy: 0.4549\n",
      "Epoch 384/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9782 - accuracy: 0.5941 - val_loss: 1.0980 - val_accuracy: 0.5277\n",
      "Epoch 385/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9967 - accuracy: 0.5811 - val_loss: 1.0778 - val_accuracy: 0.5154\n",
      "Epoch 386/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9770 - accuracy: 0.5739 - val_loss: 1.2563 - val_accuracy: 0.4123\n",
      "Epoch 387/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0055 - accuracy: 0.5831 - val_loss: 1.2415 - val_accuracy: 0.4467\n",
      "Epoch 388/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9886 - accuracy: 0.5797 - val_loss: 1.1479 - val_accuracy: 0.4990\n",
      "Epoch 389/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9992 - accuracy: 0.5762 - val_loss: 1.1401 - val_accuracy: 0.5005\n",
      "Epoch 390/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0019 - accuracy: 0.5707 - val_loss: 1.2474 - val_accuracy: 0.4328\n",
      "Epoch 391/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9856 - accuracy: 0.5857 - val_loss: 1.0760 - val_accuracy: 0.5185\n",
      "Epoch 392/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9918 - accuracy: 0.5884 - val_loss: 1.1613 - val_accuracy: 0.4795\n",
      "Epoch 393/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0010 - accuracy: 0.5718 - val_loss: 1.1066 - val_accuracy: 0.4754\n",
      "Epoch 394/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0082 - accuracy: 0.5729 - val_loss: 1.1303 - val_accuracy: 0.4769\n",
      "Epoch 395/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9880 - accuracy: 0.5804 - val_loss: 1.1074 - val_accuracy: 0.5262\n",
      "Epoch 396/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9789 - accuracy: 0.5933 - val_loss: 1.1601 - val_accuracy: 0.4682\n",
      "Epoch 397/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9614 - accuracy: 0.6066 - val_loss: 1.0961 - val_accuracy: 0.5149\n",
      "Epoch 398/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9983 - accuracy: 0.5776 - val_loss: 1.3996 - val_accuracy: 0.3318\n",
      "Epoch 399/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9903 - accuracy: 0.5845 - val_loss: 1.2432 - val_accuracy: 0.3995\n",
      "Epoch 400/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0286 - accuracy: 0.5719 - val_loss: 1.1391 - val_accuracy: 0.5144\n",
      "Epoch 401/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0024 - accuracy: 0.5741 - val_loss: 1.2083 - val_accuracy: 0.4405\n",
      "Epoch 402/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9975 - accuracy: 0.5835 - val_loss: 1.1773 - val_accuracy: 0.4523\n",
      "Epoch 403/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9966 - accuracy: 0.5683 - val_loss: 1.0973 - val_accuracy: 0.5015\n",
      "Epoch 404/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9747 - accuracy: 0.5934 - val_loss: 1.0906 - val_accuracy: 0.5344\n",
      "Epoch 405/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0054 - accuracy: 0.5826 - val_loss: 1.1846 - val_accuracy: 0.4856\n",
      "Epoch 406/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0359 - accuracy: 0.5503 - val_loss: 1.1099 - val_accuracy: 0.5385\n",
      "Epoch 407/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0005 - accuracy: 0.5727 - val_loss: 1.0773 - val_accuracy: 0.5236\n",
      "Epoch 408/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9971 - accuracy: 0.5835 - val_loss: 1.1233 - val_accuracy: 0.4841\n",
      "Epoch 409/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9894 - accuracy: 0.5862 - val_loss: 1.1073 - val_accuracy: 0.5000\n",
      "Epoch 410/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9931 - accuracy: 0.5746 - val_loss: 1.1678 - val_accuracy: 0.4605\n",
      "Epoch 411/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9805 - accuracy: 0.5857 - val_loss: 1.0914 - val_accuracy: 0.5051\n",
      "Epoch 412/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9947 - accuracy: 0.5765 - val_loss: 1.1146 - val_accuracy: 0.4908\n",
      "Epoch 413/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9908 - accuracy: 0.5796 - val_loss: 1.1691 - val_accuracy: 0.4979\n",
      "Epoch 414/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9986 - accuracy: 0.5655 - val_loss: 1.0965 - val_accuracy: 0.5149\n",
      "Epoch 415/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9942 - accuracy: 0.5742 - val_loss: 1.2281 - val_accuracy: 0.4369\n",
      "Epoch 416/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9920 - accuracy: 0.5784 - val_loss: 1.0931 - val_accuracy: 0.5082\n",
      "Epoch 417/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9832 - accuracy: 0.5864 - val_loss: 1.1580 - val_accuracy: 0.4744\n",
      "Epoch 418/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0090 - accuracy: 0.5746 - val_loss: 1.1196 - val_accuracy: 0.4974\n",
      "Epoch 419/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9891 - accuracy: 0.5841 - val_loss: 1.2936 - val_accuracy: 0.3979\n",
      "Epoch 420/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9814 - accuracy: 0.5882 - val_loss: 1.1167 - val_accuracy: 0.5292\n",
      "Epoch 421/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9817 - accuracy: 0.5815 - val_loss: 1.1243 - val_accuracy: 0.5277\n",
      "Epoch 422/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0094 - accuracy: 0.5620 - val_loss: 1.0942 - val_accuracy: 0.5154\n",
      "Epoch 423/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9935 - accuracy: 0.5775 - val_loss: 1.1293 - val_accuracy: 0.4990\n",
      "Epoch 424/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9997 - accuracy: 0.5797 - val_loss: 1.0990 - val_accuracy: 0.5031\n",
      "Epoch 425/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9872 - accuracy: 0.5841 - val_loss: 1.1015 - val_accuracy: 0.5113\n",
      "Epoch 426/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9808 - accuracy: 0.5898 - val_loss: 1.1010 - val_accuracy: 0.5215\n",
      "Epoch 427/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0170 - accuracy: 0.5709 - val_loss: 1.1014 - val_accuracy: 0.5174\n",
      "Epoch 428/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9896 - accuracy: 0.5837 - val_loss: 1.1066 - val_accuracy: 0.5123\n",
      "Epoch 429/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9690 - accuracy: 0.5917 - val_loss: 1.1770 - val_accuracy: 0.4472\n",
      "Epoch 430/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0064 - accuracy: 0.5794 - val_loss: 1.1381 - val_accuracy: 0.5164\n",
      "Epoch 431/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0142 - accuracy: 0.5577 - val_loss: 1.1852 - val_accuracy: 0.4810\n",
      "Epoch 432/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0072 - accuracy: 0.5824 - val_loss: 1.1208 - val_accuracy: 0.4892\n",
      "Epoch 433/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9694 - accuracy: 0.5862 - val_loss: 1.1289 - val_accuracy: 0.5344\n",
      "Epoch 434/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9816 - accuracy: 0.5853 - val_loss: 1.1767 - val_accuracy: 0.4667\n",
      "Epoch 435/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9847 - accuracy: 0.5872 - val_loss: 1.1407 - val_accuracy: 0.5195\n",
      "Epoch 436/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0133 - accuracy: 0.5618 - val_loss: 1.1437 - val_accuracy: 0.5205\n",
      "Epoch 437/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0294 - accuracy: 0.5605 - val_loss: 1.1651 - val_accuracy: 0.5041\n",
      "Epoch 438/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0043 - accuracy: 0.5786 - val_loss: 1.2024 - val_accuracy: 0.4513\n",
      "Epoch 439/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9796 - accuracy: 0.5798 - val_loss: 1.2280 - val_accuracy: 0.4759\n",
      "Epoch 440/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0431 - accuracy: 0.5582 - val_loss: 1.1845 - val_accuracy: 0.4954\n",
      "Epoch 441/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0064 - accuracy: 0.5783 - val_loss: 1.1252 - val_accuracy: 0.5241\n",
      "Epoch 442/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9914 - accuracy: 0.5801 - val_loss: 1.1316 - val_accuracy: 0.4867\n",
      "Epoch 443/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9947 - accuracy: 0.5818 - val_loss: 1.1975 - val_accuracy: 0.4641\n",
      "Epoch 444/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0181 - accuracy: 0.5706 - val_loss: 1.2310 - val_accuracy: 0.4662\n",
      "Epoch 445/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0102 - accuracy: 0.5667 - val_loss: 1.3444 - val_accuracy: 0.3995\n",
      "Epoch 446/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9859 - accuracy: 0.5801 - val_loss: 1.1472 - val_accuracy: 0.4815\n",
      "Epoch 447/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0000 - accuracy: 0.5800 - val_loss: 1.2231 - val_accuracy: 0.4477\n",
      "Epoch 448/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9907 - accuracy: 0.5871 - val_loss: 1.2525 - val_accuracy: 0.4600\n",
      "Epoch 449/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9814 - accuracy: 0.5926 - val_loss: 1.1621 - val_accuracy: 0.5169\n",
      "Epoch 450/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9879 - accuracy: 0.5844 - val_loss: 1.2075 - val_accuracy: 0.4918\n",
      "Epoch 451/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9837 - accuracy: 0.5703 - val_loss: 1.3236 - val_accuracy: 0.4456\n",
      "Epoch 452/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9825 - accuracy: 0.5795 - val_loss: 1.2258 - val_accuracy: 0.4718\n",
      "Epoch 453/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9819 - accuracy: 0.5882 - val_loss: 1.2217 - val_accuracy: 0.4590\n",
      "Epoch 454/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9779 - accuracy: 0.5931 - val_loss: 1.1866 - val_accuracy: 0.4785\n",
      "Epoch 455/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9712 - accuracy: 0.5955 - val_loss: 1.1706 - val_accuracy: 0.4836\n",
      "Epoch 456/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9804 - accuracy: 0.5865 - val_loss: 1.1939 - val_accuracy: 0.5021\n",
      "Epoch 457/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9932 - accuracy: 0.5751 - val_loss: 1.1769 - val_accuracy: 0.5067\n",
      "Epoch 458/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9993 - accuracy: 0.5717 - val_loss: 1.2465 - val_accuracy: 0.4400\n",
      "Epoch 459/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0240 - accuracy: 0.5648 - val_loss: 1.2458 - val_accuracy: 0.4990\n",
      "Epoch 460/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9861 - accuracy: 0.5766 - val_loss: 1.1991 - val_accuracy: 0.4851\n",
      "Epoch 461/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9910 - accuracy: 0.5778 - val_loss: 1.1405 - val_accuracy: 0.5128\n",
      "Epoch 462/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0107 - accuracy: 0.5710 - val_loss: 1.1644 - val_accuracy: 0.4703\n",
      "Epoch 463/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9890 - accuracy: 0.5775 - val_loss: 1.2271 - val_accuracy: 0.5092\n",
      "Epoch 464/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9721 - accuracy: 0.5984 - val_loss: 1.2915 - val_accuracy: 0.4221\n",
      "Epoch 465/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9912 - accuracy: 0.5795 - val_loss: 1.1763 - val_accuracy: 0.5000\n",
      "Epoch 466/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9985 - accuracy: 0.5802 - val_loss: 1.1836 - val_accuracy: 0.5251\n",
      "Epoch 467/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9746 - accuracy: 0.5914 - val_loss: 1.3286 - val_accuracy: 0.4477\n",
      "Epoch 468/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9866 - accuracy: 0.5734 - val_loss: 1.3242 - val_accuracy: 0.4067\n",
      "Epoch 469/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9859 - accuracy: 0.5806 - val_loss: 1.1471 - val_accuracy: 0.5123\n",
      "Epoch 470/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9714 - accuracy: 0.5800 - val_loss: 1.3111 - val_accuracy: 0.4400\n",
      "Epoch 471/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0089 - accuracy: 0.5620 - val_loss: 1.1808 - val_accuracy: 0.5190\n",
      "Epoch 472/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9775 - accuracy: 0.5786 - val_loss: 1.1952 - val_accuracy: 0.4959\n",
      "Epoch 473/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9940 - accuracy: 0.5683 - val_loss: 1.2534 - val_accuracy: 0.4785\n",
      "Epoch 474/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0102 - accuracy: 0.5701 - val_loss: 1.1770 - val_accuracy: 0.5041\n",
      "Epoch 475/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9833 - accuracy: 0.5896 - val_loss: 1.1962 - val_accuracy: 0.4908\n",
      "Epoch 476/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9798 - accuracy: 0.5776 - val_loss: 1.2505 - val_accuracy: 0.4697\n",
      "Epoch 477/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9755 - accuracy: 0.5971 - val_loss: 1.2814 - val_accuracy: 0.4508\n",
      "Epoch 478/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0003 - accuracy: 0.5737 - val_loss: 1.3786 - val_accuracy: 0.4313\n",
      "Epoch 479/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0539 - accuracy: 0.5446 - val_loss: 1.2598 - val_accuracy: 0.4523\n",
      "Epoch 480/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9938 - accuracy: 0.5705 - val_loss: 1.4055 - val_accuracy: 0.3800\n",
      "Epoch 481/1000\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 1.0163 - accuracy: 0.5640 - val_loss: 1.1594 - val_accuracy: 0.4903\n",
      "Epoch 482/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9839 - accuracy: 0.5789 - val_loss: 1.1809 - val_accuracy: 0.4913\n",
      "Epoch 483/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.5989 - val_loss: 1.1442 - val_accuracy: 0.4856\n",
      "Epoch 484/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9928 - accuracy: 0.5771 - val_loss: 1.1583 - val_accuracy: 0.5041\n",
      "Epoch 485/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9778 - accuracy: 0.5772 - val_loss: 1.1364 - val_accuracy: 0.5072\n",
      "Epoch 486/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9859 - accuracy: 0.5807 - val_loss: 1.2121 - val_accuracy: 0.4687\n",
      "Epoch 487/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9822 - accuracy: 0.5903 - val_loss: 1.2826 - val_accuracy: 0.4041\n",
      "Epoch 488/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9926 - accuracy: 0.5726 - val_loss: 1.2385 - val_accuracy: 0.4610\n",
      "Epoch 489/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9849 - accuracy: 0.5690 - val_loss: 1.1611 - val_accuracy: 0.5256\n",
      "Epoch 490/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9878 - accuracy: 0.5778 - val_loss: 1.1021 - val_accuracy: 0.5159\n",
      "Epoch 491/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9800 - accuracy: 0.5924 - val_loss: 1.1503 - val_accuracy: 0.5005\n",
      "Epoch 492/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9685 - accuracy: 0.5943 - val_loss: 1.1801 - val_accuracy: 0.4841\n",
      "Epoch 493/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9898 - accuracy: 0.5815 - val_loss: 1.2259 - val_accuracy: 0.4585\n",
      "Epoch 494/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9764 - accuracy: 0.5882 - val_loss: 1.2232 - val_accuracy: 0.4749\n",
      "Epoch 495/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9791 - accuracy: 0.5899 - val_loss: 1.1779 - val_accuracy: 0.4913\n",
      "Epoch 496/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.5686 - val_loss: 1.2259 - val_accuracy: 0.4626\n",
      "Epoch 497/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9825 - accuracy: 0.5903 - val_loss: 1.3113 - val_accuracy: 0.4451\n",
      "Epoch 498/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9944 - accuracy: 0.5777 - val_loss: 1.1530 - val_accuracy: 0.5215\n",
      "Epoch 499/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9522 - accuracy: 0.5994 - val_loss: 1.3901 - val_accuracy: 0.3733\n",
      "Epoch 500/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9768 - accuracy: 0.5881 - val_loss: 1.2048 - val_accuracy: 0.5046\n",
      "Epoch 501/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9993 - accuracy: 0.5817 - val_loss: 1.2853 - val_accuracy: 0.4231\n",
      "Epoch 502/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9919 - accuracy: 0.58 - 0s 2ms/step - loss: 0.9890 - accuracy: 0.5868 - val_loss: 1.2597 - val_accuracy: 0.4974\n",
      "Epoch 503/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9846 - accuracy: 0.5798 - val_loss: 1.2110 - val_accuracy: 0.4503\n",
      "Epoch 504/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0050 - accuracy: 0.5567 - val_loss: 1.1892 - val_accuracy: 0.4826\n",
      "Epoch 505/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0035 - accuracy: 0.5795 - val_loss: 1.2626 - val_accuracy: 0.4400\n",
      "Epoch 506/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9754 - accuracy: 0.5881 - val_loss: 1.3136 - val_accuracy: 0.4738\n",
      "Epoch 507/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0363 - accuracy: 0.5617 - val_loss: 1.2280 - val_accuracy: 0.4851\n",
      "Epoch 508/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0149 - accuracy: 0.5627 - val_loss: 1.2515 - val_accuracy: 0.4995\n",
      "Epoch 509/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9684 - accuracy: 0.5912 - val_loss: 1.1728 - val_accuracy: 0.5154\n",
      "Epoch 510/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9774 - accuracy: 0.5797 - val_loss: 1.1693 - val_accuracy: 0.5026\n",
      "Epoch 511/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9940 - accuracy: 0.5725 - val_loss: 1.1808 - val_accuracy: 0.5072\n",
      "Epoch 512/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9601 - accuracy: 0.5902 - val_loss: 1.2324 - val_accuracy: 0.4759\n",
      "Epoch 513/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9870 - accuracy: 0.5838 - val_loss: 1.1470 - val_accuracy: 0.5210\n",
      "Epoch 514/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0117 - accuracy: 0.5624 - val_loss: 1.2001 - val_accuracy: 0.4985\n",
      "Epoch 515/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0120 - accuracy: 0.5785 - val_loss: 1.2604 - val_accuracy: 0.4626\n",
      "Epoch 516/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9914 - accuracy: 0.5759 - val_loss: 1.2891 - val_accuracy: 0.4754\n",
      "Epoch 517/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9729 - accuracy: 0.5845 - val_loss: 1.1907 - val_accuracy: 0.4744\n",
      "Epoch 518/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9750 - accuracy: 0.5767 - val_loss: 1.1507 - val_accuracy: 0.5067\n",
      "Epoch 519/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9902 - accuracy: 0.5746 - val_loss: 1.2419 - val_accuracy: 0.4815\n",
      "Epoch 520/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9958 - accuracy: 0.5805 - val_loss: 1.5894 - val_accuracy: 0.4062\n",
      "Epoch 521/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.1673 - accuracy: 0.5086 - val_loss: 1.3224 - val_accuracy: 0.3472\n",
      "Epoch 522/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0590 - accuracy: 0.5388 - val_loss: 1.0962 - val_accuracy: 0.5041\n",
      "Epoch 523/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0384 - accuracy: 0.5710 - val_loss: 1.0827 - val_accuracy: 0.5123\n",
      "Epoch 524/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9977 - accuracy: 0.5661 - val_loss: 1.0850 - val_accuracy: 0.5036\n",
      "Epoch 525/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9941 - accuracy: 0.5732 - val_loss: 1.0680 - val_accuracy: 0.5241\n",
      "Epoch 526/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0138 - accuracy: 0.5767 - val_loss: 1.1308 - val_accuracy: 0.4815\n",
      "Epoch 527/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0186 - accuracy: 0.5759 - val_loss: 1.1507 - val_accuracy: 0.5041\n",
      "Epoch 528/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0043 - accuracy: 0.5743 - val_loss: 1.1016 - val_accuracy: 0.5262\n",
      "Epoch 529/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9870 - accuracy: 0.5763 - val_loss: 1.1724 - val_accuracy: 0.4744\n",
      "Epoch 530/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9773 - accuracy: 0.5773 - val_loss: 1.1158 - val_accuracy: 0.4944\n",
      "Epoch 531/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9837 - accuracy: 0.5799 - val_loss: 1.1379 - val_accuracy: 0.4610\n",
      "Epoch 532/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9751 - accuracy: 0.5843 - val_loss: 1.1040 - val_accuracy: 0.5164\n",
      "Epoch 533/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0090 - accuracy: 0.5739 - val_loss: 1.1615 - val_accuracy: 0.4662\n",
      "Epoch 534/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9810 - accuracy: 0.5929 - val_loss: 1.2567 - val_accuracy: 0.4103\n",
      "Epoch 535/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9782 - accuracy: 0.5916 - val_loss: 1.2006 - val_accuracy: 0.4272\n",
      "Epoch 536/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9998 - accuracy: 0.5755 - val_loss: 1.0821 - val_accuracy: 0.5190\n",
      "Epoch 537/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9583 - accuracy: 0.5924 - val_loss: 1.1624 - val_accuracy: 0.4641\n",
      "Epoch 538/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9686 - accuracy: 0.6013 - val_loss: 1.1027 - val_accuracy: 0.5354\n",
      "Epoch 539/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9670 - accuracy: 0.5888 - val_loss: 1.0984 - val_accuracy: 0.5021\n",
      "Epoch 540/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9626 - accuracy: 0.5986 - val_loss: 1.0954 - val_accuracy: 0.5031\n",
      "Epoch 541/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9812 - accuracy: 0.5883 - val_loss: 1.1793 - val_accuracy: 0.4728\n",
      "Epoch 542/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9793 - accuracy: 0.5807 - val_loss: 1.2454 - val_accuracy: 0.4087\n",
      "Epoch 543/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9711 - accuracy: 0.5894 - val_loss: 1.1230 - val_accuracy: 0.4867\n",
      "Epoch 544/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.5874 - val_loss: 1.0957 - val_accuracy: 0.5205\n",
      "Epoch 545/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9941 - accuracy: 0.5732 - val_loss: 1.1136 - val_accuracy: 0.5185\n",
      "Epoch 546/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0066 - accuracy: 0.5745 - val_loss: 1.1290 - val_accuracy: 0.4785\n",
      "Epoch 547/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9761 - accuracy: 0.5817 - val_loss: 1.1349 - val_accuracy: 0.5092\n",
      "Epoch 548/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0002 - accuracy: 0.5654 - val_loss: 1.1017 - val_accuracy: 0.5051\n",
      "Epoch 549/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9696 - accuracy: 0.5899 - val_loss: 1.1013 - val_accuracy: 0.5195\n",
      "Epoch 550/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0275 - accuracy: 0.5608 - val_loss: 1.1140 - val_accuracy: 0.5236\n",
      "Epoch 551/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9805 - accuracy: 0.5671 - val_loss: 1.1338 - val_accuracy: 0.4908\n",
      "Epoch 552/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9939 - accuracy: 0.5746 - val_loss: 1.1030 - val_accuracy: 0.5046\n",
      "Epoch 553/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9816 - accuracy: 0.5798 - val_loss: 1.1117 - val_accuracy: 0.5226\n",
      "Epoch 554/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9825 - accuracy: 0.5787 - val_loss: 1.1881 - val_accuracy: 0.4554\n",
      "Epoch 555/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9873 - accuracy: 0.5778 - val_loss: 1.0891 - val_accuracy: 0.5385\n",
      "Epoch 556/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9620 - accuracy: 0.5929 - val_loss: 1.0974 - val_accuracy: 0.5123\n",
      "Epoch 557/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0036 - accuracy: 0.5887 - val_loss: 1.0918 - val_accuracy: 0.5262\n",
      "Epoch 558/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9782 - accuracy: 0.5908 - val_loss: 1.1322 - val_accuracy: 0.5005\n",
      "Epoch 559/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9751 - accuracy: 0.5848 - val_loss: 1.1810 - val_accuracy: 0.4744\n",
      "Epoch 560/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9843 - accuracy: 0.5809 - val_loss: 1.3238 - val_accuracy: 0.3733\n",
      "Epoch 561/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9913 - accuracy: 0.5693 - val_loss: 1.2920 - val_accuracy: 0.4010\n",
      "Epoch 562/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9831 - accuracy: 0.5661 - val_loss: 1.1131 - val_accuracy: 0.5256\n",
      "Epoch 563/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9616 - accuracy: 0.5922 - val_loss: 1.2360 - val_accuracy: 0.4262\n",
      "Epoch 564/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0156 - accuracy: 0.5679 - val_loss: 1.0749 - val_accuracy: 0.5154\n",
      "Epoch 565/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9788 - accuracy: 0.5912 - val_loss: 1.1552 - val_accuracy: 0.4841\n",
      "Epoch 566/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9875 - accuracy: 0.5873 - val_loss: 1.1339 - val_accuracy: 0.4887\n",
      "Epoch 567/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9906 - accuracy: 0.5795 - val_loss: 1.1201 - val_accuracy: 0.5072\n",
      "Epoch 568/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9742 - accuracy: 0.5905 - val_loss: 1.0844 - val_accuracy: 0.4990\n",
      "Epoch 569/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9712 - accuracy: 0.5857 - val_loss: 1.1396 - val_accuracy: 0.5174\n",
      "Epoch 570/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9912 - accuracy: 0.5808 - val_loss: 1.2734 - val_accuracy: 0.4046\n",
      "Epoch 571/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9824 - accuracy: 0.5854 - val_loss: 1.1925 - val_accuracy: 0.4759\n",
      "Epoch 572/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9519 - accuracy: 0.5973 - val_loss: 1.1382 - val_accuracy: 0.4856\n",
      "Epoch 573/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9638 - accuracy: 0.5934 - val_loss: 1.1015 - val_accuracy: 0.5221\n",
      "Epoch 574/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9690 - accuracy: 0.5894 - val_loss: 1.1068 - val_accuracy: 0.5344\n",
      "Epoch 575/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9864 - accuracy: 0.5791 - val_loss: 1.2084 - val_accuracy: 0.4426\n",
      "Epoch 576/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9940 - accuracy: 0.5637 - val_loss: 1.3129 - val_accuracy: 0.3887\n",
      "Epoch 577/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 1.0001 - accuracy: 0.5826 - val_loss: 1.2331 - val_accuracy: 0.4108\n",
      "Epoch 578/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9934 - accuracy: 0.5673 - val_loss: 1.0967 - val_accuracy: 0.5354\n",
      "Epoch 579/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9772 - accuracy: 0.5832 - val_loss: 1.1571 - val_accuracy: 0.4733\n",
      "Epoch 580/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.5976 - val_loss: 1.1891 - val_accuracy: 0.4610\n",
      "Epoch 581/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9630 - accuracy: 0.5984 - val_loss: 1.2238 - val_accuracy: 0.4210\n",
      "Epoch 582/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9910 - accuracy: 0.5776 - val_loss: 1.2145 - val_accuracy: 0.4421\n",
      "Epoch 583/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9949 - accuracy: 0.5795 - val_loss: 1.2497 - val_accuracy: 0.4467\n",
      "Epoch 584/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9769 - accuracy: 0.5790 - val_loss: 1.1418 - val_accuracy: 0.4810\n",
      "Epoch 585/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9791 - accuracy: 0.5897 - val_loss: 1.1196 - val_accuracy: 0.5010\n",
      "Epoch 586/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9980 - accuracy: 0.5776 - val_loss: 1.1820 - val_accuracy: 0.4436\n",
      "Epoch 587/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9726 - accuracy: 0.5919 - val_loss: 1.1156 - val_accuracy: 0.5195\n",
      "Epoch 588/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9598 - accuracy: 0.5882 - val_loss: 1.0968 - val_accuracy: 0.5287\n",
      "Epoch 589/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9579 - accuracy: 0.6010 - val_loss: 1.1854 - val_accuracy: 0.4836\n",
      "Epoch 590/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9604 - accuracy: 0.5993 - val_loss: 1.0991 - val_accuracy: 0.5241\n",
      "Epoch 591/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9943 - accuracy: 0.5736 - val_loss: 1.1355 - val_accuracy: 0.4867\n",
      "Epoch 592/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9851 - accuracy: 0.5850 - val_loss: 1.0876 - val_accuracy: 0.5210\n",
      "Epoch 593/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9750 - accuracy: 0.5925 - val_loss: 1.1760 - val_accuracy: 0.4497\n",
      "Epoch 594/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9570 - accuracy: 0.5978 - val_loss: 1.1805 - val_accuracy: 0.4513\n",
      "Epoch 595/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9735 - accuracy: 0.5974 - val_loss: 1.1317 - val_accuracy: 0.5000\n",
      "Epoch 596/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9779 - accuracy: 0.5950 - val_loss: 1.1084 - val_accuracy: 0.4959\n",
      "Epoch 597/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9953 - accuracy: 0.5789 - val_loss: 1.1136 - val_accuracy: 0.5021\n",
      "Epoch 598/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9809 - accuracy: 0.5872 - val_loss: 1.2713 - val_accuracy: 0.3836\n",
      "Epoch 599/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9924 - accuracy: 0.5830 - val_loss: 1.1473 - val_accuracy: 0.4682\n",
      "Epoch 600/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9743 - accuracy: 0.5828 - val_loss: 1.1231 - val_accuracy: 0.4979\n",
      "Epoch 601/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9867 - accuracy: 0.5874 - val_loss: 1.0981 - val_accuracy: 0.5241\n",
      "Epoch 602/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9754 - accuracy: 0.5851 - val_loss: 1.1105 - val_accuracy: 0.4908\n",
      "Epoch 603/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9514 - accuracy: 0.5999 - val_loss: 1.1057 - val_accuracy: 0.4769\n",
      "Epoch 604/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9890 - accuracy: 0.5844 - val_loss: 1.2309 - val_accuracy: 0.4313\n",
      "Epoch 605/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9654 - accuracy: 0.6056 - val_loss: 1.1800 - val_accuracy: 0.4897\n",
      "Epoch 606/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.5965 - val_loss: 1.1158 - val_accuracy: 0.4800\n",
      "Epoch 607/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9573 - accuracy: 0.5917 - val_loss: 1.1260 - val_accuracy: 0.4841\n",
      "Epoch 608/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9557 - accuracy: 0.6030 - val_loss: 1.1543 - val_accuracy: 0.4913\n",
      "Epoch 609/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9732 - accuracy: 0.5919 - val_loss: 1.1570 - val_accuracy: 0.5144\n",
      "Epoch 610/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9855 - accuracy: 0.5858 - val_loss: 1.1467 - val_accuracy: 0.5072\n",
      "Epoch 611/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0162 - accuracy: 0.5669 - val_loss: 1.1449 - val_accuracy: 0.4744\n",
      "Epoch 612/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9739 - accuracy: 0.5902 - val_loss: 1.1195 - val_accuracy: 0.4928\n",
      "Epoch 613/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9556 - accuracy: 0.5974 - val_loss: 1.2050 - val_accuracy: 0.4215\n",
      "Epoch 614/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9828 - accuracy: 0.5873 - val_loss: 1.2241 - val_accuracy: 0.4241\n",
      "Epoch 615/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9808 - accuracy: 0.5849 - val_loss: 1.1366 - val_accuracy: 0.4826\n",
      "Epoch 616/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9642 - accuracy: 0.5969 - val_loss: 1.2728 - val_accuracy: 0.4590\n",
      "Epoch 617/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9893 - accuracy: 0.5746 - val_loss: 1.2360 - val_accuracy: 0.4626\n",
      "Epoch 618/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9649 - accuracy: 0.5880 - val_loss: 1.1739 - val_accuracy: 0.4436\n",
      "Epoch 619/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9553 - accuracy: 0.6019 - val_loss: 1.1260 - val_accuracy: 0.5154\n",
      "Epoch 620/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9768 - accuracy: 0.5984 - val_loss: 1.2211 - val_accuracy: 0.4349\n",
      "Epoch 621/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9652 - accuracy: 0.5840 - val_loss: 1.1916 - val_accuracy: 0.4554\n",
      "Epoch 622/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9812 - accuracy: 0.5823 - val_loss: 1.1040 - val_accuracy: 0.5128\n",
      "Epoch 623/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9618 - accuracy: 0.5937 - val_loss: 1.1862 - val_accuracy: 0.4462\n",
      "Epoch 624/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9383 - accuracy: 0.6107 - val_loss: 1.1276 - val_accuracy: 0.5026\n",
      "Epoch 625/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9543 - accuracy: 0.6017 - val_loss: 1.1997 - val_accuracy: 0.4318\n",
      "Epoch 626/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0491 - accuracy: 0.5519 - val_loss: 1.1336 - val_accuracy: 0.5333\n",
      "Epoch 627/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0123 - accuracy: 0.5827 - val_loss: 1.1350 - val_accuracy: 0.4774\n",
      "Epoch 628/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9569 - accuracy: 0.59 - 0s 2ms/step - loss: 0.9658 - accuracy: 0.5901 - val_loss: 1.2054 - val_accuracy: 0.4354\n",
      "Epoch 629/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0028 - accuracy: 0.5849 - val_loss: 1.1258 - val_accuracy: 0.4651\n",
      "Epoch 630/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9693 - accuracy: 0.5958 - val_loss: 1.0970 - val_accuracy: 0.5308\n",
      "Epoch 631/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9779 - accuracy: 0.5977 - val_loss: 1.1156 - val_accuracy: 0.5005\n",
      "Epoch 632/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9731 - accuracy: 0.5877 - val_loss: 1.1260 - val_accuracy: 0.5036\n",
      "Epoch 633/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9752 - accuracy: 0.5824 - val_loss: 1.1510 - val_accuracy: 0.4749\n",
      "Epoch 634/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9703 - accuracy: 0.5857 - val_loss: 1.0945 - val_accuracy: 0.5354\n",
      "Epoch 635/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9743 - accuracy: 0.5835 - val_loss: 1.0966 - val_accuracy: 0.4918\n",
      "Epoch 636/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9796 - accuracy: 0.5796 - val_loss: 1.1862 - val_accuracy: 0.4533\n",
      "Epoch 637/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9868 - accuracy: 0.5909 - val_loss: 1.2493 - val_accuracy: 0.4626\n",
      "Epoch 638/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5419 - val_loss: 1.0948 - val_accuracy: 0.4985\n",
      "Epoch 639/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9790 - accuracy: 0.5774 - val_loss: 1.1079 - val_accuracy: 0.4949\n",
      "Epoch 640/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9774 - accuracy: 0.5936 - val_loss: 1.1709 - val_accuracy: 0.5067\n",
      "Epoch 641/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9682 - accuracy: 0.6011 - val_loss: 1.3439 - val_accuracy: 0.4856\n",
      "Epoch 642/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.5946 - val_loss: 1.1111 - val_accuracy: 0.5251\n",
      "Epoch 643/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9509 - accuracy: 0.6024 - val_loss: 1.1770 - val_accuracy: 0.4692\n",
      "Epoch 644/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9876 - accuracy: 0.5772 - val_loss: 1.1582 - val_accuracy: 0.4877\n",
      "Epoch 645/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9747 - accuracy: 0.5815 - val_loss: 1.4470 - val_accuracy: 0.4805\n",
      "Epoch 646/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9873 - accuracy: 0.5852 - val_loss: 1.2186 - val_accuracy: 0.4456\n",
      "Epoch 647/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9709 - accuracy: 0.5811 - val_loss: 1.1361 - val_accuracy: 0.4964\n",
      "Epoch 648/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9417 - accuracy: 0.6036 - val_loss: 1.1140 - val_accuracy: 0.4954\n",
      "Epoch 649/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9733 - accuracy: 0.5982 - val_loss: 1.1788 - val_accuracy: 0.5303\n",
      "Epoch 650/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9644 - accuracy: 0.5926 - val_loss: 1.1427 - val_accuracy: 0.4738\n",
      "Epoch 651/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9489 - accuracy: 0.5892 - val_loss: 1.2009 - val_accuracy: 0.4431\n",
      "Epoch 652/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9749 - accuracy: 0.5805 - val_loss: 1.1070 - val_accuracy: 0.5313\n",
      "Epoch 653/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9893 - accuracy: 0.5758 - val_loss: 1.1232 - val_accuracy: 0.5036\n",
      "Epoch 654/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9570 - accuracy: 0.5975 - val_loss: 1.1946 - val_accuracy: 0.4456\n",
      "Epoch 655/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9571 - accuracy: 0.5947 - val_loss: 1.1403 - val_accuracy: 0.4754\n",
      "Epoch 656/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9547 - accuracy: 0.5902 - val_loss: 1.1401 - val_accuracy: 0.4708\n",
      "Epoch 657/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0405 - accuracy: 0.5446 - val_loss: 1.1596 - val_accuracy: 0.4810\n",
      "Epoch 658/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9733 - accuracy: 0.5921 - val_loss: 1.1724 - val_accuracy: 0.5026\n",
      "Epoch 659/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9654 - accuracy: 0.5995 - val_loss: 1.1201 - val_accuracy: 0.5272\n",
      "Epoch 660/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9687 - accuracy: 0.5931 - val_loss: 1.1158 - val_accuracy: 0.5077\n",
      "Epoch 661/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9613 - accuracy: 0.5935 - val_loss: 1.1741 - val_accuracy: 0.5087\n",
      "Epoch 662/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9594 - accuracy: 0.5862 - val_loss: 1.2013 - val_accuracy: 0.4759\n",
      "Epoch 663/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9730 - accuracy: 0.5833 - val_loss: 1.2993 - val_accuracy: 0.4272\n",
      "Epoch 664/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0046 - accuracy: 0.5710 - val_loss: 1.1881 - val_accuracy: 0.4887\n",
      "Epoch 665/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9880 - accuracy: 0.5796 - val_loss: 1.1666 - val_accuracy: 0.5128\n",
      "Epoch 666/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9872 - accuracy: 0.5844 - val_loss: 1.1734 - val_accuracy: 0.5241\n",
      "Epoch 667/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9489 - accuracy: 0.5987 - val_loss: 1.2258 - val_accuracy: 0.4826\n",
      "Epoch 668/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9451 - accuracy: 0.5957 - val_loss: 1.2123 - val_accuracy: 0.4441\n",
      "Epoch 669/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9383 - accuracy: 0.5923 - val_loss: 1.1610 - val_accuracy: 0.4882\n",
      "Epoch 670/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.5850 - val_loss: 1.1412 - val_accuracy: 0.4692\n",
      "Epoch 671/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9777 - accuracy: 0.5804 - val_loss: 1.1533 - val_accuracy: 0.4621\n",
      "Epoch 672/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9522 - accuracy: 0.6034 - val_loss: 1.3194 - val_accuracy: 0.3749\n",
      "Epoch 673/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9658 - accuracy: 0.5930 - val_loss: 1.1975 - val_accuracy: 0.5041\n",
      "Epoch 674/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9513 - accuracy: 0.5970 - val_loss: 1.1482 - val_accuracy: 0.4821\n",
      "Epoch 675/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9607 - accuracy: 0.5986 - val_loss: 1.0968 - val_accuracy: 0.5169\n",
      "Epoch 676/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9849 - accuracy: 0.5667 - val_loss: 1.2957 - val_accuracy: 0.4282\n",
      "Epoch 677/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9820 - accuracy: 0.5895 - val_loss: 1.1837 - val_accuracy: 0.4959\n",
      "Epoch 678/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9518 - accuracy: 0.5997 - val_loss: 1.2098 - val_accuracy: 0.4703\n",
      "Epoch 679/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.5866 - val_loss: 1.7196 - val_accuracy: 0.3328\n",
      "Epoch 680/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0410 - accuracy: 0.5707 - val_loss: 1.1184 - val_accuracy: 0.5133\n",
      "Epoch 681/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9595 - accuracy: 0.5736 - val_loss: 1.1391 - val_accuracy: 0.4887\n",
      "Epoch 682/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9498 - accuracy: 0.5926 - val_loss: 1.2297 - val_accuracy: 0.4585\n",
      "Epoch 683/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9721 - accuracy: 0.5900 - val_loss: 1.1461 - val_accuracy: 0.4631\n",
      "Epoch 684/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9531 - accuracy: 0.5974 - val_loss: 1.1751 - val_accuracy: 0.4800\n",
      "Epoch 685/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9773 - accuracy: 0.5693 - val_loss: 1.2528 - val_accuracy: 0.4549\n",
      "Epoch 686/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0168 - accuracy: 0.5611 - val_loss: 1.1845 - val_accuracy: 0.4462\n",
      "Epoch 687/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9600 - accuracy: 0.5974 - val_loss: 1.2103 - val_accuracy: 0.4579\n",
      "Epoch 688/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.5846 - val_loss: 1.2136 - val_accuracy: 0.4241\n",
      "Epoch 689/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9700 - accuracy: 0.5765 - val_loss: 1.1513 - val_accuracy: 0.4846\n",
      "Epoch 690/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9736 - accuracy: 0.5759 - val_loss: 1.1547 - val_accuracy: 0.5041\n",
      "Epoch 691/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9778 - accuracy: 0.5868 - val_loss: 1.1330 - val_accuracy: 0.5236\n",
      "Epoch 692/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9549 - accuracy: 0.5931 - val_loss: 1.1440 - val_accuracy: 0.4764\n",
      "Epoch 693/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9581 - accuracy: 0.5914 - val_loss: 1.0947 - val_accuracy: 0.5241\n",
      "Epoch 694/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9526 - accuracy: 0.5901 - val_loss: 1.1646 - val_accuracy: 0.4944\n",
      "Epoch 695/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9762 - accuracy: 0.5913 - val_loss: 1.1894 - val_accuracy: 0.4846\n",
      "Epoch 696/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9604 - accuracy: 0.5910 - val_loss: 1.1550 - val_accuracy: 0.4908\n",
      "Epoch 697/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9806 - accuracy: 0.5848 - val_loss: 1.1618 - val_accuracy: 0.4713\n",
      "Epoch 698/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9732 - accuracy: 0.5873 - val_loss: 1.1177 - val_accuracy: 0.5036\n",
      "Epoch 699/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9435 - accuracy: 0.6017 - val_loss: 1.1216 - val_accuracy: 0.5128\n",
      "Epoch 700/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9894 - accuracy: 0.5915 - val_loss: 1.1930 - val_accuracy: 0.5138\n",
      "Epoch 701/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9484 - accuracy: 0.5939 - val_loss: 1.1435 - val_accuracy: 0.5026\n",
      "Epoch 702/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9584 - accuracy: 0.5889 - val_loss: 1.1579 - val_accuracy: 0.5185\n",
      "Epoch 703/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9787 - accuracy: 0.5876 - val_loss: 1.1520 - val_accuracy: 0.4887\n",
      "Epoch 704/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9461 - accuracy: 0.5978 - val_loss: 1.1587 - val_accuracy: 0.4774\n",
      "Epoch 705/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9666 - accuracy: 0.5862 - val_loss: 1.2053 - val_accuracy: 0.4656\n",
      "Epoch 706/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9535 - accuracy: 0.5965 - val_loss: 1.1535 - val_accuracy: 0.4856\n",
      "Epoch 707/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9495 - accuracy: 0.6013 - val_loss: 1.2656 - val_accuracy: 0.4308\n",
      "Epoch 708/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9646 - accuracy: 0.5894 - val_loss: 1.2148 - val_accuracy: 0.4913\n",
      "Epoch 709/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9847 - accuracy: 0.5793 - val_loss: 1.3073 - val_accuracy: 0.3903\n",
      "Epoch 710/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9733 - accuracy: 0.5888 - val_loss: 1.1814 - val_accuracy: 0.4554\n",
      "Epoch 711/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9545 - accuracy: 0.5947 - val_loss: 1.1277 - val_accuracy: 0.4887\n",
      "Epoch 712/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9465 - accuracy: 0.5952 - val_loss: 1.1169 - val_accuracy: 0.5359\n",
      "Epoch 713/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9621 - accuracy: 0.5758 - val_loss: 1.1740 - val_accuracy: 0.5231\n",
      "Epoch 714/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9385 - accuracy: 0.6045 - val_loss: 1.1931 - val_accuracy: 0.4785\n",
      "Epoch 715/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9649 - accuracy: 0.5728 - val_loss: 1.1875 - val_accuracy: 0.4651\n",
      "Epoch 716/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9847 - accuracy: 0.5641 - val_loss: 1.1114 - val_accuracy: 0.5097\n",
      "Epoch 717/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9594 - accuracy: 0.5922 - val_loss: 1.1962 - val_accuracy: 0.4892\n",
      "Epoch 718/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9942 - accuracy: 0.5766 - val_loss: 1.1852 - val_accuracy: 0.4456\n",
      "Epoch 719/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9422 - accuracy: 0.6143 - val_loss: 1.1304 - val_accuracy: 0.5118\n",
      "Epoch 720/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9688 - accuracy: 0.5902 - val_loss: 1.2693 - val_accuracy: 0.4128\n",
      "Epoch 721/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9710 - accuracy: 0.5849 - val_loss: 1.3678 - val_accuracy: 0.3759\n",
      "Epoch 722/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9526 - accuracy: 0.5904 - val_loss: 1.1646 - val_accuracy: 0.4615\n",
      "Epoch 723/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9430 - accuracy: 0.5923 - val_loss: 1.2880 - val_accuracy: 0.4154\n",
      "Epoch 724/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9681 - accuracy: 0.5726 - val_loss: 1.1842 - val_accuracy: 0.4533\n",
      "Epoch 725/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9604 - accuracy: 0.5832 - val_loss: 1.1947 - val_accuracy: 0.5251\n",
      "Epoch 726/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9710 - accuracy: 0.5893 - val_loss: 1.2957 - val_accuracy: 0.4313\n",
      "Epoch 727/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9370 - accuracy: 0.5938 - val_loss: 1.1124 - val_accuracy: 0.5123\n",
      "Epoch 728/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9574 - accuracy: 0.5925 - val_loss: 1.3434 - val_accuracy: 0.3667\n",
      "Epoch 729/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9578 - accuracy: 0.5820 - val_loss: 1.2112 - val_accuracy: 0.4954\n",
      "Epoch 730/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9606 - accuracy: 0.5933 - val_loss: 1.1817 - val_accuracy: 0.4708\n",
      "Epoch 731/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9653 - accuracy: 0.5896 - val_loss: 1.3333 - val_accuracy: 0.4267\n",
      "Epoch 732/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9823 - accuracy: 0.5808 - val_loss: 1.2167 - val_accuracy: 0.4651\n",
      "Epoch 733/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9912 - accuracy: 0.5774 - val_loss: 1.1397 - val_accuracy: 0.5282\n",
      "Epoch 734/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9647 - accuracy: 0.5901 - val_loss: 1.2558 - val_accuracy: 0.4000\n",
      "Epoch 735/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9889 - accuracy: 0.5769 - val_loss: 1.2018 - val_accuracy: 0.4374\n",
      "Epoch 736/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9352 - accuracy: 0.5928 - val_loss: 1.2507 - val_accuracy: 0.4692\n",
      "Epoch 737/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9227 - accuracy: 0.6187 - val_loss: 1.1429 - val_accuracy: 0.5144\n",
      "Epoch 738/1000\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.9459 - accuracy: 0.6065 - val_loss: 1.1490 - val_accuracy: 0.4733\n",
      "Epoch 739/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9398 - accuracy: 0.6017 - val_loss: 1.2876 - val_accuracy: 0.4369\n",
      "Epoch 740/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9551 - accuracy: 0.5961 - val_loss: 1.1747 - val_accuracy: 0.4764\n",
      "Epoch 741/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9299 - accuracy: 0.6045 - val_loss: 1.1682 - val_accuracy: 0.4923\n",
      "Epoch 742/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9719 - accuracy: 0.5923 - val_loss: 1.1086 - val_accuracy: 0.5236\n",
      "Epoch 743/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9454 - accuracy: 0.5982 - val_loss: 1.1551 - val_accuracy: 0.4846\n",
      "Epoch 744/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9584 - accuracy: 0.5915 - val_loss: 1.1399 - val_accuracy: 0.5041\n",
      "Epoch 745/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9383 - accuracy: 0.5999 - val_loss: 1.1312 - val_accuracy: 0.5118\n",
      "Epoch 746/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9327 - accuracy: 0.5998 - val_loss: 1.1728 - val_accuracy: 0.4744\n",
      "Epoch 747/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9315 - accuracy: 0.6096 - val_loss: 1.1298 - val_accuracy: 0.5138\n",
      "Epoch 748/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9464 - accuracy: 0.6067 - val_loss: 1.1530 - val_accuracy: 0.4959\n",
      "Epoch 749/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9509 - accuracy: 0.5867 - val_loss: 1.1633 - val_accuracy: 0.4887\n",
      "Epoch 750/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9372 - accuracy: 0.6031 - val_loss: 1.1280 - val_accuracy: 0.5221\n",
      "Epoch 751/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9387 - accuracy: 0.5980 - val_loss: 1.2878 - val_accuracy: 0.4292\n",
      "Epoch 752/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9478 - accuracy: 0.5886 - val_loss: 1.1377 - val_accuracy: 0.4903\n",
      "Epoch 753/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9609 - accuracy: 0.5753 - val_loss: 1.1688 - val_accuracy: 0.5092\n",
      "Epoch 754/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9831 - accuracy: 0.5819 - val_loss: 1.1357 - val_accuracy: 0.5036\n",
      "Epoch 755/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9378 - accuracy: 0.6026 - val_loss: 1.3278 - val_accuracy: 0.4267\n",
      "Epoch 756/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9538 - accuracy: 0.6042 - val_loss: 1.1531 - val_accuracy: 0.4636\n",
      "Epoch 757/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9304 - accuracy: 0.6064 - val_loss: 1.2454 - val_accuracy: 0.4210\n",
      "Epoch 758/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9491 - accuracy: 0.5893 - val_loss: 1.1521 - val_accuracy: 0.4867\n",
      "Epoch 759/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9514 - accuracy: 0.5821 - val_loss: 1.1620 - val_accuracy: 0.4574\n",
      "Epoch 760/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9464 - accuracy: 0.5910 - val_loss: 1.1542 - val_accuracy: 0.5241\n",
      "Epoch 761/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9930 - accuracy: 0.5775 - val_loss: 1.1903 - val_accuracy: 0.4564\n",
      "Epoch 762/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9439 - accuracy: 0.5897 - val_loss: 1.1893 - val_accuracy: 0.4933\n",
      "Epoch 763/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9386 - accuracy: 0.6122 - val_loss: 1.1850 - val_accuracy: 0.5179\n",
      "Epoch 764/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9512 - accuracy: 0.5948 - val_loss: 1.2087 - val_accuracy: 0.4805\n",
      "Epoch 765/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9453 - accuracy: 0.6026 - val_loss: 1.3399 - val_accuracy: 0.4159\n",
      "Epoch 766/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9538 - accuracy: 0.5929 - val_loss: 1.1384 - val_accuracy: 0.5026\n",
      "Epoch 767/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9668 - accuracy: 0.5846 - val_loss: 1.1566 - val_accuracy: 0.4908\n",
      "Epoch 768/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0089 - accuracy: 0.5652 - val_loss: 1.1541 - val_accuracy: 0.4785\n",
      "Epoch 769/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9586 - accuracy: 0.5836 - val_loss: 1.1269 - val_accuracy: 0.4923\n",
      "Epoch 770/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9514 - accuracy: 0.5915 - val_loss: 1.1314 - val_accuracy: 0.5000\n",
      "Epoch 771/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9477 - accuracy: 0.5917 - val_loss: 1.1164 - val_accuracy: 0.5236\n",
      "Epoch 772/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9426 - accuracy: 0.6091 - val_loss: 1.1341 - val_accuracy: 0.5262\n",
      "Epoch 773/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9819 - accuracy: 0.5792 - val_loss: 1.1449 - val_accuracy: 0.4826\n",
      "Epoch 774/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9401 - accuracy: 0.5984 - val_loss: 1.1481 - val_accuracy: 0.5221\n",
      "Epoch 775/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9622 - accuracy: 0.5958 - val_loss: 1.1638 - val_accuracy: 0.4754\n",
      "Epoch 776/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9634 - accuracy: 0.5862 - val_loss: 1.1207 - val_accuracy: 0.4903\n",
      "Epoch 777/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9837 - accuracy: 0.5724 - val_loss: 1.1988 - val_accuracy: 0.5051\n",
      "Epoch 778/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9426 - accuracy: 0.5962 - val_loss: 1.1131 - val_accuracy: 0.4979\n",
      "Epoch 779/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9380 - accuracy: 0.6095 - val_loss: 1.1396 - val_accuracy: 0.5221\n",
      "Epoch 780/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9557 - accuracy: 0.5971 - val_loss: 1.1780 - val_accuracy: 0.4913\n",
      "Epoch 781/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9469 - accuracy: 0.6079 - val_loss: 1.1321 - val_accuracy: 0.5267\n",
      "Epoch 782/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.5835 - val_loss: 1.3312 - val_accuracy: 0.4200\n",
      "Epoch 783/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9595 - accuracy: 0.5868 - val_loss: 1.1892 - val_accuracy: 0.4682\n",
      "Epoch 784/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0736 - accuracy: 0.5414 - val_loss: 1.2745 - val_accuracy: 0.4087\n",
      "Epoch 785/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9862 - accuracy: 0.5646 - val_loss: 1.1308 - val_accuracy: 0.4785\n",
      "Epoch 786/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9635 - accuracy: 0.5893 - val_loss: 1.3044 - val_accuracy: 0.4195\n",
      "Epoch 787/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9439 - accuracy: 0.6057 - val_loss: 1.1312 - val_accuracy: 0.5200\n",
      "Epoch 788/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9645 - accuracy: 0.5801 - val_loss: 1.1145 - val_accuracy: 0.5241\n",
      "Epoch 789/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9544 - accuracy: 0.5992 - val_loss: 1.1411 - val_accuracy: 0.4990\n",
      "Epoch 790/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9532 - accuracy: 0.5951 - val_loss: 1.1500 - val_accuracy: 0.5185\n",
      "Epoch 791/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9896 - accuracy: 0.5886 - val_loss: 1.1199 - val_accuracy: 0.5205\n",
      "Epoch 792/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9471 - accuracy: 0.5869 - val_loss: 1.2076 - val_accuracy: 0.4713\n",
      "Epoch 793/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9281 - accuracy: 0.6060 - val_loss: 1.1329 - val_accuracy: 0.5185\n",
      "Epoch 794/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9421 - accuracy: 0.5953 - val_loss: 1.2697 - val_accuracy: 0.4487\n",
      "Epoch 795/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9457 - accuracy: 0.6003 - val_loss: 1.1818 - val_accuracy: 0.5082\n",
      "Epoch 796/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9397 - accuracy: 0.5912 - val_loss: 1.2173 - val_accuracy: 0.4662\n",
      "Epoch 797/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9332 - accuracy: 0.6109 - val_loss: 1.1519 - val_accuracy: 0.5303\n",
      "Epoch 798/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9504 - accuracy: 0.5923 - val_loss: 1.2437 - val_accuracy: 0.4138\n",
      "Epoch 799/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9426 - accuracy: 0.5933 - val_loss: 1.1853 - val_accuracy: 0.4585\n",
      "Epoch 800/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9361 - accuracy: 0.5952 - val_loss: 1.1606 - val_accuracy: 0.4764\n",
      "Epoch 801/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9704 - accuracy: 0.5909 - val_loss: 1.1449 - val_accuracy: 0.5246\n",
      "Epoch 802/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9607 - accuracy: 0.5984 - val_loss: 1.2906 - val_accuracy: 0.4000\n",
      "Epoch 803/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.6127 - val_loss: 1.1672 - val_accuracy: 0.5190\n",
      "Epoch 804/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9287 - accuracy: 0.6081 - val_loss: 1.2617 - val_accuracy: 0.4205\n",
      "Epoch 805/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9327 - accuracy: 0.6072 - val_loss: 1.1579 - val_accuracy: 0.5221\n",
      "Epoch 806/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9418 - accuracy: 0.5956 - val_loss: 1.3108 - val_accuracy: 0.4026\n",
      "Epoch 807/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9391 - accuracy: 0.5997 - val_loss: 1.2930 - val_accuracy: 0.4169\n",
      "Epoch 808/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9470 - accuracy: 0.6050 - val_loss: 1.1558 - val_accuracy: 0.5256\n",
      "Epoch 809/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9661 - accuracy: 0.5881 - val_loss: 1.1583 - val_accuracy: 0.4928\n",
      "Epoch 810/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9757 - accuracy: 0.5797 - val_loss: 1.1739 - val_accuracy: 0.4810\n",
      "Epoch 811/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9500 - accuracy: 0.5863 - val_loss: 1.2801 - val_accuracy: 0.4200\n",
      "Epoch 812/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9416 - accuracy: 0.5944 - val_loss: 1.1138 - val_accuracy: 0.4887\n",
      "Epoch 813/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9796 - accuracy: 0.5889 - val_loss: 1.1224 - val_accuracy: 0.5118\n",
      "Epoch 814/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9497 - accuracy: 0.5972 - val_loss: 1.2136 - val_accuracy: 0.4969\n",
      "Epoch 815/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9461 - accuracy: 0.5869 - val_loss: 1.1552 - val_accuracy: 0.4692\n",
      "Epoch 816/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.6042 - val_loss: 1.1741 - val_accuracy: 0.5118\n",
      "Epoch 817/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9365 - accuracy: 0.6006 - val_loss: 1.1982 - val_accuracy: 0.4826\n",
      "Epoch 818/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9558 - accuracy: 0.5815 - val_loss: 1.1548 - val_accuracy: 0.5062\n",
      "Epoch 819/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9659 - accuracy: 0.5820 - val_loss: 1.2570 - val_accuracy: 0.4256\n",
      "Epoch 820/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9569 - accuracy: 0.5925 - val_loss: 1.1764 - val_accuracy: 0.4990\n",
      "Epoch 821/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9694 - accuracy: 0.5912 - val_loss: 1.2012 - val_accuracy: 0.4590\n",
      "Epoch 822/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9449 - accuracy: 0.5955 - val_loss: 1.2289 - val_accuracy: 0.4744\n",
      "Epoch 823/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9384 - accuracy: 0.5948 - val_loss: 1.2336 - val_accuracy: 0.4959\n",
      "Epoch 824/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9228 - accuracy: 0.6116 - val_loss: 1.1973 - val_accuracy: 0.4508\n",
      "Epoch 825/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9295 - accuracy: 0.6060 - val_loss: 1.1901 - val_accuracy: 0.5390\n",
      "Epoch 826/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9177 - accuracy: 0.6162 - val_loss: 1.2885 - val_accuracy: 0.4646\n",
      "Epoch 827/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9453 - accuracy: 0.5820 - val_loss: 1.1818 - val_accuracy: 0.4662\n",
      "Epoch 828/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9800 - accuracy: 0.5801 - val_loss: 1.1603 - val_accuracy: 0.5179\n",
      "Epoch 829/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9472 - accuracy: 0.5922 - val_loss: 1.1675 - val_accuracy: 0.5103\n",
      "Epoch 830/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9520 - accuracy: 0.5967 - val_loss: 1.1857 - val_accuracy: 0.5021\n",
      "Epoch 831/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.5944 - val_loss: 1.1643 - val_accuracy: 0.5241\n",
      "Epoch 832/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9591 - accuracy: 0.5841 - val_loss: 1.2008 - val_accuracy: 0.4569\n",
      "Epoch 833/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9513 - accuracy: 0.5895 - val_loss: 1.1208 - val_accuracy: 0.5041\n",
      "Epoch 834/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9438 - accuracy: 0.5975 - val_loss: 1.2146 - val_accuracy: 0.4467\n",
      "Epoch 835/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9785 - accuracy: 0.5834 - val_loss: 1.1798 - val_accuracy: 0.5015\n",
      "Epoch 836/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9508 - accuracy: 0.5849 - val_loss: 1.1467 - val_accuracy: 0.5123\n",
      "Epoch 837/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9555 - accuracy: 0.5923 - val_loss: 1.1900 - val_accuracy: 0.4728\n",
      "Epoch 838/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9363 - accuracy: 0.6067 - val_loss: 1.1812 - val_accuracy: 0.5241\n",
      "Epoch 839/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0353 - accuracy: 0.5501 - val_loss: 1.4628 - val_accuracy: 0.3338\n",
      "Epoch 840/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9978 - accuracy: 0.5743 - val_loss: 1.4511 - val_accuracy: 0.3405\n",
      "Epoch 841/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9723 - accuracy: 0.5817 - val_loss: 1.1088 - val_accuracy: 0.4954\n",
      "Epoch 842/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9451 - accuracy: 0.5960 - val_loss: 1.1305 - val_accuracy: 0.5026\n",
      "Epoch 843/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9668 - accuracy: 0.5909 - val_loss: 1.2787 - val_accuracy: 0.4113\n",
      "Epoch 844/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9543 - accuracy: 0.5930 - val_loss: 1.1150 - val_accuracy: 0.5133\n",
      "Epoch 845/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9377 - accuracy: 0.5991 - val_loss: 1.1420 - val_accuracy: 0.5067\n",
      "Epoch 846/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9553 - accuracy: 0.5966 - val_loss: 1.1387 - val_accuracy: 0.5015\n",
      "Epoch 847/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9464 - accuracy: 0.5972 - val_loss: 1.2111 - val_accuracy: 0.4333\n",
      "Epoch 848/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9272 - accuracy: 0.6081 - val_loss: 1.1201 - val_accuracy: 0.4769\n",
      "Epoch 849/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9385 - accuracy: 0.5969 - val_loss: 1.1859 - val_accuracy: 0.4595\n",
      "Epoch 850/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.6052 - val_loss: 1.2373 - val_accuracy: 0.4138\n",
      "Epoch 851/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9784 - accuracy: 0.5747 - val_loss: 1.1022 - val_accuracy: 0.4959\n",
      "Epoch 852/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9544 - accuracy: 0.5800 - val_loss: 1.1476 - val_accuracy: 0.5087\n",
      "Epoch 853/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9428 - accuracy: 0.5946 - val_loss: 1.1027 - val_accuracy: 0.5251\n",
      "Epoch 854/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9514 - accuracy: 0.5906 - val_loss: 1.1121 - val_accuracy: 0.5179\n",
      "Epoch 855/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9105 - accuracy: 0.6142 - val_loss: 1.1634 - val_accuracy: 0.4667\n",
      "Epoch 856/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9184 - accuracy: 0.5990 - val_loss: 1.1314 - val_accuracy: 0.5103\n",
      "Epoch 857/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9464 - accuracy: 0.5954 - val_loss: 1.1345 - val_accuracy: 0.4969\n",
      "Epoch 858/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9419 - accuracy: 0.6001 - val_loss: 1.3066 - val_accuracy: 0.4256\n",
      "Epoch 859/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9519 - accuracy: 0.5995 - val_loss: 1.1775 - val_accuracy: 0.4826\n",
      "Epoch 860/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9501 - accuracy: 0.6015 - val_loss: 1.2886 - val_accuracy: 0.4077\n",
      "Epoch 861/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9412 - accuracy: 0.6022 - val_loss: 1.2021 - val_accuracy: 0.4744\n",
      "Epoch 862/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9322 - accuracy: 0.6119 - val_loss: 1.2870 - val_accuracy: 0.4195\n",
      "Epoch 863/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9564 - accuracy: 0.5906 - val_loss: 1.1386 - val_accuracy: 0.5118\n",
      "Epoch 864/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9773 - accuracy: 0.5747 - val_loss: 1.1706 - val_accuracy: 0.4744\n",
      "Epoch 865/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9265 - accuracy: 0.6015 - val_loss: 1.1513 - val_accuracy: 0.4831\n",
      "Epoch 866/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9587 - accuracy: 0.5861 - val_loss: 1.1635 - val_accuracy: 0.4713\n",
      "Epoch 867/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9636 - accuracy: 0.5890 - val_loss: 1.1475 - val_accuracy: 0.4877\n",
      "Epoch 868/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9117 - accuracy: 0.6167 - val_loss: 1.1402 - val_accuracy: 0.5344\n",
      "Epoch 869/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.5994 - val_loss: 1.1943 - val_accuracy: 0.4344\n",
      "Epoch 870/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9317 - accuracy: 0.6140 - val_loss: 1.1102 - val_accuracy: 0.5241\n",
      "Epoch 871/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9385 - accuracy: 0.5972 - val_loss: 1.2137 - val_accuracy: 0.4210\n",
      "Epoch 872/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9446 - accuracy: 0.5894 - val_loss: 1.1404 - val_accuracy: 0.4779\n",
      "Epoch 873/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9659 - accuracy: 0.5974 - val_loss: 1.1571 - val_accuracy: 0.4944\n",
      "Epoch 874/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9583 - accuracy: 0.5859 - val_loss: 1.2949 - val_accuracy: 0.4123\n",
      "Epoch 875/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9475 - accuracy: 0.5985 - val_loss: 1.1150 - val_accuracy: 0.4877\n",
      "Epoch 876/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.6042 - val_loss: 1.1258 - val_accuracy: 0.4979\n",
      "Epoch 877/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9438 - accuracy: 0.5947 - val_loss: 1.2140 - val_accuracy: 0.4508\n",
      "Epoch 878/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9471 - accuracy: 0.5880 - val_loss: 1.1954 - val_accuracy: 0.4851\n",
      "Epoch 879/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9724 - accuracy: 0.5824 - val_loss: 1.1184 - val_accuracy: 0.4949\n",
      "Epoch 880/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9200 - accuracy: 0.6076 - val_loss: 1.2262 - val_accuracy: 0.4446\n",
      "Epoch 881/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9499 - accuracy: 0.6036 - val_loss: 1.1086 - val_accuracy: 0.5185\n",
      "Epoch 882/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9557 - accuracy: 0.5862 - val_loss: 1.1460 - val_accuracy: 0.4713\n",
      "Epoch 883/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9213 - accuracy: 0.6168 - val_loss: 1.1506 - val_accuracy: 0.4810\n",
      "Epoch 884/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9362 - accuracy: 0.5923 - val_loss: 1.1274 - val_accuracy: 0.5123\n",
      "Epoch 885/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9337 - accuracy: 0.6035 - val_loss: 1.1286 - val_accuracy: 0.4851\n",
      "Epoch 886/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9427 - accuracy: 0.5986 - val_loss: 1.0961 - val_accuracy: 0.5010\n",
      "Epoch 887/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9478 - accuracy: 0.5950 - val_loss: 1.1660 - val_accuracy: 0.4887\n",
      "Epoch 888/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.5659 - val_loss: 1.3470 - val_accuracy: 0.3995\n",
      "Epoch 889/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9410 - accuracy: 0.6044 - val_loss: 1.1161 - val_accuracy: 0.5215\n",
      "Epoch 890/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9513 - accuracy: 0.6005 - val_loss: 1.1398 - val_accuracy: 0.4882\n",
      "Epoch 891/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9218 - accuracy: 0.6144 - val_loss: 1.1915 - val_accuracy: 0.4277\n",
      "Epoch 892/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9374 - accuracy: 0.6004 - val_loss: 1.3762 - val_accuracy: 0.3846\n",
      "Epoch 893/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9252 - accuracy: 0.6055 - val_loss: 1.1549 - val_accuracy: 0.4933\n",
      "Epoch 894/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9302 - accuracy: 0.6066 - val_loss: 1.1343 - val_accuracy: 0.4882\n",
      "Epoch 895/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9401 - accuracy: 0.6049 - val_loss: 1.1233 - val_accuracy: 0.5113\n",
      "Epoch 896/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9328 - accuracy: 0.6012 - val_loss: 1.1738 - val_accuracy: 0.4574\n",
      "Epoch 897/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9705 - accuracy: 0.5833 - val_loss: 1.2111 - val_accuracy: 0.4174\n",
      "Epoch 898/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9539 - accuracy: 0.5816 - val_loss: 1.1179 - val_accuracy: 0.4882\n",
      "Epoch 899/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9402 - accuracy: 0.5911 - val_loss: 1.1100 - val_accuracy: 0.5374\n",
      "Epoch 900/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9468 - accuracy: 0.6021 - val_loss: 1.1791 - val_accuracy: 0.4708\n",
      "Epoch 901/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9356 - accuracy: 0.5977 - val_loss: 1.1298 - val_accuracy: 0.4882\n",
      "Epoch 902/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9631 - accuracy: 0.5828 - val_loss: 1.1278 - val_accuracy: 0.5272\n",
      "Epoch 903/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9240 - accuracy: 0.6041 - val_loss: 1.1990 - val_accuracy: 0.4564\n",
      "Epoch 904/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9723 - accuracy: 0.5926 - val_loss: 1.1127 - val_accuracy: 0.4959\n",
      "Epoch 905/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9614 - accuracy: 0.5816 - val_loss: 1.1350 - val_accuracy: 0.5082\n",
      "Epoch 906/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9248 - accuracy: 0.6060 - val_loss: 1.1250 - val_accuracy: 0.5082\n",
      "Epoch 907/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9358 - accuracy: 0.6036 - val_loss: 1.1294 - val_accuracy: 0.5123\n",
      "Epoch 908/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9636 - accuracy: 0.5948 - val_loss: 1.1248 - val_accuracy: 0.5179\n",
      "Epoch 909/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9639 - accuracy: 0.5994 - val_loss: 1.1725 - val_accuracy: 0.4533\n",
      "Epoch 910/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9240 - accuracy: 0.6109 - val_loss: 1.1454 - val_accuracy: 0.4846\n",
      "Epoch 911/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9245 - accuracy: 0.5989 - val_loss: 1.1265 - val_accuracy: 0.4769\n",
      "Epoch 912/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9226 - accuracy: 0.6000 - val_loss: 1.1912 - val_accuracy: 0.4569\n",
      "Epoch 913/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9451 - accuracy: 0.6061 - val_loss: 1.1249 - val_accuracy: 0.5379\n",
      "Epoch 914/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9331 - accuracy: 0.6047 - val_loss: 1.1849 - val_accuracy: 0.4354\n",
      "Epoch 915/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9290 - accuracy: 0.6059 - val_loss: 1.1324 - val_accuracy: 0.5174\n",
      "Epoch 916/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9350 - accuracy: 0.6032 - val_loss: 1.2321 - val_accuracy: 0.4067\n",
      "Epoch 917/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9285 - accuracy: 0.6082 - val_loss: 1.1707 - val_accuracy: 0.4979\n",
      "Epoch 918/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9298 - accuracy: 0.6032 - val_loss: 1.1666 - val_accuracy: 0.4836\n",
      "Epoch 919/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9514 - accuracy: 0.6030 - val_loss: 1.1243 - val_accuracy: 0.5108\n",
      "Epoch 920/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9069 - accuracy: 0.6194 - val_loss: 1.2195 - val_accuracy: 0.4241\n",
      "Epoch 921/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9105 - accuracy: 0.6146 - val_loss: 1.2077 - val_accuracy: 0.4856\n",
      "Epoch 922/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9225 - accuracy: 0.6074 - val_loss: 1.1430 - val_accuracy: 0.4892\n",
      "Epoch 923/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9240 - accuracy: 0.6051 - val_loss: 1.1702 - val_accuracy: 0.4436\n",
      "Epoch 924/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9543 - accuracy: 0.6013 - val_loss: 1.1319 - val_accuracy: 0.4954\n",
      "Epoch 925/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9079 - accuracy: 0.6077 - val_loss: 1.1450 - val_accuracy: 0.4826\n",
      "Epoch 926/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9266 - accuracy: 0.5879 - val_loss: 1.1600 - val_accuracy: 0.4672\n",
      "Epoch 927/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9278 - accuracy: 0.6120 - val_loss: 1.1140 - val_accuracy: 0.5046\n",
      "Epoch 928/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9439 - accuracy: 0.5862 - val_loss: 1.1591 - val_accuracy: 0.5267\n",
      "Epoch 929/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9844 - accuracy: 0.5842 - val_loss: 1.1554 - val_accuracy: 0.4800\n",
      "Epoch 930/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9415 - accuracy: 0.6006 - val_loss: 1.1368 - val_accuracy: 0.5056\n",
      "Epoch 931/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9638 - accuracy: 0.5844 - val_loss: 1.1515 - val_accuracy: 0.4938\n",
      "Epoch 932/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9217 - accuracy: 0.6058 - val_loss: 1.2860 - val_accuracy: 0.4318\n",
      "Epoch 933/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9327 - accuracy: 0.6059 - val_loss: 1.1466 - val_accuracy: 0.4903\n",
      "Epoch 934/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9550 - accuracy: 0.5897 - val_loss: 1.1439 - val_accuracy: 0.4656\n",
      "Epoch 935/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9430 - accuracy: 0.5931 - val_loss: 1.2120 - val_accuracy: 0.4497\n",
      "Epoch 936/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9401 - accuracy: 0.5988 - val_loss: 1.1448 - val_accuracy: 0.4836\n",
      "Epoch 937/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9070 - accuracy: 0.6098 - val_loss: 1.5024 - val_accuracy: 0.3508\n",
      "Epoch 938/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9432 - accuracy: 0.6073 - val_loss: 1.1184 - val_accuracy: 0.5067\n",
      "Epoch 939/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9115 - accuracy: 0.6124 - val_loss: 1.1462 - val_accuracy: 0.5354\n",
      "Epoch 940/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9796 - accuracy: 0.5915 - val_loss: 1.1788 - val_accuracy: 0.4605\n",
      "Epoch 941/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9329 - accuracy: 0.6010 - val_loss: 1.1544 - val_accuracy: 0.4790\n",
      "Epoch 942/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9762 - accuracy: 0.5807 - val_loss: 1.2042 - val_accuracy: 0.4651\n",
      "Epoch 943/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9441 - accuracy: 0.5932 - val_loss: 1.1096 - val_accuracy: 0.5082\n",
      "Epoch 944/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9177 - accuracy: 0.6163 - val_loss: 1.1663 - val_accuracy: 0.4933\n",
      "Epoch 945/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9952 - accuracy: 0.5769 - val_loss: 1.6220 - val_accuracy: 0.3082\n",
      "Epoch 946/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9478 - accuracy: 0.5960 - val_loss: 1.1660 - val_accuracy: 0.4846\n",
      "Epoch 947/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9369 - accuracy: 0.5990 - val_loss: 1.1407 - val_accuracy: 0.4815\n",
      "Epoch 948/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9227 - accuracy: 0.6123 - val_loss: 1.1892 - val_accuracy: 0.4795\n",
      "Epoch 949/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9066 - accuracy: 0.6155 - val_loss: 1.1624 - val_accuracy: 0.4733\n",
      "Epoch 950/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9383 - accuracy: 0.6039 - val_loss: 1.1216 - val_accuracy: 0.5108\n",
      "Epoch 951/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9398 - accuracy: 0.5939 - val_loss: 1.1534 - val_accuracy: 0.4626\n",
      "Epoch 952/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9318 - accuracy: 0.5965 - val_loss: 1.2386 - val_accuracy: 0.4308\n",
      "Epoch 953/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9230 - accuracy: 0.6070 - val_loss: 1.1527 - val_accuracy: 0.4969\n",
      "Epoch 954/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9689 - accuracy: 0.5841 - val_loss: 1.1370 - val_accuracy: 0.4862\n",
      "Epoch 955/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9248 - accuracy: 0.6031 - val_loss: 1.1838 - val_accuracy: 0.4795\n",
      "Epoch 956/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9248 - accuracy: 0.5982 - val_loss: 1.2010 - val_accuracy: 0.4544\n",
      "Epoch 957/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9232 - accuracy: 0.6010 - val_loss: 1.1300 - val_accuracy: 0.4795\n",
      "Epoch 958/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9283 - accuracy: 0.6041 - val_loss: 1.1144 - val_accuracy: 0.5056\n",
      "Epoch 959/1000\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9317 - accuracy: 0.60 - 0s 2ms/step - loss: 0.9321 - accuracy: 0.6076 - val_loss: 1.1607 - val_accuracy: 0.4933\n",
      "Epoch 960/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9340 - accuracy: 0.6009 - val_loss: 1.3596 - val_accuracy: 0.3564\n",
      "Epoch 961/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9440 - accuracy: 0.5938 - val_loss: 1.1151 - val_accuracy: 0.5000\n",
      "Epoch 962/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9381 - accuracy: 0.6065 - val_loss: 1.1486 - val_accuracy: 0.5051\n",
      "Epoch 963/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9198 - accuracy: 0.5999 - val_loss: 1.1730 - val_accuracy: 0.5231\n",
      "Epoch 964/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9229 - accuracy: 0.6088 - val_loss: 1.2287 - val_accuracy: 0.4400\n",
      "Epoch 965/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9181 - accuracy: 0.6101 - val_loss: 1.1865 - val_accuracy: 0.4462\n",
      "Epoch 966/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9444 - accuracy: 0.5936 - val_loss: 1.1792 - val_accuracy: 0.4610\n",
      "Epoch 967/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9177 - accuracy: 0.6031 - val_loss: 1.1303 - val_accuracy: 0.5067\n",
      "Epoch 968/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9180 - accuracy: 0.6116 - val_loss: 1.2682 - val_accuracy: 0.4056\n",
      "Epoch 969/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9332 - accuracy: 0.5955 - val_loss: 1.1924 - val_accuracy: 0.4554\n",
      "Epoch 970/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9030 - accuracy: 0.6038 - val_loss: 1.2167 - val_accuracy: 0.4282\n",
      "Epoch 971/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9195 - accuracy: 0.6099 - val_loss: 1.2166 - val_accuracy: 0.5215\n",
      "Epoch 972/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9494 - accuracy: 0.5961 - val_loss: 1.3629 - val_accuracy: 0.3959\n",
      "Epoch 973/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9265 - accuracy: 0.6027 - val_loss: 1.1285 - val_accuracy: 0.4672\n",
      "Epoch 974/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9135 - accuracy: 0.6092 - val_loss: 1.1672 - val_accuracy: 0.4708\n",
      "Epoch 975/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9237 - accuracy: 0.6040 - val_loss: 1.1966 - val_accuracy: 0.4538\n",
      "Epoch 976/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9039 - accuracy: 0.6053 - val_loss: 1.1522 - val_accuracy: 0.5036\n",
      "Epoch 977/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9150 - accuracy: 0.6049 - val_loss: 1.1645 - val_accuracy: 0.4733\n",
      "Epoch 978/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9329 - accuracy: 0.6137 - val_loss: 1.2909 - val_accuracy: 0.4323\n",
      "Epoch 979/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9301 - accuracy: 0.5939 - val_loss: 1.1516 - val_accuracy: 0.5062\n",
      "Epoch 980/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9093 - accuracy: 0.6190 - val_loss: 1.1719 - val_accuracy: 0.4759\n",
      "Epoch 981/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9641 - accuracy: 0.5836 - val_loss: 1.1509 - val_accuracy: 0.4810\n",
      "Epoch 982/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9203 - accuracy: 0.6097 - val_loss: 1.4637 - val_accuracy: 0.3749\n",
      "Epoch 983/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9225 - accuracy: 0.5993 - val_loss: 1.1520 - val_accuracy: 0.5021\n",
      "Epoch 984/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9070 - accuracy: 0.6114 - val_loss: 1.4308 - val_accuracy: 0.3738\n",
      "Epoch 985/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9204 - accuracy: 0.6124 - val_loss: 1.1700 - val_accuracy: 0.4544\n",
      "Epoch 986/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9631 - accuracy: 0.5924 - val_loss: 1.1900 - val_accuracy: 0.4754\n",
      "Epoch 987/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9433 - accuracy: 0.5984 - val_loss: 1.1563 - val_accuracy: 0.4569\n",
      "Epoch 988/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9355 - accuracy: 0.5978 - val_loss: 1.2672 - val_accuracy: 0.4323\n",
      "Epoch 989/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9267 - accuracy: 0.6072 - val_loss: 1.1153 - val_accuracy: 0.5051\n",
      "Epoch 990/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9571 - accuracy: 0.5924 - val_loss: 1.1341 - val_accuracy: 0.4867\n",
      "Epoch 991/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9060 - accuracy: 0.6156 - val_loss: 1.2044 - val_accuracy: 0.4662\n",
      "Epoch 992/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9157 - accuracy: 0.6114 - val_loss: 1.1761 - val_accuracy: 0.5092\n",
      "Epoch 993/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 1.0446 - accuracy: 0.5649 - val_loss: 1.2520 - val_accuracy: 0.4226\n",
      "Epoch 994/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9579 - accuracy: 0.5876 - val_loss: 1.1719 - val_accuracy: 0.4574\n",
      "Epoch 995/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9393 - accuracy: 0.6046 - val_loss: 1.1618 - val_accuracy: 0.4933\n",
      "Epoch 996/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9280 - accuracy: 0.5998 - val_loss: 1.2582 - val_accuracy: 0.4523\n",
      "Epoch 997/1000\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.9431 - accuracy: 0.5972 - val_loss: 1.2183 - val_accuracy: 0.4764\n",
      "Epoch 998/1000\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.9231 - accuracy: 0.6049 - val_loss: 1.1356 - val_accuracy: 0.4867\n",
      "Epoch 999/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9071 - accuracy: 0.6177 - val_loss: 1.2165 - val_accuracy: 0.4467\n",
      "Epoch 1000/1000\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.9680 - accuracy: 0.5829 - val_loss: 1.1172 - val_accuracy: 0.5256\n"
     ]
    }
   ],
   "source": [
    "model_all_3 = keras.models.Sequential()\n",
    "\n",
    "model_all_3.add(keras.layers.Dense(units = 64,input_dim = 11,activation = 'relu'))\n",
    "\n",
    "model_all_3.add(keras.layers.Dense(units = 32,input_dim = 11,activation = 'relu'))\n",
    "model_all_3.add(keras.layers.Dense(units = 20,input_dim = 11,activation = 'relu'))\n",
    "\n",
    "model_all_3.add(BatchNormalization())\n",
    "model_all_3.add(keras.layers.Dense(units = 11,activation = 'softmax'))\n",
    "\n",
    "model_all_3.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_all_3.summary()\n",
    "\n",
    "\n",
    "hist_3 = model_all_3.fit(X_train,Y_train,epochs=1000,batch_size=64,validation_data = (X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "acc_ax = ax1.twinx()\n",
    "\n",
    "ax1.plot(hist_3.history['loss'], 'y', label='train loss')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('loss')\n",
    "\n",
    "\n",
    "ax2.plot(hist_3.history['val_loss'], 'r', label='val loss')\n",
    "ax2.set_ylabel('val_loss')\n",
    "\n",
    "\n",
    "ax3.plot(hist_3.history['accuracy'], 'b', label='accuracy')\n",
    "ax3.set_ylabel('accuray')\n",
    "\n",
    "ax4.plot(hist_3.history['val_accuracy'], 'g', label='val_accuracy')\n",
    "ax4.set_ylabel('val_accuracy')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 - 0s - loss: 1.1172 - accuracy: 0.5256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1172369718551636, 0.5256410241127014]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_all_3.evaluate(X_test,Y_test,verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
